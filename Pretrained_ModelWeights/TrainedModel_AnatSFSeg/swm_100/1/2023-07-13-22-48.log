2023-07-13 22:48:26,269 =======================================================
2023-07-13 22:48:26,270 Namespace(T_0=10, T_mult=2, best_metric='f1', decay_factor=0.5, epoch=800, eval_fold_zero=False, input_path='***', k_fold=5, lr=0.001, manualSeed=0, momentum=0, num_workers=4, opt='Adam', out_path='***', out_path_base='***', redistribute_class=True, scheduler='step', step_size=20, train_batch_size=2048, val_batch_size=1024, weight_decay=0.0)
2023-07-13 22:48:26,270 =======================================================
2023-07-13 22:48:26,270 Implement 1 fold experiment
2023-07-13 22:48:27,248 use [2, 3, 4, 5] fold as train data
2023-07-13 22:48:27,248 The size of feature for train is (160000, 15, 3)
2023-07-13 22:48:27,538 use 1 fold as validation data
2023-07-13 22:48:27,539 The size of feature for val is (40000, 15, 3)
2023-07-13 22:48:27,556 The training data size is:160000
2023-07-13 22:48:27,556 The validation data size is:40000
2023-07-13 22:48:27,556 The number of classes is:198
2023-07-13 22:48:27,575 The label names are: [b'cluster_00205', b'cluster_00222', b'cluster_00232', b'cluster_00246', b'cluster_00259', b'cluster_00261', b'cluster_00262', b'cluster_00267', b'cluster_00275', b'cluster_00276', b'cluster_00278', b'cluster_00287', b'cluster_00291', b'cluster_00293', b'cluster_00294', b'cluster_00296', b'cluster_00298', b'cluster_00299', b'cluster_00300', b'cluster_00303', b'cluster_00304', b'cluster_00319', b'cluster_00322', b'cluster_00333', b'cluster_00338', b'cluster_00340', b'cluster_00344', b'cluster_00346', b'cluster_00350', b'cluster_00352', b'cluster_00359', b'cluster_00360', b'cluster_00361', b'cluster_00365', b'cluster_00368', b'cluster_00373', b'cluster_00374', b'cluster_00375', b'cluster_00377', b'cluster_00380', b'cluster_00385', b'cluster_00388', b'cluster_00389', b'cluster_00390', b'cluster_00394', b'cluster_00400', b'cluster_00401', b'cluster_00405', b'cluster_00407', b'cluster_00408', b'cluster_00409', b'cluster_00412', b'cluster_00445', b'cluster_00473', b'cluster_00585', b'cluster_00589', b'cluster_00591', b'cluster_00593', b'cluster_00596', b'cluster_00603', b'cluster_00604', b'cluster_00607', b'cluster_00612', b'cluster_00616', b'cluster_00619', b'cluster_00629', b'cluster_00630', b'cluster_00635', b'cluster_00637', b'cluster_00639', b'cluster_00642', b'cluster_00645', b'cluster_00647', b'cluster_00652', b'cluster_00653', b'cluster_00656', b'cluster_00657', b'cluster_00661', b'cluster_00662', b'cluster_00667', b'cluster_00762', b'cluster_00201', b'cluster_00217', b'cluster_00239', b'cluster_00320', b'cluster_00391', b'cluster_00398', b'cluster_00415', b'cluster_00477', b'cluster_00478', b'cluster_00479', b'cluster_00078', b'cluster_00079', b'cluster_00083', b'cluster_00090', b'cluster_00094', b'cluster_00096', b'cluster_00101', b'cluster_00086', b'cluster_00095', b'cluster_00097', b'cluster_00106', b'cluster_00553', b'cluster_00554', b'cluster_00569', b'cluster_00015', b'cluster_00017', b'cluster_00018', b'cluster_00023', b'cluster_00025', b'cluster_00030', b'cluster_00035', b'cluster_00039', b'cluster_00042', b'cluster_00046', b'cluster_00055', b'cluster_00059', b'cluster_00061', b'cluster_00274', b'cluster_00308', b'cluster_00337', b'cluster_00362', b'cluster_00369', b'cluster_00392', b'cluster_00414', b'cluster_00419', b'cluster_00420', b'cluster_00421', b'cluster_00422', b'cluster_00427', b'cluster_00430', b'cluster_00431', b'cluster_00436', b'cluster_00439', b'cluster_00444', b'cluster_00447', b'cluster_00448', b'cluster_00450', b'cluster_00456', b'cluster_00458', b'cluster_00460', b'cluster_00463', b'cluster_00467', b'cluster_00483', b'cluster_00484', b'cluster_00007', b'cluster_00036', b'cluster_00054', b'cluster_00062', b'cluster_00064', b'cluster_00065', b'cluster_00067', b'cluster_00071', b'cluster_00075', b'cluster_00084', b'cluster_00093', b'cluster_00001', b'cluster_00002', b'cluster_00003', b'cluster_00006', b'cluster_00008', b'cluster_00010', b'cluster_00012', b'cluster_00019', b'cluster_00022', b'cluster_00026', b'cluster_00029', b'cluster_00031', b'cluster_00043', b'cluster_00051', b'cluster_00052', b'cluster_00073', b'cluster_00076', b'cluster_00082', b'cluster_00107', b'cluster_00432', b'cluster_00440', b'cluster_00455', b'cluster_00714', b'cluster_00791', b'cluster_00119', b'cluster_00121', b'cluster_00155', b'cluster_00556', b'cluster_00557', b'cluster_00689', b'cluster_00692', b'cluster_00718', b'cluster_00725', b'cluster_00727', b'cluster_00729', b'cluster_00733', b'cluster_00738', b'cluster_00740', b'cluster_00744', b'cluster_00753', b'cluster_00777', b'cluster_00795']
2023-07-13 22:49:00,098 epoch [1/800] time: 22.76s train loss: 2.4004 accuracy: 0.4788 f1: 0.4567
2023-07-13 22:49:01,209 epoch [1/800] time: 1.05s val loss: 1.2853 accuracy: 0.7202 f1: 0.7094
2023-07-13 22:49:06,310 epoch [2/800] time: 5.1s train loss: 0.833 accuracy: 0.7658 f1: 0.7599
2023-07-13 22:49:07,259 epoch [2/800] time: 0.94s val loss: 0.7107 accuracy: 0.7817 f1: 0.7786
2023-07-13 22:49:12,484 epoch [3/800] time: 5.22s train loss: 0.6036 accuracy: 0.8016 f1: 0.7983
2023-07-13 22:49:13,358 epoch [3/800] time: 0.87s val loss: 0.6044 accuracy: 0.7906 f1: 0.789
2023-07-13 22:49:18,645 epoch [4/800] time: 5.29s train loss: 0.5236 accuracy: 0.8179 f1: 0.8148
2023-07-13 22:49:19,543 epoch [4/800] time: 0.89s val loss: 0.4898 accuracy: 0.8278 f1: 0.8268
2023-07-13 22:49:24,700 epoch [5/800] time: 5.15s train loss: 0.4666 accuracy: 0.833 f1: 0.8303
2023-07-13 22:49:25,607 epoch [5/800] time: 0.9s val loss: 0.4871 accuracy: 0.821 f1: 0.8184
2023-07-13 22:49:30,642 epoch [6/800] time: 5.03s train loss: 0.4391 accuracy: 0.8407 f1: 0.8383
2023-07-13 22:49:31,535 epoch [6/800] time: 0.89s val loss: 0.6216 accuracy: 0.7832 f1: 0.7761
2023-07-13 22:49:36,514 epoch [7/800] time: 4.98s train loss: 0.4157 accuracy: 0.8481 f1: 0.846
2023-07-13 22:49:37,333 epoch [7/800] time: 0.81s val loss: 0.4275 accuracy: 0.8375 f1: 0.8384
2023-07-13 22:49:42,458 epoch [8/800] time: 5.12s train loss: 0.3938 accuracy: 0.8551 f1: 0.8528
2023-07-13 22:49:43,388 epoch [8/800] time: 0.92s val loss: 0.3855 accuracy: 0.8517 f1: 0.85
2023-07-13 22:49:48,361 epoch [9/800] time: 4.97s train loss: 0.3917 accuracy: 0.8548 f1: 0.8526
2023-07-13 22:49:49,224 epoch [9/800] time: 0.86s val loss: 0.4126 accuracy: 0.8408 f1: 0.8376
2023-07-13 22:49:54,124 epoch [10/800] time: 4.9s train loss: 0.3694 accuracy: 0.8623 f1: 0.8604
2023-07-13 22:49:55,006 epoch [10/800] time: 0.88s val loss: 0.4445 accuracy: 0.8344 f1: 0.8316
2023-07-13 22:50:00,080 epoch [11/800] time: 5.07s train loss: 0.3575 accuracy: 0.8654 f1: 0.864
2023-07-13 22:50:00,959 epoch [11/800] time: 0.87s val loss: 0.419 accuracy: 0.8413 f1: 0.8401
2023-07-13 22:50:05,773 epoch [12/800] time: 4.81s train loss: 0.348 accuracy: 0.8693 f1: 0.8675
2023-07-13 22:50:06,645 epoch [12/800] time: 0.86s val loss: 0.3487 accuracy: 0.8663 f1: 0.8659
2023-07-13 22:50:11,262 epoch [13/800] time: 4.62s train loss: 0.3243 accuracy: 0.8787 f1: 0.8772
2023-07-13 22:50:12,112 epoch [13/800] time: 0.84s val loss: 0.402 accuracy: 0.8468 f1: 0.8461
2023-07-13 22:50:16,740 epoch [14/800] time: 4.63s train loss: 0.3328 accuracy: 0.8752 f1: 0.8736
2023-07-13 22:50:17,608 epoch [14/800] time: 0.87s val loss: 0.3633 accuracy: 0.8603 f1: 0.8571
2023-07-13 22:50:22,313 epoch [15/800] time: 4.7s train loss: 0.3149 accuracy: 0.8808 f1: 0.8794
2023-07-13 22:50:23,169 epoch [15/800] time: 0.85s val loss: 0.4123 accuracy: 0.8448 f1: 0.8431
2023-07-13 22:50:27,822 epoch [16/800] time: 4.65s train loss: 0.3146 accuracy: 0.8798 f1: 0.8783
2023-07-13 22:50:28,691 epoch [16/800] time: 0.87s val loss: 0.4293 accuracy: 0.8366 f1: 0.8365
2023-07-13 22:50:33,607 epoch [17/800] time: 4.92s train loss: 0.309 accuracy: 0.8826 f1: 0.8807
2023-07-13 22:50:34,500 epoch [17/800] time: 0.89s val loss: 0.4016 accuracy: 0.8557 f1: 0.8555
2023-07-13 22:50:39,140 epoch [18/800] time: 4.64s train loss: 0.2945 accuracy: 0.8871 f1: 0.8855
2023-07-13 22:50:40,002 epoch [18/800] time: 0.86s val loss: 0.3941 accuracy: 0.8496 f1: 0.8483
2023-07-13 22:50:44,890 epoch [19/800] time: 4.89s train loss: 0.3161 accuracy: 0.8789 f1: 0.8774
2023-07-13 22:50:45,762 epoch [19/800] time: 0.87s val loss: 0.3439 accuracy: 0.8677 f1: 0.8656
2023-07-13 22:50:50,372 epoch [20/800] time: 4.61s train loss: 0.2977 accuracy: 0.8862 f1: 0.8849
2023-07-13 22:50:51,226 epoch [20/800] time: 0.85s val loss: 0.3219 accuracy: 0.8751 f1: 0.8733
2023-07-13 22:50:55,810 epoch [21/800] time: 4.58s train loss: 0.2454 accuracy: 0.9079 f1: 0.9066
2023-07-13 22:50:56,636 epoch [21/800] time: 0.82s val loss: 0.2392 accuracy: 0.9064 f1: 0.9053
2023-07-13 22:51:01,208 epoch [22/800] time: 4.57s train loss: 0.2318 accuracy: 0.9133 f1: 0.9123
2023-07-13 22:51:02,057 epoch [22/800] time: 0.84s val loss: 0.2474 accuracy: 0.9046 f1: 0.904
2023-07-13 22:51:07,066 epoch [23/800] time: 5.01s train loss: 0.2216 accuracy: 0.9162 f1: 0.9151
2023-07-13 22:51:08,040 epoch [23/800] time: 0.97s val loss: 0.2544 accuracy: 0.8999 f1: 0.8991
2023-07-13 22:51:13,185 epoch [24/800] time: 5.15s train loss: 0.2236 accuracy: 0.9161 f1: 0.9149
2023-07-13 22:51:13,998 epoch [24/800] time: 0.81s val loss: 0.2449 accuracy: 0.9071 f1: 0.9062
2023-07-13 22:51:18,918 epoch [25/800] time: 4.92s train loss: 0.2217 accuracy: 0.9167 f1: 0.9157
2023-07-13 22:51:19,925 epoch [25/800] time: 1.0s val loss: 0.2643 accuracy: 0.8972 f1: 0.8961
2023-07-13 22:51:25,151 epoch [26/800] time: 5.23s train loss: 0.2235 accuracy: 0.9151 f1: 0.9137
2023-07-13 22:51:26,052 epoch [26/800] time: 0.9s val loss: 0.2402 accuracy: 0.9064 f1: 0.9054
2023-07-13 22:51:31,079 epoch [27/800] time: 5.03s train loss: 0.217 accuracy: 0.9177 f1: 0.9168
2023-07-13 22:51:31,931 epoch [27/800] time: 0.85s val loss: 0.2644 accuracy: 0.8969 f1: 0.8961
2023-07-13 22:51:37,528 epoch [28/800] time: 5.6s train loss: 0.2145 accuracy: 0.9195 f1: 0.9185
2023-07-13 22:51:38,475 epoch [28/800] time: 0.94s val loss: 0.2408 accuracy: 0.9058 f1: 0.9045
2023-07-13 22:51:43,583 epoch [29/800] time: 5.11s train loss: 0.2163 accuracy: 0.9182 f1: 0.9171
2023-07-13 22:51:44,443 epoch [29/800] time: 0.86s val loss: 0.2977 accuracy: 0.8864 f1: 0.8851
2023-07-13 22:51:49,238 epoch [30/800] time: 4.79s train loss: 0.2183 accuracy: 0.9165 f1: 0.9155
2023-07-13 22:51:50,053 epoch [30/800] time: 0.81s val loss: 0.2482 accuracy: 0.9045 f1: 0.903
2023-07-13 22:51:54,875 epoch [31/800] time: 4.82s train loss: 0.2138 accuracy: 0.9192 f1: 0.9183
2023-07-13 22:51:55,737 epoch [31/800] time: 0.86s val loss: 0.2857 accuracy: 0.8897 f1: 0.8888
2023-07-13 22:52:00,583 epoch [32/800] time: 4.85s train loss: 0.2094 accuracy: 0.9209 f1: 0.92
2023-07-13 22:52:01,469 epoch [32/800] time: 0.88s val loss: 0.2404 accuracy: 0.9071 f1: 0.9064
2023-07-13 22:52:07,075 epoch [33/800] time: 5.61s train loss: 0.2047 accuracy: 0.9219 f1: 0.9208
2023-07-13 22:52:07,917 epoch [33/800] time: 0.83s val loss: 0.253 accuracy: 0.9009 f1: 0.8997
2023-07-13 22:52:12,914 epoch [34/800] time: 5.0s train loss: 0.2019 accuracy: 0.9237 f1: 0.9229
2023-07-13 22:52:13,855 epoch [34/800] time: 0.93s val loss: 0.2467 accuracy: 0.9067 f1: 0.9058
2023-07-13 22:52:19,567 epoch [35/800] time: 5.71s train loss: 0.1981 accuracy: 0.9247 f1: 0.924
2023-07-13 22:52:20,459 epoch [35/800] time: 0.88s val loss: 0.2508 accuracy: 0.9048 f1: 0.9034
2023-07-13 22:52:25,735 epoch [36/800] time: 5.28s train loss: 0.2013 accuracy: 0.9235 f1: 0.9225
2023-07-13 22:52:26,602 epoch [36/800] time: 0.87s val loss: 0.3277 accuracy: 0.8841 f1: 0.8827
2023-07-13 22:52:31,826 epoch [37/800] time: 5.22s train loss: 0.2028 accuracy: 0.9225 f1: 0.9216
2023-07-13 22:52:32,729 epoch [37/800] time: 0.9s val loss: 0.2268 accuracy: 0.9122 f1: 0.9109
2023-07-13 22:52:37,951 epoch [38/800] time: 5.22s train loss: 0.2008 accuracy: 0.924 f1: 0.9233
2023-07-13 22:52:38,917 epoch [38/800] time: 0.97s val loss: 0.2733 accuracy: 0.8975 f1: 0.8959
2023-07-13 22:52:44,062 epoch [39/800] time: 5.14s train loss: 0.2017 accuracy: 0.9238 f1: 0.9229
2023-07-13 22:52:44,942 epoch [39/800] time: 0.88s val loss: 0.2339 accuracy: 0.9103 f1: 0.9085
2023-07-13 22:52:50,218 epoch [40/800] time: 5.28s train loss: 0.1941 accuracy: 0.9264 f1: 0.9256
2023-07-13 22:52:51,113 epoch [40/800] time: 0.89s val loss: 0.2289 accuracy: 0.9135 f1: 0.9126
2023-07-13 22:52:55,696 epoch [41/800] time: 4.58s train loss: 0.1608 accuracy: 0.9411 f1: 0.9404
2023-07-13 22:52:56,558 epoch [41/800] time: 0.86s val loss: 0.2085 accuracy: 0.9201 f1: 0.9196
2023-07-13 22:53:01,592 epoch [42/800] time: 5.03s train loss: 0.155 accuracy: 0.9433 f1: 0.9426
2023-07-13 22:53:02,473 epoch [42/800] time: 0.88s val loss: 0.1991 accuracy: 0.9235 f1: 0.9231
2023-07-13 22:53:07,746 epoch [43/800] time: 5.27s train loss: 0.1529 accuracy: 0.9452 f1: 0.9445
2023-07-13 22:53:08,657 epoch [43/800] time: 0.9s val loss: 0.1936 accuracy: 0.9237 f1: 0.9227
2023-07-13 22:53:13,791 epoch [44/800] time: 5.13s train loss: 0.1521 accuracy: 0.9444 f1: 0.9436
2023-07-13 22:53:14,748 epoch [44/800] time: 0.96s val loss: 0.1906 accuracy: 0.9266 f1: 0.9251
2023-07-13 22:53:20,242 epoch [45/800] time: 5.49s train loss: 0.1485 accuracy: 0.9457 f1: 0.9451
2023-07-13 22:53:21,149 epoch [45/800] time: 0.9s val loss: 0.1921 accuracy: 0.9267 f1: 0.9261
2023-07-13 22:53:26,491 epoch [46/800] time: 5.34s train loss: 0.147 accuracy: 0.9463 f1: 0.9458
2023-07-13 22:53:27,475 epoch [46/800] time: 0.98s val loss: 0.2037 accuracy: 0.9234 f1: 0.9229
2023-07-13 22:53:32,898 epoch [47/800] time: 5.42s train loss: 0.1475 accuracy: 0.9451 f1: 0.9445
2023-07-13 22:53:33,851 epoch [47/800] time: 0.95s val loss: 0.2066 accuracy: 0.9196 f1: 0.9188
2023-07-13 22:53:38,980 epoch [48/800] time: 5.13s train loss: 0.1482 accuracy: 0.9454 f1: 0.9449
2023-07-13 22:53:39,854 epoch [48/800] time: 0.87s val loss: 0.2064 accuracy: 0.9202 f1: 0.9186
2023-07-13 22:53:44,952 epoch [49/800] time: 5.1s train loss: 0.1464 accuracy: 0.9467 f1: 0.9462
2023-07-13 22:53:45,856 epoch [49/800] time: 0.9s val loss: 0.1969 accuracy: 0.9245 f1: 0.9233
2023-07-13 22:53:50,608 epoch [50/800] time: 4.75s train loss: 0.146 accuracy: 0.9462 f1: 0.9456
2023-07-13 22:53:51,511 epoch [50/800] time: 0.9s val loss: 0.2034 accuracy: 0.9232 f1: 0.9229
2023-07-13 22:53:56,551 epoch [51/800] time: 5.04s train loss: 0.142 accuracy: 0.9477 f1: 0.947
2023-07-13 22:53:57,395 epoch [51/800] time: 0.84s val loss: 0.204 accuracy: 0.9216 f1: 0.9209
2023-07-13 22:54:02,273 epoch [52/800] time: 4.88s train loss: 0.1447 accuracy: 0.9466 f1: 0.9463
2023-07-13 22:54:03,130 epoch [52/800] time: 0.86s val loss: 0.2005 accuracy: 0.9246 f1: 0.9241
2023-07-13 22:54:07,849 epoch [53/800] time: 4.72s train loss: 0.1425 accuracy: 0.9478 f1: 0.9474
2023-07-13 22:54:08,732 epoch [53/800] time: 0.88s val loss: 0.1924 accuracy: 0.9279 f1: 0.9271
2023-07-13 22:54:13,509 epoch [54/800] time: 4.78s train loss: 0.1385 accuracy: 0.9491 f1: 0.9486
2023-07-13 22:54:14,316 epoch [54/800] time: 0.8s val loss: 0.196 accuracy: 0.9264 f1: 0.9253
2023-07-13 22:54:19,050 epoch [55/800] time: 4.73s train loss: 0.1389 accuracy: 0.9488 f1: 0.9483
2023-07-13 22:54:19,893 epoch [55/800] time: 0.84s val loss: 0.2188 accuracy: 0.9185 f1: 0.9183
2023-07-13 22:54:24,636 epoch [56/800] time: 4.74s train loss: 0.1376 accuracy: 0.9507 f1: 0.9503
2023-07-13 22:54:25,476 epoch [56/800] time: 0.83s val loss: 0.1994 accuracy: 0.9228 f1: 0.9215
2023-07-13 22:54:30,825 epoch [57/800] time: 5.35s train loss: 0.1394 accuracy: 0.9488 f1: 0.948
2023-07-13 22:54:31,679 epoch [57/800] time: 0.85s val loss: 0.2095 accuracy: 0.9224 f1: 0.9217
2023-07-13 22:54:37,073 epoch [58/800] time: 5.39s train loss: 0.1418 accuracy: 0.9478 f1: 0.9472
2023-07-13 22:54:38,028 epoch [58/800] time: 0.95s val loss: 0.1887 accuracy: 0.9288 f1: 0.928
2023-07-13 22:54:43,237 epoch [59/800] time: 5.21s train loss: 0.131 accuracy: 0.9519 f1: 0.9514
2023-07-13 22:54:44,148 epoch [59/800] time: 0.9s val loss: 0.1946 accuracy: 0.9268 f1: 0.9265
2023-07-13 22:54:49,456 epoch [60/800] time: 5.31s train loss: 0.1341 accuracy: 0.9508 f1: 0.9504
2023-07-13 22:54:50,313 epoch [60/800] time: 0.86s val loss: 0.1965 accuracy: 0.9251 f1: 0.9241
2023-07-13 22:54:55,593 epoch [61/800] time: 5.28s train loss: 0.1149 accuracy: 0.96 f1: 0.9596
2023-07-13 22:54:56,502 epoch [61/800] time: 0.9s val loss: 0.1714 accuracy: 0.9365 f1: 0.936
2023-07-13 22:55:01,349 epoch [62/800] time: 4.85s train loss: 0.1103 accuracy: 0.9618 f1: 0.9615
2023-07-13 22:55:02,243 epoch [62/800] time: 0.89s val loss: 0.1649 accuracy: 0.9391 f1: 0.9383
2023-07-13 22:55:06,947 epoch [63/800] time: 4.7s train loss: 0.1102 accuracy: 0.9621 f1: 0.9618
2023-07-13 22:55:07,766 epoch [63/800] time: 0.81s val loss: 0.174 accuracy: 0.9355 f1: 0.9344
2023-07-13 22:55:12,389 epoch [64/800] time: 4.62s train loss: 0.1082 accuracy: 0.9639 f1: 0.9633
2023-07-13 22:55:13,236 epoch [64/800] time: 0.84s val loss: 0.1692 accuracy: 0.9369 f1: 0.9362
2023-07-13 22:55:18,702 epoch [65/800] time: 5.47s train loss: 0.1125 accuracy: 0.9608 f1: 0.9604
2023-07-13 22:55:19,680 epoch [65/800] time: 0.98s val loss: 0.1675 accuracy: 0.9385 f1: 0.9378
2023-07-13 22:55:25,174 epoch [66/800] time: 5.49s train loss: 0.1051 accuracy: 0.9641 f1: 0.9638
2023-07-13 22:55:26,044 epoch [66/800] time: 0.86s val loss: 0.1654 accuracy: 0.9385 f1: 0.938
2023-07-13 22:55:31,388 epoch [67/800] time: 5.34s train loss: 0.1044 accuracy: 0.9648 f1: 0.9646
2023-07-13 22:55:32,378 epoch [67/800] time: 0.98s val loss: 0.1866 accuracy: 0.931 f1: 0.9306
2023-07-13 22:55:37,688 epoch [68/800] time: 5.31s train loss: 0.1047 accuracy: 0.9639 f1: 0.9636
2023-07-13 22:55:38,606 epoch [68/800] time: 0.92s val loss: 0.1729 accuracy: 0.9362 f1: 0.9359
2023-07-13 22:55:43,719 epoch [69/800] time: 5.11s train loss: 0.1036 accuracy: 0.9641 f1: 0.9637
2023-07-13 22:55:44,572 epoch [69/800] time: 0.85s val loss: 0.1706 accuracy: 0.9371 f1: 0.9363
2023-07-13 22:55:49,788 epoch [70/800] time: 5.22s train loss: 0.1036 accuracy: 0.9646 f1: 0.9643
2023-07-13 22:55:50,758 epoch [70/800] time: 0.97s val loss: 0.1655 accuracy: 0.9395 f1: 0.9389
2023-07-13 22:55:56,021 epoch [71/800] time: 5.26s train loss: 0.1048 accuracy: 0.9643 f1: 0.964
2023-07-13 22:55:56,985 epoch [71/800] time: 0.96s val loss: 0.1828 accuracy: 0.9321 f1: 0.9312
2023-07-13 22:56:02,520 epoch [72/800] time: 5.53s train loss: 0.1028 accuracy: 0.9649 f1: 0.9648
2023-07-13 22:56:03,412 epoch [72/800] time: 0.88s val loss: 0.1699 accuracy: 0.9367 f1: 0.9359
2023-07-13 22:56:08,698 epoch [73/800] time: 5.29s train loss: 0.1052 accuracy: 0.9633 f1: 0.9629
2023-07-13 22:56:09,625 epoch [73/800] time: 0.93s val loss: 0.1683 accuracy: 0.9381 f1: 0.9374
2023-07-13 22:56:15,422 epoch [74/800] time: 5.8s train loss: 0.1048 accuracy: 0.9637 f1: 0.9633
2023-07-13 22:56:16,430 epoch [74/800] time: 1.01s val loss: 0.1781 accuracy: 0.9348 f1: 0.9334
2023-07-13 22:56:21,575 epoch [75/800] time: 5.14s train loss: 0.1037 accuracy: 0.9641 f1: 0.9638
2023-07-13 22:56:22,415 epoch [75/800] time: 0.84s val loss: 0.1664 accuracy: 0.9396 f1: 0.9386
2023-07-13 22:56:27,698 epoch [76/800] time: 5.28s train loss: 0.1026 accuracy: 0.9639 f1: 0.9637
2023-07-13 22:56:28,708 epoch [76/800] time: 1.01s val loss: 0.1671 accuracy: 0.9382 f1: 0.9378
2023-07-13 22:56:33,887 epoch [77/800] time: 5.18s train loss: 0.0991 accuracy: 0.9654 f1: 0.9654
2023-07-13 22:56:34,764 epoch [77/800] time: 0.87s val loss: 0.1767 accuracy: 0.9351 f1: 0.9349
2023-07-13 22:56:39,906 epoch [78/800] time: 5.14s train loss: 0.0979 accuracy: 0.9665 f1: 0.9662
2023-07-13 22:56:40,856 epoch [78/800] time: 0.94s val loss: 0.1635 accuracy: 0.9415 f1: 0.9409
2023-07-13 22:56:46,475 epoch [79/800] time: 5.62s train loss: 0.0977 accuracy: 0.9661 f1: 0.9659
2023-07-13 22:56:47,383 epoch [79/800] time: 0.91s val loss: 0.1683 accuracy: 0.9389 f1: 0.938
2023-07-13 22:56:52,310 epoch [80/800] time: 4.93s train loss: 0.0965 accuracy: 0.9671 f1: 0.9667
2023-07-13 22:56:53,217 epoch [80/800] time: 0.9s val loss: 0.1748 accuracy: 0.9354 f1: 0.9346
2023-07-13 22:56:58,555 epoch [81/800] time: 5.34s train loss: 0.0894 accuracy: 0.97 f1: 0.9699
2023-07-13 22:56:59,451 epoch [81/800] time: 0.89s val loss: 0.1564 accuracy: 0.9439 f1: 0.9432
2023-07-13 22:57:04,494 epoch [82/800] time: 5.04s train loss: 0.0846 accuracy: 0.9728 f1: 0.9727
2023-07-13 22:57:05,422 epoch [82/800] time: 0.92s val loss: 0.1553 accuracy: 0.9443 f1: 0.9435
2023-07-13 22:57:10,801 epoch [83/800] time: 5.38s train loss: 0.0865 accuracy: 0.9717 f1: 0.9715
2023-07-13 22:57:11,784 epoch [83/800] time: 0.98s val loss: 0.1563 accuracy: 0.9438 f1: 0.9431
2023-07-13 22:57:16,759 epoch [84/800] time: 4.97s train loss: 0.0846 accuracy: 0.9723 f1: 0.9721
2023-07-13 22:57:17,572 epoch [84/800] time: 0.81s val loss: 0.1539 accuracy: 0.9435 f1: 0.9429
2023-07-13 22:57:22,401 epoch [85/800] time: 4.83s train loss: 0.0832 accuracy: 0.9734 f1: 0.9732
2023-07-13 22:57:23,304 epoch [85/800] time: 0.9s val loss: 0.1577 accuracy: 0.943 f1: 0.9426
2023-07-13 22:57:28,416 epoch [86/800] time: 5.11s train loss: 0.083 accuracy: 0.9728 f1: 0.9726
2023-07-13 22:57:29,323 epoch [86/800] time: 0.91s val loss: 0.1538 accuracy: 0.9447 f1: 0.944
2023-07-13 22:57:34,232 epoch [87/800] time: 4.91s train loss: 0.0828 accuracy: 0.9735 f1: 0.9733
2023-07-13 22:57:35,082 epoch [87/800] time: 0.84s val loss: 0.1575 accuracy: 0.9431 f1: 0.9425
2023-07-13 22:57:40,181 epoch [88/800] time: 5.1s train loss: 0.0845 accuracy: 0.9728 f1: 0.9726
2023-07-13 22:57:41,061 epoch [88/800] time: 0.88s val loss: 0.1557 accuracy: 0.9447 f1: 0.9439
2023-07-13 22:57:45,748 epoch [89/800] time: 4.69s train loss: 0.083 accuracy: 0.9729 f1: 0.9728
2023-07-13 22:57:46,609 epoch [89/800] time: 0.86s val loss: 0.1549 accuracy: 0.9442 f1: 0.9436
2023-07-13 22:57:51,220 epoch [90/800] time: 4.61s train loss: 0.0824 accuracy: 0.9737 f1: 0.9735
2023-07-13 22:57:52,049 epoch [90/800] time: 0.82s val loss: 0.155 accuracy: 0.9447 f1: 0.9444
2023-07-13 22:57:56,897 epoch [91/800] time: 4.85s train loss: 0.0822 accuracy: 0.9739 f1: 0.9737
2023-07-13 22:57:57,773 epoch [91/800] time: 0.87s val loss: 0.1565 accuracy: 0.9438 f1: 0.9433
2023-07-13 22:58:02,410 epoch [92/800] time: 4.64s train loss: 0.0817 accuracy: 0.9735 f1: 0.9733
2023-07-13 22:58:03,275 epoch [92/800] time: 0.86s val loss: 0.1624 accuracy: 0.9422 f1: 0.9413
2023-07-13 22:58:08,227 epoch [93/800] time: 4.95s train loss: 0.082 accuracy: 0.9735 f1: 0.9732
2023-07-13 22:58:09,061 epoch [93/800] time: 0.83s val loss: 0.1578 accuracy: 0.9425 f1: 0.9417
2023-07-13 22:58:13,922 epoch [94/800] time: 4.86s train loss: 0.081 accuracy: 0.9738 f1: 0.9736
2023-07-13 22:58:14,773 epoch [94/800] time: 0.85s val loss: 0.1523 accuracy: 0.9455 f1: 0.945
2023-07-13 22:58:19,547 epoch [95/800] time: 4.77s train loss: 0.0794 accuracy: 0.9747 f1: 0.9745
2023-07-13 22:58:20,434 epoch [95/800] time: 0.88s val loss: 0.159 accuracy: 0.9442 f1: 0.9434
2023-07-13 22:58:25,647 epoch [96/800] time: 5.21s train loss: 0.0784 accuracy: 0.9747 f1: 0.9746
2023-07-13 22:58:26,616 epoch [96/800] time: 0.97s val loss: 0.1563 accuracy: 0.9449 f1: 0.9442
2023-07-13 22:58:31,919 epoch [97/800] time: 5.3s train loss: 0.0797 accuracy: 0.9747 f1: 0.9745
2023-07-13 22:58:32,791 epoch [97/800] time: 0.87s val loss: 0.1563 accuracy: 0.9443 f1: 0.9438
2023-07-13 22:58:37,695 epoch [98/800] time: 4.9s train loss: 0.0802 accuracy: 0.9743 f1: 0.9741
2023-07-13 22:58:38,679 epoch [98/800] time: 0.98s val loss: 0.1537 accuracy: 0.9461 f1: 0.9454
2023-07-13 22:58:44,020 epoch [99/800] time: 5.34s train loss: 0.0816 accuracy: 0.9727 f1: 0.9725
2023-07-13 22:58:44,904 epoch [99/800] time: 0.88s val loss: 0.1636 accuracy: 0.9424 f1: 0.9417
2023-07-13 22:58:49,990 epoch [100/800] time: 5.09s train loss: 0.0774 accuracy: 0.9749 f1: 0.9748
2023-07-13 22:58:50,861 epoch [100/800] time: 0.86s val loss: 0.1583 accuracy: 0.9432 f1: 0.9426
2023-07-13 22:58:56,142 epoch [101/800] time: 5.28s train loss: 0.0738 accuracy: 0.9766 f1: 0.9765
2023-07-13 22:58:57,118 epoch [101/800] time: 0.97s val loss: 0.1492 accuracy: 0.9476 f1: 0.9468
2023-07-13 22:59:02,436 epoch [102/800] time: 5.32s train loss: 0.0709 accuracy: 0.9785 f1: 0.9784
2023-07-13 22:59:03,276 epoch [102/800] time: 0.83s val loss: 0.1483 accuracy: 0.9476 f1: 0.9469
2023-07-13 22:59:08,639 epoch [103/800] time: 5.36s train loss: 0.0726 accuracy: 0.9779 f1: 0.9776
2023-07-13 22:59:09,629 epoch [103/800] time: 0.99s val loss: 0.1484 accuracy: 0.947 f1: 0.9463
2023-07-13 22:59:14,997 epoch [104/800] time: 5.37s train loss: 0.0726 accuracy: 0.9772 f1: 0.977
2023-07-13 22:59:15,930 epoch [104/800] time: 0.93s val loss: 0.1532 accuracy: 0.9465 f1: 0.9458
2023-07-13 22:59:21,001 epoch [105/800] time: 5.07s train loss: 0.074 accuracy: 0.978 f1: 0.978
2023-07-13 22:59:21,907 epoch [105/800] time: 0.91s val loss: 0.1513 accuracy: 0.947 f1: 0.9466
2023-07-13 22:59:27,377 epoch [106/800] time: 5.47s train loss: 0.0719 accuracy: 0.9783 f1: 0.9781
2023-07-13 22:59:28,363 epoch [106/800] time: 0.99s val loss: 0.1493 accuracy: 0.9477 f1: 0.9471
2023-07-13 22:59:33,480 epoch [107/800] time: 5.12s train loss: 0.0732 accuracy: 0.9773 f1: 0.9772
2023-07-13 22:59:34,396 epoch [107/800] time: 0.92s val loss: 0.1497 accuracy: 0.9482 f1: 0.9475
2023-07-13 22:59:39,867 epoch [108/800] time: 5.47s train loss: 0.0713 accuracy: 0.9781 f1: 0.9779
2023-07-13 22:59:40,782 epoch [108/800] time: 0.92s val loss: 0.1502 accuracy: 0.9479 f1: 0.9472
2023-07-13 22:59:46,047 epoch [109/800] time: 5.26s train loss: 0.0698 accuracy: 0.9789 f1: 0.9787
2023-07-13 22:59:46,960 epoch [109/800] time: 0.91s val loss: 0.147 accuracy: 0.9485 f1: 0.948
2023-07-13 22:59:52,068 epoch [110/800] time: 5.11s train loss: 0.0726 accuracy: 0.9777 f1: 0.9775
2023-07-13 22:59:53,066 epoch [110/800] time: 1.0s val loss: 0.1505 accuracy: 0.9475 f1: 0.9468
2023-07-13 22:59:58,623 epoch [111/800] time: 5.56s train loss: 0.0714 accuracy: 0.9777 f1: 0.9776
2023-07-13 22:59:59,492 epoch [111/800] time: 0.87s val loss: 0.1495 accuracy: 0.9485 f1: 0.9477
2023-07-13 23:00:06,085 epoch [112/800] time: 6.59s train loss: 0.0692 accuracy: 0.9793 f1: 0.9791
2023-07-13 23:00:07,406 epoch [112/800] time: 1.31s val loss: 0.1491 accuracy: 0.9483 f1: 0.9477
2023-07-13 23:00:13,975 epoch [113/800] time: 6.57s train loss: 0.0702 accuracy: 0.9786 f1: 0.9786
2023-07-13 23:00:14,965 epoch [113/800] time: 0.99s val loss: 0.149 accuracy: 0.9486 f1: 0.948
2023-07-13 23:00:20,258 epoch [114/800] time: 5.29s train loss: 0.0702 accuracy: 0.979 f1: 0.979
2023-07-13 23:00:21,083 epoch [114/800] time: 0.82s val loss: 0.1494 accuracy: 0.9473 f1: 0.9465
2023-07-13 23:00:26,069 epoch [115/800] time: 4.99s train loss: 0.0693 accuracy: 0.9792 f1: 0.979
2023-07-13 23:00:26,961 epoch [115/800] time: 0.89s val loss: 0.1481 accuracy: 0.948 f1: 0.9475
2023-07-13 23:00:31,825 epoch [116/800] time: 4.86s train loss: 0.0671 accuracy: 0.9797 f1: 0.9796
2023-07-13 23:00:32,688 epoch [116/800] time: 0.86s val loss: 0.1491 accuracy: 0.948 f1: 0.9474
2023-07-13 23:00:37,431 epoch [117/800] time: 4.74s train loss: 0.0695 accuracy: 0.9791 f1: 0.9789
2023-07-13 23:00:38,234 epoch [117/800] time: 0.8s val loss: 0.1506 accuracy: 0.9484 f1: 0.9477
2023-07-13 23:00:43,004 epoch [118/800] time: 4.77s train loss: 0.0683 accuracy: 0.9789 f1: 0.9789
2023-07-13 23:00:43,878 epoch [118/800] time: 0.87s val loss: 0.1493 accuracy: 0.9482 f1: 0.9475
2023-07-13 23:00:48,617 epoch [119/800] time: 4.74s train loss: 0.069 accuracy: 0.979 f1: 0.9789
2023-07-13 23:00:49,482 epoch [119/800] time: 0.86s val loss: 0.1491 accuracy: 0.9486 f1: 0.948
2023-07-13 23:00:54,199 epoch [120/800] time: 4.72s train loss: 0.0693 accuracy: 0.9789 f1: 0.9788
2023-07-13 23:00:55,038 epoch [120/800] time: 0.84s val loss: 0.1488 accuracy: 0.9485 f1: 0.9478
2023-07-13 23:00:59,881 epoch [121/800] time: 4.84s train loss: 0.0661 accuracy: 0.9806 f1: 0.9805
2023-07-13 23:01:00,771 epoch [121/800] time: 0.88s val loss: 0.1495 accuracy: 0.9483 f1: 0.9475
2023-07-13 23:01:05,569 epoch [122/800] time: 4.8s train loss: 0.0656 accuracy: 0.9804 f1: 0.9803
2023-07-13 23:01:06,432 epoch [122/800] time: 0.86s val loss: 0.1469 accuracy: 0.9491 f1: 0.9485
2023-07-13 23:01:11,138 epoch [123/800] time: 4.71s train loss: 0.0648 accuracy: 0.9811 f1: 0.9811
2023-07-13 23:01:11,964 epoch [123/800] time: 0.82s val loss: 0.147 accuracy: 0.9494 f1: 0.9487
2023-07-13 23:01:17,678 epoch [124/800] time: 5.71s train loss: 0.0641 accuracy: 0.9815 f1: 0.9814
2023-07-13 23:01:18,692 epoch [124/800] time: 1.01s val loss: 0.1476 accuracy: 0.9489 f1: 0.9482
2023-07-13 23:01:23,894 epoch [125/800] time: 5.2s train loss: 0.0647 accuracy: 0.9809 f1: 0.9808
2023-07-13 23:01:24,813 epoch [125/800] time: 0.92s val loss: 0.1489 accuracy: 0.9483 f1: 0.9476
2023-07-13 23:01:30,220 epoch [126/800] time: 5.41s train loss: 0.0638 accuracy: 0.9817 f1: 0.9816
2023-07-13 23:01:31,080 epoch [126/800] time: 0.85s val loss: 0.1483 accuracy: 0.9491 f1: 0.9484
2023-07-13 23:01:36,256 epoch [127/800] time: 5.18s train loss: 0.0654 accuracy: 0.9807 f1: 0.9805
2023-07-13 23:01:37,156 epoch [127/800] time: 0.9s val loss: 0.1479 accuracy: 0.9493 f1: 0.9486
2023-07-13 23:01:42,152 epoch [128/800] time: 5.0s train loss: 0.0663 accuracy: 0.9804 f1: 0.9803
2023-07-13 23:01:43,063 epoch [128/800] time: 0.91s val loss: 0.1478 accuracy: 0.9498 f1: 0.9491
2023-07-13 23:01:48,196 epoch [129/800] time: 5.13s train loss: 0.0631 accuracy: 0.9812 f1: 0.981
2023-07-13 23:01:49,031 epoch [129/800] time: 0.83s val loss: 0.146 accuracy: 0.9498 f1: 0.9491
2023-07-13 23:01:53,898 epoch [130/800] time: 4.87s train loss: 0.0659 accuracy: 0.9806 f1: 0.9806
2023-07-13 23:01:54,741 epoch [130/800] time: 0.84s val loss: 0.1461 accuracy: 0.9499 f1: 0.9492
2023-07-13 23:01:59,497 epoch [131/800] time: 4.76s train loss: 0.064 accuracy: 0.9812 f1: 0.9811
2023-07-13 23:02:00,363 epoch [131/800] time: 0.87s val loss: 0.1468 accuracy: 0.9496 f1: 0.949
2023-07-13 23:02:05,123 epoch [132/800] time: 4.76s train loss: 0.064 accuracy: 0.9812 f1: 0.9813
2023-07-13 23:02:05,944 epoch [132/800] time: 0.82s val loss: 0.1474 accuracy: 0.9493 f1: 0.9487
2023-07-13 23:02:11,319 epoch [133/800] time: 5.38s train loss: 0.0633 accuracy: 0.9819 f1: 0.9817
2023-07-13 23:02:12,283 epoch [133/800] time: 0.96s val loss: 0.1461 accuracy: 0.95 f1: 0.9493
2023-07-13 23:02:17,293 epoch [134/800] time: 5.01s train loss: 0.0636 accuracy: 0.9814 f1: 0.9812
2023-07-13 23:02:18,167 epoch [134/800] time: 0.87s val loss: 0.1484 accuracy: 0.9487 f1: 0.9481
2023-07-13 23:02:23,394 epoch [135/800] time: 5.23s train loss: 0.0647 accuracy: 0.9813 f1: 0.9811
2023-07-13 23:02:24,233 epoch [135/800] time: 0.84s val loss: 0.1474 accuracy: 0.9502 f1: 0.9497
2023-07-13 23:02:29,435 epoch [136/800] time: 5.2s train loss: 0.0642 accuracy: 0.9809 f1: 0.9808
2023-07-13 23:02:30,376 epoch [136/800] time: 0.94s val loss: 0.1468 accuracy: 0.9501 f1: 0.9495
2023-07-13 23:02:35,387 epoch [137/800] time: 5.01s train loss: 0.0624 accuracy: 0.9817 f1: 0.9816
2023-07-13 23:02:36,248 epoch [137/800] time: 0.86s val loss: 0.1472 accuracy: 0.9488 f1: 0.9481
2023-07-13 23:02:41,317 epoch [138/800] time: 5.07s train loss: 0.0646 accuracy: 0.9811 f1: 0.9809
2023-07-13 23:02:42,204 epoch [138/800] time: 0.89s val loss: 0.1476 accuracy: 0.9493 f1: 0.9487
2023-07-13 23:02:47,568 epoch [139/800] time: 5.36s train loss: 0.0653 accuracy: 0.9812 f1: 0.9812
2023-07-13 23:02:48,513 epoch [139/800] time: 0.94s val loss: 0.1467 accuracy: 0.95 f1: 0.9494
2023-07-13 23:02:53,944 epoch [140/800] time: 5.43s train loss: 0.0647 accuracy: 0.9811 f1: 0.981
2023-07-13 23:02:54,985 epoch [140/800] time: 1.04s val loss: 0.1473 accuracy: 0.9495 f1: 0.9488
2023-07-13 23:03:00,642 epoch [141/800] time: 5.66s train loss: 0.0625 accuracy: 0.9819 f1: 0.9818
2023-07-13 23:03:01,538 epoch [141/800] time: 0.89s val loss: 0.1476 accuracy: 0.95 f1: 0.9493
2023-07-13 23:03:06,999 epoch [142/800] time: 5.46s train loss: 0.0607 accuracy: 0.9825 f1: 0.9824
2023-07-13 23:03:07,973 epoch [142/800] time: 0.97s val loss: 0.1466 accuracy: 0.95 f1: 0.9494
2023-07-13 23:03:13,238 epoch [143/800] time: 5.26s train loss: 0.0616 accuracy: 0.9828 f1: 0.9828
2023-07-13 23:03:14,197 epoch [143/800] time: 0.95s val loss: 0.1465 accuracy: 0.9497 f1: 0.9491
2023-07-13 23:03:19,231 epoch [144/800] time: 5.03s train loss: 0.0628 accuracy: 0.9822 f1: 0.9821
2023-07-13 23:03:20,074 epoch [144/800] time: 0.84s val loss: 0.1481 accuracy: 0.9488 f1: 0.9482
2023-07-13 23:03:25,547 epoch [145/800] time: 5.47s train loss: 0.0617 accuracy: 0.9823 f1: 0.9822
2023-07-13 23:03:26,643 epoch [145/800] time: 1.1s val loss: 0.1456 accuracy: 0.951 f1: 0.9503
2023-07-13 23:03:32,360 epoch [146/800] time: 5.72s train loss: 0.0614 accuracy: 0.9823 f1: 0.9821
2023-07-13 23:03:33,232 epoch [146/800] time: 0.87s val loss: 0.146 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:03:38,079 epoch [147/800] time: 4.85s train loss: 0.0615 accuracy: 0.9826 f1: 0.9824
2023-07-13 23:03:38,887 epoch [147/800] time: 0.81s val loss: 0.1453 accuracy: 0.9512 f1: 0.9505
2023-07-13 23:03:43,700 epoch [148/800] time: 4.81s train loss: 0.0604 accuracy: 0.9829 f1: 0.9827
2023-07-13 23:03:44,577 epoch [148/800] time: 0.87s val loss: 0.1463 accuracy: 0.95 f1: 0.9494
2023-07-13 23:03:49,354 epoch [149/800] time: 4.78s train loss: 0.0627 accuracy: 0.9816 f1: 0.9816
2023-07-13 23:03:50,233 epoch [149/800] time: 0.88s val loss: 0.1471 accuracy: 0.9499 f1: 0.9493
2023-07-13 23:03:55,045 epoch [150/800] time: 4.81s train loss: 0.0627 accuracy: 0.9822 f1: 0.9821
2023-07-13 23:03:55,886 epoch [150/800] time: 0.84s val loss: 0.1463 accuracy: 0.9498 f1: 0.9492
2023-07-13 23:04:00,713 epoch [151/800] time: 4.83s train loss: 0.0605 accuracy: 0.9827 f1: 0.9826
2023-07-13 23:04:01,580 epoch [151/800] time: 0.87s val loss: 0.1455 accuracy: 0.95 f1: 0.9493
2023-07-13 23:04:06,348 epoch [152/800] time: 4.77s train loss: 0.0625 accuracy: 0.9822 f1: 0.9821
2023-07-13 23:04:07,218 epoch [152/800] time: 0.87s val loss: 0.1477 accuracy: 0.9495 f1: 0.9486
2023-07-13 23:04:12,119 epoch [153/800] time: 4.9s train loss: 0.0635 accuracy: 0.982 f1: 0.9819
2023-07-13 23:04:12,952 epoch [153/800] time: 0.83s val loss: 0.1465 accuracy: 0.9495 f1: 0.9488
2023-07-13 23:04:17,893 epoch [154/800] time: 4.94s train loss: 0.0618 accuracy: 0.9826 f1: 0.9824
2023-07-13 23:04:18,773 epoch [154/800] time: 0.88s val loss: 0.147 accuracy: 0.9496 f1: 0.949
2023-07-13 23:04:23,578 epoch [155/800] time: 4.81s train loss: 0.0617 accuracy: 0.9824 f1: 0.9823
2023-07-13 23:04:24,459 epoch [155/800] time: 0.88s val loss: 0.1465 accuracy: 0.9501 f1: 0.9494
2023-07-13 23:04:29,412 epoch [156/800] time: 4.95s train loss: 0.0614 accuracy: 0.9822 f1: 0.982
2023-07-13 23:04:30,232 epoch [156/800] time: 0.82s val loss: 0.1455 accuracy: 0.95 f1: 0.9493
2023-07-13 23:04:35,050 epoch [157/800] time: 4.82s train loss: 0.0611 accuracy: 0.9824 f1: 0.9823
2023-07-13 23:04:35,919 epoch [157/800] time: 0.87s val loss: 0.1467 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:04:40,662 epoch [158/800] time: 4.74s train loss: 0.0614 accuracy: 0.9824 f1: 0.9823
2023-07-13 23:04:41,525 epoch [158/800] time: 0.86s val loss: 0.146 accuracy: 0.95 f1: 0.9492
2023-07-13 23:04:46,408 epoch [159/800] time: 4.88s train loss: 0.0614 accuracy: 0.9818 f1: 0.9816
2023-07-13 23:04:47,230 epoch [159/800] time: 0.82s val loss: 0.1455 accuracy: 0.9503 f1: 0.9495
2023-07-13 23:04:52,139 epoch [160/800] time: 4.91s train loss: 0.0613 accuracy: 0.9821 f1: 0.982
2023-07-13 23:04:53,006 epoch [160/800] time: 0.87s val loss: 0.1463 accuracy: 0.9501 f1: 0.9494
2023-07-13 23:04:58,153 epoch [161/800] time: 5.15s train loss: 0.0596 accuracy: 0.9833 f1: 0.9831
2023-07-13 23:04:59,010 epoch [161/800] time: 0.85s val loss: 0.1458 accuracy: 0.9507 f1: 0.95
2023-07-13 23:05:03,784 epoch [162/800] time: 4.77s train loss: 0.0596 accuracy: 0.9831 f1: 0.983
2023-07-13 23:05:04,585 epoch [162/800] time: 0.8s val loss: 0.1445 accuracy: 0.9508 f1: 0.9503
2023-07-13 23:05:09,379 epoch [163/800] time: 4.79s train loss: 0.061 accuracy: 0.9827 f1: 0.9826
2023-07-13 23:05:10,226 epoch [163/800] time: 0.85s val loss: 0.1464 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:05:14,944 epoch [164/800] time: 4.72s train loss: 0.0601 accuracy: 0.9825 f1: 0.9824
2023-07-13 23:05:15,792 epoch [164/800] time: 0.85s val loss: 0.1461 accuracy: 0.9503 f1: 0.9497
2023-07-13 23:05:20,541 epoch [165/800] time: 4.75s train loss: 0.0606 accuracy: 0.9828 f1: 0.9827
2023-07-13 23:05:21,345 epoch [165/800] time: 0.8s val loss: 0.1457 accuracy: 0.95 f1: 0.9493
2023-07-13 23:05:25,931 epoch [166/800] time: 4.59s train loss: 0.0596 accuracy: 0.9831 f1: 0.983
2023-07-13 23:05:26,874 epoch [166/800] time: 0.94s val loss: 0.1466 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:05:32,165 epoch [167/800] time: 5.29s train loss: 0.0616 accuracy: 0.9823 f1: 0.9822
2023-07-13 23:05:33,043 epoch [167/800] time: 0.88s val loss: 0.146 accuracy: 0.9503 f1: 0.9498
2023-07-13 23:05:37,815 epoch [168/800] time: 4.77s train loss: 0.0589 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:05:38,631 epoch [168/800] time: 0.81s val loss: 0.1458 accuracy: 0.9505 f1: 0.9497
2023-07-13 23:05:43,560 epoch [169/800] time: 4.93s train loss: 0.0605 accuracy: 0.9836 f1: 0.9835
2023-07-13 23:05:44,461 epoch [169/800] time: 0.9s val loss: 0.1464 accuracy: 0.9498 f1: 0.9492
2023-07-13 23:05:49,309 epoch [170/800] time: 4.85s train loss: 0.0591 accuracy: 0.9834 f1: 0.9832
2023-07-13 23:05:50,205 epoch [170/800] time: 0.9s val loss: 0.1458 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:05:55,641 epoch [171/800] time: 5.44s train loss: 0.0595 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:05:56,763 epoch [171/800] time: 1.12s val loss: 0.1459 accuracy: 0.9504 f1: 0.9495
2023-07-13 23:06:01,991 epoch [172/800] time: 5.23s train loss: 0.0598 accuracy: 0.9833 f1: 0.9831
2023-07-13 23:06:02,902 epoch [172/800] time: 0.91s val loss: 0.1465 accuracy: 0.9507 f1: 0.9499
2023-07-13 23:06:07,893 epoch [173/800] time: 4.99s train loss: 0.0604 accuracy: 0.9829 f1: 0.9828
2023-07-13 23:06:08,861 epoch [173/800] time: 0.97s val loss: 0.1468 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:06:13,901 epoch [174/800] time: 5.04s train loss: 0.059 accuracy: 0.9833 f1: 0.9832
2023-07-13 23:06:14,736 epoch [174/800] time: 0.83s val loss: 0.1462 accuracy: 0.9506 f1: 0.9498
2023-07-13 23:06:19,721 epoch [175/800] time: 4.98s train loss: 0.058 accuracy: 0.9839 f1: 0.9837
2023-07-13 23:06:20,619 epoch [175/800] time: 0.89s val loss: 0.1468 accuracy: 0.9498 f1: 0.949
2023-07-13 23:06:25,565 epoch [176/800] time: 4.95s train loss: 0.0605 accuracy: 0.9827 f1: 0.9826
2023-07-13 23:06:26,455 epoch [176/800] time: 0.89s val loss: 0.1464 accuracy: 0.9504 f1: 0.9498
2023-07-13 23:06:31,403 epoch [177/800] time: 4.95s train loss: 0.0601 accuracy: 0.9829 f1: 0.9828
2023-07-13 23:06:32,230 epoch [177/800] time: 0.83s val loss: 0.1459 accuracy: 0.9505 f1: 0.9497
2023-07-13 23:06:37,134 epoch [178/800] time: 4.9s train loss: 0.0581 accuracy: 0.9838 f1: 0.9838
2023-07-13 23:06:38,006 epoch [178/800] time: 0.87s val loss: 0.1454 accuracy: 0.9509 f1: 0.9502
2023-07-13 23:06:42,806 epoch [179/800] time: 4.8s train loss: 0.0604 accuracy: 0.9825 f1: 0.9823
2023-07-13 23:06:43,681 epoch [179/800] time: 0.87s val loss: 0.1458 accuracy: 0.9508 f1: 0.9501
2023-07-13 23:06:48,548 epoch [180/800] time: 4.87s train loss: 0.06 accuracy: 0.9827 f1: 0.9825
2023-07-13 23:06:49,363 epoch [180/800] time: 0.82s val loss: 0.1461 accuracy: 0.9502 f1: 0.9496
2023-07-13 23:06:54,246 epoch [181/800] time: 4.88s train loss: 0.0593 accuracy: 0.9832 f1: 0.9831
2023-07-13 23:06:55,100 epoch [181/800] time: 0.85s val loss: 0.1455 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:06:59,849 epoch [182/800] time: 4.75s train loss: 0.0591 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:07:00,709 epoch [182/800] time: 0.86s val loss: 0.1458 accuracy: 0.9503 f1: 0.9497
2023-07-13 23:07:05,532 epoch [183/800] time: 4.82s train loss: 0.0594 accuracy: 0.9832 f1: 0.983
2023-07-13 23:07:06,347 epoch [183/800] time: 0.81s val loss: 0.1456 accuracy: 0.9507 f1: 0.95
2023-07-13 23:07:11,146 epoch [184/800] time: 4.8s train loss: 0.0586 accuracy: 0.9838 f1: 0.9838
2023-07-13 23:07:12,006 epoch [184/800] time: 0.86s val loss: 0.1457 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:07:16,856 epoch [185/800] time: 4.85s train loss: 0.0584 accuracy: 0.9833 f1: 0.9832
2023-07-13 23:07:17,715 epoch [185/800] time: 0.86s val loss: 0.1452 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:07:22,645 epoch [186/800] time: 4.93s train loss: 0.0593 accuracy: 0.9833 f1: 0.9832
2023-07-13 23:07:23,487 epoch [186/800] time: 0.84s val loss: 0.1463 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:07:28,422 epoch [187/800] time: 4.93s train loss: 0.06 accuracy: 0.9834 f1: 0.9834
2023-07-13 23:07:29,311 epoch [187/800] time: 0.89s val loss: 0.146 accuracy: 0.9501 f1: 0.9495
2023-07-13 23:07:34,131 epoch [188/800] time: 4.82s train loss: 0.0589 accuracy: 0.9834 f1: 0.9833
2023-07-13 23:07:35,001 epoch [188/800] time: 0.87s val loss: 0.1453 accuracy: 0.9506 f1: 0.9498
2023-07-13 23:07:40,036 epoch [189/800] time: 5.03s train loss: 0.0586 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:07:40,881 epoch [189/800] time: 0.84s val loss: 0.1456 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:07:45,941 epoch [190/800] time: 5.06s train loss: 0.0592 accuracy: 0.9831 f1: 0.9829
2023-07-13 23:07:46,843 epoch [190/800] time: 0.9s val loss: 0.1468 accuracy: 0.9502 f1: 0.9493
2023-07-13 23:07:52,374 epoch [191/800] time: 5.53s train loss: 0.0583 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:07:53,249 epoch [191/800] time: 0.87s val loss: 0.1455 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:07:58,102 epoch [192/800] time: 4.85s train loss: 0.0603 accuracy: 0.9832 f1: 0.9831
2023-07-13 23:07:58,919 epoch [192/800] time: 0.82s val loss: 0.146 accuracy: 0.9502 f1: 0.9494
2023-07-13 23:08:04,302 epoch [193/800] time: 5.38s train loss: 0.0601 accuracy: 0.9831 f1: 0.983
2023-07-13 23:08:05,190 epoch [193/800] time: 0.89s val loss: 0.1468 accuracy: 0.95 f1: 0.9495
2023-07-13 23:08:10,071 epoch [194/800] time: 4.88s train loss: 0.0596 accuracy: 0.9834 f1: 0.9834
2023-07-13 23:08:10,949 epoch [194/800] time: 0.88s val loss: 0.1465 accuracy: 0.9501 f1: 0.9494
2023-07-13 23:08:16,311 epoch [195/800] time: 5.36s train loss: 0.0585 accuracy: 0.9831 f1: 0.9831
2023-07-13 23:08:17,158 epoch [195/800] time: 0.85s val loss: 0.1464 accuracy: 0.9499 f1: 0.9492
2023-07-13 23:08:22,118 epoch [196/800] time: 4.96s train loss: 0.0609 accuracy: 0.9828 f1: 0.9828
2023-07-13 23:08:22,973 epoch [196/800] time: 0.85s val loss: 0.1463 accuracy: 0.9497 f1: 0.9489
2023-07-13 23:08:27,859 epoch [197/800] time: 4.89s train loss: 0.0588 accuracy: 0.9836 f1: 0.9835
2023-07-13 23:08:28,735 epoch [197/800] time: 0.87s val loss: 0.1462 accuracy: 0.9501 f1: 0.9493
2023-07-13 23:08:33,574 epoch [198/800] time: 4.84s train loss: 0.058 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:08:34,394 epoch [198/800] time: 0.82s val loss: 0.146 accuracy: 0.9503 f1: 0.9495
2023-07-13 23:08:39,197 epoch [199/800] time: 4.8s train loss: 0.0583 accuracy: 0.9834 f1: 0.9834
2023-07-13 23:08:40,051 epoch [199/800] time: 0.85s val loss: 0.1463 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:08:44,830 epoch [200/800] time: 4.78s train loss: 0.059 accuracy: 0.9833 f1: 0.9832
2023-07-13 23:08:45,684 epoch [200/800] time: 0.85s val loss: 0.1462 accuracy: 0.9503 f1: 0.9497
2023-07-13 23:08:50,503 epoch [201/800] time: 4.82s train loss: 0.0576 accuracy: 0.9843 f1: 0.9841
2023-07-13 23:08:51,317 epoch [201/800] time: 0.81s val loss: 0.146 accuracy: 0.9504 f1: 0.9498
2023-07-13 23:08:56,098 epoch [202/800] time: 4.78s train loss: 0.0578 accuracy: 0.9838 f1: 0.9838
2023-07-13 23:08:56,949 epoch [202/800] time: 0.85s val loss: 0.1457 accuracy: 0.9504 f1: 0.9495
2023-07-13 23:09:01,801 epoch [203/800] time: 4.85s train loss: 0.0603 accuracy: 0.9835 f1: 0.9835
2023-07-13 23:09:02,664 epoch [203/800] time: 0.86s val loss: 0.147 accuracy: 0.9496 f1: 0.9488
2023-07-13 23:09:07,552 epoch [204/800] time: 4.89s train loss: 0.0584 accuracy: 0.9833 f1: 0.9831
2023-07-13 23:09:08,382 epoch [204/800] time: 0.83s val loss: 0.1452 accuracy: 0.9507 f1: 0.95
2023-07-13 23:09:13,238 epoch [205/800] time: 4.86s train loss: 0.06 accuracy: 0.9829 f1: 0.9827
2023-07-13 23:09:14,093 epoch [205/800] time: 0.86s val loss: 0.1458 accuracy: 0.95 f1: 0.9494
2023-07-13 23:09:19,264 epoch [206/800] time: 5.17s train loss: 0.0602 accuracy: 0.9838 f1: 0.9838
2023-07-13 23:09:20,152 epoch [206/800] time: 0.89s val loss: 0.1478 accuracy: 0.9494 f1: 0.9487
2023-07-13 23:09:25,119 epoch [207/800] time: 4.97s train loss: 0.058 accuracy: 0.984 f1: 0.9839
2023-07-13 23:09:25,946 epoch [207/800] time: 0.83s val loss: 0.1455 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:09:30,844 epoch [208/800] time: 4.9s train loss: 0.0583 accuracy: 0.9833 f1: 0.9833
2023-07-13 23:09:31,706 epoch [208/800] time: 0.86s val loss: 0.1462 accuracy: 0.9504 f1: 0.9498
2023-07-13 23:09:36,433 epoch [209/800] time: 4.73s train loss: 0.0586 accuracy: 0.9844 f1: 0.9843
2023-07-13 23:09:37,289 epoch [209/800] time: 0.85s val loss: 0.1458 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:09:42,237 epoch [210/800] time: 4.95s train loss: 0.0585 accuracy: 0.9835 f1: 0.9833
2023-07-13 23:09:43,108 epoch [210/800] time: 0.87s val loss: 0.1458 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:09:48,051 epoch [211/800] time: 4.94s train loss: 0.0583 accuracy: 0.984 f1: 0.9838
2023-07-13 23:09:48,907 epoch [211/800] time: 0.85s val loss: 0.1453 accuracy: 0.95 f1: 0.9494
2023-07-13 23:09:53,735 epoch [212/800] time: 4.83s train loss: 0.0584 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:09:54,665 epoch [212/800] time: 0.93s val loss: 0.1453 accuracy: 0.9503 f1: 0.9495
2023-07-13 23:09:59,986 epoch [213/800] time: 5.32s train loss: 0.0591 accuracy: 0.9833 f1: 0.9831
2023-07-13 23:10:00,883 epoch [213/800] time: 0.9s val loss: 0.1463 accuracy: 0.9504 f1: 0.9498
2023-07-13 23:10:05,885 epoch [214/800] time: 5.0s train loss: 0.0587 accuracy: 0.983 f1: 0.9829
2023-07-13 23:10:06,789 epoch [214/800] time: 0.9s val loss: 0.1451 accuracy: 0.95 f1: 0.9493
2023-07-13 23:10:11,743 epoch [215/800] time: 4.95s train loss: 0.0592 accuracy: 0.983 f1: 0.9829
2023-07-13 23:10:12,716 epoch [215/800] time: 0.97s val loss: 0.1463 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:10:17,712 epoch [216/800] time: 5.0s train loss: 0.0592 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:10:18,528 epoch [216/800] time: 0.82s val loss: 0.1467 accuracy: 0.9501 f1: 0.9494
2023-07-13 23:10:23,302 epoch [217/800] time: 4.77s train loss: 0.0586 accuracy: 0.984 f1: 0.984
2023-07-13 23:10:24,167 epoch [217/800] time: 0.86s val loss: 0.1465 accuracy: 0.9501 f1: 0.9494
2023-07-13 23:10:28,897 epoch [218/800] time: 4.73s train loss: 0.0592 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:10:29,782 epoch [218/800] time: 0.88s val loss: 0.1463 accuracy: 0.9499 f1: 0.9493
2023-07-13 23:10:34,538 epoch [219/800] time: 4.76s train loss: 0.0573 accuracy: 0.9843 f1: 0.9842
2023-07-13 23:10:35,346 epoch [219/800] time: 0.81s val loss: 0.1451 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:10:39,959 epoch [220/800] time: 4.61s train loss: 0.0587 accuracy: 0.9836 f1: 0.9836
2023-07-13 23:10:40,845 epoch [220/800] time: 0.89s val loss: 0.1468 accuracy: 0.9505 f1: 0.9497
2023-07-13 23:10:45,749 epoch [221/800] time: 4.9s train loss: 0.0584 accuracy: 0.9837 f1: 0.9837
2023-07-13 23:10:46,643 epoch [221/800] time: 0.89s val loss: 0.1464 accuracy: 0.9504 f1: 0.9498
2023-07-13 23:10:51,447 epoch [222/800] time: 4.8s train loss: 0.0575 accuracy: 0.984 f1: 0.9839
2023-07-13 23:10:52,248 epoch [222/800] time: 0.8s val loss: 0.1458 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:10:57,120 epoch [223/800] time: 4.87s train loss: 0.0576 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:10:58,034 epoch [223/800] time: 0.91s val loss: 0.1453 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:11:02,941 epoch [224/800] time: 4.91s train loss: 0.0579 accuracy: 0.9844 f1: 0.9843
2023-07-13 23:11:03,799 epoch [224/800] time: 0.85s val loss: 0.1456 accuracy: 0.9502 f1: 0.9497
2023-07-13 23:11:08,618 epoch [225/800] time: 4.82s train loss: 0.0577 accuracy: 0.9838 f1: 0.9836
2023-07-13 23:11:09,446 epoch [225/800] time: 0.83s val loss: 0.1453 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:11:14,494 epoch [226/800] time: 5.05s train loss: 0.0586 accuracy: 0.9837 f1: 0.9835
2023-07-13 23:11:15,533 epoch [226/800] time: 1.04s val loss: 0.1457 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:11:20,934 epoch [227/800] time: 5.4s train loss: 0.0587 accuracy: 0.9836 f1: 0.9834
2023-07-13 23:11:21,849 epoch [227/800] time: 0.91s val loss: 0.1465 accuracy: 0.9498 f1: 0.9492
2023-07-13 23:11:26,898 epoch [228/800] time: 5.05s train loss: 0.0581 accuracy: 0.9842 f1: 0.9841
2023-07-13 23:11:27,731 epoch [228/800] time: 0.83s val loss: 0.1466 accuracy: 0.9502 f1: 0.9493
2023-07-13 23:11:33,187 epoch [229/800] time: 5.46s train loss: 0.0629 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:11:34,118 epoch [229/800] time: 0.93s val loss: 0.147 accuracy: 0.9494 f1: 0.9487
2023-07-13 23:11:39,226 epoch [230/800] time: 5.11s train loss: 0.0584 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:11:40,138 epoch [230/800] time: 0.91s val loss: 0.1463 accuracy: 0.9502 f1: 0.9494
2023-07-13 23:11:45,134 epoch [231/800] time: 5.0s train loss: 0.0574 accuracy: 0.9841 f1: 0.9839
2023-07-13 23:11:45,955 epoch [231/800] time: 0.82s val loss: 0.1457 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:11:50,590 epoch [232/800] time: 4.64s train loss: 0.0591 accuracy: 0.9836 f1: 0.9834
2023-07-13 23:11:51,444 epoch [232/800] time: 0.85s val loss: 0.1461 accuracy: 0.9501 f1: 0.9494
2023-07-13 23:11:56,150 epoch [233/800] time: 4.71s train loss: 0.0587 accuracy: 0.9838 f1: 0.9838
2023-07-13 23:11:56,997 epoch [233/800] time: 0.85s val loss: 0.1463 accuracy: 0.9502 f1: 0.9496
2023-07-13 23:12:02,348 epoch [234/800] time: 5.35s train loss: 0.0605 accuracy: 0.9835 f1: 0.9833
2023-07-13 23:12:03,283 epoch [234/800] time: 0.94s val loss: 0.1484 accuracy: 0.9494 f1: 0.9486
2023-07-13 23:12:08,664 epoch [235/800] time: 5.38s train loss: 0.0579 accuracy: 0.984 f1: 0.9839
2023-07-13 23:12:09,593 epoch [235/800] time: 0.93s val loss: 0.1455 accuracy: 0.9504 f1: 0.9498
2023-07-13 23:12:14,748 epoch [236/800] time: 5.15s train loss: 0.0584 accuracy: 0.9834 f1: 0.9832
2023-07-13 23:12:15,672 epoch [236/800] time: 0.92s val loss: 0.1454 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:12:21,066 epoch [237/800] time: 5.39s train loss: 0.0589 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:12:21,913 epoch [237/800] time: 0.85s val loss: 0.1457 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:12:27,008 epoch [238/800] time: 5.1s train loss: 0.0584 accuracy: 0.9838 f1: 0.9836
2023-07-13 23:12:27,924 epoch [238/800] time: 0.92s val loss: 0.1455 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:12:33,327 epoch [239/800] time: 5.4s train loss: 0.0572 accuracy: 0.9843 f1: 0.9842
2023-07-13 23:12:34,240 epoch [239/800] time: 0.91s val loss: 0.1454 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:12:39,347 epoch [240/800] time: 5.11s train loss: 0.0588 accuracy: 0.9836 f1: 0.9835
2023-07-13 23:12:40,189 epoch [240/800] time: 0.84s val loss: 0.1454 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:12:45,327 epoch [241/800] time: 5.14s train loss: 0.0581 accuracy: 0.9836 f1: 0.9835
2023-07-13 23:12:46,240 epoch [241/800] time: 0.91s val loss: 0.1462 accuracy: 0.9501 f1: 0.9493
2023-07-13 23:12:51,446 epoch [242/800] time: 5.21s train loss: 0.0587 accuracy: 0.9835 f1: 0.9833
2023-07-13 23:12:52,369 epoch [242/800] time: 0.92s val loss: 0.1452 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:12:57,536 epoch [243/800] time: 5.17s train loss: 0.0583 accuracy: 0.9839 f1: 0.9839
2023-07-13 23:12:58,406 epoch [243/800] time: 0.87s val loss: 0.146 accuracy: 0.9501 f1: 0.9493
2023-07-13 23:13:03,573 epoch [244/800] time: 5.17s train loss: 0.0593 accuracy: 0.9832 f1: 0.9832
2023-07-13 23:13:04,455 epoch [244/800] time: 0.88s val loss: 0.1453 accuracy: 0.9509 f1: 0.9503
2023-07-13 23:13:09,506 epoch [245/800] time: 5.05s train loss: 0.058 accuracy: 0.9837 f1: 0.9837
2023-07-13 23:13:10,406 epoch [245/800] time: 0.9s val loss: 0.1454 accuracy: 0.9511 f1: 0.9505
2023-07-13 23:13:15,587 epoch [246/800] time: 5.18s train loss: 0.0583 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:13:16,444 epoch [246/800] time: 0.86s val loss: 0.1453 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:13:21,700 epoch [247/800] time: 5.26s train loss: 0.0587 accuracy: 0.9831 f1: 0.9831
2023-07-13 23:13:22,622 epoch [247/800] time: 0.92s val loss: 0.1464 accuracy: 0.9504 f1: 0.9496
2023-07-13 23:13:27,773 epoch [248/800] time: 5.15s train loss: 0.0585 accuracy: 0.9838 f1: 0.9838
2023-07-13 23:13:28,675 epoch [248/800] time: 0.9s val loss: 0.1454 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:13:33,683 epoch [249/800] time: 5.01s train loss: 0.0581 accuracy: 0.9837 f1: 0.9837
2023-07-13 23:13:34,555 epoch [249/800] time: 0.87s val loss: 0.1454 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:13:39,436 epoch [250/800] time: 4.88s train loss: 0.0592 accuracy: 0.9832 f1: 0.9831
2023-07-13 23:13:40,300 epoch [250/800] time: 0.86s val loss: 0.1452 accuracy: 0.9512 f1: 0.9506
2023-07-13 23:13:45,534 epoch [251/800] time: 5.23s train loss: 0.0576 accuracy: 0.9845 f1: 0.9843
2023-07-13 23:13:46,464 epoch [251/800] time: 0.92s val loss: 0.1452 accuracy: 0.951 f1: 0.9504
2023-07-13 23:13:51,627 epoch [252/800] time: 5.16s train loss: 0.0581 accuracy: 0.9838 f1: 0.9836
2023-07-13 23:13:52,479 epoch [252/800] time: 0.85s val loss: 0.1457 accuracy: 0.9508 f1: 0.9501
2023-07-13 23:13:57,778 epoch [253/800] time: 5.3s train loss: 0.0574 accuracy: 0.984 f1: 0.9839
2023-07-13 23:13:58,676 epoch [253/800] time: 0.9s val loss: 0.1458 accuracy: 0.9505 f1: 0.9497
2023-07-13 23:14:03,906 epoch [254/800] time: 5.23s train loss: 0.0576 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:14:04,838 epoch [254/800] time: 0.93s val loss: 0.1459 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:14:10,100 epoch [255/800] time: 5.26s train loss: 0.0577 accuracy: 0.9844 f1: 0.9843
2023-07-13 23:14:10,974 epoch [255/800] time: 0.87s val loss: 0.1459 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:14:16,197 epoch [256/800] time: 5.22s train loss: 0.059 accuracy: 0.9838 f1: 0.9839
2023-07-13 23:14:17,114 epoch [256/800] time: 0.92s val loss: 0.1472 accuracy: 0.9501 f1: 0.9494
2023-07-13 23:14:22,402 epoch [257/800] time: 5.29s train loss: 0.0581 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:14:23,396 epoch [257/800] time: 0.99s val loss: 0.145 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:14:28,682 epoch [258/800] time: 5.29s train loss: 0.0577 accuracy: 0.9839 f1: 0.9839
2023-07-13 23:14:29,502 epoch [258/800] time: 0.82s val loss: 0.145 accuracy: 0.9507 f1: 0.95
2023-07-13 23:14:34,706 epoch [259/800] time: 5.2s train loss: 0.0579 accuracy: 0.9843 f1: 0.9842
2023-07-13 23:14:35,654 epoch [259/800] time: 0.95s val loss: 0.1462 accuracy: 0.95 f1: 0.9493
2023-07-13 23:14:40,491 epoch [260/800] time: 4.84s train loss: 0.0598 accuracy: 0.9833 f1: 0.9833
2023-07-13 23:14:41,353 epoch [260/800] time: 0.86s val loss: 0.1463 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:14:46,239 epoch [261/800] time: 4.89s train loss: 0.0579 accuracy: 0.984 f1: 0.984
2023-07-13 23:14:47,058 epoch [261/800] time: 0.82s val loss: 0.1447 accuracy: 0.951 f1: 0.9503
2023-07-13 23:14:51,933 epoch [262/800] time: 4.87s train loss: 0.0581 accuracy: 0.9838 f1: 0.9838
2023-07-13 23:14:52,801 epoch [262/800] time: 0.87s val loss: 0.1454 accuracy: 0.9506 f1: 0.95
2023-07-13 23:14:57,590 epoch [263/800] time: 4.79s train loss: 0.0592 accuracy: 0.9832 f1: 0.9831
2023-07-13 23:14:58,458 epoch [263/800] time: 0.87s val loss: 0.146 accuracy: 0.9503 f1: 0.9497
2023-07-13 23:15:03,234 epoch [264/800] time: 4.78s train loss: 0.0588 accuracy: 0.9833 f1: 0.9832
2023-07-13 23:15:04,083 epoch [264/800] time: 0.85s val loss: 0.1463 accuracy: 0.9502 f1: 0.9496
2023-07-13 23:15:08,830 epoch [265/800] time: 4.75s train loss: 0.0572 accuracy: 0.9845 f1: 0.9846
2023-07-13 23:15:09,693 epoch [265/800] time: 0.86s val loss: 0.1459 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:15:14,203 epoch [266/800] time: 4.51s train loss: 0.0576 accuracy: 0.9841 f1: 0.9839
2023-07-13 23:15:15,061 epoch [266/800] time: 0.86s val loss: 0.1465 accuracy: 0.9497 f1: 0.9491
2023-07-13 23:15:19,779 epoch [267/800] time: 4.72s train loss: 0.0578 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:15:20,574 epoch [267/800] time: 0.79s val loss: 0.1456 accuracy: 0.9506 f1: 0.95
2023-07-13 23:15:25,265 epoch [268/800] time: 4.69s train loss: 0.0585 accuracy: 0.9838 f1: 0.9836
2023-07-13 23:15:26,124 epoch [268/800] time: 0.86s val loss: 0.1456 accuracy: 0.9503 f1: 0.9497
2023-07-13 23:15:30,639 epoch [269/800] time: 4.51s train loss: 0.0572 accuracy: 0.9842 f1: 0.9841
2023-07-13 23:15:31,499 epoch [269/800] time: 0.86s val loss: 0.1466 accuracy: 0.95 f1: 0.9493
2023-07-13 23:15:36,527 epoch [270/800] time: 5.03s train loss: 0.0585 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:15:37,332 epoch [270/800] time: 0.8s val loss: 0.1453 accuracy: 0.9502 f1: 0.9496
2023-07-13 23:15:41,924 epoch [271/800] time: 4.59s train loss: 0.0579 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:15:42,780 epoch [271/800] time: 0.86s val loss: 0.1454 accuracy: 0.9501 f1: 0.9494
2023-07-13 23:15:47,597 epoch [272/800] time: 4.82s train loss: 0.058 accuracy: 0.9841 f1: 0.984
2023-07-13 23:15:48,463 epoch [272/800] time: 0.87s val loss: 0.1454 accuracy: 0.9505 f1: 0.9497
2023-07-13 23:15:54,017 epoch [273/800] time: 5.55s train loss: 0.058 accuracy: 0.9841 f1: 0.984
2023-07-13 23:15:54,875 epoch [273/800] time: 0.86s val loss: 0.1449 accuracy: 0.9508 f1: 0.95
2023-07-13 23:16:00,076 epoch [274/800] time: 5.2s train loss: 0.0573 accuracy: 0.9843 f1: 0.9842
2023-07-13 23:16:01,007 epoch [274/800] time: 0.93s val loss: 0.145 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:16:06,277 epoch [275/800] time: 5.27s train loss: 0.057 accuracy: 0.9848 f1: 0.9848
2023-07-13 23:16:07,188 epoch [275/800] time: 0.9s val loss: 0.1454 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:16:12,223 epoch [276/800] time: 5.03s train loss: 0.0583 accuracy: 0.984 f1: 0.984
2023-07-13 23:16:13,350 epoch [276/800] time: 1.13s val loss: 0.1452 accuracy: 0.9506 f1: 0.95
2023-07-13 23:16:19,062 epoch [277/800] time: 5.71s train loss: 0.0601 accuracy: 0.983 f1: 0.9829
2023-07-13 23:16:19,998 epoch [277/800] time: 0.94s val loss: 0.1453 accuracy: 0.9501 f1: 0.9495
2023-07-13 23:16:25,037 epoch [278/800] time: 5.04s train loss: 0.0591 accuracy: 0.9834 f1: 0.9833
2023-07-13 23:16:25,942 epoch [278/800] time: 0.9s val loss: 0.1457 accuracy: 0.9499 f1: 0.9494
2023-07-13 23:16:31,091 epoch [279/800] time: 5.15s train loss: 0.059 accuracy: 0.9831 f1: 0.983
2023-07-13 23:16:31,926 epoch [279/800] time: 0.83s val loss: 0.1459 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:16:37,059 epoch [280/800] time: 5.13s train loss: 0.0574 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:16:37,967 epoch [280/800] time: 0.91s val loss: 0.1456 accuracy: 0.9508 f1: 0.9502
2023-07-13 23:16:43,292 epoch [281/800] time: 5.32s train loss: 0.0581 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:16:44,220 epoch [281/800] time: 0.93s val loss: 0.1453 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:16:49,285 epoch [282/800] time: 5.06s train loss: 0.0588 accuracy: 0.9833 f1: 0.9831
2023-07-13 23:16:50,138 epoch [282/800] time: 0.85s val loss: 0.1465 accuracy: 0.9506 f1: 0.95
2023-07-13 23:16:55,171 epoch [283/800] time: 5.03s train loss: 0.0589 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:16:56,059 epoch [283/800] time: 0.89s val loss: 0.1479 accuracy: 0.9504 f1: 0.9496
2023-07-13 23:17:00,887 epoch [284/800] time: 4.83s train loss: 0.0594 accuracy: 0.9834 f1: 0.9834
2023-07-13 23:17:01,770 epoch [284/800] time: 0.88s val loss: 0.1453 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:17:06,727 epoch [285/800] time: 4.96s train loss: 0.0584 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:17:07,550 epoch [285/800] time: 0.82s val loss: 0.1453 accuracy: 0.9511 f1: 0.9504
2023-07-13 23:17:12,479 epoch [286/800] time: 4.93s train loss: 0.0579 accuracy: 0.984 f1: 0.984
2023-07-13 23:17:13,375 epoch [286/800] time: 0.9s val loss: 0.1451 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:17:18,386 epoch [287/800] time: 5.01s train loss: 0.0584 accuracy: 0.9836 f1: 0.9835
2023-07-13 23:17:19,282 epoch [287/800] time: 0.9s val loss: 0.1457 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:17:24,275 epoch [288/800] time: 4.99s train loss: 0.0581 accuracy: 0.9836 f1: 0.9836
2023-07-13 23:17:25,108 epoch [288/800] time: 0.83s val loss: 0.1454 accuracy: 0.9507 f1: 0.95
2023-07-13 23:17:30,262 epoch [289/800] time: 5.15s train loss: 0.0579 accuracy: 0.984 f1: 0.9838
2023-07-13 23:17:31,258 epoch [289/800] time: 1.0s val loss: 0.1457 accuracy: 0.9502 f1: 0.9496
2023-07-13 23:17:36,625 epoch [290/800] time: 5.37s train loss: 0.0585 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:17:37,621 epoch [290/800] time: 1.0s val loss: 0.1466 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:17:43,327 epoch [291/800] time: 5.71s train loss: 0.0587 accuracy: 0.9839 f1: 0.9837
2023-07-13 23:17:44,277 epoch [291/800] time: 0.95s val loss: 0.1459 accuracy: 0.9508 f1: 0.9501
2023-07-13 23:17:49,629 epoch [292/800] time: 5.35s train loss: 0.059 accuracy: 0.9829 f1: 0.9828
2023-07-13 23:17:50,607 epoch [292/800] time: 0.98s val loss: 0.1457 accuracy: 0.9503 f1: 0.9497
2023-07-13 23:17:55,857 epoch [293/800] time: 5.25s train loss: 0.058 accuracy: 0.9836 f1: 0.9834
2023-07-13 23:17:56,760 epoch [293/800] time: 0.9s val loss: 0.1453 accuracy: 0.951 f1: 0.9504
2023-07-13 23:18:01,982 epoch [294/800] time: 5.22s train loss: 0.0582 accuracy: 0.9838 f1: 0.9838
2023-07-13 23:18:02,826 epoch [294/800] time: 0.84s val loss: 0.1462 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:18:08,071 epoch [295/800] time: 5.24s train loss: 0.0584 accuracy: 0.984 f1: 0.9838
2023-07-13 23:18:08,950 epoch [295/800] time: 0.88s val loss: 0.1452 accuracy: 0.9508 f1: 0.9501
2023-07-13 23:18:14,088 epoch [296/800] time: 5.14s train loss: 0.0581 accuracy: 0.984 f1: 0.9838
2023-07-13 23:18:15,021 epoch [296/800] time: 0.93s val loss: 0.1458 accuracy: 0.9502 f1: 0.9496
2023-07-13 23:18:20,171 epoch [297/800] time: 5.15s train loss: 0.0585 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:18:21,008 epoch [297/800] time: 0.84s val loss: 0.146 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:18:25,974 epoch [298/800] time: 4.97s train loss: 0.0581 accuracy: 0.9837 f1: 0.9835
2023-07-13 23:18:26,857 epoch [298/800] time: 0.88s val loss: 0.1451 accuracy: 0.9506 f1: 0.95
2023-07-13 23:18:31,696 epoch [299/800] time: 4.84s train loss: 0.0586 accuracy: 0.9834 f1: 0.9833
2023-07-13 23:18:32,541 epoch [299/800] time: 0.85s val loss: 0.1466 accuracy: 0.95 f1: 0.9494
2023-07-13 23:18:37,305 epoch [300/800] time: 4.76s train loss: 0.0582 accuracy: 0.9835 f1: 0.9833
2023-07-13 23:18:38,110 epoch [300/800] time: 0.8s val loss: 0.1451 accuracy: 0.9506 f1: 0.95
2023-07-13 23:18:42,934 epoch [301/800] time: 4.82s train loss: 0.0583 accuracy: 0.9843 f1: 0.9843
2023-07-13 23:18:43,808 epoch [301/800] time: 0.87s val loss: 0.146 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:18:48,473 epoch [302/800] time: 4.66s train loss: 0.0575 accuracy: 0.9843 f1: 0.9843
2023-07-13 23:18:49,343 epoch [302/800] time: 0.87s val loss: 0.1455 accuracy: 0.9509 f1: 0.9502
2023-07-13 23:18:54,113 epoch [303/800] time: 4.77s train loss: 0.0583 accuracy: 0.9836 f1: 0.9834
2023-07-13 23:18:54,938 epoch [303/800] time: 0.83s val loss: 0.1463 accuracy: 0.9499 f1: 0.9491
2023-07-13 23:18:59,854 epoch [304/800] time: 4.92s train loss: 0.0578 accuracy: 0.984 f1: 0.9839
2023-07-13 23:19:00,720 epoch [304/800] time: 0.87s val loss: 0.1455 accuracy: 0.95 f1: 0.9492
2023-07-13 23:19:05,483 epoch [305/800] time: 4.76s train loss: 0.0585 accuracy: 0.9836 f1: 0.9836
2023-07-13 23:19:06,346 epoch [305/800] time: 0.86s val loss: 0.1456 accuracy: 0.951 f1: 0.9503
2023-07-13 23:19:10,943 epoch [306/800] time: 4.6s train loss: 0.0586 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:19:11,741 epoch [306/800] time: 0.8s val loss: 0.1459 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:19:16,690 epoch [307/800] time: 4.95s train loss: 0.058 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:19:17,745 epoch [307/800] time: 1.05s val loss: 0.145 accuracy: 0.9506 f1: 0.9501
2023-07-13 23:19:23,142 epoch [308/800] time: 5.4s train loss: 0.059 accuracy: 0.9834 f1: 0.9833
2023-07-13 23:19:24,045 epoch [308/800] time: 0.9s val loss: 0.1454 accuracy: 0.9509 f1: 0.9502
2023-07-13 23:19:29,110 epoch [309/800] time: 5.06s train loss: 0.0578 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:19:29,950 epoch [309/800] time: 0.84s val loss: 0.1456 accuracy: 0.9508 f1: 0.9502
2023-07-13 23:19:35,494 epoch [310/800] time: 5.54s train loss: 0.0593 accuracy: 0.9841 f1: 0.984
2023-07-13 23:19:36,416 epoch [310/800] time: 0.92s val loss: 0.1466 accuracy: 0.9499 f1: 0.9492
2023-07-13 23:19:41,477 epoch [311/800] time: 5.06s train loss: 0.0575 accuracy: 0.984 f1: 0.9838
2023-07-13 23:19:42,377 epoch [311/800] time: 0.9s val loss: 0.1454 accuracy: 0.9506 f1: 0.9498
2023-07-13 23:19:47,394 epoch [312/800] time: 5.02s train loss: 0.0585 accuracy: 0.9844 f1: 0.9842
2023-07-13 23:19:48,198 epoch [312/800] time: 0.8s val loss: 0.1453 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:19:52,856 epoch [313/800] time: 4.66s train loss: 0.0583 accuracy: 0.9835 f1: 0.9833
2023-07-13 23:19:53,698 epoch [313/800] time: 0.84s val loss: 0.1461 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:19:58,367 epoch [314/800] time: 4.67s train loss: 0.0573 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:19:59,222 epoch [314/800] time: 0.85s val loss: 0.1453 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:20:04,102 epoch [315/800] time: 4.88s train loss: 0.0576 accuracy: 0.984 f1: 0.9838
2023-07-13 23:20:05,073 epoch [315/800] time: 0.97s val loss: 0.1452 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:20:10,524 epoch [316/800] time: 5.45s train loss: 0.0581 accuracy: 0.9839 f1: 0.9839
2023-07-13 23:20:11,451 epoch [316/800] time: 0.93s val loss: 0.1457 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:20:16,571 epoch [317/800] time: 5.12s train loss: 0.0569 accuracy: 0.9843 f1: 0.9841
2023-07-13 23:20:17,489 epoch [317/800] time: 0.92s val loss: 0.1455 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:20:22,872 epoch [318/800] time: 5.38s train loss: 0.0582 accuracy: 0.9841 f1: 0.984
2023-07-13 23:20:23,710 epoch [318/800] time: 0.84s val loss: 0.1462 accuracy: 0.9504 f1: 0.9496
2023-07-13 23:20:29,019 epoch [319/800] time: 5.31s train loss: 0.0575 accuracy: 0.9842 f1: 0.9841
2023-07-13 23:20:29,923 epoch [319/800] time: 0.9s val loss: 0.1457 accuracy: 0.9502 f1: 0.9496
2023-07-13 23:20:34,962 epoch [320/800] time: 5.04s train loss: 0.0569 accuracy: 0.9846 f1: 0.9844
2023-07-13 23:20:35,882 epoch [320/800] time: 0.92s val loss: 0.1452 accuracy: 0.9508 f1: 0.9501
2023-07-13 23:20:41,163 epoch [321/800] time: 5.28s train loss: 0.0576 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:20:42,014 epoch [321/800] time: 0.85s val loss: 0.1454 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:20:47,131 epoch [322/800] time: 5.12s train loss: 0.0589 accuracy: 0.9834 f1: 0.9833
2023-07-13 23:20:48,056 epoch [322/800] time: 0.93s val loss: 0.1453 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:20:53,114 epoch [323/800] time: 5.06s train loss: 0.0584 accuracy: 0.984 f1: 0.9839
2023-07-13 23:20:54,034 epoch [323/800] time: 0.92s val loss: 0.1461 accuracy: 0.9505 f1: 0.9497
2023-07-13 23:20:59,224 epoch [324/800] time: 5.19s train loss: 0.0582 accuracy: 0.984 f1: 0.984
2023-07-13 23:21:00,079 epoch [324/800] time: 0.85s val loss: 0.145 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:21:05,123 epoch [325/800] time: 5.04s train loss: 0.0587 accuracy: 0.9834 f1: 0.9832
2023-07-13 23:21:06,022 epoch [325/800] time: 0.9s val loss: 0.1453 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:21:10,962 epoch [326/800] time: 4.94s train loss: 0.058 accuracy: 0.9839 f1: 0.9837
2023-07-13 23:21:11,874 epoch [326/800] time: 0.91s val loss: 0.1457 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:21:16,854 epoch [327/800] time: 4.98s train loss: 0.0585 accuracy: 0.9838 f1: 0.9836
2023-07-13 23:21:17,681 epoch [327/800] time: 0.83s val loss: 0.1465 accuracy: 0.9502 f1: 0.9496
2023-07-13 23:21:22,663 epoch [328/800] time: 4.98s train loss: 0.0582 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:21:23,604 epoch [328/800] time: 0.94s val loss: 0.1467 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:21:28,454 epoch [329/800] time: 4.85s train loss: 0.0588 accuracy: 0.9842 f1: 0.9841
2023-07-13 23:21:29,338 epoch [329/800] time: 0.88s val loss: 0.1471 accuracy: 0.9495 f1: 0.9488
2023-07-13 23:21:34,318 epoch [330/800] time: 4.98s train loss: 0.058 accuracy: 0.9837 f1: 0.9837
2023-07-13 23:21:35,153 epoch [330/800] time: 0.84s val loss: 0.1452 accuracy: 0.9505 f1: 0.9497
2023-07-13 23:21:40,216 epoch [331/800] time: 5.06s train loss: 0.0577 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:21:41,139 epoch [331/800] time: 0.92s val loss: 0.1467 accuracy: 0.951 f1: 0.9502
2023-07-13 23:21:46,115 epoch [332/800] time: 4.98s train loss: 0.0573 accuracy: 0.9841 f1: 0.9841
2023-07-13 23:21:47,007 epoch [332/800] time: 0.89s val loss: 0.1458 accuracy: 0.9498 f1: 0.9493
2023-07-13 23:21:52,065 epoch [333/800] time: 5.06s train loss: 0.0582 accuracy: 0.9841 f1: 0.9839
2023-07-13 23:21:52,932 epoch [333/800] time: 0.87s val loss: 0.1458 accuracy: 0.9502 f1: 0.9497
2023-07-13 23:21:58,119 epoch [334/800] time: 5.19s train loss: 0.0584 accuracy: 0.984 f1: 0.9839
2023-07-13 23:21:59,035 epoch [334/800] time: 0.91s val loss: 0.1465 accuracy: 0.9495 f1: 0.9488
2023-07-13 23:22:03,994 epoch [335/800] time: 4.96s train loss: 0.0594 accuracy: 0.9832 f1: 0.983
2023-07-13 23:22:04,891 epoch [335/800] time: 0.9s val loss: 0.1453 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:22:09,965 epoch [336/800] time: 5.07s train loss: 0.0589 accuracy: 0.9835 f1: 0.9833
2023-07-13 23:22:10,899 epoch [336/800] time: 0.93s val loss: 0.1452 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:22:15,999 epoch [337/800] time: 5.1s train loss: 0.059 accuracy: 0.9837 f1: 0.9837
2023-07-13 23:22:16,948 epoch [337/800] time: 0.95s val loss: 0.145 accuracy: 0.9508 f1: 0.9501
2023-07-13 23:22:22,357 epoch [338/800] time: 5.41s train loss: 0.059 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:22:23,300 epoch [338/800] time: 0.94s val loss: 0.1471 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:22:28,445 epoch [339/800] time: 5.14s train loss: 0.0578 accuracy: 0.9843 f1: 0.9843
2023-07-13 23:22:29,283 epoch [339/800] time: 0.84s val loss: 0.1467 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:22:34,301 epoch [340/800] time: 5.02s train loss: 0.0574 accuracy: 0.9839 f1: 0.9837
2023-07-13 23:22:35,223 epoch [340/800] time: 0.92s val loss: 0.145 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:22:40,109 epoch [341/800] time: 4.89s train loss: 0.0576 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:22:40,970 epoch [341/800] time: 0.86s val loss: 0.1452 accuracy: 0.9502 f1: 0.9493
2023-07-13 23:22:45,789 epoch [342/800] time: 4.82s train loss: 0.0585 accuracy: 0.9835 f1: 0.9835
2023-07-13 23:22:46,640 epoch [342/800] time: 0.85s val loss: 0.1449 accuracy: 0.9502 f1: 0.9496
2023-07-13 23:22:51,678 epoch [343/800] time: 5.04s train loss: 0.0587 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:22:52,550 epoch [343/800] time: 0.87s val loss: 0.1453 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:22:57,136 epoch [344/800] time: 4.59s train loss: 0.0591 accuracy: 0.9832 f1: 0.9832
2023-07-13 23:22:57,993 epoch [344/800] time: 0.86s val loss: 0.1457 accuracy: 0.9509 f1: 0.9503
2023-07-13 23:23:02,660 epoch [345/800] time: 4.67s train loss: 0.0579 accuracy: 0.9841 f1: 0.9841
2023-07-13 23:23:03,462 epoch [345/800] time: 0.8s val loss: 0.1458 accuracy: 0.9503 f1: 0.9497
2023-07-13 23:23:08,181 epoch [346/800] time: 4.72s train loss: 0.0572 accuracy: 0.9841 f1: 0.9841
2023-07-13 23:23:09,063 epoch [346/800] time: 0.88s val loss: 0.1451 accuracy: 0.9502 f1: 0.9497
2023-07-13 23:23:13,652 epoch [347/800] time: 4.59s train loss: 0.0585 accuracy: 0.9832 f1: 0.9832
2023-07-13 23:23:14,518 epoch [347/800] time: 0.87s val loss: 0.1468 accuracy: 0.9497 f1: 0.9492
2023-07-13 23:23:19,228 epoch [348/800] time: 4.71s train loss: 0.0591 accuracy: 0.984 f1: 0.9839
2023-07-13 23:23:20,033 epoch [348/800] time: 0.81s val loss: 0.1461 accuracy: 0.9508 f1: 0.95
2023-07-13 23:23:25,314 epoch [349/800] time: 5.28s train loss: 0.0582 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:23:26,294 epoch [349/800] time: 0.98s val loss: 0.1452 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:23:31,949 epoch [350/800] time: 5.65s train loss: 0.059 accuracy: 0.9843 f1: 0.9841
2023-07-13 23:23:32,879 epoch [350/800] time: 0.93s val loss: 0.1476 accuracy: 0.9495 f1: 0.9489
2023-07-13 23:23:38,056 epoch [351/800] time: 5.18s train loss: 0.0585 accuracy: 0.9842 f1: 0.9841
2023-07-13 23:23:38,935 epoch [351/800] time: 0.88s val loss: 0.1463 accuracy: 0.95 f1: 0.9492
2023-07-13 23:23:44,085 epoch [352/800] time: 5.15s train loss: 0.0572 accuracy: 0.9843 f1: 0.9842
2023-07-13 23:23:44,991 epoch [352/800] time: 0.91s val loss: 0.1457 accuracy: 0.9508 f1: 0.9501
2023-07-13 23:23:50,024 epoch [353/800] time: 5.03s train loss: 0.0582 accuracy: 0.984 f1: 0.984
2023-07-13 23:23:50,951 epoch [353/800] time: 0.93s val loss: 0.1454 accuracy: 0.9506 f1: 0.95
2023-07-13 23:23:56,217 epoch [354/800] time: 5.27s train loss: 0.058 accuracy: 0.984 f1: 0.9841
2023-07-13 23:23:57,058 epoch [354/800] time: 0.84s val loss: 0.1462 accuracy: 0.9498 f1: 0.9491
2023-07-13 23:24:02,131 epoch [355/800] time: 5.07s train loss: 0.0591 accuracy: 0.9835 f1: 0.9835
2023-07-13 23:24:03,039 epoch [355/800] time: 0.91s val loss: 0.1453 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:24:08,084 epoch [356/800] time: 5.04s train loss: 0.0584 accuracy: 0.9836 f1: 0.9836
2023-07-13 23:24:09,003 epoch [356/800] time: 0.92s val loss: 0.1457 accuracy: 0.9506 f1: 0.95
2023-07-13 23:24:14,138 epoch [357/800] time: 5.14s train loss: 0.056 accuracy: 0.9845 f1: 0.9844
2023-07-13 23:24:14,979 epoch [357/800] time: 0.84s val loss: 0.1449 accuracy: 0.9507 f1: 0.95
2023-07-13 23:24:20,287 epoch [358/800] time: 5.31s train loss: 0.0565 accuracy: 0.9847 f1: 0.9847
2023-07-13 23:24:21,260 epoch [358/800] time: 0.97s val loss: 0.1456 accuracy: 0.9506 f1: 0.9498
2023-07-13 23:24:26,566 epoch [359/800] time: 5.31s train loss: 0.0581 accuracy: 0.9836 f1: 0.9835
2023-07-13 23:24:27,517 epoch [359/800] time: 0.95s val loss: 0.1451 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:24:32,909 epoch [360/800] time: 5.39s train loss: 0.0592 accuracy: 0.9831 f1: 0.9829
2023-07-13 23:24:33,740 epoch [360/800] time: 0.83s val loss: 0.1459 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:24:39,193 epoch [361/800] time: 5.45s train loss: 0.0576 accuracy: 0.9841 f1: 0.9841
2023-07-13 23:24:40,206 epoch [361/800] time: 1.01s val loss: 0.1453 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:24:45,816 epoch [362/800] time: 5.61s train loss: 0.0581 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:24:46,801 epoch [362/800] time: 0.98s val loss: 0.1465 accuracy: 0.9503 f1: 0.9495
2023-07-13 23:24:52,155 epoch [363/800] time: 5.35s train loss: 0.0585 accuracy: 0.9836 f1: 0.9834
2023-07-13 23:24:53,024 epoch [363/800] time: 0.87s val loss: 0.1454 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:24:58,370 epoch [364/800] time: 5.35s train loss: 0.0571 accuracy: 0.9845 f1: 0.9844
2023-07-13 23:24:59,288 epoch [364/800] time: 0.92s val loss: 0.1466 accuracy: 0.9505 f1: 0.9496
2023-07-13 23:25:04,574 epoch [365/800] time: 5.29s train loss: 0.0605 accuracy: 0.9834 f1: 0.9833
2023-07-13 23:25:05,451 epoch [365/800] time: 0.88s val loss: 0.1468 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:25:10,663 epoch [366/800] time: 5.21s train loss: 0.0587 accuracy: 0.983 f1: 0.983
2023-07-13 23:25:11,539 epoch [366/800] time: 0.88s val loss: 0.1453 accuracy: 0.9507 f1: 0.95
2023-07-13 23:25:16,787 epoch [367/800] time: 5.25s train loss: 0.0576 accuracy: 0.9841 f1: 0.9841
2023-07-13 23:25:17,687 epoch [367/800] time: 0.9s val loss: 0.1456 accuracy: 0.9497 f1: 0.9492
2023-07-13 23:25:22,953 epoch [368/800] time: 5.27s train loss: 0.0584 accuracy: 0.9836 f1: 0.9835
2023-07-13 23:25:23,916 epoch [368/800] time: 0.96s val loss: 0.145 accuracy: 0.9512 f1: 0.9505
2023-07-13 23:25:29,070 epoch [369/800] time: 5.15s train loss: 0.059 accuracy: 0.9831 f1: 0.9829
2023-07-13 23:25:29,904 epoch [369/800] time: 0.83s val loss: 0.1451 accuracy: 0.9505 f1: 0.9497
2023-07-13 23:25:35,027 epoch [370/800] time: 5.12s train loss: 0.0595 accuracy: 0.9831 f1: 0.9829
2023-07-13 23:25:35,892 epoch [370/800] time: 0.86s val loss: 0.146 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:25:40,716 epoch [371/800] time: 4.82s train loss: 0.059 accuracy: 0.9836 f1: 0.9836
2023-07-13 23:25:41,672 epoch [371/800] time: 0.96s val loss: 0.1454 accuracy: 0.9506 f1: 0.95
2023-07-13 23:25:46,598 epoch [372/800] time: 4.93s train loss: 0.0577 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:25:47,411 epoch [372/800] time: 0.81s val loss: 0.145 accuracy: 0.9508 f1: 0.9502
2023-07-13 23:25:52,277 epoch [373/800] time: 4.87s train loss: 0.0575 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:25:53,141 epoch [373/800] time: 0.86s val loss: 0.1463 accuracy: 0.9506 f1: 0.9498
2023-07-13 23:25:58,228 epoch [374/800] time: 5.09s train loss: 0.059 accuracy: 0.9841 f1: 0.984
2023-07-13 23:25:59,116 epoch [374/800] time: 0.89s val loss: 0.1458 accuracy: 0.9503 f1: 0.9497
2023-07-13 23:26:03,963 epoch [375/800] time: 4.85s train loss: 0.0576 accuracy: 0.9845 f1: 0.9844
2023-07-13 23:26:04,770 epoch [375/800] time: 0.81s val loss: 0.1454 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:26:09,678 epoch [376/800] time: 4.91s train loss: 0.0603 accuracy: 0.9835 f1: 0.9833
2023-07-13 23:26:10,574 epoch [376/800] time: 0.9s val loss: 0.1476 accuracy: 0.9497 f1: 0.9489
2023-07-13 23:26:15,470 epoch [377/800] time: 4.9s train loss: 0.0578 accuracy: 0.9844 f1: 0.9843
2023-07-13 23:26:16,346 epoch [377/800] time: 0.88s val loss: 0.1452 accuracy: 0.9507 f1: 0.9499
2023-07-13 23:26:21,013 epoch [378/800] time: 4.67s train loss: 0.058 accuracy: 0.9843 f1: 0.9842
2023-07-13 23:26:21,842 epoch [378/800] time: 0.83s val loss: 0.1461 accuracy: 0.9501 f1: 0.9494
2023-07-13 23:26:26,574 epoch [379/800] time: 4.73s train loss: 0.0601 accuracy: 0.9834 f1: 0.9833
2023-07-13 23:26:27,417 epoch [379/800] time: 0.84s val loss: 0.1457 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:26:32,493 epoch [380/800] time: 5.08s train loss: 0.0575 accuracy: 0.9841 f1: 0.9841
2023-07-13 23:26:33,471 epoch [380/800] time: 0.98s val loss: 0.1462 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:26:38,718 epoch [381/800] time: 5.25s train loss: 0.0574 accuracy: 0.9842 f1: 0.9841
2023-07-13 23:26:39,538 epoch [381/800] time: 0.82s val loss: 0.1448 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:26:44,472 epoch [382/800] time: 4.93s train loss: 0.0593 accuracy: 0.9828 f1: 0.9827
2023-07-13 23:26:45,455 epoch [382/800] time: 0.98s val loss: 0.1458 accuracy: 0.9507 f1: 0.9502
2023-07-13 23:26:50,860 epoch [383/800] time: 5.41s train loss: 0.0582 accuracy: 0.9843 f1: 0.9842
2023-07-13 23:26:51,781 epoch [383/800] time: 0.92s val loss: 0.1454 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:26:57,057 epoch [384/800] time: 5.28s train loss: 0.058 accuracy: 0.9841 f1: 0.9841
2023-07-13 23:26:57,889 epoch [384/800] time: 0.83s val loss: 0.1454 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:27:02,926 epoch [385/800] time: 5.04s train loss: 0.0586 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:27:03,833 epoch [385/800] time: 0.91s val loss: 0.1452 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:27:08,799 epoch [386/800] time: 4.97s train loss: 0.0593 accuracy: 0.983 f1: 0.9829
2023-07-13 23:27:09,661 epoch [386/800] time: 0.86s val loss: 0.146 accuracy: 0.9505 f1: 0.9497
2023-07-13 23:27:14,448 epoch [387/800] time: 4.79s train loss: 0.0583 accuracy: 0.9839 f1: 0.9837
2023-07-13 23:27:15,250 epoch [387/800] time: 0.8s val loss: 0.1457 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:27:20,888 epoch [388/800] time: 5.64s train loss: 0.0581 accuracy: 0.9838 f1: 0.9836
2023-07-13 23:27:21,850 epoch [388/800] time: 0.96s val loss: 0.1455 accuracy: 0.9511 f1: 0.9504
2023-07-13 23:27:27,104 epoch [389/800] time: 5.25s train loss: 0.0581 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:27:28,016 epoch [389/800] time: 0.91s val loss: 0.1455 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:27:33,148 epoch [390/800] time: 5.13s train loss: 0.0591 accuracy: 0.9836 f1: 0.9836
2023-07-13 23:27:33,996 epoch [390/800] time: 0.85s val loss: 0.1449 accuracy: 0.9503 f1: 0.9497
2023-07-13 23:27:39,148 epoch [391/800] time: 5.15s train loss: 0.0566 accuracy: 0.9844 f1: 0.9843
2023-07-13 23:27:40,063 epoch [391/800] time: 0.91s val loss: 0.1454 accuracy: 0.9509 f1: 0.9503
2023-07-13 23:27:45,133 epoch [392/800] time: 5.07s train loss: 0.0568 accuracy: 0.9843 f1: 0.9842
2023-07-13 23:27:46,051 epoch [392/800] time: 0.92s val loss: 0.1454 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:27:51,369 epoch [393/800] time: 5.32s train loss: 0.0577 accuracy: 0.984 f1: 0.9837
2023-07-13 23:27:52,209 epoch [393/800] time: 0.84s val loss: 0.1459 accuracy: 0.9509 f1: 0.9503
2023-07-13 23:27:57,202 epoch [394/800] time: 4.99s train loss: 0.0579 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:27:58,094 epoch [394/800] time: 0.89s val loss: 0.1461 accuracy: 0.9507 f1: 0.9499
2023-07-13 23:28:03,285 epoch [395/800] time: 5.19s train loss: 0.0584 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:28:04,194 epoch [395/800] time: 0.91s val loss: 0.1461 accuracy: 0.9502 f1: 0.9496
2023-07-13 23:28:09,188 epoch [396/800] time: 4.99s train loss: 0.0587 accuracy: 0.9838 f1: 0.9836
2023-07-13 23:28:10,026 epoch [396/800] time: 0.84s val loss: 0.1455 accuracy: 0.9507 f1: 0.95
2023-07-13 23:28:15,201 epoch [397/800] time: 5.17s train loss: 0.0597 accuracy: 0.9834 f1: 0.9833
2023-07-13 23:28:16,121 epoch [397/800] time: 0.92s val loss: 0.1467 accuracy: 0.95 f1: 0.9492
2023-07-13 23:28:21,053 epoch [398/800] time: 4.93s train loss: 0.059 accuracy: 0.9844 f1: 0.9843
2023-07-13 23:28:21,982 epoch [398/800] time: 0.93s val loss: 0.1467 accuracy: 0.9498 f1: 0.949
2023-07-13 23:28:27,714 epoch [399/800] time: 5.73s train loss: 0.0576 accuracy: 0.9836 f1: 0.9835
2023-07-13 23:28:28,653 epoch [399/800] time: 0.94s val loss: 0.1455 accuracy: 0.9509 f1: 0.9501
2023-07-13 23:28:33,907 epoch [400/800] time: 5.25s train loss: 0.0583 accuracy: 0.9834 f1: 0.9833
2023-07-13 23:28:34,888 epoch [400/800] time: 0.98s val loss: 0.1455 accuracy: 0.9506 f1: 0.95
2023-07-13 23:28:40,385 epoch [401/800] time: 5.5s train loss: 0.0581 accuracy: 0.9837 f1: 0.9837
2023-07-13 23:28:41,533 epoch [401/800] time: 1.15s val loss: 0.1455 accuracy: 0.9503 f1: 0.9495
2023-07-13 23:28:47,097 epoch [402/800] time: 5.56s train loss: 0.0576 accuracy: 0.9842 f1: 0.9841
2023-07-13 23:28:47,945 epoch [402/800] time: 0.85s val loss: 0.1456 accuracy: 0.9506 f1: 0.95
2023-07-13 23:28:53,274 epoch [403/800] time: 5.33s train loss: 0.0587 accuracy: 0.9832 f1: 0.9831
2023-07-13 23:28:54,252 epoch [403/800] time: 0.98s val loss: 0.1454 accuracy: 0.95 f1: 0.9493
2023-07-13 23:28:59,481 epoch [404/800] time: 5.23s train loss: 0.0584 accuracy: 0.984 f1: 0.9839
2023-07-13 23:29:00,387 epoch [404/800] time: 0.91s val loss: 0.1463 accuracy: 0.9505 f1: 0.9497
2023-07-13 23:29:05,964 epoch [405/800] time: 5.58s train loss: 0.0583 accuracy: 0.984 f1: 0.9839
2023-07-13 23:29:06,938 epoch [405/800] time: 0.97s val loss: 0.1455 accuracy: 0.9506 f1: 0.9498
2023-07-13 23:29:12,228 epoch [406/800] time: 5.29s train loss: 0.058 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:29:13,205 epoch [406/800] time: 0.98s val loss: 0.1455 accuracy: 0.9502 f1: 0.9494
2023-07-13 23:29:18,503 epoch [407/800] time: 5.3s train loss: 0.0588 accuracy: 0.9841 f1: 0.984
2023-07-13 23:29:19,427 epoch [407/800] time: 0.92s val loss: 0.1461 accuracy: 0.95 f1: 0.9492
2023-07-13 23:29:24,601 epoch [408/800] time: 5.17s train loss: 0.0578 accuracy: 0.9839 f1: 0.9837
2023-07-13 23:29:25,503 epoch [408/800] time: 0.9s val loss: 0.1461 accuracy: 0.9511 f1: 0.9503
2023-07-13 23:29:30,670 epoch [409/800] time: 5.17s train loss: 0.0582 accuracy: 0.9832 f1: 0.983
2023-07-13 23:29:31,592 epoch [409/800] time: 0.92s val loss: 0.1453 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:29:36,604 epoch [410/800] time: 5.01s train loss: 0.0578 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:29:37,500 epoch [410/800] time: 0.9s val loss: 0.1461 accuracy: 0.9509 f1: 0.9501
2023-07-13 23:29:42,691 epoch [411/800] time: 5.19s train loss: 0.0594 accuracy: 0.9833 f1: 0.9832
2023-07-13 23:29:43,546 epoch [411/800] time: 0.85s val loss: 0.1457 accuracy: 0.9511 f1: 0.9505
2023-07-13 23:29:48,545 epoch [412/800] time: 5.0s train loss: 0.0584 accuracy: 0.9836 f1: 0.9835
2023-07-13 23:29:49,429 epoch [412/800] time: 0.88s val loss: 0.1465 accuracy: 0.95 f1: 0.9494
2023-07-13 23:29:54,152 epoch [413/800] time: 4.72s train loss: 0.0573 accuracy: 0.9841 f1: 0.9839
2023-07-13 23:29:55,030 epoch [413/800] time: 0.88s val loss: 0.1459 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:29:59,682 epoch [414/800] time: 4.65s train loss: 0.0577 accuracy: 0.9841 f1: 0.9839
2023-07-13 23:30:00,488 epoch [414/800] time: 0.81s val loss: 0.1461 accuracy: 0.9504 f1: 0.9499
2023-07-13 23:30:05,360 epoch [415/800] time: 4.87s train loss: 0.0582 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:30:06,232 epoch [415/800] time: 0.87s val loss: 0.1458 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:30:11,004 epoch [416/800] time: 4.77s train loss: 0.0598 accuracy: 0.983 f1: 0.9829
2023-07-13 23:30:11,852 epoch [416/800] time: 0.85s val loss: 0.1451 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:30:16,665 epoch [417/800] time: 4.81s train loss: 0.0591 accuracy: 0.9835 f1: 0.9835
2023-07-13 23:30:17,533 epoch [417/800] time: 0.87s val loss: 0.1458 accuracy: 0.9504 f1: 0.9498
2023-07-13 23:30:22,458 epoch [418/800] time: 4.92s train loss: 0.0578 accuracy: 0.9841 f1: 0.9841
2023-07-13 23:30:23,312 epoch [418/800] time: 0.85s val loss: 0.1458 accuracy: 0.9502 f1: 0.9496
2023-07-13 23:30:28,068 epoch [419/800] time: 4.76s train loss: 0.0569 accuracy: 0.9842 f1: 0.984
2023-07-13 23:30:28,916 epoch [419/800] time: 0.85s val loss: 0.1459 accuracy: 0.9501 f1: 0.9493
2023-07-13 23:30:33,650 epoch [420/800] time: 4.73s train loss: 0.0586 accuracy: 0.9838 f1: 0.9836
2023-07-13 23:30:34,449 epoch [420/800] time: 0.8s val loss: 0.1457 accuracy: 0.9507 f1: 0.9502
2023-07-13 23:30:39,120 epoch [421/800] time: 4.67s train loss: 0.0572 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:30:39,958 epoch [421/800] time: 0.84s val loss: 0.1451 accuracy: 0.9505 f1: 0.9497
2023-07-13 23:30:44,585 epoch [422/800] time: 4.63s train loss: 0.058 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:30:45,421 epoch [422/800] time: 0.84s val loss: 0.145 accuracy: 0.9508 f1: 0.9501
2023-07-13 23:30:50,366 epoch [423/800] time: 4.95s train loss: 0.0587 accuracy: 0.9837 f1: 0.9835
2023-07-13 23:30:51,302 epoch [423/800] time: 0.94s val loss: 0.1457 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:30:56,456 epoch [424/800] time: 5.15s train loss: 0.0568 accuracy: 0.9844 f1: 0.9843
2023-07-13 23:30:57,357 epoch [424/800] time: 0.9s val loss: 0.1453 accuracy: 0.9503 f1: 0.9497
2023-07-13 23:31:02,529 epoch [425/800] time: 5.17s train loss: 0.0582 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:31:03,454 epoch [425/800] time: 0.92s val loss: 0.1471 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:31:08,808 epoch [426/800] time: 5.35s train loss: 0.0579 accuracy: 0.9839 f1: 0.9837
2023-07-13 23:31:09,700 epoch [426/800] time: 0.89s val loss: 0.1455 accuracy: 0.9506 f1: 0.95
2023-07-13 23:31:14,873 epoch [427/800] time: 5.17s train loss: 0.059 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:31:15,769 epoch [427/800] time: 0.9s val loss: 0.1462 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:31:20,758 epoch [428/800] time: 4.99s train loss: 0.0579 accuracy: 0.9841 f1: 0.984
2023-07-13 23:31:21,657 epoch [428/800] time: 0.9s val loss: 0.1463 accuracy: 0.9506 f1: 0.95
2023-07-13 23:31:26,766 epoch [429/800] time: 5.11s train loss: 0.0579 accuracy: 0.9842 f1: 0.984
2023-07-13 23:31:27,657 epoch [429/800] time: 0.89s val loss: 0.1457 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:31:32,906 epoch [430/800] time: 5.25s train loss: 0.0578 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:31:33,814 epoch [430/800] time: 0.91s val loss: 0.1459 accuracy: 0.9507 f1: 0.9499
2023-07-13 23:31:38,752 epoch [431/800] time: 4.94s train loss: 0.057 accuracy: 0.984 f1: 0.984
2023-07-13 23:31:39,654 epoch [431/800] time: 0.9s val loss: 0.1453 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:31:44,709 epoch [432/800] time: 5.06s train loss: 0.0583 accuracy: 0.9837 f1: 0.9837
2023-07-13 23:31:45,578 epoch [432/800] time: 0.87s val loss: 0.1461 accuracy: 0.9498 f1: 0.9491
2023-07-13 23:31:50,641 epoch [433/800] time: 5.06s train loss: 0.0578 accuracy: 0.9839 f1: 0.9837
2023-07-13 23:31:51,528 epoch [433/800] time: 0.89s val loss: 0.1453 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:31:56,443 epoch [434/800] time: 4.91s train loss: 0.0585 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:31:57,357 epoch [434/800] time: 0.91s val loss: 0.1477 accuracy: 0.9506 f1: 0.9498
2023-07-13 23:32:02,397 epoch [435/800] time: 5.04s train loss: 0.0572 accuracy: 0.9843 f1: 0.9842
2023-07-13 23:32:03,269 epoch [435/800] time: 0.87s val loss: 0.1455 accuracy: 0.9507 f1: 0.95
2023-07-13 23:32:08,497 epoch [436/800] time: 5.23s train loss: 0.0588 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:32:09,437 epoch [436/800] time: 0.94s val loss: 0.1464 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:32:14,509 epoch [437/800] time: 5.07s train loss: 0.0579 accuracy: 0.9837 f1: 0.9837
2023-07-13 23:32:15,370 epoch [437/800] time: 0.86s val loss: 0.1462 accuracy: 0.9506 f1: 0.95
2023-07-13 23:32:20,195 epoch [438/800] time: 4.82s train loss: 0.0577 accuracy: 0.984 f1: 0.9839
2023-07-13 23:32:21,010 epoch [438/800] time: 0.82s val loss: 0.1465 accuracy: 0.9504 f1: 0.9498
2023-07-13 23:32:25,787 epoch [439/800] time: 4.78s train loss: 0.0582 accuracy: 0.9833 f1: 0.9832
2023-07-13 23:32:26,651 epoch [439/800] time: 0.86s val loss: 0.1461 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:32:31,537 epoch [440/800] time: 4.89s train loss: 0.0584 accuracy: 0.9834 f1: 0.9832
2023-07-13 23:32:32,393 epoch [440/800] time: 0.86s val loss: 0.147 accuracy: 0.9503 f1: 0.9495
2023-07-13 23:32:37,183 epoch [441/800] time: 4.79s train loss: 0.0571 accuracy: 0.9842 f1: 0.9841
2023-07-13 23:32:38,010 epoch [441/800] time: 0.83s val loss: 0.1452 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:32:42,771 epoch [442/800] time: 4.76s train loss: 0.0588 accuracy: 0.9832 f1: 0.9832
2023-07-13 23:32:43,661 epoch [442/800] time: 0.89s val loss: 0.1454 accuracy: 0.9506 f1: 0.9498
2023-07-13 23:32:48,607 epoch [443/800] time: 4.95s train loss: 0.0572 accuracy: 0.9841 f1: 0.9839
2023-07-13 23:32:49,502 epoch [443/800] time: 0.89s val loss: 0.1461 accuracy: 0.9505 f1: 0.9497
2023-07-13 23:32:54,461 epoch [444/800] time: 4.96s train loss: 0.0587 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:32:55,268 epoch [444/800] time: 0.81s val loss: 0.1459 accuracy: 0.9504 f1: 0.9496
2023-07-13 23:33:00,131 epoch [445/800] time: 4.86s train loss: 0.0575 accuracy: 0.9843 f1: 0.9842
2023-07-13 23:33:01,002 epoch [445/800] time: 0.87s val loss: 0.1457 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:33:06,256 epoch [446/800] time: 5.25s train loss: 0.0584 accuracy: 0.9839 f1: 0.9839
2023-07-13 23:33:07,201 epoch [446/800] time: 0.94s val loss: 0.1454 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:33:12,500 epoch [447/800] time: 5.3s train loss: 0.0589 accuracy: 0.9836 f1: 0.9836
2023-07-13 23:33:13,324 epoch [447/800] time: 0.82s val loss: 0.1463 accuracy: 0.9504 f1: 0.9498
2023-07-13 23:33:18,217 epoch [448/800] time: 4.89s train loss: 0.0582 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:33:19,131 epoch [448/800] time: 0.91s val loss: 0.1458 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:33:24,050 epoch [449/800] time: 4.92s train loss: 0.0583 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:33:24,906 epoch [449/800] time: 0.86s val loss: 0.1459 accuracy: 0.9503 f1: 0.9497
2023-07-13 23:33:29,859 epoch [450/800] time: 4.95s train loss: 0.0604 accuracy: 0.9834 f1: 0.9833
2023-07-13 23:33:30,667 epoch [450/800] time: 0.81s val loss: 0.1465 accuracy: 0.9501 f1: 0.9495
2023-07-13 23:33:35,461 epoch [451/800] time: 4.79s train loss: 0.0585 accuracy: 0.9842 f1: 0.9841
2023-07-13 23:33:36,310 epoch [451/800] time: 0.85s val loss: 0.1452 accuracy: 0.9506 f1: 0.9498
2023-07-13 23:33:41,219 epoch [452/800] time: 4.91s train loss: 0.058 accuracy: 0.9833 f1: 0.9831
2023-07-13 23:33:42,084 epoch [452/800] time: 0.86s val loss: 0.1453 accuracy: 0.9508 f1: 0.9501
2023-07-13 23:33:46,919 epoch [453/800] time: 4.83s train loss: 0.058 accuracy: 0.984 f1: 0.9839
2023-07-13 23:33:47,719 epoch [453/800] time: 0.8s val loss: 0.145 accuracy: 0.9506 f1: 0.95
2023-07-13 23:33:52,495 epoch [454/800] time: 4.78s train loss: 0.0583 accuracy: 0.9838 f1: 0.9836
2023-07-13 23:33:53,391 epoch [454/800] time: 0.9s val loss: 0.1449 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:33:58,314 epoch [455/800] time: 4.92s train loss: 0.0581 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:33:59,179 epoch [455/800] time: 0.86s val loss: 0.1457 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:34:03,975 epoch [456/800] time: 4.8s train loss: 0.0595 accuracy: 0.9836 f1: 0.9835
2023-07-13 23:34:04,775 epoch [456/800] time: 0.8s val loss: 0.1459 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:34:09,711 epoch [457/800] time: 4.94s train loss: 0.0583 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:34:10,589 epoch [457/800] time: 0.88s val loss: 0.1477 accuracy: 0.9501 f1: 0.9493
2023-07-13 23:34:15,318 epoch [458/800] time: 4.73s train loss: 0.0585 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:34:16,173 epoch [458/800] time: 0.86s val loss: 0.1458 accuracy: 0.951 f1: 0.9503
2023-07-13 23:34:20,934 epoch [459/800] time: 4.76s train loss: 0.0592 accuracy: 0.9837 f1: 0.9837
2023-07-13 23:34:21,736 epoch [459/800] time: 0.8s val loss: 0.1458 accuracy: 0.9506 f1: 0.9501
2023-07-13 23:34:26,535 epoch [460/800] time: 4.8s train loss: 0.0583 accuracy: 0.9839 f1: 0.9837
2023-07-13 23:34:27,379 epoch [460/800] time: 0.84s val loss: 0.1452 accuracy: 0.9508 f1: 0.9501
2023-07-13 23:34:32,155 epoch [461/800] time: 4.78s train loss: 0.0575 accuracy: 0.9837 f1: 0.9837
2023-07-13 23:34:33,009 epoch [461/800] time: 0.85s val loss: 0.1451 accuracy: 0.9508 f1: 0.9502
2023-07-13 23:34:37,772 epoch [462/800] time: 4.76s train loss: 0.0575 accuracy: 0.984 f1: 0.9839
2023-07-13 23:34:38,584 epoch [462/800] time: 0.81s val loss: 0.146 accuracy: 0.95 f1: 0.9495
2023-07-13 23:34:43,338 epoch [463/800] time: 4.75s train loss: 0.06 accuracy: 0.9835 f1: 0.9835
2023-07-13 23:34:44,204 epoch [463/800] time: 0.87s val loss: 0.1459 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:34:48,785 epoch [464/800] time: 4.58s train loss: 0.0575 accuracy: 0.984 f1: 0.984
2023-07-13 23:34:49,670 epoch [464/800] time: 0.88s val loss: 0.1458 accuracy: 0.9509 f1: 0.9502
2023-07-13 23:34:54,443 epoch [465/800] time: 4.77s train loss: 0.0579 accuracy: 0.9841 f1: 0.984
2023-07-13 23:34:55,248 epoch [465/800] time: 0.8s val loss: 0.1458 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:34:59,899 epoch [466/800] time: 4.65s train loss: 0.0584 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:35:00,751 epoch [466/800] time: 0.85s val loss: 0.1452 accuracy: 0.9501 f1: 0.9493
2023-07-13 23:35:05,374 epoch [467/800] time: 4.62s train loss: 0.0594 accuracy: 0.9831 f1: 0.983
2023-07-13 23:35:06,215 epoch [467/800] time: 0.84s val loss: 0.1462 accuracy: 0.9503 f1: 0.9495
2023-07-13 23:35:10,758 epoch [468/800] time: 4.54s train loss: 0.0576 accuracy: 0.984 f1: 0.9839
2023-07-13 23:35:11,556 epoch [468/800] time: 0.8s val loss: 0.1473 accuracy: 0.95 f1: 0.9491
2023-07-13 23:35:16,100 epoch [469/800] time: 4.54s train loss: 0.057 accuracy: 0.9843 f1: 0.9842
2023-07-13 23:35:16,941 epoch [469/800] time: 0.84s val loss: 0.1452 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:35:21,622 epoch [470/800] time: 4.68s train loss: 0.0576 accuracy: 0.9843 f1: 0.9842
2023-07-13 23:35:22,464 epoch [470/800] time: 0.84s val loss: 0.1455 accuracy: 0.9507 f1: 0.95
2023-07-13 23:35:27,239 epoch [471/800] time: 4.78s train loss: 0.0583 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:35:28,039 epoch [471/800] time: 0.8s val loss: 0.1458 accuracy: 0.9504 f1: 0.9496
2023-07-13 23:35:32,649 epoch [472/800] time: 4.61s train loss: 0.0572 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:35:33,494 epoch [472/800] time: 0.85s val loss: 0.1453 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:35:38,122 epoch [473/800] time: 4.63s train loss: 0.0587 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:35:38,967 epoch [473/800] time: 0.84s val loss: 0.1466 accuracy: 0.9497 f1: 0.9489
2023-07-13 23:35:43,686 epoch [474/800] time: 4.72s train loss: 0.0601 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:35:44,484 epoch [474/800] time: 0.8s val loss: 0.1461 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:35:49,254 epoch [475/800] time: 4.77s train loss: 0.0582 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:35:50,109 epoch [475/800] time: 0.86s val loss: 0.1455 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:35:54,818 epoch [476/800] time: 4.71s train loss: 0.0592 accuracy: 0.9834 f1: 0.9833
2023-07-13 23:35:55,665 epoch [476/800] time: 0.85s val loss: 0.1464 accuracy: 0.9507 f1: 0.9499
2023-07-13 23:36:00,382 epoch [477/800] time: 4.72s train loss: 0.0612 accuracy: 0.9842 f1: 0.984
2023-07-13 23:36:01,180 epoch [477/800] time: 0.8s val loss: 0.1477 accuracy: 0.95 f1: 0.9492
2023-07-13 23:36:05,885 epoch [478/800] time: 4.7s train loss: 0.0572 accuracy: 0.9848 f1: 0.9848
2023-07-13 23:36:06,730 epoch [478/800] time: 0.84s val loss: 0.145 accuracy: 0.9508 f1: 0.9501
2023-07-13 23:36:11,364 epoch [479/800] time: 4.63s train loss: 0.0585 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:36:12,207 epoch [479/800] time: 0.84s val loss: 0.1458 accuracy: 0.9508 f1: 0.9501
2023-07-13 23:36:16,976 epoch [480/800] time: 4.77s train loss: 0.0589 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:36:17,775 epoch [480/800] time: 0.8s val loss: 0.1456 accuracy: 0.9504 f1: 0.9498
2023-07-13 23:36:22,507 epoch [481/800] time: 4.73s train loss: 0.0579 accuracy: 0.9837 f1: 0.9837
2023-07-13 23:36:23,364 epoch [481/800] time: 0.86s val loss: 0.1463 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:36:27,964 epoch [482/800] time: 4.6s train loss: 0.058 accuracy: 0.9836 f1: 0.9835
2023-07-13 23:36:28,815 epoch [482/800] time: 0.85s val loss: 0.1453 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:36:34,001 epoch [483/800] time: 5.19s train loss: 0.0569 accuracy: 0.9842 f1: 0.9841
2023-07-13 23:36:34,901 epoch [483/800] time: 0.9s val loss: 0.1453 accuracy: 0.9502 f1: 0.9493
2023-07-13 23:36:40,008 epoch [484/800] time: 5.11s train loss: 0.0583 accuracy: 0.9836 f1: 0.9834
2023-07-13 23:36:40,901 epoch [484/800] time: 0.89s val loss: 0.1467 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:36:45,740 epoch [485/800] time: 4.84s train loss: 0.0576 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:36:46,714 epoch [485/800] time: 0.97s val loss: 0.1459 accuracy: 0.9507 f1: 0.95
2023-07-13 23:36:51,754 epoch [486/800] time: 5.04s train loss: 0.059 accuracy: 0.9832 f1: 0.9831
2023-07-13 23:36:52,568 epoch [486/800] time: 0.81s val loss: 0.1459 accuracy: 0.9504 f1: 0.9496
2023-07-13 23:36:57,339 epoch [487/800] time: 4.77s train loss: 0.0578 accuracy: 0.9839 f1: 0.9839
2023-07-13 23:36:58,230 epoch [487/800] time: 0.89s val loss: 0.1458 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:37:02,814 epoch [488/800] time: 4.58s train loss: 0.0583 accuracy: 0.9838 f1: 0.9836
2023-07-13 23:37:03,678 epoch [488/800] time: 0.86s val loss: 0.1465 accuracy: 0.9507 f1: 0.95
2023-07-13 23:37:08,616 epoch [489/800] time: 4.94s train loss: 0.0589 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:37:09,425 epoch [489/800] time: 0.81s val loss: 0.1458 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:37:13,999 epoch [490/800] time: 4.57s train loss: 0.0573 accuracy: 0.9841 f1: 0.9839
2023-07-13 23:37:14,848 epoch [490/800] time: 0.85s val loss: 0.146 accuracy: 0.9508 f1: 0.9502
2023-07-13 23:37:20,033 epoch [491/800] time: 5.18s train loss: 0.0584 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:37:20,902 epoch [491/800] time: 0.87s val loss: 0.1458 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:37:25,751 epoch [492/800] time: 4.85s train loss: 0.0617 accuracy: 0.984 f1: 0.9839
2023-07-13 23:37:26,570 epoch [492/800] time: 0.82s val loss: 0.1464 accuracy: 0.95 f1: 0.9493
2023-07-13 23:37:31,415 epoch [493/800] time: 4.84s train loss: 0.0573 accuracy: 0.9842 f1: 0.9841
2023-07-13 23:37:32,261 epoch [493/800] time: 0.85s val loss: 0.1446 accuracy: 0.9508 f1: 0.9502
2023-07-13 23:37:37,021 epoch [494/800] time: 4.76s train loss: 0.0577 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:37:37,863 epoch [494/800] time: 0.84s val loss: 0.1453 accuracy: 0.9509 f1: 0.9502
2023-07-13 23:37:42,662 epoch [495/800] time: 4.8s train loss: 0.058 accuracy: 0.9838 f1: 0.9836
2023-07-13 23:37:43,465 epoch [495/800] time: 0.8s val loss: 0.1452 accuracy: 0.9509 f1: 0.9502
2023-07-13 23:37:48,262 epoch [496/800] time: 4.8s train loss: 0.0584 accuracy: 0.9832 f1: 0.9831
2023-07-13 23:37:49,107 epoch [496/800] time: 0.84s val loss: 0.1453 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:37:53,841 epoch [497/800] time: 4.73s train loss: 0.0581 accuracy: 0.9836 f1: 0.9835
2023-07-13 23:37:54,685 epoch [497/800] time: 0.84s val loss: 0.1455 accuracy: 0.9509 f1: 0.9503
2023-07-13 23:37:59,426 epoch [498/800] time: 4.74s train loss: 0.0579 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:38:00,228 epoch [498/800] time: 0.8s val loss: 0.1453 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:38:04,987 epoch [499/800] time: 4.76s train loss: 0.0568 accuracy: 0.9841 f1: 0.984
2023-07-13 23:38:05,843 epoch [499/800] time: 0.86s val loss: 0.1454 accuracy: 0.9509 f1: 0.9502
2023-07-13 23:38:10,613 epoch [500/800] time: 4.77s train loss: 0.0571 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:38:11,461 epoch [500/800] time: 0.85s val loss: 0.1458 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:38:16,285 epoch [501/800] time: 4.82s train loss: 0.0576 accuracy: 0.9843 f1: 0.9842
2023-07-13 23:38:17,085 epoch [501/800] time: 0.8s val loss: 0.1458 accuracy: 0.9502 f1: 0.9494
2023-07-13 23:38:21,728 epoch [502/800] time: 4.64s train loss: 0.0589 accuracy: 0.9832 f1: 0.9832
2023-07-13 23:38:22,605 epoch [502/800] time: 0.88s val loss: 0.1461 accuracy: 0.9498 f1: 0.9493
2023-07-13 23:38:27,533 epoch [503/800] time: 4.93s train loss: 0.0587 accuracy: 0.9829 f1: 0.9828
2023-07-13 23:38:28,387 epoch [503/800] time: 0.85s val loss: 0.1462 accuracy: 0.9501 f1: 0.9492
2023-07-13 23:38:33,339 epoch [504/800] time: 4.95s train loss: 0.0581 accuracy: 0.9843 f1: 0.9842
2023-07-13 23:38:34,192 epoch [504/800] time: 0.85s val loss: 0.1456 accuracy: 0.9502 f1: 0.9496
2023-07-13 23:38:39,307 epoch [505/800] time: 5.11s train loss: 0.0586 accuracy: 0.9837 f1: 0.9837
2023-07-13 23:38:40,191 epoch [505/800] time: 0.88s val loss: 0.1468 accuracy: 0.9502 f1: 0.9494
2023-07-13 23:38:45,131 epoch [506/800] time: 4.94s train loss: 0.0575 accuracy: 0.984 f1: 0.9839
2023-07-13 23:38:46,069 epoch [506/800] time: 0.94s val loss: 0.1462 accuracy: 0.9497 f1: 0.9491
2023-07-13 23:38:51,177 epoch [507/800] time: 5.11s train loss: 0.0576 accuracy: 0.9842 f1: 0.984
2023-07-13 23:38:52,028 epoch [507/800] time: 0.85s val loss: 0.1451 accuracy: 0.9509 f1: 0.9503
2023-07-13 23:38:56,903 epoch [508/800] time: 4.87s train loss: 0.0583 accuracy: 0.9835 f1: 0.9835
2023-07-13 23:38:57,780 epoch [508/800] time: 0.88s val loss: 0.1456 accuracy: 0.9505 f1: 0.95
2023-07-13 23:39:02,886 epoch [509/800] time: 5.11s train loss: 0.0581 accuracy: 0.984 f1: 0.984
2023-07-13 23:39:03,807 epoch [509/800] time: 0.92s val loss: 0.1451 accuracy: 0.9495 f1: 0.9489
2023-07-13 23:39:08,828 epoch [510/800] time: 5.02s train loss: 0.0588 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:39:09,642 epoch [510/800] time: 0.81s val loss: 0.147 accuracy: 0.9497 f1: 0.9492
2023-07-13 23:39:14,655 epoch [511/800] time: 5.01s train loss: 0.0578 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:39:15,565 epoch [511/800] time: 0.91s val loss: 0.1453 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:39:20,433 epoch [512/800] time: 4.87s train loss: 0.0576 accuracy: 0.9841 f1: 0.984
2023-07-13 23:39:21,288 epoch [512/800] time: 0.85s val loss: 0.1455 accuracy: 0.9508 f1: 0.9501
2023-07-13 23:39:25,973 epoch [513/800] time: 4.68s train loss: 0.0588 accuracy: 0.9838 f1: 0.9838
2023-07-13 23:39:26,811 epoch [513/800] time: 0.84s val loss: 0.1456 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:39:31,982 epoch [514/800] time: 5.17s train loss: 0.0576 accuracy: 0.9838 f1: 0.9836
2023-07-13 23:39:32,870 epoch [514/800] time: 0.89s val loss: 0.1457 accuracy: 0.9502 f1: 0.9496
2023-07-13 23:39:37,680 epoch [515/800] time: 4.81s train loss: 0.0593 accuracy: 0.9841 f1: 0.9841
2023-07-13 23:39:38,533 epoch [515/800] time: 0.85s val loss: 0.1464 accuracy: 0.9499 f1: 0.9493
2023-07-13 23:39:43,570 epoch [516/800] time: 5.04s train loss: 0.058 accuracy: 0.9838 f1: 0.9838
2023-07-13 23:39:44,425 epoch [516/800] time: 0.85s val loss: 0.146 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:39:49,407 epoch [517/800] time: 4.98s train loss: 0.0578 accuracy: 0.9837 f1: 0.9837
2023-07-13 23:39:50,264 epoch [517/800] time: 0.86s val loss: 0.1447 accuracy: 0.9508 f1: 0.9502
2023-07-13 23:39:55,045 epoch [518/800] time: 4.78s train loss: 0.058 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:39:55,910 epoch [518/800] time: 0.86s val loss: 0.1452 accuracy: 0.9509 f1: 0.9503
2023-07-13 23:40:00,701 epoch [519/800] time: 4.79s train loss: 0.0573 accuracy: 0.9844 f1: 0.9843
2023-07-13 23:40:01,581 epoch [519/800] time: 0.88s val loss: 0.1462 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:40:06,568 epoch [520/800] time: 4.99s train loss: 0.0581 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:40:07,427 epoch [520/800] time: 0.86s val loss: 0.1453 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:40:12,207 epoch [521/800] time: 4.78s train loss: 0.0571 accuracy: 0.9844 f1: 0.9843
2023-07-13 23:40:13,087 epoch [521/800] time: 0.88s val loss: 0.1456 accuracy: 0.9506 f1: 0.9498
2023-07-13 23:40:18,199 epoch [522/800] time: 5.11s train loss: 0.0578 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:40:19,014 epoch [522/800] time: 0.81s val loss: 0.1464 accuracy: 0.9497 f1: 0.949
2023-07-13 23:40:24,099 epoch [523/800] time: 5.08s train loss: 0.0593 accuracy: 0.9843 f1: 0.9841
2023-07-13 23:40:25,263 epoch [523/800] time: 1.16s val loss: 0.1468 accuracy: 0.9503 f1: 0.9497
2023-07-13 23:40:30,370 epoch [524/800] time: 5.11s train loss: 0.0584 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:40:31,333 epoch [524/800] time: 0.96s val loss: 0.1455 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:40:36,994 epoch [525/800] time: 5.66s train loss: 0.0605 accuracy: 0.9834 f1: 0.9833
2023-07-13 23:40:37,827 epoch [525/800] time: 0.83s val loss: 0.1459 accuracy: 0.95 f1: 0.9493
2023-07-13 23:40:42,907 epoch [526/800] time: 5.08s train loss: 0.0578 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:40:43,795 epoch [526/800] time: 0.89s val loss: 0.1459 accuracy: 0.9502 f1: 0.9496
2023-07-13 23:40:48,700 epoch [527/800] time: 4.9s train loss: 0.0577 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:40:49,566 epoch [527/800] time: 0.87s val loss: 0.1459 accuracy: 0.9501 f1: 0.9494
2023-07-13 23:40:54,576 epoch [528/800] time: 5.01s train loss: 0.0576 accuracy: 0.9843 f1: 0.984
2023-07-13 23:40:55,442 epoch [528/800] time: 0.87s val loss: 0.1455 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:41:00,278 epoch [529/800] time: 4.84s train loss: 0.0584 accuracy: 0.9838 f1: 0.9836
2023-07-13 23:41:01,136 epoch [529/800] time: 0.86s val loss: 0.1454 accuracy: 0.9503 f1: 0.9495
2023-07-13 23:41:05,914 epoch [530/800] time: 4.78s train loss: 0.0576 accuracy: 0.9838 f1: 0.9838
2023-07-13 23:41:06,766 epoch [530/800] time: 0.85s val loss: 0.1446 accuracy: 0.9509 f1: 0.9503
2023-07-13 23:41:11,549 epoch [531/800] time: 4.78s train loss: 0.0601 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:41:12,356 epoch [531/800] time: 0.81s val loss: 0.146 accuracy: 0.9502 f1: 0.9493
2023-07-13 23:41:17,116 epoch [532/800] time: 4.76s train loss: 0.0588 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:41:17,977 epoch [532/800] time: 0.86s val loss: 0.1463 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:41:22,669 epoch [533/800] time: 4.69s train loss: 0.0585 accuracy: 0.9835 f1: 0.9835
2023-07-13 23:41:23,515 epoch [533/800] time: 0.85s val loss: 0.1456 accuracy: 0.9508 f1: 0.9502
2023-07-13 23:41:28,301 epoch [534/800] time: 4.79s train loss: 0.0579 accuracy: 0.984 f1: 0.9839
2023-07-13 23:41:29,102 epoch [534/800] time: 0.8s val loss: 0.1466 accuracy: 0.9506 f1: 0.95
2023-07-13 23:41:34,063 epoch [535/800] time: 4.96s train loss: 0.0581 accuracy: 0.9836 f1: 0.9835
2023-07-13 23:41:34,948 epoch [535/800] time: 0.89s val loss: 0.146 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:41:39,895 epoch [536/800] time: 4.95s train loss: 0.0589 accuracy: 0.9832 f1: 0.983
2023-07-13 23:41:40,781 epoch [536/800] time: 0.89s val loss: 0.1458 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:41:45,844 epoch [537/800] time: 5.06s train loss: 0.058 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:41:46,671 epoch [537/800] time: 0.83s val loss: 0.1456 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:41:51,629 epoch [538/800] time: 4.96s train loss: 0.059 accuracy: 0.9837 f1: 0.9837
2023-07-13 23:41:52,530 epoch [538/800] time: 0.9s val loss: 0.146 accuracy: 0.9506 f1: 0.95
2023-07-13 23:41:58,187 epoch [539/800] time: 5.66s train loss: 0.0579 accuracy: 0.9839 f1: 0.9839
2023-07-13 23:41:59,038 epoch [539/800] time: 0.85s val loss: 0.1463 accuracy: 0.9503 f1: 0.9494
2023-07-13 23:42:03,803 epoch [540/800] time: 4.76s train loss: 0.0612 accuracy: 0.9825 f1: 0.9825
2023-07-13 23:42:04,609 epoch [540/800] time: 0.81s val loss: 0.1463 accuracy: 0.9501 f1: 0.9496
2023-07-13 23:42:09,384 epoch [541/800] time: 4.77s train loss: 0.0604 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:42:10,245 epoch [541/800] time: 0.86s val loss: 0.1465 accuracy: 0.9502 f1: 0.9496
2023-07-13 23:42:15,284 epoch [542/800] time: 5.04s train loss: 0.0585 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:42:16,188 epoch [542/800] time: 0.9s val loss: 0.1453 accuracy: 0.9508 f1: 0.9501
2023-07-13 23:42:21,149 epoch [543/800] time: 4.96s train loss: 0.0587 accuracy: 0.9836 f1: 0.9836
2023-07-13 23:42:21,956 epoch [543/800] time: 0.81s val loss: 0.1447 accuracy: 0.9507 f1: 0.95
2023-07-13 23:42:26,908 epoch [544/800] time: 4.95s train loss: 0.058 accuracy: 0.9834 f1: 0.9833
2023-07-13 23:42:27,791 epoch [544/800] time: 0.88s val loss: 0.1459 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:42:32,877 epoch [545/800] time: 5.09s train loss: 0.059 accuracy: 0.9836 f1: 0.9834
2023-07-13 23:42:33,741 epoch [545/800] time: 0.86s val loss: 0.1452 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:42:38,620 epoch [546/800] time: 4.88s train loss: 0.0572 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:42:39,447 epoch [546/800] time: 0.83s val loss: 0.1463 accuracy: 0.9502 f1: 0.9496
2023-07-13 23:42:44,347 epoch [547/800] time: 4.9s train loss: 0.0572 accuracy: 0.9843 f1: 0.9842
2023-07-13 23:42:45,250 epoch [547/800] time: 0.9s val loss: 0.1458 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:42:50,258 epoch [548/800] time: 5.01s train loss: 0.0577 accuracy: 0.984 f1: 0.9839
2023-07-13 23:42:51,129 epoch [548/800] time: 0.87s val loss: 0.1456 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:42:56,096 epoch [549/800] time: 4.97s train loss: 0.0584 accuracy: 0.9842 f1: 0.984
2023-07-13 23:42:56,903 epoch [549/800] time: 0.81s val loss: 0.1463 accuracy: 0.9499 f1: 0.9493
2023-07-13 23:43:01,730 epoch [550/800] time: 4.83s train loss: 0.059 accuracy: 0.9835 f1: 0.9835
2023-07-13 23:43:02,584 epoch [550/800] time: 0.85s val loss: 0.1447 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:43:07,432 epoch [551/800] time: 4.85s train loss: 0.0576 accuracy: 0.984 f1: 0.9839
2023-07-13 23:43:08,279 epoch [551/800] time: 0.85s val loss: 0.1452 accuracy: 0.9507 f1: 0.95
2023-07-13 23:43:13,085 epoch [552/800] time: 4.81s train loss: 0.0578 accuracy: 0.984 f1: 0.984
2023-07-13 23:43:13,887 epoch [552/800] time: 0.8s val loss: 0.1458 accuracy: 0.951 f1: 0.9503
2023-07-13 23:43:18,643 epoch [553/800] time: 4.76s train loss: 0.0575 accuracy: 0.9842 f1: 0.9841
2023-07-13 23:43:19,506 epoch [553/800] time: 0.86s val loss: 0.146 accuracy: 0.9507 f1: 0.95
2023-07-13 23:43:24,242 epoch [554/800] time: 4.74s train loss: 0.0587 accuracy: 0.9841 f1: 0.984
2023-07-13 23:43:25,098 epoch [554/800] time: 0.86s val loss: 0.146 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:43:29,859 epoch [555/800] time: 4.76s train loss: 0.0591 accuracy: 0.9833 f1: 0.9832
2023-07-13 23:43:30,658 epoch [555/800] time: 0.8s val loss: 0.1454 accuracy: 0.9509 f1: 0.9502
2023-07-13 23:43:35,563 epoch [556/800] time: 4.9s train loss: 0.0594 accuracy: 0.9833 f1: 0.9832
2023-07-13 23:43:36,470 epoch [556/800] time: 0.91s val loss: 0.1454 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:43:41,304 epoch [557/800] time: 4.83s train loss: 0.0571 accuracy: 0.9844 f1: 0.9843
2023-07-13 23:43:42,194 epoch [557/800] time: 0.89s val loss: 0.1452 accuracy: 0.9499 f1: 0.9493
2023-07-13 23:43:47,152 epoch [558/800] time: 4.96s train loss: 0.0588 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:43:48,072 epoch [558/800] time: 0.92s val loss: 0.1466 accuracy: 0.9498 f1: 0.9492
2023-07-13 23:43:52,923 epoch [559/800] time: 4.85s train loss: 0.0576 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:43:53,792 epoch [559/800] time: 0.87s val loss: 0.1448 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:43:58,414 epoch [560/800] time: 4.62s train loss: 0.0578 accuracy: 0.9841 f1: 0.984
2023-07-13 23:43:59,266 epoch [560/800] time: 0.85s val loss: 0.1454 accuracy: 0.9505 f1: 0.9497
2023-07-13 23:44:03,951 epoch [561/800] time: 4.68s train loss: 0.057 accuracy: 0.984 f1: 0.9839
2023-07-13 23:44:04,754 epoch [561/800] time: 0.8s val loss: 0.1452 accuracy: 0.9506 f1: 0.9498
2023-07-13 23:44:09,460 epoch [562/800] time: 4.71s train loss: 0.0578 accuracy: 0.9841 f1: 0.984
2023-07-13 23:44:10,309 epoch [562/800] time: 0.85s val loss: 0.1452 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:44:14,795 epoch [563/800] time: 4.49s train loss: 0.057 accuracy: 0.984 f1: 0.9839
2023-07-13 23:44:15,645 epoch [563/800] time: 0.85s val loss: 0.1458 accuracy: 0.9511 f1: 0.9502
2023-07-13 23:44:20,160 epoch [564/800] time: 4.52s train loss: 0.0573 accuracy: 0.9841 f1: 0.984
2023-07-13 23:44:20,967 epoch [564/800] time: 0.81s val loss: 0.1454 accuracy: 0.9499 f1: 0.9494
2023-07-13 23:44:25,762 epoch [565/800] time: 4.79s train loss: 0.0585 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:44:26,626 epoch [565/800] time: 0.86s val loss: 0.1458 accuracy: 0.9512 f1: 0.9504
2023-07-13 23:44:31,652 epoch [566/800] time: 5.03s train loss: 0.0582 accuracy: 0.9844 f1: 0.9843
2023-07-13 23:44:32,589 epoch [566/800] time: 0.94s val loss: 0.1462 accuracy: 0.9506 f1: 0.95
2023-07-13 23:44:37,836 epoch [567/800] time: 5.25s train loss: 0.0565 accuracy: 0.9847 f1: 0.9846
2023-07-13 23:44:38,755 epoch [567/800] time: 0.92s val loss: 0.146 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:44:43,791 epoch [568/800] time: 5.04s train loss: 0.0579 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:44:44,693 epoch [568/800] time: 0.9s val loss: 0.1453 accuracy: 0.9509 f1: 0.9502
2023-07-13 23:44:49,688 epoch [569/800] time: 4.99s train loss: 0.0594 accuracy: 0.9838 f1: 0.9838
2023-07-13 23:44:50,546 epoch [569/800] time: 0.86s val loss: 0.1464 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:44:55,433 epoch [570/800] time: 4.89s train loss: 0.0589 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:44:56,253 epoch [570/800] time: 0.82s val loss: 0.1456 accuracy: 0.9504 f1: 0.9498
2023-07-13 23:45:01,211 epoch [571/800] time: 4.96s train loss: 0.0585 accuracy: 0.9831 f1: 0.983
2023-07-13 23:45:02,098 epoch [571/800] time: 0.89s val loss: 0.1455 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:45:06,898 epoch [572/800] time: 4.8s train loss: 0.0575 accuracy: 0.9842 f1: 0.9841
2023-07-13 23:45:07,783 epoch [572/800] time: 0.89s val loss: 0.1454 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:45:12,628 epoch [573/800] time: 4.84s train loss: 0.0583 accuracy: 0.9838 f1: 0.9836
2023-07-13 23:45:13,452 epoch [573/800] time: 0.82s val loss: 0.1457 accuracy: 0.9507 f1: 0.95
2023-07-13 23:45:18,383 epoch [574/800] time: 4.93s train loss: 0.0588 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:45:19,271 epoch [574/800] time: 0.89s val loss: 0.1478 accuracy: 0.9499 f1: 0.9491
2023-07-13 23:45:24,306 epoch [575/800] time: 5.03s train loss: 0.0587 accuracy: 0.984 f1: 0.9839
2023-07-13 23:45:25,173 epoch [575/800] time: 0.87s val loss: 0.1454 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:45:30,011 epoch [576/800] time: 4.84s train loss: 0.0574 accuracy: 0.9839 f1: 0.9837
2023-07-13 23:45:30,820 epoch [576/800] time: 0.81s val loss: 0.1452 accuracy: 0.9508 f1: 0.9501
2023-07-13 23:45:35,434 epoch [577/800] time: 4.61s train loss: 0.0586 accuracy: 0.9832 f1: 0.9831
2023-07-13 23:45:36,297 epoch [577/800] time: 0.86s val loss: 0.1457 accuracy: 0.9507 f1: 0.9499
2023-07-13 23:45:40,952 epoch [578/800] time: 4.66s train loss: 0.0588 accuracy: 0.9833 f1: 0.9832
2023-07-13 23:45:41,806 epoch [578/800] time: 0.85s val loss: 0.1453 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:45:46,501 epoch [579/800] time: 4.7s train loss: 0.0575 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:45:47,307 epoch [579/800] time: 0.81s val loss: 0.1456 accuracy: 0.9509 f1: 0.9502
2023-07-13 23:45:52,079 epoch [580/800] time: 4.77s train loss: 0.0588 accuracy: 0.9836 f1: 0.9835
2023-07-13 23:45:52,925 epoch [580/800] time: 0.85s val loss: 0.1455 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:45:57,563 epoch [581/800] time: 4.64s train loss: 0.058 accuracy: 0.984 f1: 0.984
2023-07-13 23:45:58,416 epoch [581/800] time: 0.85s val loss: 0.1466 accuracy: 0.9507 f1: 0.95
2023-07-13 23:46:03,108 epoch [582/800] time: 4.69s train loss: 0.058 accuracy: 0.9837 f1: 0.9835
2023-07-13 23:46:03,912 epoch [582/800] time: 0.8s val loss: 0.1458 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:46:08,641 epoch [583/800] time: 4.73s train loss: 0.0577 accuracy: 0.9843 f1: 0.9842
2023-07-13 23:46:09,487 epoch [583/800] time: 0.85s val loss: 0.1455 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:46:14,224 epoch [584/800] time: 4.74s train loss: 0.0569 accuracy: 0.9842 f1: 0.9842
2023-07-13 23:46:15,067 epoch [584/800] time: 0.84s val loss: 0.1451 accuracy: 0.9509 f1: 0.9504
2023-07-13 23:46:19,748 epoch [585/800] time: 4.68s train loss: 0.059 accuracy: 0.9833 f1: 0.9831
2023-07-13 23:46:20,551 epoch [585/800] time: 0.8s val loss: 0.1455 accuracy: 0.9508 f1: 0.9502
2023-07-13 23:46:25,515 epoch [586/800] time: 4.96s train loss: 0.0578 accuracy: 0.9843 f1: 0.9842
2023-07-13 23:46:26,417 epoch [586/800] time: 0.9s val loss: 0.1456 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:46:31,201 epoch [587/800] time: 4.78s train loss: 0.0581 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:46:32,062 epoch [587/800] time: 0.86s val loss: 0.146 accuracy: 0.9504 f1: 0.9498
2023-07-13 23:46:37,016 epoch [588/800] time: 4.95s train loss: 0.058 accuracy: 0.9841 f1: 0.984
2023-07-13 23:46:37,918 epoch [588/800] time: 0.9s val loss: 0.1463 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:46:42,903 epoch [589/800] time: 4.98s train loss: 0.0582 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:46:43,769 epoch [589/800] time: 0.87s val loss: 0.1454 accuracy: 0.9501 f1: 0.9494
2023-07-13 23:46:48,607 epoch [590/800] time: 4.84s train loss: 0.058 accuracy: 0.9839 f1: 0.9837
2023-07-13 23:46:49,508 epoch [590/800] time: 0.9s val loss: 0.1454 accuracy: 0.9511 f1: 0.9504
2023-07-13 23:46:54,697 epoch [591/800] time: 5.19s train loss: 0.0583 accuracy: 0.9842 f1: 0.9841
2023-07-13 23:46:55,545 epoch [591/800] time: 0.85s val loss: 0.1494 accuracy: 0.9494 f1: 0.9486
2023-07-13 23:47:00,521 epoch [592/800] time: 4.98s train loss: 0.0599 accuracy: 0.9835 f1: 0.9833
2023-07-13 23:47:01,416 epoch [592/800] time: 0.9s val loss: 0.1468 accuracy: 0.9502 f1: 0.9496
2023-07-13 23:47:06,466 epoch [593/800] time: 5.05s train loss: 0.0586 accuracy: 0.9838 f1: 0.9836
2023-07-13 23:47:07,382 epoch [593/800] time: 0.92s val loss: 0.1464 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:47:12,237 epoch [594/800] time: 4.85s train loss: 0.0576 accuracy: 0.984 f1: 0.9839
2023-07-13 23:47:13,051 epoch [594/800] time: 0.81s val loss: 0.1451 accuracy: 0.9509 f1: 0.9503
2023-07-13 23:47:18,112 epoch [595/800] time: 5.06s train loss: 0.0593 accuracy: 0.9834 f1: 0.9833
2023-07-13 23:47:18,986 epoch [595/800] time: 0.87s val loss: 0.1455 accuracy: 0.9507 f1: 0.9499
2023-07-13 23:47:23,601 epoch [596/800] time: 4.62s train loss: 0.0578 accuracy: 0.9843 f1: 0.9841
2023-07-13 23:47:24,459 epoch [596/800] time: 0.86s val loss: 0.1452 accuracy: 0.9501 f1: 0.9494
2023-07-13 23:47:29,106 epoch [597/800] time: 4.65s train loss: 0.0572 accuracy: 0.9842 f1: 0.9842
2023-07-13 23:47:29,912 epoch [597/800] time: 0.8s val loss: 0.1457 accuracy: 0.9508 f1: 0.9501
2023-07-13 23:47:34,512 epoch [598/800] time: 4.6s train loss: 0.0581 accuracy: 0.984 f1: 0.984
2023-07-13 23:47:35,361 epoch [598/800] time: 0.85s val loss: 0.1462 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:47:40,089 epoch [599/800] time: 4.73s train loss: 0.0588 accuracy: 0.9841 f1: 0.9841
2023-07-13 23:47:40,940 epoch [599/800] time: 0.85s val loss: 0.147 accuracy: 0.9497 f1: 0.9491
2023-07-13 23:47:45,705 epoch [600/800] time: 4.77s train loss: 0.0573 accuracy: 0.9841 f1: 0.984
2023-07-13 23:47:46,510 epoch [600/800] time: 0.8s val loss: 0.1451 accuracy: 0.9509 f1: 0.9502
2023-07-13 23:47:51,110 epoch [601/800] time: 4.6s train loss: 0.0587 accuracy: 0.9832 f1: 0.9831
2023-07-13 23:47:51,957 epoch [601/800] time: 0.85s val loss: 0.1465 accuracy: 0.9503 f1: 0.9493
2023-07-13 23:47:56,672 epoch [602/800] time: 4.71s train loss: 0.0584 accuracy: 0.9837 f1: 0.9837
2023-07-13 23:47:57,520 epoch [602/800] time: 0.85s val loss: 0.1462 accuracy: 0.9512 f1: 0.9504
2023-07-13 23:48:02,249 epoch [603/800] time: 4.73s train loss: 0.058 accuracy: 0.9836 f1: 0.9836
2023-07-13 23:48:03,050 epoch [603/800] time: 0.8s val loss: 0.1461 accuracy: 0.9508 f1: 0.9501
2023-07-13 23:48:07,742 epoch [604/800] time: 4.69s train loss: 0.0574 accuracy: 0.9841 f1: 0.9839
2023-07-13 23:48:08,591 epoch [604/800] time: 0.85s val loss: 0.1455 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:48:13,348 epoch [605/800] time: 4.76s train loss: 0.0586 accuracy: 0.9835 f1: 0.9835
2023-07-13 23:48:14,225 epoch [605/800] time: 0.88s val loss: 0.1454 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:48:19,274 epoch [606/800] time: 5.05s train loss: 0.063 accuracy: 0.9835 f1: 0.9833
2023-07-13 23:48:20,110 epoch [606/800] time: 0.83s val loss: 0.1484 accuracy: 0.9495 f1: 0.9488
2023-07-13 23:48:24,965 epoch [607/800] time: 4.86s train loss: 0.0573 accuracy: 0.984 f1: 0.9839
2023-07-13 23:48:25,834 epoch [607/800] time: 0.87s val loss: 0.1453 accuracy: 0.9504 f1: 0.9498
2023-07-13 23:48:30,885 epoch [608/800] time: 5.05s train loss: 0.0579 accuracy: 0.9838 f1: 0.9838
2023-07-13 23:48:31,769 epoch [608/800] time: 0.88s val loss: 0.1451 accuracy: 0.9507 f1: 0.95
2023-07-13 23:48:36,673 epoch [609/800] time: 4.9s train loss: 0.058 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:48:37,481 epoch [609/800] time: 0.81s val loss: 0.1453 accuracy: 0.9504 f1: 0.9498
2023-07-13 23:48:42,441 epoch [610/800] time: 4.96s train loss: 0.0589 accuracy: 0.9834 f1: 0.9833
2023-07-13 23:48:43,341 epoch [610/800] time: 0.9s val loss: 0.1462 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:48:48,393 epoch [611/800] time: 5.05s train loss: 0.0583 accuracy: 0.9841 f1: 0.984
2023-07-13 23:48:49,257 epoch [611/800] time: 0.86s val loss: 0.1462 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:48:54,092 epoch [612/800] time: 4.83s train loss: 0.0582 accuracy: 0.9837 f1: 0.9837
2023-07-13 23:48:54,953 epoch [612/800] time: 0.86s val loss: 0.1454 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:49:00,082 epoch [613/800] time: 5.13s train loss: 0.0563 accuracy: 0.9849 f1: 0.9847
2023-07-13 23:49:00,985 epoch [613/800] time: 0.9s val loss: 0.1453 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:49:05,860 epoch [614/800] time: 4.87s train loss: 0.0597 accuracy: 0.9833 f1: 0.9833
2023-07-13 23:49:06,732 epoch [614/800] time: 0.87s val loss: 0.1486 accuracy: 0.9496 f1: 0.9489
2023-07-13 23:49:11,647 epoch [615/800] time: 4.91s train loss: 0.0579 accuracy: 0.9841 f1: 0.9841
2023-07-13 23:49:12,458 epoch [615/800] time: 0.81s val loss: 0.146 accuracy: 0.9499 f1: 0.9491
2023-07-13 23:49:17,343 epoch [616/800] time: 4.89s train loss: 0.0584 accuracy: 0.9835 f1: 0.9833
2023-07-13 23:49:18,223 epoch [616/800] time: 0.88s val loss: 0.1456 accuracy: 0.95 f1: 0.9492
2023-07-13 23:49:23,078 epoch [617/800] time: 4.85s train loss: 0.0577 accuracy: 0.9842 f1: 0.9842
2023-07-13 23:49:23,937 epoch [617/800] time: 0.86s val loss: 0.1461 accuracy: 0.9506 f1: 0.9498
2023-07-13 23:49:28,853 epoch [618/800] time: 4.92s train loss: 0.0597 accuracy: 0.983 f1: 0.983
2023-07-13 23:49:29,693 epoch [618/800] time: 0.84s val loss: 0.1463 accuracy: 0.9502 f1: 0.9496
2023-07-13 23:49:34,665 epoch [619/800] time: 4.97s train loss: 0.0591 accuracy: 0.9834 f1: 0.9833
2023-07-13 23:49:35,528 epoch [619/800] time: 0.86s val loss: 0.1461 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:49:40,354 epoch [620/800] time: 4.83s train loss: 0.0594 accuracy: 0.9834 f1: 0.9833
2023-07-13 23:49:41,239 epoch [620/800] time: 0.88s val loss: 0.1457 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:49:46,285 epoch [621/800] time: 5.05s train loss: 0.058 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:49:47,104 epoch [621/800] time: 0.82s val loss: 0.1457 accuracy: 0.9507 f1: 0.95
2023-07-13 23:49:51,984 epoch [622/800] time: 4.88s train loss: 0.0582 accuracy: 0.9841 f1: 0.984
2023-07-13 23:49:52,845 epoch [622/800] time: 0.86s val loss: 0.1451 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:49:57,802 epoch [623/800] time: 4.96s train loss: 0.0595 accuracy: 0.9834 f1: 0.9833
2023-07-13 23:49:58,683 epoch [623/800] time: 0.88s val loss: 0.1462 accuracy: 0.9499 f1: 0.949
2023-07-13 23:50:03,591 epoch [624/800] time: 4.91s train loss: 0.0595 accuracy: 0.9832 f1: 0.9831
2023-07-13 23:50:04,405 epoch [624/800] time: 0.81s val loss: 0.1462 accuracy: 0.9499 f1: 0.9492
2023-07-13 23:50:09,326 epoch [625/800] time: 4.92s train loss: 0.0582 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:50:10,202 epoch [625/800] time: 0.88s val loss: 0.1451 accuracy: 0.9509 f1: 0.9502
2023-07-13 23:50:15,175 epoch [626/800] time: 4.97s train loss: 0.0587 accuracy: 0.9834 f1: 0.9834
2023-07-13 23:50:16,031 epoch [626/800] time: 0.86s val loss: 0.1455 accuracy: 0.9508 f1: 0.9502
2023-07-13 23:50:20,871 epoch [627/800] time: 4.84s train loss: 0.0574 accuracy: 0.9843 f1: 0.9841
2023-07-13 23:50:21,676 epoch [627/800] time: 0.8s val loss: 0.1455 accuracy: 0.951 f1: 0.9503
2023-07-13 23:50:26,651 epoch [628/800] time: 4.97s train loss: 0.0598 accuracy: 0.9829 f1: 0.9828
2023-07-13 23:50:27,523 epoch [628/800] time: 0.87s val loss: 0.1466 accuracy: 0.9504 f1: 0.9498
2023-07-13 23:50:32,289 epoch [629/800] time: 4.77s train loss: 0.0586 accuracy: 0.9838 f1: 0.9836
2023-07-13 23:50:33,140 epoch [629/800] time: 0.85s val loss: 0.146 accuracy: 0.9501 f1: 0.9495
2023-07-13 23:50:38,013 epoch [630/800] time: 4.87s train loss: 0.058 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:50:38,812 epoch [630/800] time: 0.8s val loss: 0.1448 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:50:43,582 epoch [631/800] time: 4.77s train loss: 0.0581 accuracy: 0.9836 f1: 0.9835
2023-07-13 23:50:44,423 epoch [631/800] time: 0.84s val loss: 0.145 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:50:49,145 epoch [632/800] time: 4.72s train loss: 0.0574 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:50:49,992 epoch [632/800] time: 0.85s val loss: 0.1456 accuracy: 0.9508 f1: 0.9502
2023-07-13 23:50:54,784 epoch [633/800] time: 4.79s train loss: 0.0586 accuracy: 0.9836 f1: 0.9835
2023-07-13 23:50:55,582 epoch [633/800] time: 0.8s val loss: 0.1458 accuracy: 0.9501 f1: 0.9493
2023-07-13 23:51:00,344 epoch [634/800] time: 4.76s train loss: 0.058 accuracy: 0.9836 f1: 0.9835
2023-07-13 23:51:01,188 epoch [634/800] time: 0.84s val loss: 0.145 accuracy: 0.951 f1: 0.9504
2023-07-13 23:51:05,686 epoch [635/800] time: 4.5s train loss: 0.0579 accuracy: 0.9841 f1: 0.984
2023-07-13 23:51:06,536 epoch [635/800] time: 0.85s val loss: 0.1459 accuracy: 0.9504 f1: 0.9498
2023-07-13 23:51:11,075 epoch [636/800] time: 4.54s train loss: 0.0578 accuracy: 0.9843 f1: 0.9841
2023-07-13 23:51:11,874 epoch [636/800] time: 0.8s val loss: 0.1455 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:51:16,419 epoch [637/800] time: 4.54s train loss: 0.0575 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:51:17,266 epoch [637/800] time: 0.85s val loss: 0.1461 accuracy: 0.9512 f1: 0.9504
2023-07-13 23:51:21,772 epoch [638/800] time: 4.51s train loss: 0.0583 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:51:22,614 epoch [638/800] time: 0.84s val loss: 0.1455 accuracy: 0.9511 f1: 0.9504
2023-07-13 23:51:27,192 epoch [639/800] time: 4.58s train loss: 0.06 accuracy: 0.9836 f1: 0.9836
2023-07-13 23:51:27,990 epoch [639/800] time: 0.8s val loss: 0.1467 accuracy: 0.9499 f1: 0.9492
2023-07-13 23:51:32,602 epoch [640/800] time: 4.61s train loss: 0.058 accuracy: 0.984 f1: 0.9839
2023-07-13 23:51:33,449 epoch [640/800] time: 0.85s val loss: 0.1454 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:51:38,034 epoch [641/800] time: 4.59s train loss: 0.0594 accuracy: 0.9833 f1: 0.9832
2023-07-13 23:51:38,879 epoch [641/800] time: 0.84s val loss: 0.1454 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:51:43,475 epoch [642/800] time: 4.6s train loss: 0.0579 accuracy: 0.9839 f1: 0.9836
2023-07-13 23:51:44,273 epoch [642/800] time: 0.8s val loss: 0.1458 accuracy: 0.9508 f1: 0.9501
2023-07-13 23:51:48,824 epoch [643/800] time: 4.55s train loss: 0.0584 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:51:49,666 epoch [643/800] time: 0.84s val loss: 0.1457 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:51:54,187 epoch [644/800] time: 4.52s train loss: 0.0592 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:51:55,029 epoch [644/800] time: 0.84s val loss: 0.1464 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:51:59,567 epoch [645/800] time: 4.54s train loss: 0.0578 accuracy: 0.9838 f1: 0.9838
2023-07-13 23:52:00,365 epoch [645/800] time: 0.8s val loss: 0.1447 accuracy: 0.9509 f1: 0.9503
2023-07-13 23:52:04,928 epoch [646/800] time: 4.56s train loss: 0.0608 accuracy: 0.9827 f1: 0.9826
2023-07-13 23:52:05,772 epoch [646/800] time: 0.84s val loss: 0.147 accuracy: 0.9499 f1: 0.9491
2023-07-13 23:52:10,277 epoch [647/800] time: 4.5s train loss: 0.0585 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:52:11,156 epoch [647/800] time: 0.88s val loss: 0.145 accuracy: 0.951 f1: 0.9503
2023-07-13 23:52:15,912 epoch [648/800] time: 4.76s train loss: 0.0578 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:52:16,718 epoch [648/800] time: 0.81s val loss: 0.1457 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:52:21,314 epoch [649/800] time: 4.6s train loss: 0.0578 accuracy: 0.984 f1: 0.9838
2023-07-13 23:52:22,163 epoch [649/800] time: 0.85s val loss: 0.1456 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:52:27,112 epoch [650/800] time: 4.95s train loss: 0.0597 accuracy: 0.9833 f1: 0.9831
2023-07-13 23:52:27,987 epoch [650/800] time: 0.87s val loss: 0.1477 accuracy: 0.9501 f1: 0.9495
2023-07-13 23:52:33,079 epoch [651/800] time: 5.09s train loss: 0.0585 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:52:33,942 epoch [651/800] time: 0.86s val loss: 0.1451 accuracy: 0.9499 f1: 0.9492
2023-07-13 23:52:39,156 epoch [652/800] time: 5.21s train loss: 0.0578 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:52:40,123 epoch [652/800] time: 0.97s val loss: 0.145 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:52:45,293 epoch [653/800] time: 5.17s train loss: 0.0579 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:52:46,213 epoch [653/800] time: 0.92s val loss: 0.1449 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:52:51,316 epoch [654/800] time: 5.1s train loss: 0.0574 accuracy: 0.9841 f1: 0.984
2023-07-13 23:52:52,179 epoch [654/800] time: 0.86s val loss: 0.1457 accuracy: 0.9503 f1: 0.9498
2023-07-13 23:52:57,416 epoch [655/800] time: 5.24s train loss: 0.0584 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:52:58,333 epoch [655/800] time: 0.92s val loss: 0.1454 accuracy: 0.9508 f1: 0.9502
2023-07-13 23:53:03,310 epoch [656/800] time: 4.98s train loss: 0.0579 accuracy: 0.9841 f1: 0.984
2023-07-13 23:53:04,188 epoch [656/800] time: 0.88s val loss: 0.1448 accuracy: 0.9508 f1: 0.9502
2023-07-13 23:53:09,122 epoch [657/800] time: 4.93s train loss: 0.0575 accuracy: 0.984 f1: 0.9838
2023-07-13 23:53:09,932 epoch [657/800] time: 0.81s val loss: 0.1458 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:53:14,675 epoch [658/800] time: 4.74s train loss: 0.0576 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:53:15,535 epoch [658/800] time: 0.86s val loss: 0.1452 accuracy: 0.9507 f1: 0.9502
2023-07-13 23:53:20,099 epoch [659/800] time: 4.56s train loss: 0.0586 accuracy: 0.9841 f1: 0.984
2023-07-13 23:53:21,003 epoch [659/800] time: 0.9s val loss: 0.1466 accuracy: 0.9498 f1: 0.9491
2023-07-13 23:53:25,813 epoch [660/800] time: 4.81s train loss: 0.0586 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:53:26,621 epoch [660/800] time: 0.81s val loss: 0.1461 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:53:31,252 epoch [661/800] time: 4.63s train loss: 0.0571 accuracy: 0.9843 f1: 0.9842
2023-07-13 23:53:32,106 epoch [661/800] time: 0.85s val loss: 0.1455 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:53:37,016 epoch [662/800] time: 4.91s train loss: 0.0579 accuracy: 0.9845 f1: 0.9843
2023-07-13 23:53:37,899 epoch [662/800] time: 0.88s val loss: 0.146 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:53:42,563 epoch [663/800] time: 4.66s train loss: 0.0585 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:53:43,375 epoch [663/800] time: 0.81s val loss: 0.1461 accuracy: 0.9509 f1: 0.9502
2023-07-13 23:53:48,303 epoch [664/800] time: 4.93s train loss: 0.0576 accuracy: 0.9844 f1: 0.9842
2023-07-13 23:53:49,223 epoch [664/800] time: 0.92s val loss: 0.145 accuracy: 0.9506 f1: 0.95
2023-07-13 23:53:54,657 epoch [665/800] time: 5.43s train loss: 0.0587 accuracy: 0.9835 f1: 0.9833
2023-07-13 23:53:55,680 epoch [665/800] time: 1.02s val loss: 0.145 accuracy: 0.951 f1: 0.9503
2023-07-13 23:54:00,903 epoch [666/800] time: 5.22s train loss: 0.0587 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:54:01,879 epoch [666/800] time: 0.98s val loss: 0.1473 accuracy: 0.9503 f1: 0.9495
2023-07-13 23:54:07,184 epoch [667/800] time: 5.3s train loss: 0.0576 accuracy: 0.9842 f1: 0.9841
2023-07-13 23:54:08,097 epoch [667/800] time: 0.91s val loss: 0.1452 accuracy: 0.9503 f1: 0.9495
2023-07-13 23:54:13,255 epoch [668/800] time: 5.16s train loss: 0.0592 accuracy: 0.9836 f1: 0.9836
2023-07-13 23:54:14,142 epoch [668/800] time: 0.89s val loss: 0.1466 accuracy: 0.9501 f1: 0.9495
2023-07-13 23:54:19,160 epoch [669/800] time: 5.02s train loss: 0.0591 accuracy: 0.9835 f1: 0.9833
2023-07-13 23:54:20,019 epoch [669/800] time: 0.86s val loss: 0.1463 accuracy: 0.9498 f1: 0.9492
2023-07-13 23:54:24,977 epoch [670/800] time: 4.96s train loss: 0.0578 accuracy: 0.9841 f1: 0.984
2023-07-13 23:54:25,837 epoch [670/800] time: 0.86s val loss: 0.1455 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:54:30,637 epoch [671/800] time: 4.8s train loss: 0.0569 accuracy: 0.9841 f1: 0.984
2023-07-13 23:54:31,507 epoch [671/800] time: 0.87s val loss: 0.1457 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:54:36,233 epoch [672/800] time: 4.73s train loss: 0.0578 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:54:37,038 epoch [672/800] time: 0.8s val loss: 0.1457 accuracy: 0.95 f1: 0.9494
2023-07-13 23:54:41,842 epoch [673/800] time: 4.8s train loss: 0.0576 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:54:42,693 epoch [673/800] time: 0.85s val loss: 0.1454 accuracy: 0.9503 f1: 0.9495
2023-07-13 23:54:47,419 epoch [674/800] time: 4.73s train loss: 0.0592 accuracy: 0.9837 f1: 0.9837
2023-07-13 23:54:48,271 epoch [674/800] time: 0.85s val loss: 0.1481 accuracy: 0.9495 f1: 0.9488
2023-07-13 23:54:53,036 epoch [675/800] time: 4.77s train loss: 0.0595 accuracy: 0.9834 f1: 0.9833
2023-07-13 23:54:53,852 epoch [675/800] time: 0.82s val loss: 0.1466 accuracy: 0.95 f1: 0.9493
2023-07-13 23:54:58,574 epoch [676/800] time: 4.72s train loss: 0.0581 accuracy: 0.9841 f1: 0.984
2023-07-13 23:54:59,420 epoch [676/800] time: 0.85s val loss: 0.1459 accuracy: 0.9508 f1: 0.9502
2023-07-13 23:55:04,130 epoch [677/800] time: 4.71s train loss: 0.0587 accuracy: 0.9834 f1: 0.9834
2023-07-13 23:55:05,002 epoch [677/800] time: 0.87s val loss: 0.1464 accuracy: 0.9499 f1: 0.9491
2023-07-13 23:55:09,619 epoch [678/800] time: 4.62s train loss: 0.0577 accuracy: 0.9839 f1: 0.9839
2023-07-13 23:55:10,425 epoch [678/800] time: 0.81s val loss: 0.1449 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:55:15,070 epoch [679/800] time: 4.65s train loss: 0.0589 accuracy: 0.9836 f1: 0.9834
2023-07-13 23:55:15,920 epoch [679/800] time: 0.85s val loss: 0.1462 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:55:20,482 epoch [680/800] time: 4.56s train loss: 0.0584 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:55:21,371 epoch [680/800] time: 0.89s val loss: 0.1458 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:55:26,079 epoch [681/800] time: 4.71s train loss: 0.0583 accuracy: 0.984 f1: 0.9839
2023-07-13 23:55:26,900 epoch [681/800] time: 0.82s val loss: 0.1454 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:55:31,585 epoch [682/800] time: 4.68s train loss: 0.0588 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:55:32,449 epoch [682/800] time: 0.86s val loss: 0.1455 accuracy: 0.9506 f1: 0.95
2023-07-13 23:55:37,003 epoch [683/800] time: 4.55s train loss: 0.0586 accuracy: 0.9837 f1: 0.9837
2023-07-13 23:55:37,868 epoch [683/800] time: 0.86s val loss: 0.1454 accuracy: 0.9498 f1: 0.9492
2023-07-13 23:55:42,870 epoch [684/800] time: 5.0s train loss: 0.059 accuracy: 0.9835 f1: 0.9833
2023-07-13 23:55:43,677 epoch [684/800] time: 0.81s val loss: 0.1464 accuracy: 0.9497 f1: 0.9492
2023-07-13 23:55:48,436 epoch [685/800] time: 4.76s train loss: 0.0574 accuracy: 0.9841 f1: 0.984
2023-07-13 23:55:49,288 epoch [685/800] time: 0.85s val loss: 0.1452 accuracy: 0.9506 f1: 0.9498
2023-07-13 23:55:53,857 epoch [686/800] time: 4.57s train loss: 0.058 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:55:54,704 epoch [686/800] time: 0.85s val loss: 0.146 accuracy: 0.9505 f1: 0.95
2023-07-13 23:55:59,304 epoch [687/800] time: 4.6s train loss: 0.0579 accuracy: 0.9836 f1: 0.9835
2023-07-13 23:56:00,104 epoch [687/800] time: 0.8s val loss: 0.1456 accuracy: 0.9503 f1: 0.9498
2023-07-13 23:56:04,653 epoch [688/800] time: 4.55s train loss: 0.0582 accuracy: 0.984 f1: 0.984
2023-07-13 23:56:05,501 epoch [688/800] time: 0.85s val loss: 0.1461 accuracy: 0.9503 f1: 0.9497
2023-07-13 23:56:10,031 epoch [689/800] time: 4.53s train loss: 0.0594 accuracy: 0.984 f1: 0.984
2023-07-13 23:56:10,877 epoch [689/800] time: 0.84s val loss: 0.146 accuracy: 0.9506 f1: 0.95
2023-07-13 23:56:15,431 epoch [690/800] time: 4.55s train loss: 0.0574 accuracy: 0.9845 f1: 0.9845
2023-07-13 23:56:16,232 epoch [690/800] time: 0.8s val loss: 0.1459 accuracy: 0.9507 f1: 0.95
2023-07-13 23:56:20,779 epoch [691/800] time: 4.55s train loss: 0.0577 accuracy: 0.9842 f1: 0.9841
2023-07-13 23:56:21,629 epoch [691/800] time: 0.85s val loss: 0.1455 accuracy: 0.9509 f1: 0.9502
2023-07-13 23:56:26,148 epoch [692/800] time: 4.52s train loss: 0.0582 accuracy: 0.9832 f1: 0.983
2023-07-13 23:56:26,993 epoch [692/800] time: 0.84s val loss: 0.1462 accuracy: 0.9498 f1: 0.9491
2023-07-13 23:56:31,542 epoch [693/800] time: 4.55s train loss: 0.0587 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:56:32,341 epoch [693/800] time: 0.8s val loss: 0.145 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:56:36,901 epoch [694/800] time: 4.56s train loss: 0.0579 accuracy: 0.9835 f1: 0.9834
2023-07-13 23:56:37,750 epoch [694/800] time: 0.85s val loss: 0.1464 accuracy: 0.9502 f1: 0.9495
2023-07-13 23:56:42,260 epoch [695/800] time: 4.51s train loss: 0.0583 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:56:43,105 epoch [695/800] time: 0.84s val loss: 0.1485 accuracy: 0.9493 f1: 0.9484
2023-07-13 23:56:47,785 epoch [696/800] time: 4.68s train loss: 0.0581 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:56:48,587 epoch [696/800] time: 0.8s val loss: 0.1456 accuracy: 0.951 f1: 0.9503
2023-07-13 23:56:53,374 epoch [697/800] time: 4.79s train loss: 0.0573 accuracy: 0.9841 f1: 0.984
2023-07-13 23:56:54,223 epoch [697/800] time: 0.85s val loss: 0.1455 accuracy: 0.9503 f1: 0.9496
2023-07-13 23:56:58,741 epoch [698/800] time: 4.52s train loss: 0.0576 accuracy: 0.984 f1: 0.9838
2023-07-13 23:56:59,586 epoch [698/800] time: 0.84s val loss: 0.1456 accuracy: 0.9504 f1: 0.9498
2023-07-13 23:57:04,142 epoch [699/800] time: 4.56s train loss: 0.0574 accuracy: 0.9842 f1: 0.9842
2023-07-13 23:57:04,944 epoch [699/800] time: 0.8s val loss: 0.1465 accuracy: 0.9503 f1: 0.9497
2023-07-13 23:57:09,746 epoch [700/800] time: 4.8s train loss: 0.0578 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:57:10,591 epoch [700/800] time: 0.84s val loss: 0.1449 accuracy: 0.9505 f1: 0.9499
2023-07-13 23:57:15,099 epoch [701/800] time: 4.51s train loss: 0.0575 accuracy: 0.984 f1: 0.9839
2023-07-13 23:57:15,943 epoch [701/800] time: 0.84s val loss: 0.1452 accuracy: 0.9508 f1: 0.9502
2023-07-13 23:57:20,489 epoch [702/800] time: 4.55s train loss: 0.058 accuracy: 0.9842 f1: 0.9841
2023-07-13 23:57:21,294 epoch [702/800] time: 0.8s val loss: 0.1455 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:57:25,841 epoch [703/800] time: 4.55s train loss: 0.0587 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:57:26,689 epoch [703/800] time: 0.85s val loss: 0.1466 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:57:31,196 epoch [704/800] time: 4.51s train loss: 0.0573 accuracy: 0.9843 f1: 0.9843
2023-07-13 23:57:32,040 epoch [704/800] time: 0.84s val loss: 0.146 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:57:36,584 epoch [705/800] time: 4.54s train loss: 0.0595 accuracy: 0.983 f1: 0.9829
2023-07-13 23:57:37,387 epoch [705/800] time: 0.8s val loss: 0.1448 accuracy: 0.9509 f1: 0.9501
2023-07-13 23:57:41,937 epoch [706/800] time: 4.55s train loss: 0.0588 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:57:42,782 epoch [706/800] time: 0.84s val loss: 0.1468 accuracy: 0.9495 f1: 0.9488
2023-07-13 23:57:47,319 epoch [707/800] time: 4.54s train loss: 0.0589 accuracy: 0.9839 f1: 0.9838
2023-07-13 23:57:48,164 epoch [707/800] time: 0.85s val loss: 0.1465 accuracy: 0.9501 f1: 0.9493
2023-07-13 23:57:52,839 epoch [708/800] time: 4.67s train loss: 0.0579 accuracy: 0.9843 f1: 0.9841
2023-07-13 23:57:53,642 epoch [708/800] time: 0.8s val loss: 0.1448 accuracy: 0.9506 f1: 0.95
2023-07-13 23:57:58,240 epoch [709/800] time: 4.6s train loss: 0.0581 accuracy: 0.9839 f1: 0.9839
2023-07-13 23:57:59,085 epoch [709/800] time: 0.85s val loss: 0.1453 accuracy: 0.9503 f1: 0.9497
2023-07-13 23:58:03,642 epoch [710/800] time: 4.56s train loss: 0.0596 accuracy: 0.9836 f1: 0.9835
2023-07-13 23:58:04,495 epoch [710/800] time: 0.85s val loss: 0.1458 accuracy: 0.9501 f1: 0.9495
2023-07-13 23:58:09,088 epoch [711/800] time: 4.59s train loss: 0.0582 accuracy: 0.9835 f1: 0.9835
2023-07-13 23:58:09,891 epoch [711/800] time: 0.8s val loss: 0.1452 accuracy: 0.9507 f1: 0.95
2023-07-13 23:58:14,465 epoch [712/800] time: 4.57s train loss: 0.0593 accuracy: 0.9839 f1: 0.9839
2023-07-13 23:58:15,312 epoch [712/800] time: 0.85s val loss: 0.1457 accuracy: 0.9508 f1: 0.95
2023-07-13 23:58:19,831 epoch [713/800] time: 4.52s train loss: 0.059 accuracy: 0.9833 f1: 0.9832
2023-07-13 23:58:20,681 epoch [713/800] time: 0.85s val loss: 0.1466 accuracy: 0.9499 f1: 0.9491
2023-07-13 23:58:25,245 epoch [714/800] time: 4.56s train loss: 0.0575 accuracy: 0.9842 f1: 0.984
2023-07-13 23:58:26,047 epoch [714/800] time: 0.8s val loss: 0.1451 accuracy: 0.9504 f1: 0.9498
2023-07-13 23:58:30,613 epoch [715/800] time: 4.57s train loss: 0.0574 accuracy: 0.9844 f1: 0.9844
2023-07-13 23:58:31,458 epoch [715/800] time: 0.84s val loss: 0.1456 accuracy: 0.9506 f1: 0.95
2023-07-13 23:58:36,182 epoch [716/800] time: 4.72s train loss: 0.0601 accuracy: 0.9837 f1: 0.9837
2023-07-13 23:58:37,028 epoch [716/800] time: 0.85s val loss: 0.1459 accuracy: 0.9498 f1: 0.949
2023-07-13 23:58:41,585 epoch [717/800] time: 4.56s train loss: 0.0585 accuracy: 0.9838 f1: 0.9836
2023-07-13 23:58:42,387 epoch [717/800] time: 0.8s val loss: 0.1454 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:58:46,962 epoch [718/800] time: 4.57s train loss: 0.0576 accuracy: 0.9844 f1: 0.9844
2023-07-13 23:58:47,807 epoch [718/800] time: 0.84s val loss: 0.146 accuracy: 0.9507 f1: 0.9499
2023-07-13 23:58:52,434 epoch [719/800] time: 4.63s train loss: 0.058 accuracy: 0.9834 f1: 0.9833
2023-07-13 23:58:53,285 epoch [719/800] time: 0.85s val loss: 0.1456 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:58:57,840 epoch [720/800] time: 4.55s train loss: 0.0584 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:58:58,643 epoch [720/800] time: 0.8s val loss: 0.1455 accuracy: 0.9507 f1: 0.95
2023-07-13 23:59:03,228 epoch [721/800] time: 4.58s train loss: 0.0578 accuracy: 0.9837 f1: 0.9836
2023-07-13 23:59:04,078 epoch [721/800] time: 0.85s val loss: 0.1452 accuracy: 0.9504 f1: 0.9497
2023-07-13 23:59:08,605 epoch [722/800] time: 4.53s train loss: 0.0578 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:59:09,454 epoch [722/800] time: 0.85s val loss: 0.1459 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:59:14,029 epoch [723/800] time: 4.57s train loss: 0.0569 accuracy: 0.9841 f1: 0.9839
2023-07-13 23:59:14,829 epoch [723/800] time: 0.8s val loss: 0.1456 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:59:19,408 epoch [724/800] time: 4.58s train loss: 0.0578 accuracy: 0.9838 f1: 0.9837
2023-07-13 23:59:20,257 epoch [724/800] time: 0.85s val loss: 0.1457 accuracy: 0.9502 f1: 0.9496
2023-07-13 23:59:24,891 epoch [725/800] time: 4.63s train loss: 0.0585 accuracy: 0.9836 f1: 0.9836
2023-07-13 23:59:25,799 epoch [725/800] time: 0.91s val loss: 0.1461 accuracy: 0.9507 f1: 0.9501
2023-07-13 23:59:30,608 epoch [726/800] time: 4.81s train loss: 0.0573 accuracy: 0.9838 f1: 0.9838
2023-07-13 23:59:31,416 epoch [726/800] time: 0.81s val loss: 0.1454 accuracy: 0.9513 f1: 0.9506
2023-07-13 23:59:36,116 epoch [727/800] time: 4.7s train loss: 0.0568 accuracy: 0.9845 f1: 0.9845
2023-07-13 23:59:36,969 epoch [727/800] time: 0.85s val loss: 0.1453 accuracy: 0.9509 f1: 0.9502
2023-07-13 23:59:41,897 epoch [728/800] time: 4.93s train loss: 0.0583 accuracy: 0.9839 f1: 0.9839
2023-07-13 23:59:42,770 epoch [728/800] time: 0.87s val loss: 0.1458 accuracy: 0.9506 f1: 0.9499
2023-07-13 23:59:47,837 epoch [729/800] time: 5.07s train loss: 0.0576 accuracy: 0.984 f1: 0.984
2023-07-13 23:59:48,713 epoch [729/800] time: 0.88s val loss: 0.1455 accuracy: 0.9505 f1: 0.9498
2023-07-13 23:59:53,819 epoch [730/800] time: 5.11s train loss: 0.0572 accuracy: 0.9842 f1: 0.9841
2023-07-13 23:59:54,681 epoch [730/800] time: 0.86s val loss: 0.1449 accuracy: 0.9506 f1: 0.95
2023-07-13 23:59:59,459 epoch [731/800] time: 4.78s train loss: 0.0576 accuracy: 0.9838 f1: 0.9837
2023-07-14 00:00:00,376 epoch [731/800] time: 0.92s val loss: 0.145 accuracy: 0.9503 f1: 0.9496
2023-07-14 00:00:05,390 epoch [732/800] time: 5.01s train loss: 0.0577 accuracy: 0.984 f1: 0.9839
2023-07-14 00:00:06,222 epoch [732/800] time: 0.83s val loss: 0.1465 accuracy: 0.95 f1: 0.9494
2023-07-14 00:00:11,166 epoch [733/800] time: 4.94s train loss: 0.0583 accuracy: 0.9836 f1: 0.9836
2023-07-14 00:00:12,058 epoch [733/800] time: 0.89s val loss: 0.1454 accuracy: 0.9503 f1: 0.9497
2023-07-14 00:00:16,866 epoch [734/800] time: 4.81s train loss: 0.058 accuracy: 0.984 f1: 0.9838
2023-07-14 00:00:17,747 epoch [734/800] time: 0.88s val loss: 0.1467 accuracy: 0.9503 f1: 0.9497
2023-07-14 00:00:22,528 epoch [735/800] time: 4.78s train loss: 0.0593 accuracy: 0.9839 f1: 0.9838
2023-07-14 00:00:23,392 epoch [735/800] time: 0.86s val loss: 0.1469 accuracy: 0.9501 f1: 0.9493
2023-07-14 00:00:28,427 epoch [736/800] time: 5.03s train loss: 0.0581 accuracy: 0.9839 f1: 0.9838
2023-07-14 00:00:29,332 epoch [736/800] time: 0.9s val loss: 0.1458 accuracy: 0.9505 f1: 0.9498
2023-07-14 00:00:34,108 epoch [737/800] time: 4.78s train loss: 0.0592 accuracy: 0.984 f1: 0.9839
2023-07-14 00:00:34,967 epoch [737/800] time: 0.86s val loss: 0.1458 accuracy: 0.95 f1: 0.9492
2023-07-14 00:00:39,653 epoch [738/800] time: 4.69s train loss: 0.0582 accuracy: 0.9832 f1: 0.9832
2023-07-14 00:00:40,462 epoch [738/800] time: 0.81s val loss: 0.1455 accuracy: 0.9504 f1: 0.9497
2023-07-14 00:00:45,092 epoch [739/800] time: 4.63s train loss: 0.0582 accuracy: 0.9835 f1: 0.9835
2023-07-14 00:00:45,938 epoch [739/800] time: 0.84s val loss: 0.146 accuracy: 0.9507 f1: 0.9501
2023-07-14 00:00:50,460 epoch [740/800] time: 4.52s train loss: 0.0576 accuracy: 0.9848 f1: 0.9847
2023-07-14 00:00:51,311 epoch [740/800] time: 0.85s val loss: 0.1455 accuracy: 0.95 f1: 0.9495
2023-07-14 00:00:55,947 epoch [741/800] time: 4.64s train loss: 0.0594 accuracy: 0.9835 f1: 0.9834
2023-07-14 00:00:56,753 epoch [741/800] time: 0.81s val loss: 0.1459 accuracy: 0.9505 f1: 0.9497
2023-07-14 00:01:01,370 epoch [742/800] time: 4.62s train loss: 0.0583 accuracy: 0.984 f1: 0.9839
2023-07-14 00:01:02,232 epoch [742/800] time: 0.86s val loss: 0.1465 accuracy: 0.9506 f1: 0.9498
2023-07-14 00:01:06,847 epoch [743/800] time: 4.61s train loss: 0.0604 accuracy: 0.9832 f1: 0.983
2023-07-14 00:01:07,693 epoch [743/800] time: 0.85s val loss: 0.1467 accuracy: 0.9501 f1: 0.9494
2023-07-14 00:01:12,369 epoch [744/800] time: 4.68s train loss: 0.0604 accuracy: 0.984 f1: 0.984
2023-07-14 00:01:13,173 epoch [744/800] time: 0.8s val loss: 0.147 accuracy: 0.9499 f1: 0.9491
2023-07-14 00:01:17,818 epoch [745/800] time: 4.64s train loss: 0.0575 accuracy: 0.984 f1: 0.9839
2023-07-14 00:01:18,664 epoch [745/800] time: 0.85s val loss: 0.1452 accuracy: 0.9509 f1: 0.9503
2023-07-14 00:01:23,336 epoch [746/800] time: 4.67s train loss: 0.0606 accuracy: 0.9841 f1: 0.9839
2023-07-14 00:01:24,182 epoch [746/800] time: 0.85s val loss: 0.1454 accuracy: 0.9502 f1: 0.9495
2023-07-14 00:01:28,898 epoch [747/800] time: 4.72s train loss: 0.058 accuracy: 0.9837 f1: 0.9836
2023-07-14 00:01:29,699 epoch [747/800] time: 0.8s val loss: 0.1452 accuracy: 0.951 f1: 0.9503
2023-07-14 00:01:34,450 epoch [748/800] time: 4.75s train loss: 0.058 accuracy: 0.984 f1: 0.9839
2023-07-14 00:01:35,296 epoch [748/800] time: 0.84s val loss: 0.1452 accuracy: 0.9507 f1: 0.95
2023-07-14 00:01:39,972 epoch [749/800] time: 4.68s train loss: 0.0584 accuracy: 0.9836 f1: 0.9835
2023-07-14 00:01:40,818 epoch [749/800] time: 0.85s val loss: 0.146 accuracy: 0.9505 f1: 0.9498
2023-07-14 00:01:45,603 epoch [750/800] time: 4.79s train loss: 0.0576 accuracy: 0.9843 f1: 0.9842
2023-07-14 00:01:46,402 epoch [750/800] time: 0.8s val loss: 0.1457 accuracy: 0.9502 f1: 0.9495
2023-07-14 00:01:50,975 epoch [751/800] time: 4.57s train loss: 0.0583 accuracy: 0.984 f1: 0.9839
2023-07-14 00:01:51,832 epoch [751/800] time: 0.86s val loss: 0.1471 accuracy: 0.9501 f1: 0.9494
2023-07-14 00:01:56,406 epoch [752/800] time: 4.57s train loss: 0.0582 accuracy: 0.9837 f1: 0.9837
2023-07-14 00:01:57,252 epoch [752/800] time: 0.85s val loss: 0.1455 accuracy: 0.9507 f1: 0.9501
2023-07-14 00:02:01,873 epoch [753/800] time: 4.62s train loss: 0.0577 accuracy: 0.9838 f1: 0.9836
2023-07-14 00:02:02,673 epoch [753/800] time: 0.8s val loss: 0.1455 accuracy: 0.9508 f1: 0.9501
2023-07-14 00:02:07,338 epoch [754/800] time: 4.66s train loss: 0.0576 accuracy: 0.9842 f1: 0.9842
2023-07-14 00:02:08,183 epoch [754/800] time: 0.85s val loss: 0.1456 accuracy: 0.9506 f1: 0.9499
2023-07-14 00:02:12,826 epoch [755/800] time: 4.64s train loss: 0.0604 accuracy: 0.9831 f1: 0.9831
2023-07-14 00:02:13,671 epoch [755/800] time: 0.84s val loss: 0.1457 accuracy: 0.95 f1: 0.9494
2023-07-14 00:02:18,400 epoch [756/800] time: 4.73s train loss: 0.0576 accuracy: 0.9841 f1: 0.9839
2023-07-14 00:02:19,201 epoch [756/800] time: 0.8s val loss: 0.1455 accuracy: 0.951 f1: 0.9503
2023-07-14 00:02:23,936 epoch [757/800] time: 4.73s train loss: 0.0581 accuracy: 0.9838 f1: 0.9837
2023-07-14 00:02:24,780 epoch [757/800] time: 0.84s val loss: 0.1458 accuracy: 0.9508 f1: 0.9502
2023-07-14 00:02:29,513 epoch [758/800] time: 4.73s train loss: 0.0577 accuracy: 0.9839 f1: 0.9838
2023-07-14 00:02:30,358 epoch [758/800] time: 0.84s val loss: 0.1459 accuracy: 0.9505 f1: 0.9498
2023-07-14 00:02:35,131 epoch [759/800] time: 4.77s train loss: 0.0591 accuracy: 0.9833 f1: 0.9832
2023-07-14 00:02:35,932 epoch [759/800] time: 0.8s val loss: 0.1452 accuracy: 0.951 f1: 0.9504
2023-07-14 00:02:40,488 epoch [760/800] time: 4.56s train loss: 0.058 accuracy: 0.9839 f1: 0.9838
2023-07-14 00:02:41,333 epoch [760/800] time: 0.84s val loss: 0.1455 accuracy: 0.9506 f1: 0.9499
2023-07-14 00:02:45,868 epoch [761/800] time: 4.53s train loss: 0.0579 accuracy: 0.9837 f1: 0.9836
2023-07-14 00:02:46,729 epoch [761/800] time: 0.86s val loss: 0.1458 accuracy: 0.9507 f1: 0.9501
2023-07-14 00:02:51,513 epoch [762/800] time: 4.78s train loss: 0.0589 accuracy: 0.9834 f1: 0.9834
2023-07-14 00:02:52,315 epoch [762/800] time: 0.8s val loss: 0.1462 accuracy: 0.9503 f1: 0.9497
2023-07-14 00:02:57,081 epoch [763/800] time: 4.77s train loss: 0.0576 accuracy: 0.9842 f1: 0.9842
2023-07-14 00:02:57,927 epoch [763/800] time: 0.85s val loss: 0.1457 accuracy: 0.9511 f1: 0.9503
2023-07-14 00:03:02,845 epoch [764/800] time: 4.92s train loss: 0.0582 accuracy: 0.9838 f1: 0.9838
2023-07-14 00:03:03,794 epoch [764/800] time: 0.95s val loss: 0.1461 accuracy: 0.9506 f1: 0.9497
2023-07-14 00:03:08,831 epoch [765/800] time: 5.04s train loss: 0.0576 accuracy: 0.9839 f1: 0.9838
2023-07-14 00:03:09,643 epoch [765/800] time: 0.81s val loss: 0.1472 accuracy: 0.9494 f1: 0.9486
2023-07-14 00:03:14,486 epoch [766/800] time: 4.84s train loss: 0.0587 accuracy: 0.9841 f1: 0.984
2023-07-14 00:03:15,415 epoch [766/800] time: 0.93s val loss: 0.146 accuracy: 0.9507 f1: 0.95
2023-07-14 00:03:20,576 epoch [767/800] time: 5.16s train loss: 0.0595 accuracy: 0.9838 f1: 0.9836
2023-07-14 00:03:21,453 epoch [767/800] time: 0.88s val loss: 0.1465 accuracy: 0.9496 f1: 0.949
2023-07-14 00:03:26,154 epoch [768/800] time: 4.7s train loss: 0.0584 accuracy: 0.9833 f1: 0.9832
2023-07-14 00:03:26,964 epoch [768/800] time: 0.81s val loss: 0.145 accuracy: 0.9506 f1: 0.9499
2023-07-14 00:03:32,109 epoch [769/800] time: 5.15s train loss: 0.0568 accuracy: 0.9843 f1: 0.9843
2023-07-14 00:03:33,035 epoch [769/800] time: 0.93s val loss: 0.1455 accuracy: 0.9501 f1: 0.9495
2023-07-14 00:03:37,912 epoch [770/800] time: 4.88s train loss: 0.0578 accuracy: 0.9838 f1: 0.9838
2023-07-14 00:03:38,773 epoch [770/800] time: 0.86s val loss: 0.1456 accuracy: 0.9503 f1: 0.9496
2023-07-14 00:03:43,689 epoch [771/800] time: 4.92s train loss: 0.0582 accuracy: 0.9839 f1: 0.9837
2023-07-14 00:03:44,595 epoch [771/800] time: 0.91s val loss: 0.146 accuracy: 0.9508 f1: 0.9502
2023-07-14 00:03:49,717 epoch [772/800] time: 5.12s train loss: 0.0593 accuracy: 0.9833 f1: 0.9832
2023-07-14 00:03:50,579 epoch [772/800] time: 0.86s val loss: 0.1463 accuracy: 0.9504 f1: 0.9497
2023-07-14 00:03:55,274 epoch [773/800] time: 4.7s train loss: 0.0573 accuracy: 0.9841 f1: 0.9841
2023-07-14 00:03:56,156 epoch [773/800] time: 0.88s val loss: 0.1459 accuracy: 0.9507 f1: 0.95
2023-07-14 00:04:00,799 epoch [774/800] time: 4.64s train loss: 0.0586 accuracy: 0.9834 f1: 0.9833
2023-07-14 00:04:01,614 epoch [774/800] time: 0.81s val loss: 0.1461 accuracy: 0.9507 f1: 0.9501
2023-07-14 00:04:06,245 epoch [775/800] time: 4.63s train loss: 0.0569 accuracy: 0.9842 f1: 0.9841
2023-07-14 00:04:07,096 epoch [775/800] time: 0.85s val loss: 0.1453 accuracy: 0.9504 f1: 0.9498
2023-07-14 00:04:11,815 epoch [776/800] time: 4.72s train loss: 0.0595 accuracy: 0.983 f1: 0.9829
2023-07-14 00:04:12,665 epoch [776/800] time: 0.85s val loss: 0.1456 accuracy: 0.9505 f1: 0.9497
2023-07-14 00:04:17,638 epoch [777/800] time: 4.97s train loss: 0.0575 accuracy: 0.984 f1: 0.9837
2023-07-14 00:04:18,499 epoch [777/800] time: 0.86s val loss: 0.1457 accuracy: 0.9502 f1: 0.9494
2023-07-14 00:04:23,233 epoch [778/800] time: 4.73s train loss: 0.0581 accuracy: 0.9843 f1: 0.9841
2023-07-14 00:04:24,088 epoch [778/800] time: 0.85s val loss: 0.1462 accuracy: 0.9505 f1: 0.9498
2023-07-14 00:04:28,918 epoch [779/800] time: 4.83s train loss: 0.0586 accuracy: 0.9832 f1: 0.9831
2023-07-14 00:04:29,856 epoch [779/800] time: 0.94s val loss: 0.1465 accuracy: 0.9498 f1: 0.9493
2023-07-14 00:04:35,100 epoch [780/800] time: 5.24s train loss: 0.0585 accuracy: 0.9839 f1: 0.9839
2023-07-14 00:04:35,946 epoch [780/800] time: 0.85s val loss: 0.1464 accuracy: 0.9501 f1: 0.9494
2023-07-14 00:04:40,926 epoch [781/800] time: 4.98s train loss: 0.0578 accuracy: 0.9838 f1: 0.9837
2023-07-14 00:04:41,797 epoch [781/800] time: 0.87s val loss: 0.1453 accuracy: 0.9505 f1: 0.9496
2023-07-14 00:04:46,773 epoch [782/800] time: 4.98s train loss: 0.0577 accuracy: 0.9837 f1: 0.9836
2023-07-14 00:04:47,704 epoch [782/800] time: 0.93s val loss: 0.145 accuracy: 0.9509 f1: 0.9503
2023-07-14 00:04:52,674 epoch [783/800] time: 4.97s train loss: 0.0582 accuracy: 0.9837 f1: 0.9835
2023-07-14 00:04:53,490 epoch [783/800] time: 0.82s val loss: 0.1455 accuracy: 0.9507 f1: 0.95
2023-07-14 00:04:58,364 epoch [784/800] time: 4.87s train loss: 0.0581 accuracy: 0.9835 f1: 0.9834
2023-07-14 00:04:59,256 epoch [784/800] time: 0.89s val loss: 0.1457 accuracy: 0.9503 f1: 0.9496
2023-07-14 00:05:04,402 epoch [785/800] time: 5.15s train loss: 0.0584 accuracy: 0.9838 f1: 0.9837
2023-07-14 00:05:05,299 epoch [785/800] time: 0.9s val loss: 0.1471 accuracy: 0.9491 f1: 0.9485
2023-07-14 00:05:10,192 epoch [786/800] time: 4.89s train loss: 0.0583 accuracy: 0.9839 f1: 0.9839
2023-07-14 00:05:11,049 epoch [786/800] time: 0.86s val loss: 0.1458 accuracy: 0.9504 f1: 0.9497
2023-07-14 00:05:16,412 epoch [787/800] time: 5.36s train loss: 0.0579 accuracy: 0.9841 f1: 0.984
2023-07-14 00:05:17,357 epoch [787/800] time: 0.94s val loss: 0.1457 accuracy: 0.9506 f1: 0.9498
2023-07-14 00:05:22,582 epoch [788/800] time: 5.23s train loss: 0.0579 accuracy: 0.9837 f1: 0.9837
2023-07-14 00:05:23,726 epoch [788/800] time: 1.14s val loss: 0.1464 accuracy: 0.9499 f1: 0.9491
2023-07-14 00:05:28,949 epoch [789/800] time: 5.22s train loss: 0.0582 accuracy: 0.9835 f1: 0.9835
2023-07-14 00:05:29,836 epoch [789/800] time: 0.89s val loss: 0.1455 accuracy: 0.9505 f1: 0.9499
2023-07-14 00:05:35,040 epoch [790/800] time: 5.2s train loss: 0.059 accuracy: 0.9834 f1: 0.9833
2023-07-14 00:05:35,967 epoch [790/800] time: 0.93s val loss: 0.148 accuracy: 0.9495 f1: 0.9488
2023-07-14 00:05:40,909 epoch [791/800] time: 4.94s train loss: 0.0594 accuracy: 0.9837 f1: 0.9836
2023-07-14 00:05:41,811 epoch [791/800] time: 0.9s val loss: 0.1469 accuracy: 0.9499 f1: 0.9491
2023-07-14 00:05:46,844 epoch [792/800] time: 5.03s train loss: 0.0592 accuracy: 0.9836 f1: 0.9835
2023-07-14 00:05:47,688 epoch [792/800] time: 0.84s val loss: 0.1456 accuracy: 0.9501 f1: 0.9492
2023-07-14 00:05:52,699 epoch [793/800] time: 5.01s train loss: 0.0581 accuracy: 0.9835 f1: 0.9834
2023-07-14 00:05:53,611 epoch [793/800] time: 0.91s val loss: 0.1451 accuracy: 0.9505 f1: 0.9498
2023-07-14 00:05:58,570 epoch [794/800] time: 4.96s train loss: 0.0587 accuracy: 0.9839 f1: 0.9838
2023-07-14 00:05:59,454 epoch [794/800] time: 0.88s val loss: 0.1458 accuracy: 0.9504 f1: 0.9498
2023-07-14 00:06:04,259 epoch [795/800] time: 4.81s train loss: 0.0597 accuracy: 0.9837 f1: 0.9837
2023-07-14 00:06:05,109 epoch [795/800] time: 0.85s val loss: 0.1481 accuracy: 0.9496 f1: 0.9489
2023-07-14 00:06:10,063 epoch [796/800] time: 4.95s train loss: 0.0578 accuracy: 0.984 f1: 0.9839
2023-07-14 00:06:11,012 epoch [796/800] time: 0.95s val loss: 0.1454 accuracy: 0.9505 f1: 0.9497
2023-07-14 00:06:16,245 epoch [797/800] time: 5.23s train loss: 0.0584 accuracy: 0.9841 f1: 0.984
2023-07-14 00:06:17,142 epoch [797/800] time: 0.9s val loss: 0.1451 accuracy: 0.9508 f1: 0.9502
2023-07-14 00:06:22,008 epoch [798/800] time: 4.87s train loss: 0.0581 accuracy: 0.9835 f1: 0.9834
2023-07-14 00:06:22,836 epoch [798/800] time: 0.83s val loss: 0.1457 accuracy: 0.9502 f1: 0.9495
2023-07-14 00:06:27,933 epoch [799/800] time: 5.1s train loss: 0.0576 accuracy: 0.9839 f1: 0.9839
2023-07-14 00:06:28,815 epoch [799/800] time: 0.88s val loss: 0.1448 accuracy: 0.9507 f1: 0.9501
2023-07-14 00:06:33,507 epoch [800/800] time: 4.69s train loss: 0.057 accuracy: 0.984 f1: 0.9839
2023-07-14 00:06:34,375 epoch [800/800] time: 0.87s val loss: 0.1457 accuracy: 0.9506 f1: 0.9499
2023-07-14 00:06:34,468 The model with best acc is saved: epoch 613, acc 0.98486875
2023-07-14 00:06:34,482 The model with best f1 is saved: epoch 478, f1 0.9847573882497495
2023-07-14 00:06:34,560 =======================================================
2023-07-14 00:06:34,561 Best acc classification report:
               precision    recall  f1-score   support

cluster_00205    0.95385   0.78481   0.86111       237
cluster_00222    0.96825   0.73939   0.83849       165
cluster_00232    0.83846   0.82576   0.83206       264
cluster_00246    0.78107   0.81988   0.80000       161
cluster_00259    0.86188   0.86188   0.86188       181
cluster_00261    0.90580   0.91912   0.91241       136
cluster_00262    0.75180   0.92889   0.83101       225
cluster_00267    0.83696   0.90058   0.86761       342
cluster_00275    0.93491   0.60076   0.73148       263
cluster_00276    0.76216   0.89809   0.82456       157
cluster_00278    0.90625   0.62703   0.74121       185
cluster_00287    0.85625   0.85093   0.85358       161
cluster_00291    0.88439   0.86932   0.87679       176
cluster_00293    0.94898   0.66192   0.77987       281
cluster_00294    0.82707   0.90909   0.86614       121
cluster_00296    0.90196   0.86792   0.88462       159
cluster_00298    0.71111   0.86747   0.78155       332
cluster_00299    0.89247   0.69167   0.77934       120
cluster_00300    0.79293   0.75120   0.77150       209
cluster_00303    0.78325   0.95783   0.86179       166
cluster_00304    0.93529   0.87363   0.90341       182
cluster_00319    0.80000   0.85217   0.82526       230
cluster_00322    0.89928   0.87108   0.88496       287
cluster_00333    0.84211   0.82759   0.83478       116
cluster_00338    0.83333   0.80357   0.81818       168
cluster_00340    0.98198   0.49772   0.66061       219
cluster_00344    0.75806   0.80571   0.78116       175
cluster_00346    0.79227   0.76995   0.78095       213
cluster_00350    0.73810   0.91513   0.81713       271
cluster_00352    0.82222   0.72078   0.76817       154
cluster_00359    0.67686   0.87079   0.76167       178
cluster_00360    0.87745   0.84038   0.85851       213
cluster_00361    0.86897   0.75000   0.80511       168
cluster_00365    0.90355   0.83962   0.87042       212
cluster_00368    0.84454   0.95261   0.89532       211
cluster_00373    0.81290   0.82895   0.82085       152
cluster_00374    0.85106   0.72398   0.78240       221
cluster_00375    0.81273   0.84436   0.82824       257
cluster_00377    0.81250   0.86667   0.83871       255
cluster_00380    0.88485   0.85882   0.87164       170
cluster_00385    0.88372   0.85714   0.87023       266
cluster_00388    0.74041   0.81759   0.77709       307
cluster_00389    0.63462   0.74157   0.68394       178
cluster_00390    0.96859   0.75510   0.84862       245
cluster_00394    0.82857   0.67442   0.74359       172
cluster_00400    0.75385   0.91589   0.82700       107
cluster_00401    0.53242   0.89143   0.66667       175
cluster_00405    0.79581   0.91018   0.84916       167
cluster_00407    0.79861   0.88803   0.84095       259
cluster_00408    0.92969   0.53846   0.68195       221
cluster_00409    0.86385   0.76033   0.80879       242
cluster_00412    0.97253   0.77974   0.86553       227
cluster_00445    0.75658   0.88462   0.81560       130
cluster_00473    0.81538   0.86885   0.84127       122
cluster_00585    0.72385   0.85644   0.78458       202
cluster_00589    0.76471   0.80690   0.78523       145
cluster_00591    0.81614   0.89655   0.85446       203
cluster_00593    0.80120   0.93662   0.86364       142
cluster_00596    0.84496   0.67284   0.74914       162
cluster_00603    0.83684   0.81122   0.82383       196
cluster_00604    0.91045   0.88406   0.89706       138
cluster_00607    0.79894   0.79474   0.79683       190
cluster_00612    0.92517   0.70466   0.80000       193
cluster_00616    0.79839   0.80488   0.80162       246
cluster_00619    0.67368   0.68817   0.68085       186
cluster_00629    0.81855   0.85294   0.83539       238
cluster_00630    0.69424   0.93689   0.79752       206
cluster_00635    0.74370   0.88945   0.81007       199
cluster_00637    0.62807   0.96757   0.76170       185
cluster_00639    0.83607   0.90265   0.86809       226
cluster_00642    0.92958   0.79839   0.85900       248
cluster_00645    0.77838   0.83237   0.80447       173
cluster_00647    0.75909   0.75909   0.75909       220
cluster_00652    0.78970   0.86385   0.82511       213
cluster_00653    0.90511   0.77987   0.83784       159
cluster_00656    0.89677   0.67476   0.77008       206
cluster_00657    0.72028   0.86555   0.78626       238
cluster_00661    0.97561   0.64171   0.77419       187
cluster_00662    0.80224   0.87398   0.83658       246
cluster_00667    0.80252   0.94554   0.86818       202
cluster_00762    0.91620   0.80392   0.85640       204
cluster_00201    0.99492   1.00000   0.99746       196
cluster_00217    0.85417   0.92655   0.88889       177
cluster_00239    0.96721   0.77293   0.85922       229
cluster_00320    0.82840   0.80460   0.81633       174
cluster_00391    0.88477   0.77338   0.82534       278
cluster_00398    0.79554   0.93450   0.85944       229
cluster_00415    0.73109   0.87437   0.79634       199
cluster_00477    0.94898   0.64583   0.76860       144
cluster_00478    0.95139   0.74457   0.83537       184
cluster_00479    0.76301   0.95652   0.84887       138
cluster_00078    0.96875   0.71264   0.82119       261
cluster_00079    0.66667   0.83158   0.74005       190
cluster_00083    0.81778   0.65018   0.72441       283
cluster_00090    0.72727   0.94624   0.82243        93
cluster_00094    0.68613   0.83186   0.75200       113
cluster_00096    0.95575   0.85039   0.90000       127
cluster_00101    0.88596   0.89381   0.88987       113
cluster_00086    0.85953   0.92115   0.88927       279
cluster_00095    0.98758   0.68831   0.81122       231
cluster_00097    0.80916   0.86885   0.83794       122
cluster_00106    0.80223   0.99654   0.88889       289
cluster_00553    0.91414   0.83796   0.87440       216
cluster_00554    0.83384   0.87342   0.85317       316
cluster_00569    0.88827   0.71622   0.79302       222
cluster_00015    0.88393   0.91667   0.90000       108
cluster_00017    0.84397   0.50638   0.63298       235
cluster_00018    0.71676   0.69274   0.70455       179
cluster_00023    0.58896   0.41202   0.48485       233
cluster_00025    0.82812   0.70199   0.75986       151
cluster_00030    0.56863   0.76720   0.65315       189
cluster_00035    0.81481   0.70968   0.75862       124
cluster_00039    0.46512   0.91954   0.61776       174
cluster_00042    0.87838   0.67358   0.76246       193
cluster_00046    0.60324   0.65639   0.62869       227
cluster_00055    0.67509   0.96891   0.79574       193
cluster_00059    0.80275   0.78125   0.79186       224
cluster_00061    0.84756   0.80347   0.82493       173
cluster_00274    0.95000   0.80282   0.87023       213
cluster_00308    0.78986   0.68125   0.73154       160
cluster_00337    0.89655   0.88136   0.88889       177
cluster_00362    0.82569   0.92308   0.87167       195
cluster_00369    0.93077   0.96032   0.94531       126
cluster_00392    0.87245   0.85930   0.86582       199
cluster_00414    0.85526   0.99237   0.91873       131
cluster_00419    0.69286   0.91509   0.78862       212
cluster_00420    0.81633   0.85106   0.83333       188
cluster_00421    0.77857   0.99091   0.87200       110
cluster_00422    0.90955   0.73279   0.81166       247
cluster_00427    0.89706   0.77215   0.82993       158
cluster_00430    0.72222   0.90278   0.80247       216
cluster_00431    0.79661   0.77686   0.78661       242
cluster_00436    0.95676   0.91237   0.93404       194
cluster_00439    0.90909   0.89928   0.90416       278
cluster_00444    0.90129   0.98131   0.93960       214
cluster_00447    0.80952   0.68000   0.73913       150
cluster_00448    0.91623   0.78829   0.84746       222
cluster_00450    0.94203   0.73308   0.82452       266
cluster_00456    0.73684   0.89362   0.80769       141
cluster_00458    0.91810   0.72945   0.81298       292
cluster_00460    0.85909   0.91304   0.88525       207
cluster_00463    0.81548   0.87261   0.84308       157
cluster_00467    0.91743   0.75758   0.82988       132
cluster_00483    0.89600   0.80576   0.84848       139
cluster_00484    0.89516   0.84091   0.86719       132
cluster_00007    0.74641   0.87151   0.80412       179
cluster_00036    0.74490   0.87600   0.80515       250
cluster_00054    0.78788   0.83200   0.80934       125
cluster_00062    0.85366   0.84000   0.84677       250
cluster_00064    0.80695   0.92478   0.86186       226
cluster_00065    0.85845   0.97917   0.91484       192
cluster_00067    0.84672   0.77852   0.81119       149
cluster_00071    0.65556   0.88060   0.75159       134
cluster_00075    0.81122   0.72603   0.76627       219
cluster_00084    0.91943   0.80833   0.86031       240
cluster_00093    0.76763   0.79060   0.77895       234
cluster_00001    0.81333   0.95686   0.87928       255
cluster_00002    0.79856   0.66071   0.72313       168
cluster_00003    0.88696   0.76981   0.82424       265
cluster_00006    0.98901   0.85714   0.91837       210
cluster_00008    0.85619   0.93431   0.89354       274
cluster_00010    0.89944   0.69099   0.78155       233
cluster_00012    0.89560   0.84456   0.86933       193
cluster_00019    0.94286   0.69231   0.79839       143
cluster_00022    0.85185   0.78922   0.81934       204
cluster_00026    0.89333   0.74444   0.81212       180
cluster_00029    0.82243   0.77533   0.79819       227
cluster_00031    0.76000   0.64528   0.69796       265
cluster_00043    0.84868   0.97358   0.90685       265
cluster_00051    0.83019   0.84211   0.83610       209
cluster_00052    0.80857   0.81089   0.80973       349
cluster_00073    0.70323   0.93162   0.80147       234
cluster_00076    0.77830   0.81281   0.79518       203
cluster_00082    0.82667   0.87324   0.84932       284
cluster_00107    0.83521   0.95708   0.89200       233
cluster_00432    0.95161   0.91473   0.93281       258
cluster_00440    0.90323   0.82700   0.86344       237
cluster_00455    0.82000   0.95349   0.88172       172
cluster_00714    0.93088   0.91818   0.92449       220
cluster_00791    0.95055   0.83981   0.89175       206
cluster_00119    0.79812   0.89947   0.84577       189
cluster_00121    0.94872   0.98930   0.96859       187
cluster_00155    0.91636   0.95455   0.93506       264
cluster_00556    0.96447   0.91346   0.93827       208
cluster_00557    0.96864   0.93603   0.95205       297
cluster_00689    0.96581   0.93004   0.94759       243
cluster_00692    0.85959   0.98819   0.91941       254
cluster_00718    0.96203   0.68468   0.80000       222
cluster_00725    0.85799   0.85294   0.85546       170
cluster_00727    0.92063   0.87879   0.89922       132
cluster_00729    0.88475   0.95956   0.92063       272
cluster_00733    0.96026   0.94771   0.95395       153
cluster_00738    0.87500   0.89535   0.88506       172
cluster_00740    0.98347   0.80405   0.88476       148
cluster_00744    0.85841   0.88584   0.87191       219
cluster_00753    0.87019   0.87019   0.87019       208
cluster_00777    0.79630   0.96413   0.87221       223
cluster_00795    0.90110   0.88172   0.89130       186

     accuracy                        0.82778     40000
    macro avg    0.83812   0.82902   0.82679     40000
 weighted avg    0.84008   0.82778   0.82713     40000

2023-07-14 00:06:34,561 =======================================================
2023-07-14 00:06:34,561 

2023-07-14 00:06:34,930 =======================================================
2023-07-14 00:06:34,930 Best f1 classification report:
               precision    recall  f1-score   support

cluster_00205    0.95385   0.78481   0.86111       237
cluster_00222    0.96825   0.73939   0.83849       165
cluster_00232    0.83846   0.82576   0.83206       264
cluster_00246    0.78107   0.81988   0.80000       161
cluster_00259    0.86188   0.86188   0.86188       181
cluster_00261    0.90580   0.91912   0.91241       136
cluster_00262    0.75180   0.92889   0.83101       225
cluster_00267    0.83696   0.90058   0.86761       342
cluster_00275    0.93491   0.60076   0.73148       263
cluster_00276    0.76216   0.89809   0.82456       157
cluster_00278    0.90625   0.62703   0.74121       185
cluster_00287    0.85625   0.85093   0.85358       161
cluster_00291    0.88439   0.86932   0.87679       176
cluster_00293    0.94898   0.66192   0.77987       281
cluster_00294    0.82707   0.90909   0.86614       121
cluster_00296    0.90196   0.86792   0.88462       159
cluster_00298    0.71111   0.86747   0.78155       332
cluster_00299    0.89247   0.69167   0.77934       120
cluster_00300    0.79293   0.75120   0.77150       209
cluster_00303    0.78325   0.95783   0.86179       166
cluster_00304    0.93529   0.87363   0.90341       182
cluster_00319    0.80000   0.85217   0.82526       230
cluster_00322    0.89928   0.87108   0.88496       287
cluster_00333    0.84211   0.82759   0.83478       116
cluster_00338    0.83333   0.80357   0.81818       168
cluster_00340    0.98198   0.49772   0.66061       219
cluster_00344    0.75806   0.80571   0.78116       175
cluster_00346    0.79227   0.76995   0.78095       213
cluster_00350    0.73810   0.91513   0.81713       271
cluster_00352    0.82222   0.72078   0.76817       154
cluster_00359    0.67686   0.87079   0.76167       178
cluster_00360    0.87745   0.84038   0.85851       213
cluster_00361    0.86897   0.75000   0.80511       168
cluster_00365    0.90355   0.83962   0.87042       212
cluster_00368    0.84454   0.95261   0.89532       211
cluster_00373    0.81290   0.82895   0.82085       152
cluster_00374    0.85106   0.72398   0.78240       221
cluster_00375    0.81273   0.84436   0.82824       257
cluster_00377    0.81250   0.86667   0.83871       255
cluster_00380    0.88485   0.85882   0.87164       170
cluster_00385    0.88372   0.85714   0.87023       266
cluster_00388    0.74041   0.81759   0.77709       307
cluster_00389    0.63462   0.74157   0.68394       178
cluster_00390    0.96859   0.75510   0.84862       245
cluster_00394    0.82857   0.67442   0.74359       172
cluster_00400    0.75385   0.91589   0.82700       107
cluster_00401    0.53242   0.89143   0.66667       175
cluster_00405    0.79581   0.91018   0.84916       167
cluster_00407    0.79861   0.88803   0.84095       259
cluster_00408    0.92969   0.53846   0.68195       221
cluster_00409    0.86385   0.76033   0.80879       242
cluster_00412    0.97253   0.77974   0.86553       227
cluster_00445    0.75658   0.88462   0.81560       130
cluster_00473    0.81538   0.86885   0.84127       122
cluster_00585    0.72385   0.85644   0.78458       202
cluster_00589    0.76471   0.80690   0.78523       145
cluster_00591    0.81614   0.89655   0.85446       203
cluster_00593    0.80120   0.93662   0.86364       142
cluster_00596    0.84496   0.67284   0.74914       162
cluster_00603    0.83684   0.81122   0.82383       196
cluster_00604    0.91045   0.88406   0.89706       138
cluster_00607    0.79894   0.79474   0.79683       190
cluster_00612    0.92517   0.70466   0.80000       193
cluster_00616    0.79839   0.80488   0.80162       246
cluster_00619    0.67368   0.68817   0.68085       186
cluster_00629    0.81855   0.85294   0.83539       238
cluster_00630    0.69424   0.93689   0.79752       206
cluster_00635    0.74370   0.88945   0.81007       199
cluster_00637    0.62807   0.96757   0.76170       185
cluster_00639    0.83607   0.90265   0.86809       226
cluster_00642    0.92958   0.79839   0.85900       248
cluster_00645    0.77838   0.83237   0.80447       173
cluster_00647    0.75909   0.75909   0.75909       220
cluster_00652    0.78970   0.86385   0.82511       213
cluster_00653    0.90511   0.77987   0.83784       159
cluster_00656    0.89677   0.67476   0.77008       206
cluster_00657    0.72028   0.86555   0.78626       238
cluster_00661    0.97561   0.64171   0.77419       187
cluster_00662    0.80224   0.87398   0.83658       246
cluster_00667    0.80252   0.94554   0.86818       202
cluster_00762    0.91620   0.80392   0.85640       204
cluster_00201    0.99492   1.00000   0.99746       196
cluster_00217    0.85417   0.92655   0.88889       177
cluster_00239    0.96721   0.77293   0.85922       229
cluster_00320    0.82840   0.80460   0.81633       174
cluster_00391    0.88477   0.77338   0.82534       278
cluster_00398    0.79554   0.93450   0.85944       229
cluster_00415    0.73109   0.87437   0.79634       199
cluster_00477    0.94898   0.64583   0.76860       144
cluster_00478    0.95139   0.74457   0.83537       184
cluster_00479    0.76301   0.95652   0.84887       138
cluster_00078    0.96875   0.71264   0.82119       261
cluster_00079    0.66667   0.83158   0.74005       190
cluster_00083    0.81778   0.65018   0.72441       283
cluster_00090    0.72727   0.94624   0.82243        93
cluster_00094    0.68613   0.83186   0.75200       113
cluster_00096    0.95575   0.85039   0.90000       127
cluster_00101    0.88596   0.89381   0.88987       113
cluster_00086    0.85953   0.92115   0.88927       279
cluster_00095    0.98758   0.68831   0.81122       231
cluster_00097    0.80916   0.86885   0.83794       122
cluster_00106    0.80223   0.99654   0.88889       289
cluster_00553    0.91414   0.83796   0.87440       216
cluster_00554    0.83384   0.87342   0.85317       316
cluster_00569    0.88827   0.71622   0.79302       222
cluster_00015    0.88393   0.91667   0.90000       108
cluster_00017    0.84397   0.50638   0.63298       235
cluster_00018    0.71676   0.69274   0.70455       179
cluster_00023    0.58896   0.41202   0.48485       233
cluster_00025    0.82812   0.70199   0.75986       151
cluster_00030    0.56863   0.76720   0.65315       189
cluster_00035    0.81481   0.70968   0.75862       124
cluster_00039    0.46512   0.91954   0.61776       174
cluster_00042    0.87838   0.67358   0.76246       193
cluster_00046    0.60324   0.65639   0.62869       227
cluster_00055    0.67509   0.96891   0.79574       193
cluster_00059    0.80275   0.78125   0.79186       224
cluster_00061    0.84756   0.80347   0.82493       173
cluster_00274    0.95000   0.80282   0.87023       213
cluster_00308    0.78986   0.68125   0.73154       160
cluster_00337    0.89655   0.88136   0.88889       177
cluster_00362    0.82569   0.92308   0.87167       195
cluster_00369    0.93077   0.96032   0.94531       126
cluster_00392    0.87245   0.85930   0.86582       199
cluster_00414    0.85526   0.99237   0.91873       131
cluster_00419    0.69286   0.91509   0.78862       212
cluster_00420    0.81633   0.85106   0.83333       188
cluster_00421    0.77857   0.99091   0.87200       110
cluster_00422    0.90955   0.73279   0.81166       247
cluster_00427    0.89706   0.77215   0.82993       158
cluster_00430    0.72222   0.90278   0.80247       216
cluster_00431    0.79661   0.77686   0.78661       242
cluster_00436    0.95676   0.91237   0.93404       194
cluster_00439    0.90909   0.89928   0.90416       278
cluster_00444    0.90129   0.98131   0.93960       214
cluster_00447    0.80952   0.68000   0.73913       150
cluster_00448    0.91623   0.78829   0.84746       222
cluster_00450    0.94203   0.73308   0.82452       266
cluster_00456    0.73684   0.89362   0.80769       141
cluster_00458    0.91810   0.72945   0.81298       292
cluster_00460    0.85909   0.91304   0.88525       207
cluster_00463    0.81548   0.87261   0.84308       157
cluster_00467    0.91743   0.75758   0.82988       132
cluster_00483    0.89600   0.80576   0.84848       139
cluster_00484    0.89516   0.84091   0.86719       132
cluster_00007    0.74641   0.87151   0.80412       179
cluster_00036    0.74490   0.87600   0.80515       250
cluster_00054    0.78788   0.83200   0.80934       125
cluster_00062    0.85366   0.84000   0.84677       250
cluster_00064    0.80695   0.92478   0.86186       226
cluster_00065    0.85845   0.97917   0.91484       192
cluster_00067    0.84672   0.77852   0.81119       149
cluster_00071    0.65556   0.88060   0.75159       134
cluster_00075    0.81122   0.72603   0.76627       219
cluster_00084    0.91943   0.80833   0.86031       240
cluster_00093    0.76763   0.79060   0.77895       234
cluster_00001    0.81333   0.95686   0.87928       255
cluster_00002    0.79856   0.66071   0.72313       168
cluster_00003    0.88696   0.76981   0.82424       265
cluster_00006    0.98901   0.85714   0.91837       210
cluster_00008    0.85619   0.93431   0.89354       274
cluster_00010    0.89944   0.69099   0.78155       233
cluster_00012    0.89560   0.84456   0.86933       193
cluster_00019    0.94286   0.69231   0.79839       143
cluster_00022    0.85185   0.78922   0.81934       204
cluster_00026    0.89333   0.74444   0.81212       180
cluster_00029    0.82243   0.77533   0.79819       227
cluster_00031    0.76000   0.64528   0.69796       265
cluster_00043    0.84868   0.97358   0.90685       265
cluster_00051    0.83019   0.84211   0.83610       209
cluster_00052    0.80857   0.81089   0.80973       349
cluster_00073    0.70323   0.93162   0.80147       234
cluster_00076    0.77830   0.81281   0.79518       203
cluster_00082    0.82667   0.87324   0.84932       284
cluster_00107    0.83521   0.95708   0.89200       233
cluster_00432    0.95161   0.91473   0.93281       258
cluster_00440    0.90323   0.82700   0.86344       237
cluster_00455    0.82000   0.95349   0.88172       172
cluster_00714    0.93088   0.91818   0.92449       220
cluster_00791    0.95055   0.83981   0.89175       206
cluster_00119    0.79812   0.89947   0.84577       189
cluster_00121    0.94872   0.98930   0.96859       187
cluster_00155    0.91636   0.95455   0.93506       264
cluster_00556    0.96447   0.91346   0.93827       208
cluster_00557    0.96864   0.93603   0.95205       297
cluster_00689    0.96581   0.93004   0.94759       243
cluster_00692    0.85959   0.98819   0.91941       254
cluster_00718    0.96203   0.68468   0.80000       222
cluster_00725    0.85799   0.85294   0.85546       170
cluster_00727    0.92063   0.87879   0.89922       132
cluster_00729    0.88475   0.95956   0.92063       272
cluster_00733    0.96026   0.94771   0.95395       153
cluster_00738    0.87500   0.89535   0.88506       172
cluster_00740    0.98347   0.80405   0.88476       148
cluster_00744    0.85841   0.88584   0.87191       219
cluster_00753    0.87019   0.87019   0.87019       208
cluster_00777    0.79630   0.96413   0.87221       223
cluster_00795    0.90110   0.88172   0.89130       186

     accuracy                        0.82778     40000
    macro avg    0.83812   0.82902   0.82679     40000
 weighted avg    0.84008   0.82778   0.82713     40000

2023-07-14 00:06:34,930 =======================================================
2023-07-14 00:06:34,930 

2023-07-14 00:06:35,648 =======================================================
2023-07-14 00:06:35,648 Best acc classification report:
               precision    recall  f1-score   support

cluster_00205    0.99115   0.99006   0.99060       905
cluster_00222    0.98939   0.99240   0.99090       658
cluster_00232    0.97246   0.97972   0.97608       937
cluster_00246    0.97858   0.97858   0.97858       747
cluster_00259    0.97984   0.97852   0.97918       745
cluster_00261    0.98448   0.98789   0.98618       578
cluster_00262    0.98140   0.97926   0.98033       916
cluster_00267    0.98342   0.98912   0.98626      1379
cluster_00275    0.97757   0.98165   0.97961      1199
cluster_00276    0.98413   0.99042   0.98726       626
cluster_00278    0.96807   0.96948   0.96877       688
cluster_00287    0.98830   0.99120   0.98975       682
cluster_00291    0.98271   0.98555   0.98413       692
cluster_00293    0.98233   0.98050   0.98141      1077
cluster_00294    0.97852   0.98086   0.97969       418
cluster_00296    0.98630   0.98361   0.98495       732
cluster_00298    0.98269   0.97884   0.98076      1276
cluster_00299    0.98967   0.98357   0.98661       487
cluster_00300    0.97279   0.96840   0.97059       886
cluster_00303    0.98647   0.99049   0.98847       736
cluster_00304    0.99444   0.99306   0.99375       720
cluster_00319    0.98922   0.98686   0.98804       837
cluster_00322    0.98974   0.98721   0.98848      1173
cluster_00333    0.96337   0.97048   0.96691       542
cluster_00338    0.97281   0.97281   0.97281       662
cluster_00340    0.98243   0.98509   0.98376       738
cluster_00344    0.98198   0.97148   0.97670       561
cluster_00346    0.98650   0.98958   0.98804       960
cluster_00350    0.98132   0.98394   0.98263      1121
cluster_00352    0.97906   0.98594   0.98249       569
cluster_00359    0.96599   0.96966   0.96782       791
cluster_00360    0.98485   0.97990   0.98237       796
cluster_00361    0.97531   0.97531   0.97531       648
cluster_00365    0.98515   0.98882   0.98698       805
cluster_00368    0.98299   0.97823   0.98061       827
cluster_00373    0.97713   0.97962   0.97837       785
cluster_00374    0.98900   0.98144   0.98521       916
cluster_00375    0.97665   0.97570   0.97618      1029
cluster_00377    0.98483   0.98185   0.98334       992
cluster_00380    0.99310   0.98765   0.99037       729
cluster_00385    0.98607   0.99001   0.98804      1001
cluster_00388    0.98024   0.98362   0.98193      1160
cluster_00389    0.97059   0.96350   0.96703       822
cluster_00390    0.98946   0.99062   0.99004       853
cluster_00394    0.96044   0.96965   0.96502       626
cluster_00400    0.99327   0.98664   0.98994       449
cluster_00401    0.96907   0.97337   0.97122       676
cluster_00405    0.97356   0.97508   0.97432       642
cluster_00407    0.98748   0.98748   0.98748      1038
cluster_00408    0.97666   0.97666   0.97666       857
cluster_00409    0.97326   0.97430   0.97378       934
cluster_00412    0.98328   0.98637   0.98482       954
cluster_00445    0.96756   0.96941   0.96848       523
cluster_00473    0.98523   0.97904   0.98212       477
cluster_00585    0.98028   0.98028   0.98028       862
cluster_00589    0.98969   0.99139   0.99054       581
cluster_00591    0.98446   0.98191   0.98318       774
cluster_00593    0.99158   0.97035   0.98085       607
cluster_00596    0.98462   0.98084   0.98273       522
cluster_00603    0.98873   0.99153   0.99013       708
cluster_00604    0.99499   0.99666   0.99582       598
cluster_00607    0.98155   0.98519   0.98336       810
cluster_00612    0.98918   0.99037   0.98978       831
cluster_00616    0.97669   0.97566   0.97618       945
cluster_00619    0.96700   0.97118   0.96909       694
cluster_00629    0.99413   0.99297   0.99355       853
cluster_00630    0.98670   0.98432   0.98551       829
cluster_00635    0.98456   0.98965   0.98710       773
cluster_00637    0.98092   0.97967   0.98029       787
cluster_00639    0.98601   0.98997   0.98799       997
cluster_00642    0.98957   0.98843   0.98900       864
cluster_00645    0.97872   0.97734   0.97803       706
cluster_00647    0.96946   0.96306   0.96625       758
cluster_00652    0.98011   0.98556   0.98283       900
cluster_00653    0.98712   0.98395   0.98553       623
cluster_00656    0.98669   0.98523   0.98596       677
cluster_00657    0.98050   0.97838   0.97944       925
cluster_00661    0.99154   0.99014   0.99084       710
cluster_00662    0.99195   0.98501   0.98847      1001
cluster_00667    0.98926   0.99044   0.98985       837
cluster_00762    0.99046   0.99453   0.99249       731
cluster_00201    1.00000   1.00000   1.00000       851
cluster_00217    0.98750   0.99163   0.98956       717
cluster_00239    0.98975   0.98526   0.98750       882
cluster_00320    0.98312   0.98036   0.98174       713
cluster_00391    0.98080   0.98170   0.98125      1093
cluster_00398    0.98626   0.98723   0.98675      1018
cluster_00415    0.99151   0.98732   0.98941       710
cluster_00477    0.97597   0.97727   0.97662       748
cluster_00478    0.99329   0.98143   0.98732       754
cluster_00479    0.98964   0.99702   0.99332       671
cluster_00078    0.97361   0.97743   0.97551      1019
cluster_00079    0.96936   0.97479   0.97207       714
cluster_00083    0.97118   0.96949   0.97033      1147
cluster_00090    0.96760   0.97180   0.96970       461
cluster_00094    0.96139   0.95220   0.95677       523
cluster_00096    0.98060   0.96809   0.97430       470
cluster_00101    0.98381   0.99094   0.98736       552
cluster_00086    0.98963   0.99392   0.99177      1152
cluster_00095    0.98874   0.98874   0.98874       799
cluster_00097    0.99586   0.99380   0.99483       484
cluster_00106    0.99587   0.99505   0.99546      1211
cluster_00553    0.98443   0.99636   0.99036       825
cluster_00554    0.99042   0.99128   0.99085      1147
cluster_00569    0.99258   0.98528   0.98892       815
cluster_00015    0.98663   0.98400   0.98531       375
cluster_00017    0.98098   0.97744   0.97920      1108
cluster_00018    0.97470   0.97470   0.97470       593
cluster_00023    0.97629   0.97002   0.97315       934
cluster_00025    0.98154   0.98003   0.98078       651
cluster_00030    0.96662   0.97665   0.97161       771
cluster_00035    0.97841   0.98495   0.98167       598
cluster_00039    0.98189   0.97935   0.98062       775
cluster_00042    0.97011   0.97942   0.97474       729
cluster_00046    0.98158   0.98478   0.98318       920
cluster_00055    0.98381   0.97852   0.98116       745
cluster_00059    0.98173   0.97816   0.97994       824
cluster_00061    0.99626   0.99133   0.99379       807
cluster_00274    0.99461   0.99060   0.99260       745
cluster_00308    0.96842   0.98264   0.97548       749
cluster_00337    0.98649   0.99050   0.98849       737
cluster_00362    0.99213   0.98695   0.98953       766
cluster_00369    0.99213   0.98824   0.99018       510
cluster_00392    0.99058   0.99058   0.99058       849
cluster_00414    0.98167   0.99381   0.98770       485
cluster_00419    0.98113   0.98551   0.98331       897
cluster_00420    0.98794   0.99059   0.98926       744
cluster_00421    0.99582   0.99167   0.99374       480
cluster_00422    0.97973   0.97973   0.97973      1036
cluster_00427    0.98211   0.97419   0.97814       620
cluster_00430    0.97363   0.96937   0.97149       914
cluster_00431    0.96765   0.96765   0.96765      1020
cluster_00436    0.99228   0.99741   0.99484       773
cluster_00439    0.98538   0.98859   0.98698      1227
cluster_00444    0.99490   0.99617   0.99554       784
cluster_00447    0.97751   0.97246   0.97498       581
cluster_00448    0.99121   0.99873   0.99496       790
cluster_00450    0.97927   0.98218   0.98072      1010
cluster_00456    0.98537   0.99081   0.98808       544
cluster_00458    0.98650   0.98120   0.98384      1117
cluster_00460    0.98983   0.97987   0.98483       795
cluster_00463    0.98623   0.97449   0.98033       588
cluster_00467    0.99052   0.98896   0.98974       634
cluster_00483    0.99180   0.98978   0.99079       489
cluster_00484    0.98778   0.98951   0.98865       572
cluster_00007    0.98910   0.98450   0.98679       645
cluster_00036    0.97013   0.97957   0.97483      1028
cluster_00054    0.98853   0.98853   0.98853       523
cluster_00062    0.96150   0.95950   0.96050       963
cluster_00064    0.98556   0.97687   0.98119       908
cluster_00065    0.98527   0.98527   0.98527       747
cluster_00067    0.98132   0.97966   0.98049       590
cluster_00071    0.97540   0.97368   0.97454       570
cluster_00075    0.96970   0.96644   0.96807       894
cluster_00084    0.98533   0.98624   0.98579      1090
cluster_00093    0.97555   0.97555   0.97555       859
cluster_00001    0.98357   0.98453   0.98405      1034
cluster_00002    0.98955   0.98808   0.98881       671
cluster_00003    0.97678   0.98100   0.97889      1158
cluster_00006    0.99739   0.99221   0.99479       770
cluster_00008    0.98714   0.99139   0.98926      1161
cluster_00010    0.97808   0.98528   0.98166       815
cluster_00012    0.97863   0.97863   0.97863       655
cluster_00019    0.98696   0.99437   0.99065       533
cluster_00022    0.97622   0.97237   0.97429       760
cluster_00026    0.98394   0.98790   0.98592       744
cluster_00029    0.98779   0.97910   0.98343       909
cluster_00031    0.97977   0.99022   0.98497      1125
cluster_00043    0.99376   0.99821   0.99598      1117
cluster_00051    0.99483   0.99226   0.99354       775
cluster_00052    0.98748   0.98170   0.98458      1366
cluster_00073    0.98832   0.98623   0.98727       944
cluster_00076    0.98674   0.98132   0.98402       910
cluster_00082    0.98936   0.98849   0.98892      1129
cluster_00107    0.99772   0.99319   0.99545       881
cluster_00432    0.99704   0.99704   0.99704      1015
cluster_00440    0.99800   0.99402   0.99600      1003
cluster_00455    0.99568   0.99711   0.99640       693
cluster_00714    0.99775   0.99775   0.99775       888
cluster_00791    0.99554   0.99554   0.99554       672
cluster_00119    0.99676   0.99892   0.99784       923
cluster_00121    0.99591   0.99591   0.99591       734
cluster_00155    0.99812   0.99812   0.99812      1066
cluster_00556    0.99569   0.99892   0.99730       925
cluster_00557    0.99730   0.99462   0.99596      1115
cluster_00689    1.00000   0.99892   0.99946       928
cluster_00692    0.99781   0.99891   0.99836       914
cluster_00718    0.99765   0.99765   0.99765       852
cluster_00725    0.99579   0.99439   0.99509       713
cluster_00727    0.99008   0.99337   0.99172       603
cluster_00729    0.99737   0.99475   0.99605      1142
cluster_00733    0.99830   0.99830   0.99830       589
cluster_00738    1.00000   0.99690   0.99845       646
cluster_00740    1.00000   0.99683   0.99841       630
cluster_00744    0.99685   0.99895   0.99790       951
cluster_00753    0.99329   0.99440   0.99384       893
cluster_00777    0.99880   0.99760   0.99820       834
cluster_00795    0.99341   0.99868   0.99604       755

     accuracy                        0.98487    160000
    macro avg    0.98476   0.98467   0.98471    160000
 weighted avg    0.98488   0.98487   0.98487    160000

2023-07-14 00:06:35,648 =======================================================
2023-07-14 00:06:35,648 

2023-07-14 00:06:37,009 =======================================================
2023-07-14 00:06:37,009 Best f1 classification report:
               precision    recall  f1-score   support

cluster_00205    0.98242   0.98785   0.98512       905
cluster_00222    0.98941   0.99392   0.99166       658
cluster_00232    0.98378   0.97118   0.97744       937
cluster_00246    0.97610   0.98394   0.98000       747
cluster_00259    0.98128   0.98523   0.98326       745
cluster_00261    0.98964   0.99135   0.99049       578
cluster_00262    0.97814   0.97707   0.97761       916
cluster_00267    0.98199   0.98840   0.98518      1379
cluster_00275    0.97593   0.98082   0.97837      1199
cluster_00276    0.99516   0.98562   0.99037       626
cluster_00278    0.97226   0.96802   0.97014       688
cluster_00287    0.98394   0.98827   0.98610       682
cluster_00291    0.98842   0.98699   0.98771       692
cluster_00293    0.98043   0.97679   0.97860      1077
cluster_00294    0.99038   0.98565   0.98801       418
cluster_00296    0.98777   0.99317   0.99046       732
cluster_00298    0.97736   0.98119   0.97927      1276
cluster_00299    0.98361   0.98563   0.98462       487
cluster_00300    0.97727   0.97065   0.97395       886
cluster_00303    0.98636   0.98234   0.98434       736
cluster_00304    0.99303   0.98889   0.99095       720
cluster_00319    0.98684   0.98566   0.98625       837
cluster_00322    0.98889   0.98636   0.98762      1173
cluster_00333    0.97009   0.95756   0.96379       542
cluster_00338    0.98331   0.97885   0.98107       662
cluster_00340    0.98913   0.98645   0.98779       738
cluster_00344    0.98205   0.97504   0.97853       561
cluster_00346    0.98951   0.98229   0.98589       960
cluster_00350    0.98754   0.99019   0.98886      1121
cluster_00352    0.98074   0.98418   0.98246       569
cluster_00359    0.97107   0.97598   0.97352       791
cluster_00360    0.98243   0.98367   0.98305       796
cluster_00361    0.97829   0.97377   0.97602       648
cluster_00365    0.99122   0.98137   0.98627       805
cluster_00368    0.98665   0.98307   0.98486       827
cluster_00373    0.97455   0.97580   0.97518       785
cluster_00374    0.98142   0.98035   0.98088       916
cluster_00375    0.97361   0.96793   0.97076      1029
cluster_00377    0.97311   0.98488   0.97896       992
cluster_00380    0.98767   0.98903   0.98835       729
cluster_00385    0.99102   0.99201   0.99151      1001
cluster_00388    0.98618   0.98448   0.98533      1160
cluster_00389    0.96933   0.96107   0.96518       822
cluster_00390    0.99064   0.99297   0.99180       853
cluster_00394    0.96830   0.97604   0.97216       626
cluster_00400    0.99109   0.99109   0.99109       449
cluster_00401    0.97788   0.98077   0.97932       676
cluster_00405    0.97809   0.97352   0.97580       642
cluster_00407    0.99322   0.98844   0.99083      1038
cluster_00408    0.96774   0.98016   0.97391       857
cluster_00409    0.96716   0.97752   0.97231       934
cluster_00412    0.98220   0.98323   0.98271       954
cluster_00445    0.95652   0.96750   0.96198       523
cluster_00473    0.98732   0.97904   0.98316       477
cluster_00585    0.97332   0.97332   0.97332       862
cluster_00589    0.98456   0.98795   0.98625       581
cluster_00591    0.98705   0.98450   0.98577       774
cluster_00593    0.98673   0.98023   0.98347       607
cluster_00596    0.98263   0.97510   0.97885       522
cluster_00603    0.98582   0.98164   0.98372       708
cluster_00604    0.99003   0.99666   0.99333       598
cluster_00607    0.98515   0.98272   0.98393       810
cluster_00612    0.99035   0.98797   0.98916       831
cluster_00616    0.98627   0.98836   0.98732       945
cluster_00619    0.96987   0.97406   0.97196       694
cluster_00629    0.99067   0.99531   0.99298       853
cluster_00630    0.98077   0.98432   0.98254       829
cluster_00635    0.98570   0.98060   0.98314       773
cluster_00637    0.97957   0.97459   0.97707       787
cluster_00639    0.98310   0.99198   0.98752       997
cluster_00642    0.99188   0.98958   0.99073       864
cluster_00645    0.97483   0.98725   0.98100       706
cluster_00647    0.96316   0.96570   0.96443       758
cluster_00652    0.98004   0.98222   0.98113       900
cluster_00653    0.99516   0.99037   0.99276       623
cluster_00656    0.98516   0.98080   0.98298       677
cluster_00657    0.97198   0.97514   0.97356       925
cluster_00661    0.99297   0.99437   0.99367       710
cluster_00662    0.99099   0.98901   0.99000      1001
cluster_00667    0.99046   0.99283   0.99165       837
cluster_00762    0.99315   0.99179   0.99247       731
cluster_00201    1.00000   0.99882   0.99941       851
cluster_00217    0.99301   0.99024   0.99162       717
cluster_00239    0.99095   0.99320   0.99207       882
cluster_00320    0.98317   0.98317   0.98317       713
cluster_00391    0.98993   0.98902   0.98947      1093
cluster_00398    0.98917   0.98723   0.98820      1018
cluster_00415    0.98169   0.98169   0.98169       710
cluster_00477    0.97847   0.97193   0.97518       748
cluster_00478    0.98677   0.98939   0.98808       754
cluster_00479    0.99403   0.99255   0.99329       671
cluster_00078    0.96474   0.96663   0.96569      1019
cluster_00079    0.97171   0.96218   0.96692       714
cluster_00083    0.96850   0.96513   0.96681      1147
cluster_00090    0.96406   0.98915   0.97645       461
cluster_00094    0.96311   0.94837   0.95568       523
cluster_00096    0.98707   0.97447   0.98073       470
cluster_00101    0.98387   0.99457   0.98919       552
cluster_00086    0.99652   0.99306   0.99478      1152
cluster_00095    0.98865   0.98123   0.98492       799
cluster_00097    0.99380   0.99380   0.99380       484
cluster_00106    0.99587   0.99587   0.99587      1211
cluster_00553    0.98678   0.99515   0.99095       825
cluster_00554    0.99216   0.99303   0.99259      1147
cluster_00569    0.98886   0.98037   0.98460       815
cluster_00015    0.99467   0.99467   0.99467       375
cluster_00017    0.97662   0.98014   0.97838      1108
cluster_00018    0.97970   0.97639   0.97804       593
cluster_00023    0.97619   0.96574   0.97094       934
cluster_00025    0.99068   0.98003   0.98533       651
cluster_00030    0.97266   0.96887   0.97076       771
cluster_00035    0.98314   0.97492   0.97901       598
cluster_00039    0.96943   0.98194   0.97564       775
cluster_00042    0.98212   0.97942   0.98077       729
cluster_00046    0.98371   0.98478   0.98425       920
cluster_00055    0.97852   0.97852   0.97852       745
cluster_00059    0.98063   0.98301   0.98182       824
cluster_00061    0.99009   0.99009   0.99009       807
cluster_00274    0.99328   0.99195   0.99261       745
cluster_00308    0.97748   0.98531   0.98138       749
cluster_00337    0.99457   0.99457   0.99457       737
cluster_00362    0.99086   0.99086   0.99086       766
cluster_00369    0.99607   0.99412   0.99509       510
cluster_00392    0.99294   0.99411   0.99353       849
cluster_00414    0.98973   0.99381   0.99177       485
cluster_00419    0.98216   0.98216   0.98216       897
cluster_00420    0.98794   0.99059   0.98926       744
cluster_00421    0.99790   0.98958   0.99372       480
cluster_00422    0.97409   0.97973   0.97690      1036
cluster_00427    0.96332   0.97419   0.96872       620
cluster_00430    0.96937   0.96937   0.96937       914
cluster_00431    0.96422   0.97745   0.97079      1020
cluster_00436    0.99226   0.99483   0.99354       773
cluster_00439    0.98458   0.98859   0.98658      1227
cluster_00444    0.99872   0.99745   0.99809       784
cluster_00447    0.98435   0.97418   0.97924       581
cluster_00448    0.98858   0.98608   0.98733       790
cluster_00450    0.97718   0.97525   0.97621      1010
cluster_00456    0.99076   0.98529   0.98802       544
cluster_00458    0.98034   0.98209   0.98122      1117
cluster_00460    0.98723   0.97233   0.97972       795
cluster_00463    0.98288   0.97619   0.97952       588
cluster_00467    0.99366   0.98896   0.99130       634
cluster_00483    0.98760   0.97751   0.98253       489
cluster_00484    0.98778   0.98951   0.98865       572
cluster_00007    0.99064   0.98450   0.98756       645
cluster_00036    0.97093   0.97471   0.97282      1028
cluster_00054    0.99232   0.98853   0.99042       523
cluster_00062    0.95725   0.95327   0.95525       963
cluster_00064    0.97366   0.97687   0.97526       908
cluster_00065    0.99064   0.99197   0.99130       747
cluster_00067    0.97143   0.97966   0.97553       590
cluster_00071    0.98053   0.97193   0.97621       570
cluster_00075    0.97745   0.96980   0.97361       894
cluster_00084    0.98274   0.99266   0.98768      1090
cluster_00093    0.97907   0.98021   0.97964       859
cluster_00001    0.98271   0.98936   0.98602      1034
cluster_00002    0.98366   0.98659   0.98512       671
cluster_00003    0.98447   0.98532   0.98489      1158
cluster_00006    0.99611   0.99870   0.99741       770
cluster_00008    0.99054   0.99225   0.99139      1161
cluster_00010    0.98637   0.97669   0.98150       815
cluster_00012    0.97876   0.98473   0.98174       655
cluster_00019    0.98874   0.98874   0.98874       533
cluster_00022    0.97001   0.97895   0.97446       760
cluster_00026    0.99194   0.99194   0.99194       744
cluster_00029    0.97910   0.97910   0.97910       909
cluster_00031    0.98314   0.98489   0.98401      1125
cluster_00043    0.99643   0.99821   0.99732      1117
cluster_00051    0.99094   0.98839   0.98966       775
cluster_00052    0.98387   0.98243   0.98315      1366
cluster_00073    0.98211   0.98835   0.98522       944
cluster_00076    0.98018   0.97802   0.97910       910
cluster_00082    0.98761   0.98849   0.98805      1129
cluster_00107    0.99545   0.99432   0.99489       881
cluster_00432    0.99803   0.99606   0.99704      1015
cluster_00440    0.99205   0.99501   0.99353      1003
cluster_00455    0.99278   0.99278   0.99278       693
cluster_00714    0.99887   0.99550   0.99718       888
cluster_00791    0.99406   0.99554   0.99480       672
cluster_00119    0.99782   0.99242   0.99511       923
cluster_00121    0.99864   0.99864   0.99864       734
cluster_00155    0.99625   0.99719   0.99672      1066
cluster_00556    0.99461   0.99676   0.99568       925
cluster_00557    0.99910   0.99552   0.99730      1115
cluster_00689    0.99892   0.99569   0.99730       928
cluster_00692    0.99456   1.00000   0.99727       914
cluster_00718    1.00000   0.99765   0.99882       852
cluster_00725    0.99859   0.99299   0.99578       713
cluster_00727    0.98849   0.99668   0.99257       603
cluster_00729    0.99476   0.99737   0.99606      1142
cluster_00733    1.00000   0.99830   0.99915       589
cluster_00738    1.00000   1.00000   1.00000       646
cluster_00740    0.99525   0.99841   0.99683       630
cluster_00744    0.99268   0.99790   0.99528       951
cluster_00753    0.99663   0.99216   0.99439       893
cluster_00777    0.99880   0.99400   0.99639       834
cluster_00795    0.99472   0.99868   0.99670       755

     accuracy                        0.98480    160000
    macro avg    0.98488   0.98465   0.98476    160000
 weighted avg    0.98481   0.98480   0.98480    160000

2023-07-14 00:06:37,009 =======================================================
2023-07-14 00:06:37,009 

2023-07-14 00:06:37,767 Total processing time is 4680.43s
2023-07-14 00:06:37,770 =======================================================
2023-07-14 00:06:37,770 Namespace(T_0=10, T_mult=2, best_metric='f1', decay_factor=0.5, epoch=800, eval_fold_zero=False, input_path='***', k_fold=5, lr=0.001, manualSeed=0, momentum=0, num_workers=4, opt='Adam', out_path='***', out_path_base='***', redistribute_class=True, scheduler='step', step_size=20, train_batch_size=2048, val_batch_size=1024, weight_decay=0.0)
2023-07-14 00:06:37,770 =======================================================
2023-07-14 00:06:37,771 Implement 2 fold experiment
2023-07-14 00:06:38,593 use [1, 3, 4, 5] fold as train data
2023-07-14 00:06:38,593 The size of feature for train is (160000, 15, 3)
2023-07-14 00:06:38,847 use 2 fold as validation data
2023-07-14 00:06:38,848 The size of feature for val is (40000, 15, 3)
2023-07-14 00:06:38,912 The training data size is:160000
2023-07-14 00:06:38,912 The validation data size is:40000
2023-07-14 00:06:38,912 The number of classes is:198
2023-07-14 00:06:38,913 The label names are: [b'cluster_00205', b'cluster_00222', b'cluster_00232', b'cluster_00246', b'cluster_00259', b'cluster_00261', b'cluster_00262', b'cluster_00267', b'cluster_00275', b'cluster_00276', b'cluster_00278', b'cluster_00287', b'cluster_00291', b'cluster_00293', b'cluster_00294', b'cluster_00296', b'cluster_00298', b'cluster_00299', b'cluster_00300', b'cluster_00303', b'cluster_00304', b'cluster_00319', b'cluster_00322', b'cluster_00333', b'cluster_00338', b'cluster_00340', b'cluster_00344', b'cluster_00346', b'cluster_00350', b'cluster_00352', b'cluster_00359', b'cluster_00360', b'cluster_00361', b'cluster_00365', b'cluster_00368', b'cluster_00373', b'cluster_00374', b'cluster_00375', b'cluster_00377', b'cluster_00380', b'cluster_00385', b'cluster_00388', b'cluster_00389', b'cluster_00390', b'cluster_00394', b'cluster_00400', b'cluster_00401', b'cluster_00405', b'cluster_00407', b'cluster_00408', b'cluster_00409', b'cluster_00412', b'cluster_00445', b'cluster_00473', b'cluster_00585', b'cluster_00589', b'cluster_00591', b'cluster_00593', b'cluster_00596', b'cluster_00603', b'cluster_00604', b'cluster_00607', b'cluster_00612', b'cluster_00616', b'cluster_00619', b'cluster_00629', b'cluster_00630', b'cluster_00635', b'cluster_00637', b'cluster_00639', b'cluster_00642', b'cluster_00645', b'cluster_00647', b'cluster_00652', b'cluster_00653', b'cluster_00656', b'cluster_00657', b'cluster_00661', b'cluster_00662', b'cluster_00667', b'cluster_00762', b'cluster_00201', b'cluster_00217', b'cluster_00239', b'cluster_00320', b'cluster_00391', b'cluster_00398', b'cluster_00415', b'cluster_00477', b'cluster_00478', b'cluster_00479', b'cluster_00078', b'cluster_00079', b'cluster_00083', b'cluster_00090', b'cluster_00094', b'cluster_00096', b'cluster_00101', b'cluster_00086', b'cluster_00095', b'cluster_00097', b'cluster_00106', b'cluster_00553', b'cluster_00554', b'cluster_00569', b'cluster_00015', b'cluster_00017', b'cluster_00018', b'cluster_00023', b'cluster_00025', b'cluster_00030', b'cluster_00035', b'cluster_00039', b'cluster_00042', b'cluster_00046', b'cluster_00055', b'cluster_00059', b'cluster_00061', b'cluster_00274', b'cluster_00308', b'cluster_00337', b'cluster_00362', b'cluster_00369', b'cluster_00392', b'cluster_00414', b'cluster_00419', b'cluster_00420', b'cluster_00421', b'cluster_00422', b'cluster_00427', b'cluster_00430', b'cluster_00431', b'cluster_00436', b'cluster_00439', b'cluster_00444', b'cluster_00447', b'cluster_00448', b'cluster_00450', b'cluster_00456', b'cluster_00458', b'cluster_00460', b'cluster_00463', b'cluster_00467', b'cluster_00483', b'cluster_00484', b'cluster_00007', b'cluster_00036', b'cluster_00054', b'cluster_00062', b'cluster_00064', b'cluster_00065', b'cluster_00067', b'cluster_00071', b'cluster_00075', b'cluster_00084', b'cluster_00093', b'cluster_00001', b'cluster_00002', b'cluster_00003', b'cluster_00006', b'cluster_00008', b'cluster_00010', b'cluster_00012', b'cluster_00019', b'cluster_00022', b'cluster_00026', b'cluster_00029', b'cluster_00031', b'cluster_00043', b'cluster_00051', b'cluster_00052', b'cluster_00073', b'cluster_00076', b'cluster_00082', b'cluster_00107', b'cluster_00432', b'cluster_00440', b'cluster_00455', b'cluster_00714', b'cluster_00791', b'cluster_00119', b'cluster_00121', b'cluster_00155', b'cluster_00556', b'cluster_00557', b'cluster_00689', b'cluster_00692', b'cluster_00718', b'cluster_00725', b'cluster_00727', b'cluster_00729', b'cluster_00733', b'cluster_00738', b'cluster_00740', b'cluster_00744', b'cluster_00753', b'cluster_00777', b'cluster_00795']
2023-07-14 00:06:43,833 epoch [1/800] time: 4.76s train loss: 2.4278 accuracy: 0.4761 f1: 0.446
2023-07-14 00:06:44,637 epoch [1/800] time: 0.8s val loss: 1.3005 accuracy: 0.7076 f1: 0.6948
2023-07-14 00:06:49,278 epoch [2/800] time: 4.64s train loss: 0.8496 accuracy: 0.76 f1: 0.7534
2023-07-14 00:06:50,128 epoch [2/800] time: 0.84s val loss: 0.7677 accuracy: 0.7531 f1: 0.7486
2023-07-14 00:06:54,633 epoch [3/800] time: 4.51s train loss: 0.6101 accuracy: 0.802 f1: 0.7984
2023-07-14 00:06:55,482 epoch [3/800] time: 0.84s val loss: 0.5397 accuracy: 0.8207 f1: 0.8166
2023-07-14 00:06:59,995 epoch [4/800] time: 4.51s train loss: 0.5224 accuracy: 0.8191 f1: 0.8165
2023-07-14 00:07:00,842 epoch [4/800] time: 0.85s val loss: 0.5054 accuracy: 0.819 f1: 0.8144
2023-07-14 00:07:05,398 epoch [5/800] time: 4.56s train loss: 0.4862 accuracy: 0.8265 f1: 0.8239
2023-07-14 00:07:06,245 epoch [5/800] time: 0.84s val loss: 0.5248 accuracy: 0.8046 f1: 0.8006
2023-07-14 00:07:10,754 epoch [6/800] time: 4.51s train loss: 0.4505 accuracy: 0.8359 f1: 0.8335
2023-07-14 00:07:11,602 epoch [6/800] time: 0.84s val loss: 0.4916 accuracy: 0.8167 f1: 0.8131
2023-07-14 00:07:16,103 epoch [7/800] time: 4.5s train loss: 0.4178 accuracy: 0.846 f1: 0.8436
2023-07-14 00:07:16,952 epoch [7/800] time: 0.84s val loss: 0.4139 accuracy: 0.8438 f1: 0.8414
2023-07-14 00:07:21,669 epoch [8/800] time: 4.72s train loss: 0.4004 accuracy: 0.8517 f1: 0.8497
2023-07-14 00:07:22,518 epoch [8/800] time: 0.84s val loss: 0.4667 accuracy: 0.8206 f1: 0.8173
2023-07-14 00:07:27,148 epoch [9/800] time: 4.63s train loss: 0.3874 accuracy: 0.8553 f1: 0.8533
2023-07-14 00:07:27,996 epoch [9/800] time: 0.84s val loss: 0.4389 accuracy: 0.8341 f1: 0.8326
2023-07-14 00:07:32,492 epoch [10/800] time: 4.5s train loss: 0.3711 accuracy: 0.8618 f1: 0.86
2023-07-14 00:07:33,340 epoch [10/800] time: 0.84s val loss: 0.3751 accuracy: 0.8573 f1: 0.8547
2023-07-14 00:07:37,833 epoch [11/800] time: 4.49s train loss: 0.3571 accuracy: 0.867 f1: 0.8653
2023-07-14 00:07:38,679 epoch [11/800] time: 0.84s val loss: 0.3817 accuracy: 0.8528 f1: 0.8511
2023-07-14 00:07:43,222 epoch [12/800] time: 4.54s train loss: 0.3505 accuracy: 0.8681 f1: 0.8667
2023-07-14 00:07:44,027 epoch [12/800] time: 0.8s val loss: 0.428 accuracy: 0.8423 f1: 0.8416
2023-07-14 00:07:48,573 epoch [13/800] time: 4.55s train loss: 0.342 accuracy: 0.872 f1: 0.8705
2023-07-14 00:07:49,419 epoch [13/800] time: 0.84s val loss: 0.4152 accuracy: 0.8415 f1: 0.8396
2023-07-14 00:07:53,924 epoch [14/800] time: 4.5s train loss: 0.3371 accuracy: 0.8716 f1: 0.8699
2023-07-14 00:07:54,772 epoch [14/800] time: 0.85s val loss: 0.4044 accuracy: 0.8458 f1: 0.844
2023-07-14 00:07:59,315 epoch [15/800] time: 4.54s train loss: 0.3253 accuracy: 0.8757 f1: 0.8744
2023-07-14 00:08:00,120 epoch [15/800] time: 0.8s val loss: 0.3377 accuracy: 0.8701 f1: 0.8686
2023-07-14 00:08:04,659 epoch [16/800] time: 4.54s train loss: 0.3239 accuracy: 0.8769 f1: 0.8759
2023-07-14 00:08:05,509 epoch [16/800] time: 0.84s val loss: 0.5013 accuracy: 0.8173 f1: 0.8141
2023-07-14 00:08:10,009 epoch [17/800] time: 4.5s train loss: 0.3206 accuracy: 0.8788 f1: 0.8775
2023-07-14 00:08:10,855 epoch [17/800] time: 0.84s val loss: 0.4318 accuracy: 0.8436 f1: 0.8438
2023-07-14 00:08:15,506 epoch [18/800] time: 4.65s train loss: 0.3143 accuracy: 0.8807 f1: 0.8797
2023-07-14 00:08:16,312 epoch [18/800] time: 0.8s val loss: 0.3984 accuracy: 0.8481 f1: 0.8453
2023-07-14 00:08:20,847 epoch [19/800] time: 4.53s train loss: 0.2909 accuracy: 0.8888 f1: 0.8873
2023-07-14 00:08:21,693 epoch [19/800] time: 0.84s val loss: 0.3618 accuracy: 0.8598 f1: 0.8584
2023-07-14 00:08:26,233 epoch [20/800] time: 4.54s train loss: 0.3044 accuracy: 0.8829 f1: 0.8816
2023-07-14 00:08:27,078 epoch [20/800] time: 0.84s val loss: 0.3106 accuracy: 0.8773 f1: 0.8755
2023-07-14 00:08:31,619 epoch [21/800] time: 4.54s train loss: 0.2472 accuracy: 0.9065 f1: 0.9054
2023-07-14 00:08:32,422 epoch [21/800] time: 0.8s val loss: 0.2585 accuracy: 0.8976 f1: 0.8964
2023-07-14 00:08:36,960 epoch [22/800] time: 4.54s train loss: 0.231 accuracy: 0.9135 f1: 0.9125
2023-07-14 00:08:37,806 epoch [22/800] time: 0.84s val loss: 0.2434 accuracy: 0.9055 f1: 0.9035
2023-07-14 00:08:42,313 epoch [23/800] time: 4.51s train loss: 0.2347 accuracy: 0.9108 f1: 0.9096
2023-07-14 00:08:43,168 epoch [23/800] time: 0.85s val loss: 0.2408 accuracy: 0.9058 f1: 0.9041
2023-07-14 00:08:47,710 epoch [24/800] time: 4.54s train loss: 0.2268 accuracy: 0.9144 f1: 0.9135
2023-07-14 00:08:48,515 epoch [24/800] time: 0.8s val loss: 0.2797 accuracy: 0.8921 f1: 0.8918
2023-07-14 00:08:53,431 epoch [25/800] time: 4.92s train loss: 0.2337 accuracy: 0.9104 f1: 0.9093
2023-07-14 00:08:54,346 epoch [25/800] time: 0.92s val loss: 0.282 accuracy: 0.8903 f1: 0.8883
2023-07-14 00:08:59,318 epoch [26/800] time: 4.97s train loss: 0.233 accuracy: 0.9109 f1: 0.9098
2023-07-14 00:09:00,217 epoch [26/800] time: 0.9s val loss: 0.27 accuracy: 0.8939 f1: 0.892
2023-07-14 00:09:05,363 epoch [27/800] time: 5.15s train loss: 0.2262 accuracy: 0.9138 f1: 0.913
2023-07-14 00:09:06,465 epoch [27/800] time: 1.1s val loss: 0.2514 accuracy: 0.9014 f1: 0.8997
2023-07-14 00:09:11,800 epoch [28/800] time: 5.33s train loss: 0.2237 accuracy: 0.9149 f1: 0.9142
2023-07-14 00:09:12,714 epoch [28/800] time: 0.91s val loss: 0.2544 accuracy: 0.9018 f1: 0.9005
2023-07-14 00:09:17,771 epoch [29/800] time: 5.06s train loss: 0.2269 accuracy: 0.9134 f1: 0.9127
2023-07-14 00:09:18,735 epoch [29/800] time: 0.96s val loss: 0.2546 accuracy: 0.9012 f1: 0.8996
2023-07-14 00:09:24,797 epoch [30/800] time: 6.06s train loss: 0.2171 accuracy: 0.9178 f1: 0.917
2023-07-14 00:09:25,880 epoch [30/800] time: 1.07s val loss: 0.2715 accuracy: 0.897 f1: 0.8954
2023-07-14 00:09:31,384 epoch [31/800] time: 5.5s train loss: 0.2168 accuracy: 0.917 f1: 0.9161
2023-07-14 00:09:32,289 epoch [31/800] time: 0.9s val loss: 0.2473 accuracy: 0.9049 f1: 0.9036
2023-07-14 00:09:37,564 epoch [32/800] time: 5.28s train loss: 0.2095 accuracy: 0.9198 f1: 0.9191
2023-07-14 00:09:38,467 epoch [32/800] time: 0.9s val loss: 0.2415 accuracy: 0.9037 f1: 0.9026
2023-07-14 00:09:43,492 epoch [33/800] time: 5.02s train loss: 0.208 accuracy: 0.9212 f1: 0.9202
2023-07-14 00:09:44,387 epoch [33/800] time: 0.89s val loss: 0.2473 accuracy: 0.9034 f1: 0.9028
2023-07-14 00:09:49,603 epoch [34/800] time: 5.22s train loss: 0.2076 accuracy: 0.9221 f1: 0.9211
2023-07-14 00:09:50,538 epoch [34/800] time: 0.93s val loss: 0.2579 accuracy: 0.8991 f1: 0.8972
2023-07-14 00:09:55,397 epoch [35/800] time: 4.86s train loss: 0.2109 accuracy: 0.9199 f1: 0.9189
2023-07-14 00:09:56,266 epoch [35/800] time: 0.87s val loss: 0.2502 accuracy: 0.9049 f1: 0.9036
2023-07-14 00:10:01,088 epoch [36/800] time: 4.82s train loss: 0.2089 accuracy: 0.9204 f1: 0.9194
2023-07-14 00:10:01,892 epoch [36/800] time: 0.8s val loss: 0.2635 accuracy: 0.8986 f1: 0.8978
2023-07-14 00:10:06,509 epoch [37/800] time: 4.62s train loss: 0.2099 accuracy: 0.9204 f1: 0.9194
2023-07-14 00:10:07,364 epoch [37/800] time: 0.85s val loss: 0.2685 accuracy: 0.8965 f1: 0.8944
2023-07-14 00:10:11,975 epoch [38/800] time: 4.61s train loss: 0.2035 accuracy: 0.9226 f1: 0.9219
2023-07-14 00:10:12,823 epoch [38/800] time: 0.84s val loss: 0.2504 accuracy: 0.9058 f1: 0.9052
2023-07-14 00:10:17,473 epoch [39/800] time: 4.65s train loss: 0.2022 accuracy: 0.9225 f1: 0.9218
2023-07-14 00:10:18,274 epoch [39/800] time: 0.8s val loss: 0.283 accuracy: 0.8932 f1: 0.8919
2023-07-14 00:10:22,950 epoch [40/800] time: 4.68s train loss: 0.2016 accuracy: 0.9237 f1: 0.9229
2023-07-14 00:10:23,800 epoch [40/800] time: 0.84s val loss: 0.2662 accuracy: 0.8993 f1: 0.8971
2023-07-14 00:10:28,466 epoch [41/800] time: 4.67s train loss: 0.1733 accuracy: 0.9357 f1: 0.9349
2023-07-14 00:10:29,309 epoch [41/800] time: 0.84s val loss: 0.1969 accuracy: 0.9259 f1: 0.9246
2023-07-14 00:10:33,968 epoch [42/800] time: 4.66s train loss: 0.1606 accuracy: 0.9403 f1: 0.9397
2023-07-14 00:10:34,777 epoch [42/800] time: 0.8s val loss: 0.2113 accuracy: 0.9207 f1: 0.9192
2023-07-14 00:10:39,467 epoch [43/800] time: 4.69s train loss: 0.1571 accuracy: 0.9422 f1: 0.9415
2023-07-14 00:10:40,317 epoch [43/800] time: 0.84s val loss: 0.193 accuracy: 0.9264 f1: 0.9255
2023-07-14 00:10:44,960 epoch [44/800] time: 4.64s train loss: 0.1585 accuracy: 0.9415 f1: 0.941
2023-07-14 00:10:45,807 epoch [44/800] time: 0.85s val loss: 0.2325 accuracy: 0.9098 f1: 0.9088
2023-07-14 00:10:50,466 epoch [45/800] time: 4.66s train loss: 0.1581 accuracy: 0.9416 f1: 0.9412
2023-07-14 00:10:51,269 epoch [45/800] time: 0.8s val loss: 0.1947 accuracy: 0.9264 f1: 0.925
2023-07-14 00:10:55,861 epoch [46/800] time: 4.59s train loss: 0.1574 accuracy: 0.942 f1: 0.9413
2023-07-14 00:10:56,708 epoch [46/800] time: 0.85s val loss: 0.1913 accuracy: 0.928 f1: 0.9265
2023-07-14 00:11:01,608 epoch [47/800] time: 4.9s train loss: 0.1537 accuracy: 0.9438 f1: 0.9433
2023-07-14 00:11:02,492 epoch [47/800] time: 0.88s val loss: 0.1968 accuracy: 0.9248 f1: 0.9233
2023-07-14 00:11:07,549 epoch [48/800] time: 5.06s train loss: 0.1556 accuracy: 0.9427 f1: 0.9421
2023-07-14 00:11:08,379 epoch [48/800] time: 0.83s val loss: 0.1946 accuracy: 0.9249 f1: 0.9233
2023-07-14 00:11:13,281 epoch [49/800] time: 4.9s train loss: 0.1518 accuracy: 0.9438 f1: 0.9433
2023-07-14 00:11:14,169 epoch [49/800] time: 0.88s val loss: 0.2132 accuracy: 0.9184 f1: 0.9171
2023-07-14 00:11:19,163 epoch [50/800] time: 4.99s train loss: 0.153 accuracy: 0.9435 f1: 0.943
2023-07-14 00:11:20,040 epoch [50/800] time: 0.88s val loss: 0.2072 accuracy: 0.9212 f1: 0.9197
2023-07-14 00:11:24,928 epoch [51/800] time: 4.89s train loss: 0.1518 accuracy: 0.9434 f1: 0.9429
2023-07-14 00:11:25,748 epoch [51/800] time: 0.82s val loss: 0.209 accuracy: 0.9194 f1: 0.918
2023-07-14 00:11:30,352 epoch [52/800] time: 4.6s train loss: 0.1489 accuracy: 0.9443 f1: 0.9438
2023-07-14 00:11:31,213 epoch [52/800] time: 0.85s val loss: 0.2024 accuracy: 0.9234 f1: 0.9222
2023-07-14 00:11:35,934 epoch [53/800] time: 4.72s train loss: 0.1478 accuracy: 0.9459 f1: 0.9456
2023-07-14 00:11:36,778 epoch [53/800] time: 0.84s val loss: 0.2055 accuracy: 0.9212 f1: 0.9204
2023-07-14 00:11:41,497 epoch [54/800] time: 4.72s train loss: 0.1477 accuracy: 0.9454 f1: 0.9448
2023-07-14 00:11:42,298 epoch [54/800] time: 0.8s val loss: 0.197 accuracy: 0.9257 f1: 0.9244
2023-07-14 00:11:47,064 epoch [55/800] time: 4.77s train loss: 0.1472 accuracy: 0.945 f1: 0.9443
2023-07-14 00:11:47,908 epoch [55/800] time: 0.84s val loss: 0.1917 accuracy: 0.9266 f1: 0.9255
2023-07-14 00:11:52,651 epoch [56/800] time: 4.74s train loss: 0.1453 accuracy: 0.9465 f1: 0.9458
2023-07-14 00:11:53,497 epoch [56/800] time: 0.84s val loss: 0.2343 accuracy: 0.9135 f1: 0.9121
2023-07-14 00:11:58,300 epoch [57/800] time: 4.8s train loss: 0.1489 accuracy: 0.945 f1: 0.9447
2023-07-14 00:11:59,099 epoch [57/800] time: 0.8s val loss: 0.1873 accuracy: 0.9309 f1: 0.9297
2023-07-14 00:12:03,886 epoch [58/800] time: 4.79s train loss: 0.1426 accuracy: 0.9477 f1: 0.9473
2023-07-14 00:12:04,736 epoch [58/800] time: 0.84s val loss: 0.1949 accuracy: 0.9275 f1: 0.9261
2023-07-14 00:12:09,471 epoch [59/800] time: 4.73s train loss: 0.147 accuracy: 0.945 f1: 0.9444
2023-07-14 00:12:10,315 epoch [59/800] time: 0.84s val loss: 0.2068 accuracy: 0.9211 f1: 0.9198
2023-07-14 00:12:15,102 epoch [60/800] time: 4.79s train loss: 0.142 accuracy: 0.9476 f1: 0.9472
2023-07-14 00:12:15,903 epoch [60/800] time: 0.8s val loss: 0.2171 accuracy: 0.9174 f1: 0.9158
2023-07-14 00:12:20,691 epoch [61/800] time: 4.79s train loss: 0.1246 accuracy: 0.9551 f1: 0.9546
2023-07-14 00:12:21,538 epoch [61/800] time: 0.84s val loss: 0.1664 accuracy: 0.9377 f1: 0.9362
2023-07-14 00:12:26,298 epoch [62/800] time: 4.76s train loss: 0.1166 accuracy: 0.9594 f1: 0.959
2023-07-14 00:12:27,147 epoch [62/800] time: 0.84s val loss: 0.1747 accuracy: 0.935 f1: 0.9337
2023-07-14 00:12:31,934 epoch [63/800] time: 4.79s train loss: 0.1155 accuracy: 0.9597 f1: 0.9593
2023-07-14 00:12:32,754 epoch [63/800] time: 0.81s val loss: 0.1716 accuracy: 0.9361 f1: 0.9347
2023-07-14 00:12:37,528 epoch [64/800] time: 4.77s train loss: 0.1156 accuracy: 0.9595 f1: 0.9592
2023-07-14 00:12:38,380 epoch [64/800] time: 0.85s val loss: 0.1669 accuracy: 0.9385 f1: 0.9372
2023-07-14 00:12:43,129 epoch [65/800] time: 4.75s train loss: 0.1144 accuracy: 0.9602 f1: 0.9601
2023-07-14 00:12:43,977 epoch [65/800] time: 0.84s val loss: 0.1697 accuracy: 0.9374 f1: 0.9362
2023-07-14 00:12:48,744 epoch [66/800] time: 4.77s train loss: 0.1194 accuracy: 0.9576 f1: 0.9573
2023-07-14 00:12:49,544 epoch [66/800] time: 0.8s val loss: 0.1705 accuracy: 0.9373 f1: 0.9362
2023-07-14 00:12:54,333 epoch [67/800] time: 4.79s train loss: 0.1149 accuracy: 0.9593 f1: 0.959
2023-07-14 00:12:55,176 epoch [67/800] time: 0.84s val loss: 0.1669 accuracy: 0.9381 f1: 0.9368
2023-07-14 00:12:59,925 epoch [68/800] time: 4.75s train loss: 0.1144 accuracy: 0.9599 f1: 0.9594
2023-07-14 00:13:00,768 epoch [68/800] time: 0.84s val loss: 0.1779 accuracy: 0.9341 f1: 0.9335
2023-07-14 00:13:05,550 epoch [69/800] time: 4.78s train loss: 0.1163 accuracy: 0.9589 f1: 0.9588
2023-07-14 00:13:06,348 epoch [69/800] time: 0.8s val loss: 0.174 accuracy: 0.9362 f1: 0.9351
2023-07-14 00:13:11,017 epoch [70/800] time: 4.67s train loss: 0.1123 accuracy: 0.961 f1: 0.9606
2023-07-14 00:13:11,870 epoch [70/800] time: 0.85s val loss: 0.1692 accuracy: 0.938 f1: 0.9368
2023-07-14 00:13:16,380 epoch [71/800] time: 4.51s train loss: 0.1098 accuracy: 0.9622 f1: 0.962
2023-07-14 00:13:17,227 epoch [71/800] time: 0.84s val loss: 0.1683 accuracy: 0.9382 f1: 0.9371
2023-07-14 00:13:21,780 epoch [72/800] time: 4.55s train loss: 0.1121 accuracy: 0.9601 f1: 0.9598
2023-07-14 00:13:22,580 epoch [72/800] time: 0.8s val loss: 0.1721 accuracy: 0.9368 f1: 0.9355
2023-07-14 00:13:27,138 epoch [73/800] time: 4.56s train loss: 0.1101 accuracy: 0.9614 f1: 0.9612
2023-07-14 00:13:27,990 epoch [73/800] time: 0.85s val loss: 0.1679 accuracy: 0.9394 f1: 0.9383
2023-07-14 00:13:32,491 epoch [74/800] time: 4.5s train loss: 0.1107 accuracy: 0.9614 f1: 0.9611
2023-07-14 00:13:33,334 epoch [74/800] time: 0.84s val loss: 0.1669 accuracy: 0.9399 f1: 0.939
2023-07-14 00:13:37,867 epoch [75/800] time: 4.53s train loss: 0.1112 accuracy: 0.9608 f1: 0.9605
2023-07-14 00:13:38,666 epoch [75/800] time: 0.8s val loss: 0.1682 accuracy: 0.9387 f1: 0.9377
2023-07-14 00:13:43,197 epoch [76/800] time: 4.53s train loss: 0.1078 accuracy: 0.9626 f1: 0.9623
2023-07-14 00:13:44,045 epoch [76/800] time: 0.84s val loss: 0.1677 accuracy: 0.9382 f1: 0.9372
2023-07-14 00:13:48,563 epoch [77/800] time: 4.52s train loss: 0.1077 accuracy: 0.962 f1: 0.9617
2023-07-14 00:13:49,408 epoch [77/800] time: 0.85s val loss: 0.1813 accuracy: 0.9343 f1: 0.9326
2023-07-14 00:13:53,962 epoch [78/800] time: 4.55s train loss: 0.1109 accuracy: 0.9606 f1: 0.9603
2023-07-14 00:13:54,764 epoch [78/800] time: 0.8s val loss: 0.1746 accuracy: 0.9361 f1: 0.9344
2023-07-14 00:13:59,323 epoch [79/800] time: 4.56s train loss: 0.1075 accuracy: 0.9621 f1: 0.9618
2023-07-14 00:14:00,169 epoch [79/800] time: 0.85s val loss: 0.1679 accuracy: 0.9383 f1: 0.9374
2023-07-14 00:14:04,689 epoch [80/800] time: 4.52s train loss: 0.1091 accuracy: 0.9612 f1: 0.961
2023-07-14 00:14:05,534 epoch [80/800] time: 0.84s val loss: 0.1798 accuracy: 0.9339 f1: 0.9326
2023-07-14 00:14:10,101 epoch [81/800] time: 4.57s train loss: 0.0979 accuracy: 0.9671 f1: 0.9667
2023-07-14 00:14:10,906 epoch [81/800] time: 0.8s val loss: 0.1581 accuracy: 0.9439 f1: 0.9429
2023-07-14 00:14:15,459 epoch [82/800] time: 4.55s train loss: 0.0934 accuracy: 0.9693 f1: 0.969
2023-07-14 00:14:16,308 epoch [82/800] time: 0.84s val loss: 0.1571 accuracy: 0.9444 f1: 0.9433
2023-07-14 00:14:20,852 epoch [83/800] time: 4.54s train loss: 0.0936 accuracy: 0.9689 f1: 0.9686
2023-07-14 00:14:21,698 epoch [83/800] time: 0.85s val loss: 0.1598 accuracy: 0.9428 f1: 0.9417
2023-07-14 00:14:26,265 epoch [84/800] time: 4.57s train loss: 0.0936 accuracy: 0.9691 f1: 0.9689
2023-07-14 00:14:27,067 epoch [84/800] time: 0.8s val loss: 0.1589 accuracy: 0.9422 f1: 0.9411
2023-07-14 00:14:31,648 epoch [85/800] time: 4.58s train loss: 0.0943 accuracy: 0.9686 f1: 0.9684
2023-07-14 00:14:32,495 epoch [85/800] time: 0.85s val loss: 0.1563 accuracy: 0.9434 f1: 0.9425
2023-07-14 00:14:37,027 epoch [86/800] time: 4.53s train loss: 0.0908 accuracy: 0.97 f1: 0.9698
2023-07-14 00:14:37,876 epoch [86/800] time: 0.84s val loss: 0.1553 accuracy: 0.9444 f1: 0.9434
2023-07-14 00:14:42,433 epoch [87/800] time: 4.56s train loss: 0.0911 accuracy: 0.9697 f1: 0.9695
2023-07-14 00:14:43,235 epoch [87/800] time: 0.8s val loss: 0.164 accuracy: 0.9418 f1: 0.9408
2023-07-14 00:14:47,775 epoch [88/800] time: 4.54s train loss: 0.0896 accuracy: 0.9698 f1: 0.9697
2023-07-14 00:14:48,619 epoch [88/800] time: 0.84s val loss: 0.1589 accuracy: 0.943 f1: 0.9417
2023-07-14 00:14:53,132 epoch [89/800] time: 4.51s train loss: 0.0889 accuracy: 0.9701 f1: 0.9699
2023-07-14 00:14:53,981 epoch [89/800] time: 0.84s val loss: 0.1574 accuracy: 0.9436 f1: 0.9426
2023-07-14 00:14:58,622 epoch [90/800] time: 4.64s train loss: 0.0903 accuracy: 0.9701 f1: 0.9699
2023-07-14 00:14:59,429 epoch [90/800] time: 0.8s val loss: 0.1574 accuracy: 0.9448 f1: 0.9436
2023-07-14 00:15:04,114 epoch [91/800] time: 4.68s train loss: 0.093 accuracy: 0.9695 f1: 0.9692
2023-07-14 00:15:04,963 epoch [91/800] time: 0.85s val loss: 0.1568 accuracy: 0.9435 f1: 0.9423
2023-07-14 00:15:09,677 epoch [92/800] time: 4.71s train loss: 0.0902 accuracy: 0.9708 f1: 0.9706
2023-07-14 00:15:10,524 epoch [92/800] time: 0.84s val loss: 0.155 accuracy: 0.9454 f1: 0.9442
2023-07-14 00:15:15,281 epoch [93/800] time: 4.76s train loss: 0.091 accuracy: 0.9702 f1: 0.9699
2023-07-14 00:15:16,082 epoch [93/800] time: 0.8s val loss: 0.155 accuracy: 0.9442 f1: 0.9431
2023-07-14 00:15:20,873 epoch [94/800] time: 4.79s train loss: 0.09 accuracy: 0.9701 f1: 0.9699
2023-07-14 00:15:21,717 epoch [94/800] time: 0.84s val loss: 0.1542 accuracy: 0.9454 f1: 0.9442
2023-07-14 00:15:26,453 epoch [95/800] time: 4.74s train loss: 0.088 accuracy: 0.9708 f1: 0.9707
2023-07-14 00:15:27,298 epoch [95/800] time: 0.84s val loss: 0.154 accuracy: 0.9457 f1: 0.9447
2023-07-14 00:15:32,022 epoch [96/800] time: 4.72s train loss: 0.0872 accuracy: 0.971 f1: 0.9708
2023-07-14 00:15:32,825 epoch [96/800] time: 0.8s val loss: 0.1543 accuracy: 0.9448 f1: 0.9438
2023-07-14 00:15:37,578 epoch [97/800] time: 4.75s train loss: 0.0881 accuracy: 0.971 f1: 0.971
2023-07-14 00:15:38,425 epoch [97/800] time: 0.84s val loss: 0.153 accuracy: 0.9449 f1: 0.9439
2023-07-14 00:15:43,065 epoch [98/800] time: 4.64s train loss: 0.0894 accuracy: 0.9707 f1: 0.9705
2023-07-14 00:15:43,907 epoch [98/800] time: 0.84s val loss: 0.1591 accuracy: 0.9452 f1: 0.9443
2023-07-14 00:15:48,611 epoch [99/800] time: 4.7s train loss: 0.0877 accuracy: 0.9711 f1: 0.9709
2023-07-14 00:15:49,413 epoch [99/800] time: 0.8s val loss: 0.1553 accuracy: 0.9449 f1: 0.9437
2023-07-14 00:15:54,181 epoch [100/800] time: 4.77s train loss: 0.0853 accuracy: 0.9718 f1: 0.9716
2023-07-14 00:15:55,027 epoch [100/800] time: 0.84s val loss: 0.1561 accuracy: 0.945 f1: 0.9438
2023-07-14 00:15:59,790 epoch [101/800] time: 4.76s train loss: 0.0814 accuracy: 0.974 f1: 0.9739
2023-07-14 00:16:00,636 epoch [101/800] time: 0.84s val loss: 0.1507 accuracy: 0.9477 f1: 0.9467
2023-07-14 00:16:05,310 epoch [102/800] time: 4.67s train loss: 0.082 accuracy: 0.9735 f1: 0.9734
2023-07-14 00:16:06,111 epoch [102/800] time: 0.8s val loss: 0.1504 accuracy: 0.9471 f1: 0.946
2023-07-14 00:16:10,794 epoch [103/800] time: 4.68s train loss: 0.0813 accuracy: 0.974 f1: 0.9738
2023-07-14 00:16:11,639 epoch [103/800] time: 0.84s val loss: 0.1498 accuracy: 0.9471 f1: 0.9458
2023-07-14 00:16:16,340 epoch [104/800] time: 4.7s train loss: 0.0799 accuracy: 0.9746 f1: 0.9744
2023-07-14 00:16:17,189 epoch [104/800] time: 0.84s val loss: 0.15 accuracy: 0.9477 f1: 0.9468
2023-07-14 00:16:21,789 epoch [105/800] time: 4.6s train loss: 0.0831 accuracy: 0.974 f1: 0.9738
2023-07-14 00:16:22,589 epoch [105/800] time: 0.8s val loss: 0.1525 accuracy: 0.9465 f1: 0.9454
2023-07-14 00:16:27,220 epoch [106/800] time: 4.63s train loss: 0.0795 accuracy: 0.975 f1: 0.9749
2023-07-14 00:16:28,066 epoch [106/800] time: 0.84s val loss: 0.1499 accuracy: 0.9475 f1: 0.9464
2023-07-14 00:16:32,801 epoch [107/800] time: 4.73s train loss: 0.0799 accuracy: 0.9747 f1: 0.9746
2023-07-14 00:16:33,641 epoch [107/800] time: 0.84s val loss: 0.1502 accuracy: 0.9466 f1: 0.9456
2023-07-14 00:16:38,385 epoch [108/800] time: 4.74s train loss: 0.0812 accuracy: 0.974 f1: 0.9739
2023-07-14 00:16:39,184 epoch [108/800] time: 0.8s val loss: 0.1509 accuracy: 0.9476 f1: 0.9465
2023-07-14 00:16:43,905 epoch [109/800] time: 4.72s train loss: 0.08 accuracy: 0.9745 f1: 0.9744
2023-07-14 00:16:44,762 epoch [109/800] time: 0.86s val loss: 0.1501 accuracy: 0.9476 f1: 0.9465
2023-07-14 00:16:49,497 epoch [110/800] time: 4.73s train loss: 0.0793 accuracy: 0.975 f1: 0.9748
2023-07-14 00:16:50,340 epoch [110/800] time: 0.84s val loss: 0.1493 accuracy: 0.948 f1: 0.9468
2023-07-14 00:16:55,113 epoch [111/800] time: 4.77s train loss: 0.0782 accuracy: 0.9751 f1: 0.975
2023-07-14 00:16:55,915 epoch [111/800] time: 0.8s val loss: 0.1497 accuracy: 0.9474 f1: 0.9464
2023-07-14 00:17:00,675 epoch [112/800] time: 4.76s train loss: 0.079 accuracy: 0.9748 f1: 0.9746
2023-07-14 00:17:01,516 epoch [112/800] time: 0.84s val loss: 0.1518 accuracy: 0.947 f1: 0.9459
2023-07-14 00:17:06,191 epoch [113/800] time: 4.67s train loss: 0.0787 accuracy: 0.9754 f1: 0.9752
2023-07-14 00:17:07,037 epoch [113/800] time: 0.84s val loss: 0.1563 accuracy: 0.9454 f1: 0.9443
2023-07-14 00:17:11,725 epoch [114/800] time: 4.69s train loss: 0.0781 accuracy: 0.9758 f1: 0.9757
2023-07-14 00:17:12,529 epoch [114/800] time: 0.8s val loss: 0.1495 accuracy: 0.9477 f1: 0.9467
2023-07-14 00:17:17,327 epoch [115/800] time: 4.8s train loss: 0.0799 accuracy: 0.9751 f1: 0.975
2023-07-14 00:17:18,170 epoch [115/800] time: 0.84s val loss: 0.1508 accuracy: 0.9467 f1: 0.9455
2023-07-14 00:17:22,897 epoch [116/800] time: 4.73s train loss: 0.0766 accuracy: 0.976 f1: 0.976
2023-07-14 00:17:23,742 epoch [116/800] time: 0.84s val loss: 0.1496 accuracy: 0.9483 f1: 0.9473
2023-07-14 00:17:28,982 epoch [117/800] time: 5.24s train loss: 0.0785 accuracy: 0.9749 f1: 0.9748
2023-07-14 00:17:30,066 epoch [117/800] time: 1.08s val loss: 0.1527 accuracy: 0.9465 f1: 0.9453
2023-07-14 00:17:35,061 epoch [118/800] time: 4.99s train loss: 0.0775 accuracy: 0.9751 f1: 0.9751
2023-07-14 00:17:35,963 epoch [118/800] time: 0.9s val loss: 0.1501 accuracy: 0.9492 f1: 0.9484
2023-07-14 00:17:41,163 epoch [119/800] time: 5.2s train loss: 0.075 accuracy: 0.9765 f1: 0.9764
2023-07-14 00:17:42,081 epoch [119/800] time: 0.91s val loss: 0.1484 accuracy: 0.9479 f1: 0.9467
2023-07-14 00:17:46,846 epoch [120/800] time: 4.76s train loss: 0.0782 accuracy: 0.9756 f1: 0.9755
2023-07-14 00:17:47,653 epoch [120/800] time: 0.81s val loss: 0.1515 accuracy: 0.9469 f1: 0.9457
2023-07-14 00:17:52,623 epoch [121/800] time: 4.97s train loss: 0.0761 accuracy: 0.976 f1: 0.9758
2023-07-14 00:17:53,553 epoch [121/800] time: 0.93s val loss: 0.1484 accuracy: 0.9495 f1: 0.9485
2023-07-14 00:17:58,608 epoch [122/800] time: 5.05s train loss: 0.0748 accuracy: 0.9768 f1: 0.9767
2023-07-14 00:17:59,476 epoch [122/800] time: 0.86s val loss: 0.1477 accuracy: 0.9486 f1: 0.9475
2023-07-14 00:18:04,203 epoch [123/800] time: 4.73s train loss: 0.0761 accuracy: 0.977 f1: 0.977
2023-07-14 00:18:05,073 epoch [123/800] time: 0.86s val loss: 0.1495 accuracy: 0.9487 f1: 0.9476
2023-07-14 00:18:10,178 epoch [124/800] time: 5.11s train loss: 0.0746 accuracy: 0.9765 f1: 0.9764
2023-07-14 00:18:11,131 epoch [124/800] time: 0.95s val loss: 0.1474 accuracy: 0.9498 f1: 0.9489
2023-07-14 00:18:16,521 epoch [125/800] time: 5.39s train loss: 0.0738 accuracy: 0.977 f1: 0.9769
2023-07-14 00:18:17,411 epoch [125/800] time: 0.89s val loss: 0.148 accuracy: 0.9488 f1: 0.9475
2023-07-14 00:18:22,423 epoch [126/800] time: 5.01s train loss: 0.0742 accuracy: 0.9768 f1: 0.9767
2023-07-14 00:18:23,260 epoch [126/800] time: 0.84s val loss: 0.1479 accuracy: 0.9492 f1: 0.9481
2023-07-14 00:18:28,360 epoch [127/800] time: 5.1s train loss: 0.0743 accuracy: 0.9773 f1: 0.9771
2023-07-14 00:18:29,260 epoch [127/800] time: 0.89s val loss: 0.1485 accuracy: 0.9489 f1: 0.9478
2023-07-14 00:18:34,206 epoch [128/800] time: 4.95s train loss: 0.0733 accuracy: 0.9775 f1: 0.9773
2023-07-14 00:18:35,105 epoch [128/800] time: 0.89s val loss: 0.1474 accuracy: 0.9495 f1: 0.9485
2023-07-14 00:18:40,379 epoch [129/800] time: 5.27s train loss: 0.0738 accuracy: 0.9776 f1: 0.9774
2023-07-14 00:18:41,265 epoch [129/800] time: 0.88s val loss: 0.1473 accuracy: 0.9488 f1: 0.9476
2023-07-14 00:18:46,213 epoch [130/800] time: 4.95s train loss: 0.0738 accuracy: 0.977 f1: 0.9768
2023-07-14 00:18:47,080 epoch [130/800] time: 0.87s val loss: 0.1472 accuracy: 0.9482 f1: 0.9471
2023-07-14 00:18:52,116 epoch [131/800] time: 5.04s train loss: 0.0725 accuracy: 0.9779 f1: 0.9778
2023-07-14 00:18:53,097 epoch [131/800] time: 0.97s val loss: 0.148 accuracy: 0.949 f1: 0.948
2023-07-14 00:18:58,238 epoch [132/800] time: 5.14s train loss: 0.0714 accuracy: 0.9781 f1: 0.9779
2023-07-14 00:18:59,063 epoch [132/800] time: 0.82s val loss: 0.1477 accuracy: 0.9494 f1: 0.9484
2023-07-14 00:19:03,923 epoch [133/800] time: 4.86s train loss: 0.0724 accuracy: 0.9775 f1: 0.9775
2023-07-14 00:19:04,825 epoch [133/800] time: 0.9s val loss: 0.1473 accuracy: 0.9496 f1: 0.9485
2023-07-14 00:19:09,860 epoch [134/800] time: 5.03s train loss: 0.0727 accuracy: 0.9776 f1: 0.9775
2023-07-14 00:19:10,733 epoch [134/800] time: 0.87s val loss: 0.1483 accuracy: 0.9494 f1: 0.9484
2023-07-14 00:19:15,586 epoch [135/800] time: 4.85s train loss: 0.0736 accuracy: 0.9772 f1: 0.977
2023-07-14 00:19:16,397 epoch [135/800] time: 0.81s val loss: 0.1469 accuracy: 0.9492 f1: 0.9478
2023-07-14 00:19:21,313 epoch [136/800] time: 4.92s train loss: 0.0717 accuracy: 0.9778 f1: 0.9776
2023-07-14 00:19:22,191 epoch [136/800] time: 0.88s val loss: 0.1478 accuracy: 0.9489 f1: 0.9478
2023-07-14 00:19:27,028 epoch [137/800] time: 4.84s train loss: 0.0732 accuracy: 0.9774 f1: 0.9773
2023-07-14 00:19:27,885 epoch [137/800] time: 0.86s val loss: 0.1476 accuracy: 0.9493 f1: 0.9482
2023-07-14 00:19:32,664 epoch [138/800] time: 4.78s train loss: 0.0723 accuracy: 0.9775 f1: 0.9774
2023-07-14 00:19:33,469 epoch [138/800] time: 0.8s val loss: 0.147 accuracy: 0.9501 f1: 0.949
2023-07-14 00:19:38,210 epoch [139/800] time: 4.74s train loss: 0.0716 accuracy: 0.9781 f1: 0.9779
2023-07-14 00:19:39,075 epoch [139/800] time: 0.86s val loss: 0.1472 accuracy: 0.9501 f1: 0.949
2023-07-14 00:19:43,839 epoch [140/800] time: 4.76s train loss: 0.0707 accuracy: 0.978 f1: 0.9779
2023-07-14 00:19:44,692 epoch [140/800] time: 0.85s val loss: 0.1461 accuracy: 0.9502 f1: 0.9492
2023-07-14 00:19:49,486 epoch [141/800] time: 4.79s train loss: 0.0725 accuracy: 0.9779 f1: 0.9777
2023-07-14 00:19:50,311 epoch [141/800] time: 0.82s val loss: 0.1471 accuracy: 0.9491 f1: 0.9482
2023-07-14 00:19:55,275 epoch [142/800] time: 4.96s train loss: 0.0698 accuracy: 0.9787 f1: 0.9787
2023-07-14 00:19:56,146 epoch [142/800] time: 0.86s val loss: 0.1464 accuracy: 0.9502 f1: 0.9491
2023-07-14 00:20:00,877 epoch [143/800] time: 4.73s train loss: 0.071 accuracy: 0.9789 f1: 0.9789
2023-07-14 00:20:01,736 epoch [143/800] time: 0.85s val loss: 0.1471 accuracy: 0.9498 f1: 0.9486
2023-07-14 00:20:06,683 epoch [144/800] time: 4.95s train loss: 0.0708 accuracy: 0.9785 f1: 0.9783
2023-07-14 00:20:07,521 epoch [144/800] time: 0.84s val loss: 0.1462 accuracy: 0.9498 f1: 0.9486
2023-07-14 00:20:12,482 epoch [145/800] time: 4.96s train loss: 0.0723 accuracy: 0.9779 f1: 0.9777
2023-07-14 00:20:13,351 epoch [145/800] time: 0.87s val loss: 0.1478 accuracy: 0.9496 f1: 0.9485
2023-07-14 00:20:18,197 epoch [146/800] time: 4.85s train loss: 0.0705 accuracy: 0.9787 f1: 0.9785
2023-07-14 00:20:19,075 epoch [146/800] time: 0.88s val loss: 0.1463 accuracy: 0.9504 f1: 0.9492
2023-07-14 00:20:24,046 epoch [147/800] time: 4.97s train loss: 0.0706 accuracy: 0.978 f1: 0.9778
2023-07-14 00:20:24,854 epoch [147/800] time: 0.81s val loss: 0.1466 accuracy: 0.9502 f1: 0.9492
2023-07-14 00:20:29,688 epoch [148/800] time: 4.83s train loss: 0.0681 accuracy: 0.9793 f1: 0.9792
2023-07-14 00:20:30,541 epoch [148/800] time: 0.85s val loss: 0.1464 accuracy: 0.9503 f1: 0.9492
2023-07-14 00:20:35,169 epoch [149/800] time: 4.63s train loss: 0.0702 accuracy: 0.9788 f1: 0.9787
2023-07-14 00:20:36,022 epoch [149/800] time: 0.85s val loss: 0.1474 accuracy: 0.9502 f1: 0.9492
2023-07-14 00:20:40,757 epoch [150/800] time: 4.74s train loss: 0.0686 accuracy: 0.9798 f1: 0.9796
2023-07-14 00:20:41,562 epoch [150/800] time: 0.8s val loss: 0.1462 accuracy: 0.9503 f1: 0.9493
2023-07-14 00:20:46,152 epoch [151/800] time: 4.59s train loss: 0.0686 accuracy: 0.9793 f1: 0.9791
2023-07-14 00:20:47,002 epoch [151/800] time: 0.85s val loss: 0.1465 accuracy: 0.9501 f1: 0.9489
2023-07-14 00:20:51,757 epoch [152/800] time: 4.76s train loss: 0.0694 accuracy: 0.9797 f1: 0.9796
2023-07-14 00:20:52,606 epoch [152/800] time: 0.85s val loss: 0.1479 accuracy: 0.9504 f1: 0.9494
2023-07-14 00:20:57,281 epoch [153/800] time: 4.67s train loss: 0.0695 accuracy: 0.979 f1: 0.979
2023-07-14 00:20:58,087 epoch [153/800] time: 0.81s val loss: 0.1462 accuracy: 0.9502 f1: 0.9491
2023-07-14 00:21:02,887 epoch [154/800] time: 4.8s train loss: 0.0686 accuracy: 0.9795 f1: 0.9794
2023-07-14 00:21:03,749 epoch [154/800] time: 0.86s val loss: 0.1472 accuracy: 0.9496 f1: 0.9486
2023-07-14 00:21:08,657 epoch [155/800] time: 4.91s train loss: 0.0717 accuracy: 0.9787 f1: 0.9785
2023-07-14 00:21:09,519 epoch [155/800] time: 0.86s val loss: 0.1472 accuracy: 0.9502 f1: 0.9491
2023-07-14 00:21:14,338 epoch [156/800] time: 4.82s train loss: 0.0693 accuracy: 0.9786 f1: 0.9785
2023-07-14 00:21:15,156 epoch [156/800] time: 0.82s val loss: 0.1464 accuracy: 0.9495 f1: 0.9483
2023-07-14 00:21:19,966 epoch [157/800] time: 4.81s train loss: 0.0699 accuracy: 0.9793 f1: 0.9791
2023-07-14 00:21:20,829 epoch [157/800] time: 0.86s val loss: 0.1465 accuracy: 0.9502 f1: 0.9492
2023-07-14 00:21:25,627 epoch [158/800] time: 4.8s train loss: 0.0684 accuracy: 0.9798 f1: 0.9798
2023-07-14 00:21:26,486 epoch [158/800] time: 0.86s val loss: 0.1457 accuracy: 0.9503 f1: 0.9491
2023-07-14 00:21:31,102 epoch [159/800] time: 4.62s train loss: 0.068 accuracy: 0.9793 f1: 0.9791
2023-07-14 00:21:31,921 epoch [159/800] time: 0.82s val loss: 0.1463 accuracy: 0.9496 f1: 0.9484
2023-07-14 00:21:36,526 epoch [160/800] time: 4.6s train loss: 0.0688 accuracy: 0.9792 f1: 0.9792
2023-07-14 00:21:37,380 epoch [160/800] time: 0.85s val loss: 0.1459 accuracy: 0.9507 f1: 0.9496
2023-07-14 00:21:41,961 epoch [161/800] time: 4.58s train loss: 0.0689 accuracy: 0.9797 f1: 0.9796
2023-07-14 00:21:42,818 epoch [161/800] time: 0.86s val loss: 0.1466 accuracy: 0.9494 f1: 0.9482
2023-07-14 00:21:47,502 epoch [162/800] time: 4.68s train loss: 0.0692 accuracy: 0.9795 f1: 0.9794
2023-07-14 00:21:48,320 epoch [162/800] time: 0.82s val loss: 0.1465 accuracy: 0.9507 f1: 0.9497
2023-07-14 00:21:53,095 epoch [163/800] time: 4.77s train loss: 0.0667 accuracy: 0.9807 f1: 0.9805
2023-07-14 00:21:53,951 epoch [163/800] time: 0.85s val loss: 0.1464 accuracy: 0.9504 f1: 0.9494
2023-07-14 00:21:58,651 epoch [164/800] time: 4.7s train loss: 0.0684 accuracy: 0.9802 f1: 0.9801
2023-07-14 00:21:59,503 epoch [164/800] time: 0.85s val loss: 0.1462 accuracy: 0.9501 f1: 0.949
2023-07-14 00:22:04,245 epoch [165/800] time: 4.74s train loss: 0.0714 accuracy: 0.9785 f1: 0.9784
2023-07-14 00:22:05,059 epoch [165/800] time: 0.81s val loss: 0.1472 accuracy: 0.9495 f1: 0.9483
2023-07-14 00:22:09,668 epoch [166/800] time: 4.61s train loss: 0.069 accuracy: 0.9797 f1: 0.9796
2023-07-14 00:22:10,529 epoch [166/800] time: 0.86s val loss: 0.1457 accuracy: 0.9497 f1: 0.9485
2023-07-14 00:22:15,096 epoch [167/800] time: 4.57s train loss: 0.0692 accuracy: 0.9795 f1: 0.9794
2023-07-14 00:22:15,948 epoch [167/800] time: 0.85s val loss: 0.1459 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:22:20,552 epoch [168/800] time: 4.6s train loss: 0.0688 accuracy: 0.9802 f1: 0.9801
2023-07-14 00:22:21,356 epoch [168/800] time: 0.8s val loss: 0.1461 accuracy: 0.9499 f1: 0.9489
2023-07-14 00:22:25,962 epoch [169/800] time: 4.61s train loss: 0.0698 accuracy: 0.9795 f1: 0.9795
2023-07-14 00:22:26,817 epoch [169/800] time: 0.85s val loss: 0.1473 accuracy: 0.9493 f1: 0.9482
2023-07-14 00:22:31,398 epoch [170/800] time: 4.58s train loss: 0.0676 accuracy: 0.9797 f1: 0.9795
2023-07-14 00:22:32,259 epoch [170/800] time: 0.86s val loss: 0.146 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:22:36,851 epoch [171/800] time: 4.59s train loss: 0.0678 accuracy: 0.9794 f1: 0.9793
2023-07-14 00:22:37,658 epoch [171/800] time: 0.81s val loss: 0.146 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:22:42,252 epoch [172/800] time: 4.59s train loss: 0.0677 accuracy: 0.9797 f1: 0.9795
2023-07-14 00:22:43,105 epoch [172/800] time: 0.85s val loss: 0.1459 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:22:47,718 epoch [173/800] time: 4.61s train loss: 0.0687 accuracy: 0.9798 f1: 0.9797
2023-07-14 00:22:48,580 epoch [173/800] time: 0.86s val loss: 0.1458 accuracy: 0.9502 f1: 0.9492
2023-07-14 00:22:53,677 epoch [174/800] time: 5.1s train loss: 0.0697 accuracy: 0.9792 f1: 0.979
2023-07-14 00:22:54,571 epoch [174/800] time: 0.89s val loss: 0.1461 accuracy: 0.95 f1: 0.949
2023-07-14 00:22:59,764 epoch [175/800] time: 5.19s train loss: 0.0664 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:23:00,683 epoch [175/800] time: 0.91s val loss: 0.1458 accuracy: 0.9505 f1: 0.9495
2023-07-14 00:23:05,786 epoch [176/800] time: 5.1s train loss: 0.068 accuracy: 0.9797 f1: 0.9795
2023-07-14 00:23:06,711 epoch [176/800] time: 0.93s val loss: 0.1474 accuracy: 0.9497 f1: 0.9486
2023-07-14 00:23:11,933 epoch [177/800] time: 5.22s train loss: 0.0677 accuracy: 0.9796 f1: 0.9794
2023-07-14 00:23:12,784 epoch [177/800] time: 0.85s val loss: 0.1465 accuracy: 0.9503 f1: 0.9491
2023-07-14 00:23:17,818 epoch [178/800] time: 5.03s train loss: 0.0673 accuracy: 0.9801 f1: 0.9801
2023-07-14 00:23:18,698 epoch [178/800] time: 0.88s val loss: 0.1459 accuracy: 0.9507 f1: 0.9496
2023-07-14 00:23:23,593 epoch [179/800] time: 4.9s train loss: 0.0685 accuracy: 0.9797 f1: 0.9795
2023-07-14 00:23:24,457 epoch [179/800] time: 0.86s val loss: 0.1467 accuracy: 0.9511 f1: 0.95
2023-07-14 00:23:29,338 epoch [180/800] time: 4.88s train loss: 0.0669 accuracy: 0.9801 f1: 0.9798
2023-07-14 00:23:30,179 epoch [180/800] time: 0.84s val loss: 0.1459 accuracy: 0.9503 f1: 0.9492
2023-07-14 00:23:35,408 epoch [181/800] time: 5.23s train loss: 0.0671 accuracy: 0.9799 f1: 0.9797
2023-07-14 00:23:36,299 epoch [181/800] time: 0.89s val loss: 0.1459 accuracy: 0.9502 f1: 0.9491
2023-07-14 00:23:41,202 epoch [182/800] time: 4.9s train loss: 0.0659 accuracy: 0.9807 f1: 0.9804
2023-07-14 00:23:42,056 epoch [182/800] time: 0.85s val loss: 0.1469 accuracy: 0.95 f1: 0.949
2023-07-14 00:23:47,057 epoch [183/800] time: 5.0s train loss: 0.0675 accuracy: 0.9798 f1: 0.9798
2023-07-14 00:23:47,917 epoch [183/800] time: 0.86s val loss: 0.1478 accuracy: 0.9496 f1: 0.9485
2023-07-14 00:23:52,790 epoch [184/800] time: 4.87s train loss: 0.0685 accuracy: 0.9802 f1: 0.9802
2023-07-14 00:23:53,673 epoch [184/800] time: 0.88s val loss: 0.1462 accuracy: 0.9508 f1: 0.9497
2023-07-14 00:23:58,544 epoch [185/800] time: 4.87s train loss: 0.0666 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:23:59,434 epoch [185/800] time: 0.89s val loss: 0.1455 accuracy: 0.9504 f1: 0.9492
2023-07-14 00:24:04,326 epoch [186/800] time: 4.89s train loss: 0.0672 accuracy: 0.9797 f1: 0.9796
2023-07-14 00:24:05,145 epoch [186/800] time: 0.82s val loss: 0.1455 accuracy: 0.9508 f1: 0.9497
2023-07-14 00:24:09,967 epoch [187/800] time: 4.82s train loss: 0.0678 accuracy: 0.9802 f1: 0.9801
2023-07-14 00:24:10,837 epoch [187/800] time: 0.87s val loss: 0.1455 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:24:15,641 epoch [188/800] time: 4.8s train loss: 0.0689 accuracy: 0.9793 f1: 0.9792
2023-07-14 00:24:16,490 epoch [188/800] time: 0.85s val loss: 0.1455 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:24:21,304 epoch [189/800] time: 4.81s train loss: 0.0676 accuracy: 0.9803 f1: 0.9802
2023-07-14 00:24:22,110 epoch [189/800] time: 0.81s val loss: 0.1456 accuracy: 0.951 f1: 0.95
2023-07-14 00:24:26,810 epoch [190/800] time: 4.7s train loss: 0.0681 accuracy: 0.9797 f1: 0.9795
2023-07-14 00:24:27,661 epoch [190/800] time: 0.85s val loss: 0.146 accuracy: 0.9505 f1: 0.9496
2023-07-14 00:24:32,288 epoch [191/800] time: 4.63s train loss: 0.0674 accuracy: 0.9802 f1: 0.98
2023-07-14 00:24:33,134 epoch [191/800] time: 0.85s val loss: 0.1463 accuracy: 0.9507 f1: 0.9496
2023-07-14 00:24:37,848 epoch [192/800] time: 4.71s train loss: 0.0673 accuracy: 0.98 f1: 0.9798
2023-07-14 00:24:38,656 epoch [192/800] time: 0.81s val loss: 0.1464 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:24:43,393 epoch [193/800] time: 4.74s train loss: 0.0678 accuracy: 0.98 f1: 0.9798
2023-07-14 00:24:44,242 epoch [193/800] time: 0.85s val loss: 0.1459 accuracy: 0.9502 f1: 0.949
2023-07-14 00:24:48,925 epoch [194/800] time: 4.68s train loss: 0.0677 accuracy: 0.9795 f1: 0.9793
2023-07-14 00:24:49,775 epoch [194/800] time: 0.85s val loss: 0.1464 accuracy: 0.9505 f1: 0.9493
2023-07-14 00:24:54,506 epoch [195/800] time: 4.73s train loss: 0.0672 accuracy: 0.9802 f1: 0.9801
2023-07-14 00:24:55,311 epoch [195/800] time: 0.81s val loss: 0.1464 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:25:00,072 epoch [196/800] time: 4.76s train loss: 0.067 accuracy: 0.9801 f1: 0.98
2023-07-14 00:25:00,921 epoch [196/800] time: 0.85s val loss: 0.1461 accuracy: 0.9503 f1: 0.9492
2023-07-14 00:25:05,666 epoch [197/800] time: 4.74s train loss: 0.0668 accuracy: 0.9802 f1: 0.9802
2023-07-14 00:25:06,510 epoch [197/800] time: 0.84s val loss: 0.1455 accuracy: 0.9504 f1: 0.9494
2023-07-14 00:25:11,245 epoch [198/800] time: 4.73s train loss: 0.0678 accuracy: 0.98 f1: 0.9799
2023-07-14 00:25:12,043 epoch [198/800] time: 0.8s val loss: 0.1462 accuracy: 0.9507 f1: 0.9497
2023-07-14 00:25:16,721 epoch [199/800] time: 4.68s train loss: 0.067 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:25:17,562 epoch [199/800] time: 0.84s val loss: 0.146 accuracy: 0.951 f1: 0.9501
2023-07-14 00:25:22,266 epoch [200/800] time: 4.7s train loss: 0.0666 accuracy: 0.9804 f1: 0.9802
2023-07-14 00:25:23,106 epoch [200/800] time: 0.84s val loss: 0.1458 accuracy: 0.9504 f1: 0.9492
2023-07-14 00:25:27,850 epoch [201/800] time: 4.74s train loss: 0.0678 accuracy: 0.9798 f1: 0.9796
2023-07-14 00:25:28,651 epoch [201/800] time: 0.8s val loss: 0.1458 accuracy: 0.95 f1: 0.9489
2023-07-14 00:25:33,285 epoch [202/800] time: 4.63s train loss: 0.068 accuracy: 0.9803 f1: 0.9802
2023-07-14 00:25:34,130 epoch [202/800] time: 0.84s val loss: 0.1459 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:25:38,770 epoch [203/800] time: 4.64s train loss: 0.0683 accuracy: 0.98 f1: 0.9799
2023-07-14 00:25:39,615 epoch [203/800] time: 0.84s val loss: 0.1462 accuracy: 0.9502 f1: 0.949
2023-07-14 00:25:44,324 epoch [204/800] time: 4.71s train loss: 0.0677 accuracy: 0.98 f1: 0.9799
2023-07-14 00:25:45,126 epoch [204/800] time: 0.8s val loss: 0.1458 accuracy: 0.9506 f1: 0.9497
2023-07-14 00:25:49,851 epoch [205/800] time: 4.73s train loss: 0.068 accuracy: 0.9797 f1: 0.9796
2023-07-14 00:25:50,694 epoch [205/800] time: 0.84s val loss: 0.1465 accuracy: 0.9506 f1: 0.9496
2023-07-14 00:25:55,407 epoch [206/800] time: 4.71s train loss: 0.0673 accuracy: 0.9798 f1: 0.9796
2023-07-14 00:25:56,265 epoch [206/800] time: 0.86s val loss: 0.1453 accuracy: 0.951 f1: 0.9498
2023-07-14 00:26:00,817 epoch [207/800] time: 4.55s train loss: 0.0668 accuracy: 0.9803 f1: 0.9801
2023-07-14 00:26:01,619 epoch [207/800] time: 0.8s val loss: 0.1454 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:26:06,172 epoch [208/800] time: 4.55s train loss: 0.0672 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:26:07,020 epoch [208/800] time: 0.84s val loss: 0.1476 accuracy: 0.9498 f1: 0.9485
2023-07-14 00:26:11,517 epoch [209/800] time: 4.5s train loss: 0.067 accuracy: 0.9803 f1: 0.9802
2023-07-14 00:26:12,364 epoch [209/800] time: 0.85s val loss: 0.1459 accuracy: 0.9503 f1: 0.949
2023-07-14 00:26:16,935 epoch [210/800] time: 4.57s train loss: 0.0662 accuracy: 0.9806 f1: 0.9805
2023-07-14 00:26:17,736 epoch [210/800] time: 0.8s val loss: 0.1468 accuracy: 0.9498 f1: 0.9488
2023-07-14 00:26:22,333 epoch [211/800] time: 4.6s train loss: 0.0681 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:26:23,176 epoch [211/800] time: 0.84s val loss: 0.1461 accuracy: 0.9506 f1: 0.9496
2023-07-14 00:26:27,756 epoch [212/800] time: 4.58s train loss: 0.066 accuracy: 0.9804 f1: 0.9802
2023-07-14 00:26:28,603 epoch [212/800] time: 0.85s val loss: 0.1456 accuracy: 0.9507 f1: 0.9498
2023-07-14 00:26:33,258 epoch [213/800] time: 4.65s train loss: 0.0669 accuracy: 0.9804 f1: 0.9804
2023-07-14 00:26:34,059 epoch [213/800] time: 0.8s val loss: 0.1463 accuracy: 0.9506 f1: 0.9494
2023-07-14 00:26:38,730 epoch [214/800] time: 4.67s train loss: 0.0661 accuracy: 0.9806 f1: 0.9804
2023-07-14 00:26:39,574 epoch [214/800] time: 0.84s val loss: 0.146 accuracy: 0.9507 f1: 0.9495
2023-07-14 00:26:44,262 epoch [215/800] time: 4.69s train loss: 0.0678 accuracy: 0.9801 f1: 0.98
2023-07-14 00:26:45,122 epoch [215/800] time: 0.86s val loss: 0.1464 accuracy: 0.9507 f1: 0.9497
2023-07-14 00:26:50,165 epoch [216/800] time: 5.04s train loss: 0.0652 accuracy: 0.9811 f1: 0.981
2023-07-14 00:26:51,048 epoch [216/800] time: 0.88s val loss: 0.1455 accuracy: 0.9512 f1: 0.9503
2023-07-14 00:26:56,515 epoch [217/800] time: 5.47s train loss: 0.0659 accuracy: 0.9809 f1: 0.9809
2023-07-14 00:26:57,557 epoch [217/800] time: 1.04s val loss: 0.1463 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:27:02,524 epoch [218/800] time: 4.97s train loss: 0.0663 accuracy: 0.9807 f1: 0.9807
2023-07-14 00:27:03,443 epoch [218/800] time: 0.92s val loss: 0.1456 accuracy: 0.9507 f1: 0.9496
2023-07-14 00:27:08,517 epoch [219/800] time: 5.07s train loss: 0.0665 accuracy: 0.9803 f1: 0.9801
2023-07-14 00:27:09,334 epoch [219/800] time: 0.82s val loss: 0.1454 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:27:14,286 epoch [220/800] time: 4.95s train loss: 0.0667 accuracy: 0.9806 f1: 0.9805
2023-07-14 00:27:15,185 epoch [220/800] time: 0.9s val loss: 0.1463 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:27:19,996 epoch [221/800] time: 4.81s train loss: 0.0674 accuracy: 0.9804 f1: 0.9804
2023-07-14 00:27:20,859 epoch [221/800] time: 0.86s val loss: 0.1465 accuracy: 0.9513 f1: 0.9502
2023-07-14 00:27:25,718 epoch [222/800] time: 4.86s train loss: 0.0674 accuracy: 0.9806 f1: 0.9806
2023-07-14 00:27:26,526 epoch [222/800] time: 0.81s val loss: 0.1462 accuracy: 0.9507 f1: 0.9496
2023-07-14 00:27:31,439 epoch [223/800] time: 4.91s train loss: 0.0658 accuracy: 0.9802 f1: 0.9801
2023-07-14 00:27:32,350 epoch [223/800] time: 0.91s val loss: 0.1454 accuracy: 0.9503 f1: 0.9492
2023-07-14 00:27:37,271 epoch [224/800] time: 4.92s train loss: 0.0672 accuracy: 0.9804 f1: 0.9802
2023-07-14 00:27:38,157 epoch [224/800] time: 0.89s val loss: 0.1457 accuracy: 0.9512 f1: 0.9501
2023-07-14 00:27:42,974 epoch [225/800] time: 4.82s train loss: 0.066 accuracy: 0.9807 f1: 0.9805
2023-07-14 00:27:43,797 epoch [225/800] time: 0.82s val loss: 0.1457 accuracy: 0.9504 f1: 0.9492
2023-07-14 00:27:48,654 epoch [226/800] time: 4.86s train loss: 0.0664 accuracy: 0.9798 f1: 0.9798
2023-07-14 00:27:49,541 epoch [226/800] time: 0.89s val loss: 0.1459 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:27:54,361 epoch [227/800] time: 4.82s train loss: 0.0681 accuracy: 0.98 f1: 0.9799
2023-07-14 00:27:55,221 epoch [227/800] time: 0.86s val loss: 0.148 accuracy: 0.9487 f1: 0.9475
2023-07-14 00:27:59,997 epoch [228/800] time: 4.78s train loss: 0.0666 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:28:00,804 epoch [228/800] time: 0.81s val loss: 0.1469 accuracy: 0.9507 f1: 0.9497
2023-07-14 00:28:05,587 epoch [229/800] time: 4.78s train loss: 0.0666 accuracy: 0.98 f1: 0.9799
2023-07-14 00:28:06,431 epoch [229/800] time: 0.84s val loss: 0.1457 accuracy: 0.9502 f1: 0.9491
2023-07-14 00:28:10,955 epoch [230/800] time: 4.52s train loss: 0.0666 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:28:11,799 epoch [230/800] time: 0.84s val loss: 0.1457 accuracy: 0.9505 f1: 0.9495
2023-07-14 00:28:16,430 epoch [231/800] time: 4.63s train loss: 0.0656 accuracy: 0.9806 f1: 0.9804
2023-07-14 00:28:17,231 epoch [231/800] time: 0.8s val loss: 0.1462 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:28:21,784 epoch [232/800] time: 4.55s train loss: 0.0679 accuracy: 0.9798 f1: 0.9797
2023-07-14 00:28:22,639 epoch [232/800] time: 0.85s val loss: 0.1466 accuracy: 0.9507 f1: 0.9496
2023-07-14 00:28:27,196 epoch [233/800] time: 4.56s train loss: 0.0661 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:28:28,044 epoch [233/800] time: 0.85s val loss: 0.146 accuracy: 0.9506 f1: 0.9497
2023-07-14 00:28:32,608 epoch [234/800] time: 4.56s train loss: 0.0664 accuracy: 0.9801 f1: 0.98
2023-07-14 00:28:33,408 epoch [234/800] time: 0.8s val loss: 0.1468 accuracy: 0.9503 f1: 0.9491
2023-07-14 00:28:38,005 epoch [235/800] time: 4.6s train loss: 0.0674 accuracy: 0.9802 f1: 0.9801
2023-07-14 00:28:38,848 epoch [235/800] time: 0.84s val loss: 0.1458 accuracy: 0.9501 f1: 0.949
2023-07-14 00:28:43,405 epoch [236/800] time: 4.56s train loss: 0.0671 accuracy: 0.9803 f1: 0.9802
2023-07-14 00:28:44,251 epoch [236/800] time: 0.85s val loss: 0.1461 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:28:48,885 epoch [237/800] time: 4.63s train loss: 0.0665 accuracy: 0.9804 f1: 0.9801
2023-07-14 00:28:49,685 epoch [237/800] time: 0.8s val loss: 0.1464 accuracy: 0.9501 f1: 0.949
2023-07-14 00:28:54,349 epoch [238/800] time: 4.66s train loss: 0.0673 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:28:55,190 epoch [238/800] time: 0.84s val loss: 0.1458 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:28:59,867 epoch [239/800] time: 4.68s train loss: 0.067 accuracy: 0.98 f1: 0.98
2023-07-14 00:29:00,710 epoch [239/800] time: 0.84s val loss: 0.1463 accuracy: 0.9509 f1: 0.95
2023-07-14 00:29:05,437 epoch [240/800] time: 4.73s train loss: 0.0671 accuracy: 0.9802 f1: 0.9801
2023-07-14 00:29:06,250 epoch [240/800] time: 0.81s val loss: 0.1457 accuracy: 0.9506 f1: 0.9494
2023-07-14 00:29:10,797 epoch [241/800] time: 4.55s train loss: 0.0661 accuracy: 0.9808 f1: 0.9807
2023-07-14 00:29:11,641 epoch [241/800] time: 0.84s val loss: 0.146 accuracy: 0.9508 f1: 0.9499
2023-07-14 00:29:16,141 epoch [242/800] time: 4.5s train loss: 0.0661 accuracy: 0.9808 f1: 0.9807
2023-07-14 00:29:16,984 epoch [242/800] time: 0.84s val loss: 0.1457 accuracy: 0.9504 f1: 0.9494
2023-07-14 00:29:21,516 epoch [243/800] time: 4.53s train loss: 0.0675 accuracy: 0.9797 f1: 0.9796
2023-07-14 00:29:22,316 epoch [243/800] time: 0.8s val loss: 0.1459 accuracy: 0.9506 f1: 0.9494
2023-07-14 00:29:26,887 epoch [244/800] time: 4.57s train loss: 0.0669 accuracy: 0.9802 f1: 0.9799
2023-07-14 00:29:27,731 epoch [244/800] time: 0.84s val loss: 0.1456 accuracy: 0.9509 f1: 0.9498
2023-07-14 00:29:32,373 epoch [245/800] time: 4.64s train loss: 0.0671 accuracy: 0.9801 f1: 0.98
2023-07-14 00:29:33,218 epoch [245/800] time: 0.84s val loss: 0.1469 accuracy: 0.9501 f1: 0.9491
2023-07-14 00:29:37,934 epoch [246/800] time: 4.72s train loss: 0.0655 accuracy: 0.9806 f1: 0.9805
2023-07-14 00:29:38,735 epoch [246/800] time: 0.8s val loss: 0.1452 accuracy: 0.9509 f1: 0.9497
2023-07-14 00:29:43,468 epoch [247/800] time: 4.73s train loss: 0.0674 accuracy: 0.9799 f1: 0.9799
2023-07-14 00:29:44,318 epoch [247/800] time: 0.85s val loss: 0.1454 accuracy: 0.951 f1: 0.9499
2023-07-14 00:29:49,067 epoch [248/800] time: 4.75s train loss: 0.0661 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:29:49,909 epoch [248/800] time: 0.84s val loss: 0.1453 accuracy: 0.9509 f1: 0.9497
2023-07-14 00:29:54,451 epoch [249/800] time: 4.54s train loss: 0.0664 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:29:55,251 epoch [249/800] time: 0.8s val loss: 0.1454 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:30:00,029 epoch [250/800] time: 4.78s train loss: 0.0674 accuracy: 0.9801 f1: 0.9799
2023-07-14 00:30:00,878 epoch [250/800] time: 0.85s val loss: 0.1453 accuracy: 0.9509 f1: 0.9499
2023-07-14 00:30:05,671 epoch [251/800] time: 4.79s train loss: 0.067 accuracy: 0.9802 f1: 0.9801
2023-07-14 00:30:06,523 epoch [251/800] time: 0.85s val loss: 0.1464 accuracy: 0.9508 f1: 0.9496
2023-07-14 00:30:11,299 epoch [252/800] time: 4.78s train loss: 0.0653 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:30:12,107 epoch [252/800] time: 0.81s val loss: 0.1458 accuracy: 0.9508 f1: 0.9496
2023-07-14 00:30:16,741 epoch [253/800] time: 4.63s train loss: 0.067 accuracy: 0.9801 f1: 0.9799
2023-07-14 00:30:17,599 epoch [253/800] time: 0.86s val loss: 0.1458 accuracy: 0.9504 f1: 0.9492
2023-07-14 00:30:22,258 epoch [254/800] time: 4.66s train loss: 0.0667 accuracy: 0.9801 f1: 0.98
2023-07-14 00:30:23,111 epoch [254/800] time: 0.85s val loss: 0.1454 accuracy: 0.9502 f1: 0.9491
2023-07-14 00:30:27,668 epoch [255/800] time: 4.56s train loss: 0.0655 accuracy: 0.981 f1: 0.9809
2023-07-14 00:30:28,477 epoch [255/800] time: 0.81s val loss: 0.1462 accuracy: 0.9501 f1: 0.9489
2023-07-14 00:30:33,134 epoch [256/800] time: 4.66s train loss: 0.0653 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:30:33,983 epoch [256/800] time: 0.85s val loss: 0.1454 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:30:38,513 epoch [257/800] time: 4.53s train loss: 0.0666 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:30:39,363 epoch [257/800] time: 0.85s val loss: 0.1462 accuracy: 0.9505 f1: 0.9495
2023-07-14 00:30:43,937 epoch [258/800] time: 4.57s train loss: 0.065 accuracy: 0.9808 f1: 0.9806
2023-07-14 00:30:44,744 epoch [258/800] time: 0.81s val loss: 0.1448 accuracy: 0.9507 f1: 0.9497
2023-07-14 00:30:49,359 epoch [259/800] time: 4.61s train loss: 0.0668 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:30:50,224 epoch [259/800] time: 0.86s val loss: 0.1461 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:30:54,751 epoch [260/800] time: 4.53s train loss: 0.0667 accuracy: 0.9801 f1: 0.9801
2023-07-14 00:30:55,606 epoch [260/800] time: 0.85s val loss: 0.1454 accuracy: 0.9512 f1: 0.9501
2023-07-14 00:31:00,175 epoch [261/800] time: 4.57s train loss: 0.0654 accuracy: 0.9805 f1: 0.9803
2023-07-14 00:31:00,979 epoch [261/800] time: 0.8s val loss: 0.145 accuracy: 0.9506 f1: 0.9494
2023-07-14 00:31:05,535 epoch [262/800] time: 4.56s train loss: 0.067 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:31:06,383 epoch [262/800] time: 0.85s val loss: 0.1456 accuracy: 0.9499 f1: 0.9489
2023-07-14 00:31:10,897 epoch [263/800] time: 4.51s train loss: 0.0665 accuracy: 0.9806 f1: 0.9805
2023-07-14 00:31:11,740 epoch [263/800] time: 0.84s val loss: 0.1463 accuracy: 0.9509 f1: 0.9499
2023-07-14 00:31:16,277 epoch [264/800] time: 4.54s train loss: 0.0653 accuracy: 0.9806 f1: 0.9805
2023-07-14 00:31:17,078 epoch [264/800] time: 0.8s val loss: 0.1457 accuracy: 0.9505 f1: 0.9495
2023-07-14 00:31:21,628 epoch [265/800] time: 4.55s train loss: 0.0667 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:31:22,471 epoch [265/800] time: 0.84s val loss: 0.146 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:31:26,975 epoch [266/800] time: 4.5s train loss: 0.0673 accuracy: 0.98 f1: 0.9798
2023-07-14 00:31:27,817 epoch [266/800] time: 0.84s val loss: 0.1465 accuracy: 0.9508 f1: 0.9497
2023-07-14 00:31:32,357 epoch [267/800] time: 4.54s train loss: 0.0661 accuracy: 0.9806 f1: 0.9806
2023-07-14 00:31:33,156 epoch [267/800] time: 0.8s val loss: 0.1467 accuracy: 0.9509 f1: 0.9498
2023-07-14 00:31:37,831 epoch [268/800] time: 4.67s train loss: 0.0664 accuracy: 0.9803 f1: 0.9803
2023-07-14 00:31:38,675 epoch [268/800] time: 0.84s val loss: 0.1454 accuracy: 0.9506 f1: 0.9496
2023-07-14 00:31:43,176 epoch [269/800] time: 4.5s train loss: 0.0661 accuracy: 0.9803 f1: 0.9803
2023-07-14 00:31:44,018 epoch [269/800] time: 0.84s val loss: 0.1456 accuracy: 0.9509 f1: 0.9498
2023-07-14 00:31:48,559 epoch [270/800] time: 4.54s train loss: 0.0676 accuracy: 0.9806 f1: 0.9806
2023-07-14 00:31:49,360 epoch [270/800] time: 0.8s val loss: 0.1472 accuracy: 0.9502 f1: 0.9493
2023-07-14 00:31:53,906 epoch [271/800] time: 4.55s train loss: 0.066 accuracy: 0.9809 f1: 0.9807
2023-07-14 00:31:54,771 epoch [271/800] time: 0.86s val loss: 0.1467 accuracy: 0.9503 f1: 0.9493
2023-07-14 00:31:59,315 epoch [272/800] time: 4.54s train loss: 0.0671 accuracy: 0.9803 f1: 0.9803
2023-07-14 00:32:00,159 epoch [272/800] time: 0.84s val loss: 0.1459 accuracy: 0.9505 f1: 0.9496
2023-07-14 00:32:04,684 epoch [273/800] time: 4.52s train loss: 0.0675 accuracy: 0.9805 f1: 0.9805
2023-07-14 00:32:05,486 epoch [273/800] time: 0.8s val loss: 0.1458 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:32:10,173 epoch [274/800] time: 4.69s train loss: 0.0672 accuracy: 0.9803 f1: 0.9802
2023-07-14 00:32:11,016 epoch [274/800] time: 0.84s val loss: 0.1461 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:32:15,654 epoch [275/800] time: 4.64s train loss: 0.0664 accuracy: 0.9804 f1: 0.9802
2023-07-14 00:32:16,497 epoch [275/800] time: 0.84s val loss: 0.1454 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:32:21,187 epoch [276/800] time: 4.69s train loss: 0.0663 accuracy: 0.9803 f1: 0.9802
2023-07-14 00:32:21,987 epoch [276/800] time: 0.8s val loss: 0.1458 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:32:26,673 epoch [277/800] time: 4.69s train loss: 0.067 accuracy: 0.9805 f1: 0.9805
2023-07-14 00:32:27,516 epoch [277/800] time: 0.84s val loss: 0.1463 accuracy: 0.9503 f1: 0.9491
2023-07-14 00:32:32,177 epoch [278/800] time: 4.66s train loss: 0.0664 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:32:33,024 epoch [278/800] time: 0.85s val loss: 0.1459 accuracy: 0.95 f1: 0.9489
2023-07-14 00:32:37,717 epoch [279/800] time: 4.69s train loss: 0.0653 accuracy: 0.9809 f1: 0.9808
2023-07-14 00:32:38,516 epoch [279/800] time: 0.8s val loss: 0.146 accuracy: 0.9512 f1: 0.9501
2023-07-14 00:32:43,194 epoch [280/800] time: 4.68s train loss: 0.0663 accuracy: 0.9804 f1: 0.9802
2023-07-14 00:32:44,038 epoch [280/800] time: 0.84s val loss: 0.1453 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:32:48,754 epoch [281/800] time: 4.72s train loss: 0.0655 accuracy: 0.981 f1: 0.9808
2023-07-14 00:32:49,609 epoch [281/800] time: 0.86s val loss: 0.1463 accuracy: 0.9511 f1: 0.9501
2023-07-14 00:32:54,394 epoch [282/800] time: 4.78s train loss: 0.0682 accuracy: 0.9809 f1: 0.9807
2023-07-14 00:32:55,195 epoch [282/800] time: 0.8s val loss: 0.1469 accuracy: 0.95 f1: 0.9489
2023-07-14 00:32:59,979 epoch [283/800] time: 4.78s train loss: 0.0666 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:33:00,825 epoch [283/800] time: 0.85s val loss: 0.1469 accuracy: 0.9501 f1: 0.949
2023-07-14 00:33:05,549 epoch [284/800] time: 4.72s train loss: 0.0668 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:33:06,392 epoch [284/800] time: 0.84s val loss: 0.1465 accuracy: 0.9502 f1: 0.949
2023-07-14 00:33:11,158 epoch [285/800] time: 4.77s train loss: 0.0674 accuracy: 0.9809 f1: 0.9808
2023-07-14 00:33:11,957 epoch [285/800] time: 0.8s val loss: 0.1469 accuracy: 0.9503 f1: 0.9492
2023-07-14 00:33:16,728 epoch [286/800] time: 4.77s train loss: 0.0665 accuracy: 0.9808 f1: 0.9807
2023-07-14 00:33:17,572 epoch [286/800] time: 0.84s val loss: 0.1459 accuracy: 0.9501 f1: 0.9489
2023-07-14 00:33:22,297 epoch [287/800] time: 4.72s train loss: 0.0675 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:33:23,140 epoch [287/800] time: 0.84s val loss: 0.1461 accuracy: 0.9502 f1: 0.9492
2023-07-14 00:33:27,842 epoch [288/800] time: 4.7s train loss: 0.066 accuracy: 0.9806 f1: 0.9805
2023-07-14 00:33:28,643 epoch [288/800] time: 0.8s val loss: 0.1459 accuracy: 0.9512 f1: 0.95
2023-07-14 00:33:33,327 epoch [289/800] time: 4.68s train loss: 0.0667 accuracy: 0.9805 f1: 0.9806
2023-07-14 00:33:34,178 epoch [289/800] time: 0.85s val loss: 0.1457 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:33:38,998 epoch [290/800] time: 4.82s train loss: 0.0674 accuracy: 0.9807 f1: 0.9805
2023-07-14 00:33:39,898 epoch [290/800] time: 0.9s val loss: 0.1453 accuracy: 0.9507 f1: 0.9495
2023-07-14 00:33:44,939 epoch [291/800] time: 5.04s train loss: 0.0663 accuracy: 0.9805 f1: 0.9805
2023-07-14 00:33:45,750 epoch [291/800] time: 0.81s val loss: 0.1454 accuracy: 0.951 f1: 0.95
2023-07-14 00:33:50,674 epoch [292/800] time: 4.92s train loss: 0.0669 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:33:51,550 epoch [292/800] time: 0.88s val loss: 0.1457 accuracy: 0.9502 f1: 0.9492
2023-07-14 00:33:56,700 epoch [293/800] time: 5.15s train loss: 0.0664 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:33:57,570 epoch [293/800] time: 0.87s val loss: 0.145 accuracy: 0.951 f1: 0.9499
2023-07-14 00:34:02,498 epoch [294/800] time: 4.93s train loss: 0.0663 accuracy: 0.9809 f1: 0.9808
2023-07-14 00:34:03,313 epoch [294/800] time: 0.82s val loss: 0.1459 accuracy: 0.9502 f1: 0.9491
2023-07-14 00:34:08,203 epoch [295/800] time: 4.89s train loss: 0.0688 accuracy: 0.9795 f1: 0.9794
2023-07-14 00:34:09,051 epoch [295/800] time: 0.85s val loss: 0.1467 accuracy: 0.9494 f1: 0.9482
2023-07-14 00:34:13,812 epoch [296/800] time: 4.76s train loss: 0.0665 accuracy: 0.9807 f1: 0.9805
2023-07-14 00:34:14,661 epoch [296/800] time: 0.85s val loss: 0.1466 accuracy: 0.9504 f1: 0.9494
2023-07-14 00:34:19,396 epoch [297/800] time: 4.74s train loss: 0.0662 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:34:20,199 epoch [297/800] time: 0.8s val loss: 0.146 accuracy: 0.9505 f1: 0.9493
2023-07-14 00:34:24,874 epoch [298/800] time: 4.67s train loss: 0.0668 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:34:25,719 epoch [298/800] time: 0.84s val loss: 0.1456 accuracy: 0.9506 f1: 0.9496
2023-07-14 00:34:30,629 epoch [299/800] time: 4.91s train loss: 0.0668 accuracy: 0.9804 f1: 0.9804
2023-07-14 00:34:31,542 epoch [299/800] time: 0.91s val loss: 0.1459 accuracy: 0.9508 f1: 0.9498
2023-07-14 00:34:36,507 epoch [300/800] time: 4.96s train loss: 0.0656 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:34:37,322 epoch [300/800] time: 0.81s val loss: 0.1463 accuracy: 0.9508 f1: 0.9497
2023-07-14 00:34:42,384 epoch [301/800] time: 5.06s train loss: 0.0659 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:34:43,313 epoch [301/800] time: 0.93s val loss: 0.1456 accuracy: 0.9509 f1: 0.9498
2023-07-14 00:34:48,403 epoch [302/800] time: 5.09s train loss: 0.0651 accuracy: 0.9808 f1: 0.9806
2023-07-14 00:34:49,290 epoch [302/800] time: 0.89s val loss: 0.1457 accuracy: 0.9508 f1: 0.9498
2023-07-14 00:34:54,238 epoch [303/800] time: 4.95s train loss: 0.0673 accuracy: 0.9798 f1: 0.9797
2023-07-14 00:34:55,046 epoch [303/800] time: 0.81s val loss: 0.1457 accuracy: 0.9504 f1: 0.9494
2023-07-14 00:34:59,939 epoch [304/800] time: 4.89s train loss: 0.0662 accuracy: 0.9803 f1: 0.9802
2023-07-14 00:35:00,789 epoch [304/800] time: 0.85s val loss: 0.1457 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:35:05,537 epoch [305/800] time: 4.75s train loss: 0.0661 accuracy: 0.9805 f1: 0.9803
2023-07-14 00:35:06,380 epoch [305/800] time: 0.84s val loss: 0.1451 accuracy: 0.9507 f1: 0.9496
2023-07-14 00:35:10,923 epoch [306/800] time: 4.54s train loss: 0.0663 accuracy: 0.9803 f1: 0.9802
2023-07-14 00:35:11,726 epoch [306/800] time: 0.8s val loss: 0.1454 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:35:16,270 epoch [307/800] time: 4.54s train loss: 0.0665 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:35:17,116 epoch [307/800] time: 0.85s val loss: 0.1455 accuracy: 0.9512 f1: 0.9502
2023-07-14 00:35:21,614 epoch [308/800] time: 4.5s train loss: 0.0674 accuracy: 0.9801 f1: 0.98
2023-07-14 00:35:22,456 epoch [308/800] time: 0.84s val loss: 0.1466 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:35:27,146 epoch [309/800] time: 4.69s train loss: 0.0674 accuracy: 0.981 f1: 0.9809
2023-07-14 00:35:27,945 epoch [309/800] time: 0.8s val loss: 0.1466 accuracy: 0.9503 f1: 0.9494
2023-07-14 00:35:32,721 epoch [310/800] time: 4.78s train loss: 0.0681 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:35:33,564 epoch [310/800] time: 0.84s val loss: 0.1463 accuracy: 0.9508 f1: 0.9498
2023-07-14 00:35:38,268 epoch [311/800] time: 4.7s train loss: 0.0674 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:35:39,109 epoch [311/800] time: 0.84s val loss: 0.1463 accuracy: 0.95 f1: 0.9489
2023-07-14 00:35:43,715 epoch [312/800] time: 4.61s train loss: 0.0655 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:35:44,515 epoch [312/800] time: 0.8s val loss: 0.1457 accuracy: 0.9507 f1: 0.9497
2023-07-14 00:35:49,198 epoch [313/800] time: 4.68s train loss: 0.0675 accuracy: 0.9806 f1: 0.9803
2023-07-14 00:35:50,042 epoch [313/800] time: 0.84s val loss: 0.1457 accuracy: 0.9506 f1: 0.9496
2023-07-14 00:35:54,650 epoch [314/800] time: 4.61s train loss: 0.0664 accuracy: 0.9807 f1: 0.9805
2023-07-14 00:35:55,493 epoch [314/800] time: 0.84s val loss: 0.1458 accuracy: 0.9512 f1: 0.95
2023-07-14 00:36:00,242 epoch [315/800] time: 4.75s train loss: 0.0665 accuracy: 0.9801 f1: 0.9801
2023-07-14 00:36:01,052 epoch [315/800] time: 0.81s val loss: 0.1454 accuracy: 0.9507 f1: 0.9496
2023-07-14 00:36:05,710 epoch [316/800] time: 4.66s train loss: 0.0649 accuracy: 0.9807 f1: 0.9805
2023-07-14 00:36:06,553 epoch [316/800] time: 0.84s val loss: 0.1455 accuracy: 0.9508 f1: 0.9498
2023-07-14 00:36:11,259 epoch [317/800] time: 4.71s train loss: 0.0654 accuracy: 0.9811 f1: 0.9808
2023-07-14 00:36:12,107 epoch [317/800] time: 0.85s val loss: 0.1456 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:36:16,636 epoch [318/800] time: 4.53s train loss: 0.0665 accuracy: 0.9804 f1: 0.9802
2023-07-14 00:36:17,435 epoch [318/800] time: 0.8s val loss: 0.1467 accuracy: 0.9506 f1: 0.9496
2023-07-14 00:36:22,056 epoch [319/800] time: 4.62s train loss: 0.066 accuracy: 0.9808 f1: 0.9807
2023-07-14 00:36:22,899 epoch [319/800] time: 0.84s val loss: 0.1459 accuracy: 0.9505 f1: 0.9493
2023-07-14 00:36:27,629 epoch [320/800] time: 4.73s train loss: 0.0666 accuracy: 0.9801 f1: 0.98
2023-07-14 00:36:28,471 epoch [320/800] time: 0.84s val loss: 0.1455 accuracy: 0.9508 f1: 0.9496
2023-07-14 00:36:33,221 epoch [321/800] time: 4.75s train loss: 0.0665 accuracy: 0.9804 f1: 0.9802
2023-07-14 00:36:34,022 epoch [321/800] time: 0.8s val loss: 0.1476 accuracy: 0.9493 f1: 0.948
2023-07-14 00:36:38,795 epoch [322/800] time: 4.77s train loss: 0.0668 accuracy: 0.9803 f1: 0.9801
2023-07-14 00:36:39,639 epoch [322/800] time: 0.84s val loss: 0.1466 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:36:44,359 epoch [323/800] time: 4.72s train loss: 0.0672 accuracy: 0.9799 f1: 0.9798
2023-07-14 00:36:45,201 epoch [323/800] time: 0.84s val loss: 0.1455 accuracy: 0.9506 f1: 0.9496
2023-07-14 00:36:49,734 epoch [324/800] time: 4.53s train loss: 0.0664 accuracy: 0.9803 f1: 0.9803
2023-07-14 00:36:50,546 epoch [324/800] time: 0.81s val loss: 0.1454 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:36:55,080 epoch [325/800] time: 4.53s train loss: 0.0663 accuracy: 0.9803 f1: 0.9803
2023-07-14 00:36:55,928 epoch [325/800] time: 0.85s val loss: 0.1453 accuracy: 0.951 f1: 0.95
2023-07-14 00:37:00,420 epoch [326/800] time: 4.49s train loss: 0.0663 accuracy: 0.9804 f1: 0.9804
2023-07-14 00:37:01,263 epoch [326/800] time: 0.84s val loss: 0.1463 accuracy: 0.9509 f1: 0.9498
2023-07-14 00:37:05,797 epoch [327/800] time: 4.53s train loss: 0.0667 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:37:06,601 epoch [327/800] time: 0.8s val loss: 0.1464 accuracy: 0.9503 f1: 0.9493
2023-07-14 00:37:11,318 epoch [328/800] time: 4.72s train loss: 0.0656 accuracy: 0.9806 f1: 0.9804
2023-07-14 00:37:12,164 epoch [328/800] time: 0.85s val loss: 0.1454 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:37:16,829 epoch [329/800] time: 4.66s train loss: 0.0689 accuracy: 0.9793 f1: 0.9793
2023-07-14 00:37:17,674 epoch [329/800] time: 0.85s val loss: 0.1456 accuracy: 0.9507 f1: 0.9497
2023-07-14 00:37:22,613 epoch [330/800] time: 4.94s train loss: 0.0663 accuracy: 0.9808 f1: 0.9807
2023-07-14 00:37:23,435 epoch [330/800] time: 0.82s val loss: 0.1454 accuracy: 0.9507 f1: 0.9497
2023-07-14 00:37:28,263 epoch [331/800] time: 4.83s train loss: 0.0665 accuracy: 0.9809 f1: 0.9808
2023-07-14 00:37:29,130 epoch [331/800] time: 0.87s val loss: 0.1457 accuracy: 0.9504 f1: 0.9494
2023-07-14 00:37:33,914 epoch [332/800] time: 4.78s train loss: 0.0651 accuracy: 0.9808 f1: 0.9806
2023-07-14 00:37:34,829 epoch [332/800] time: 0.91s val loss: 0.1461 accuracy: 0.9506 f1: 0.9496
2023-07-14 00:37:40,011 epoch [333/800] time: 5.18s train loss: 0.0658 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:37:40,862 epoch [333/800] time: 0.85s val loss: 0.1456 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:37:45,875 epoch [334/800] time: 5.01s train loss: 0.0667 accuracy: 0.98 f1: 0.9799
2023-07-14 00:37:46,758 epoch [334/800] time: 0.88s val loss: 0.1462 accuracy: 0.9507 f1: 0.9497
2023-07-14 00:37:51,947 epoch [335/800] time: 5.19s train loss: 0.0666 accuracy: 0.9808 f1: 0.9808
2023-07-14 00:37:52,877 epoch [335/800] time: 0.93s val loss: 0.1458 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:37:57,946 epoch [336/800] time: 5.07s train loss: 0.067 accuracy: 0.9804 f1: 0.9801
2023-07-14 00:37:58,766 epoch [336/800] time: 0.82s val loss: 0.1456 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:38:03,796 epoch [337/800] time: 5.03s train loss: 0.0676 accuracy: 0.9802 f1: 0.9801
2023-07-14 00:38:04,757 epoch [337/800] time: 0.96s val loss: 0.1455 accuracy: 0.9507 f1: 0.9496
2023-07-14 00:38:09,817 epoch [338/800] time: 5.06s train loss: 0.0666 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:38:10,724 epoch [338/800] time: 0.91s val loss: 0.1455 accuracy: 0.9506 f1: 0.9494
2023-07-14 00:38:15,661 epoch [339/800] time: 4.94s train loss: 0.0668 accuracy: 0.9805 f1: 0.9805
2023-07-14 00:38:16,556 epoch [339/800] time: 0.89s val loss: 0.1472 accuracy: 0.9505 f1: 0.9496
2023-07-14 00:38:21,933 epoch [340/800] time: 5.38s train loss: 0.0654 accuracy: 0.9811 f1: 0.981
2023-07-14 00:38:22,860 epoch [340/800] time: 0.92s val loss: 0.1447 accuracy: 0.9506 f1: 0.9493
2023-07-14 00:38:27,823 epoch [341/800] time: 4.96s train loss: 0.0665 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:38:28,714 epoch [341/800] time: 0.89s val loss: 0.1462 accuracy: 0.9502 f1: 0.9491
2023-07-14 00:38:33,957 epoch [342/800] time: 5.24s train loss: 0.0662 accuracy: 0.9806 f1: 0.9805
2023-07-14 00:38:34,771 epoch [342/800] time: 0.81s val loss: 0.1463 accuracy: 0.9502 f1: 0.9491
2023-07-14 00:38:39,764 epoch [343/800] time: 4.99s train loss: 0.0656 accuracy: 0.9808 f1: 0.9808
2023-07-14 00:38:40,633 epoch [343/800] time: 0.87s val loss: 0.1453 accuracy: 0.9508 f1: 0.9497
2023-07-14 00:38:45,447 epoch [344/800] time: 4.81s train loss: 0.0668 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:38:46,309 epoch [344/800] time: 0.86s val loss: 0.1456 accuracy: 0.9509 f1: 0.9499
2023-07-14 00:38:51,230 epoch [345/800] time: 4.92s train loss: 0.0668 accuracy: 0.9801 f1: 0.98
2023-07-14 00:38:52,056 epoch [345/800] time: 0.83s val loss: 0.1469 accuracy: 0.9507 f1: 0.9497
2023-07-14 00:38:56,843 epoch [346/800] time: 4.79s train loss: 0.0658 accuracy: 0.9803 f1: 0.9803
2023-07-14 00:38:57,693 epoch [346/800] time: 0.85s val loss: 0.1452 accuracy: 0.9508 f1: 0.9497
2023-07-14 00:39:02,509 epoch [347/800] time: 4.82s train loss: 0.0665 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:39:03,413 epoch [347/800] time: 0.9s val loss: 0.1462 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:39:08,357 epoch [348/800] time: 4.94s train loss: 0.0678 accuracy: 0.9799 f1: 0.9798
2023-07-14 00:39:09,164 epoch [348/800] time: 0.81s val loss: 0.145 accuracy: 0.9509 f1: 0.9498
2023-07-14 00:39:13,893 epoch [349/800] time: 4.73s train loss: 0.0669 accuracy: 0.9803 f1: 0.9802
2023-07-14 00:39:14,776 epoch [349/800] time: 0.88s val loss: 0.1459 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:39:19,811 epoch [350/800] time: 5.04s train loss: 0.0665 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:39:20,709 epoch [350/800] time: 0.9s val loss: 0.1456 accuracy: 0.9506 f1: 0.9497
2023-07-14 00:39:25,631 epoch [351/800] time: 4.92s train loss: 0.066 accuracy: 0.9806 f1: 0.9804
2023-07-14 00:39:26,441 epoch [351/800] time: 0.81s val loss: 0.1463 accuracy: 0.9503 f1: 0.9492
2023-07-14 00:39:31,412 epoch [352/800] time: 4.97s train loss: 0.0657 accuracy: 0.9808 f1: 0.9807
2023-07-14 00:39:32,294 epoch [352/800] time: 0.88s val loss: 0.146 accuracy: 0.9508 f1: 0.9498
2023-07-14 00:39:37,145 epoch [353/800] time: 4.85s train loss: 0.0655 accuracy: 0.9806 f1: 0.9805
2023-07-14 00:39:38,004 epoch [353/800] time: 0.86s val loss: 0.1461 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:39:42,669 epoch [354/800] time: 4.66s train loss: 0.0659 accuracy: 0.9806 f1: 0.9804
2023-07-14 00:39:43,489 epoch [354/800] time: 0.82s val loss: 0.1451 accuracy: 0.9513 f1: 0.9502
2023-07-14 00:39:48,332 epoch [355/800] time: 4.84s train loss: 0.0665 accuracy: 0.9802 f1: 0.9801
2023-07-14 00:39:49,192 epoch [355/800] time: 0.86s val loss: 0.1462 accuracy: 0.9508 f1: 0.9496
2023-07-14 00:39:53,784 epoch [356/800] time: 4.59s train loss: 0.0671 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:39:54,634 epoch [356/800] time: 0.85s val loss: 0.1471 accuracy: 0.9499 f1: 0.9489
2023-07-14 00:39:59,406 epoch [357/800] time: 4.77s train loss: 0.0661 accuracy: 0.9806 f1: 0.9804
2023-07-14 00:40:00,225 epoch [357/800] time: 0.82s val loss: 0.1459 accuracy: 0.9508 f1: 0.9498
2023-07-14 00:40:04,909 epoch [358/800] time: 4.68s train loss: 0.0667 accuracy: 0.9807 f1: 0.9805
2023-07-14 00:40:05,761 epoch [358/800] time: 0.85s val loss: 0.1453 accuracy: 0.9507 f1: 0.9498
2023-07-14 00:40:10,313 epoch [359/800] time: 4.55s train loss: 0.066 accuracy: 0.9807 f1: 0.9805
2023-07-14 00:40:11,176 epoch [359/800] time: 0.86s val loss: 0.1457 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:40:15,806 epoch [360/800] time: 4.63s train loss: 0.0655 accuracy: 0.9805 f1: 0.9803
2023-07-14 00:40:16,605 epoch [360/800] time: 0.8s val loss: 0.1455 accuracy: 0.9508 f1: 0.9497
2023-07-14 00:40:21,288 epoch [361/800] time: 4.68s train loss: 0.0648 accuracy: 0.9809 f1: 0.9808
2023-07-14 00:40:22,135 epoch [361/800] time: 0.85s val loss: 0.1451 accuracy: 0.9507 f1: 0.9497
2023-07-14 00:40:26,635 epoch [362/800] time: 4.5s train loss: 0.066 accuracy: 0.9806 f1: 0.9804
2023-07-14 00:40:27,475 epoch [362/800] time: 0.84s val loss: 0.1452 accuracy: 0.9512 f1: 0.9502
2023-07-14 00:40:32,001 epoch [363/800] time: 4.53s train loss: 0.0657 accuracy: 0.9806 f1: 0.9804
2023-07-14 00:40:32,798 epoch [363/800] time: 0.8s val loss: 0.1465 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:40:37,332 epoch [364/800] time: 4.53s train loss: 0.0666 accuracy: 0.9805 f1: 0.9803
2023-07-14 00:40:38,174 epoch [364/800] time: 0.84s val loss: 0.1452 accuracy: 0.9507 f1: 0.9497
2023-07-14 00:40:42,661 epoch [365/800] time: 4.49s train loss: 0.0668 accuracy: 0.981 f1: 0.9809
2023-07-14 00:40:43,502 epoch [365/800] time: 0.84s val loss: 0.1461 accuracy: 0.95 f1: 0.9489
2023-07-14 00:40:48,218 epoch [366/800] time: 4.72s train loss: 0.0661 accuracy: 0.9807 f1: 0.9805
2023-07-14 00:40:49,021 epoch [366/800] time: 0.8s val loss: 0.1462 accuracy: 0.9505 f1: 0.9493
2023-07-14 00:40:53,658 epoch [367/800] time: 4.64s train loss: 0.0673 accuracy: 0.9806 f1: 0.9804
2023-07-14 00:40:54,498 epoch [367/800] time: 0.84s val loss: 0.1452 accuracy: 0.9505 f1: 0.9493
2023-07-14 00:40:59,228 epoch [368/800] time: 4.73s train loss: 0.0664 accuracy: 0.9807 f1: 0.9807
2023-07-14 00:41:00,071 epoch [368/800] time: 0.84s val loss: 0.1457 accuracy: 0.9508 f1: 0.9496
2023-07-14 00:41:04,843 epoch [369/800] time: 4.77s train loss: 0.0665 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:41:05,643 epoch [369/800] time: 0.8s val loss: 0.1454 accuracy: 0.9502 f1: 0.9491
2023-07-14 00:41:10,385 epoch [370/800] time: 4.74s train loss: 0.0655 accuracy: 0.9811 f1: 0.981
2023-07-14 00:41:11,226 epoch [370/800] time: 0.84s val loss: 0.1459 accuracy: 0.9502 f1: 0.9489
2023-07-14 00:41:15,917 epoch [371/800] time: 4.69s train loss: 0.0677 accuracy: 0.9803 f1: 0.9802
2023-07-14 00:41:16,764 epoch [371/800] time: 0.85s val loss: 0.146 accuracy: 0.9502 f1: 0.9489
2023-07-14 00:41:21,445 epoch [372/800] time: 4.68s train loss: 0.0658 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:41:22,244 epoch [372/800] time: 0.8s val loss: 0.1465 accuracy: 0.9503 f1: 0.9492
2023-07-14 00:41:26,892 epoch [373/800] time: 4.65s train loss: 0.0659 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:41:27,733 epoch [373/800] time: 0.84s val loss: 0.1453 accuracy: 0.95 f1: 0.949
2023-07-14 00:41:32,546 epoch [374/800] time: 4.81s train loss: 0.0666 accuracy: 0.9803 f1: 0.9803
2023-07-14 00:41:33,400 epoch [374/800] time: 0.85s val loss: 0.1461 accuracy: 0.9509 f1: 0.9499
2023-07-14 00:41:38,191 epoch [375/800] time: 4.79s train loss: 0.0665 accuracy: 0.9807 f1: 0.9805
2023-07-14 00:41:38,998 epoch [375/800] time: 0.81s val loss: 0.1454 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:41:43,884 epoch [376/800] time: 4.89s train loss: 0.0669 accuracy: 0.9803 f1: 0.9802
2023-07-14 00:41:44,766 epoch [376/800] time: 0.88s val loss: 0.1453 accuracy: 0.9513 f1: 0.9502
2023-07-14 00:41:49,773 epoch [377/800] time: 5.01s train loss: 0.066 accuracy: 0.9804 f1: 0.9802
2023-07-14 00:41:50,721 epoch [377/800] time: 0.95s val loss: 0.1452 accuracy: 0.9506 f1: 0.9494
2023-07-14 00:41:56,044 epoch [378/800] time: 5.32s train loss: 0.068 accuracy: 0.98 f1: 0.9798
2023-07-14 00:41:56,876 epoch [378/800] time: 0.83s val loss: 0.1467 accuracy: 0.9505 f1: 0.9493
2023-07-14 00:42:02,201 epoch [379/800] time: 5.32s train loss: 0.0661 accuracy: 0.9808 f1: 0.9807
2023-07-14 00:42:03,147 epoch [379/800] time: 0.95s val loss: 0.1463 accuracy: 0.9502 f1: 0.9491
2023-07-14 00:42:08,236 epoch [380/800] time: 5.09s train loss: 0.0671 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:42:09,146 epoch [380/800] time: 0.91s val loss: 0.1456 accuracy: 0.9506 f1: 0.9496
2023-07-14 00:42:14,291 epoch [381/800] time: 5.14s train loss: 0.0667 accuracy: 0.9799 f1: 0.9799
2023-07-14 00:42:15,138 epoch [381/800] time: 0.85s val loss: 0.1453 accuracy: 0.9508 f1: 0.9498
2023-07-14 00:42:20,247 epoch [382/800] time: 5.11s train loss: 0.0662 accuracy: 0.9807 f1: 0.9805
2023-07-14 00:42:21,115 epoch [382/800] time: 0.87s val loss: 0.1455 accuracy: 0.9506 f1: 0.9496
2023-07-14 00:42:25,817 epoch [383/800] time: 4.7s train loss: 0.0662 accuracy: 0.9805 f1: 0.9805
2023-07-14 00:42:26,712 epoch [383/800] time: 0.89s val loss: 0.1455 accuracy: 0.9509 f1: 0.9499
2023-07-14 00:42:31,581 epoch [384/800] time: 4.87s train loss: 0.0681 accuracy: 0.9808 f1: 0.9807
2023-07-14 00:42:32,386 epoch [384/800] time: 0.8s val loss: 0.1464 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:42:37,144 epoch [385/800] time: 4.76s train loss: 0.0673 accuracy: 0.9804 f1: 0.9804
2023-07-14 00:42:38,014 epoch [385/800] time: 0.87s val loss: 0.1467 accuracy: 0.9503 f1: 0.9493
2023-07-14 00:42:42,849 epoch [386/800] time: 4.83s train loss: 0.068 accuracy: 0.9802 f1: 0.9801
2023-07-14 00:42:43,764 epoch [386/800] time: 0.91s val loss: 0.1459 accuracy: 0.9506 f1: 0.9494
2023-07-14 00:42:48,824 epoch [387/800] time: 5.06s train loss: 0.0659 accuracy: 0.9808 f1: 0.9807
2023-07-14 00:42:49,702 epoch [387/800] time: 0.88s val loss: 0.1456 accuracy: 0.9501 f1: 0.949
2023-07-14 00:42:54,745 epoch [388/800] time: 5.04s train loss: 0.0647 accuracy: 0.9813 f1: 0.9813
2023-07-14 00:42:55,675 epoch [388/800] time: 0.92s val loss: 0.1465 accuracy: 0.9508 f1: 0.9496
2023-07-14 00:43:00,776 epoch [389/800] time: 5.1s train loss: 0.068 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:43:01,664 epoch [389/800] time: 0.89s val loss: 0.1461 accuracy: 0.9511 f1: 0.9499
2023-07-14 00:43:06,728 epoch [390/800] time: 5.06s train loss: 0.0665 accuracy: 0.9808 f1: 0.9807
2023-07-14 00:43:07,551 epoch [390/800] time: 0.82s val loss: 0.1457 accuracy: 0.9503 f1: 0.9493
2023-07-14 00:43:12,420 epoch [391/800] time: 4.87s train loss: 0.0659 accuracy: 0.9807 f1: 0.9805
2023-07-14 00:43:13,277 epoch [391/800] time: 0.86s val loss: 0.1456 accuracy: 0.951 f1: 0.9499
2023-07-14 00:43:18,019 epoch [392/800] time: 4.74s train loss: 0.0666 accuracy: 0.9805 f1: 0.9805
2023-07-14 00:43:18,865 epoch [392/800] time: 0.85s val loss: 0.1472 accuracy: 0.9506 f1: 0.9494
2023-07-14 00:43:23,608 epoch [393/800] time: 4.74s train loss: 0.0665 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:43:24,408 epoch [393/800] time: 0.8s val loss: 0.1451 accuracy: 0.9509 f1: 0.9499
2023-07-14 00:43:29,280 epoch [394/800] time: 4.87s train loss: 0.0671 accuracy: 0.9799 f1: 0.9798
2023-07-14 00:43:30,149 epoch [394/800] time: 0.87s val loss: 0.1457 accuracy: 0.9503 f1: 0.9494
2023-07-14 00:43:34,970 epoch [395/800] time: 4.82s train loss: 0.0653 accuracy: 0.9809 f1: 0.9808
2023-07-14 00:43:35,833 epoch [395/800] time: 0.86s val loss: 0.1456 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:43:40,559 epoch [396/800] time: 4.73s train loss: 0.0657 accuracy: 0.9807 f1: 0.9805
2023-07-14 00:43:41,404 epoch [396/800] time: 0.85s val loss: 0.1461 accuracy: 0.9505 f1: 0.9492
2023-07-14 00:43:46,205 epoch [397/800] time: 4.8s train loss: 0.0659 accuracy: 0.9806 f1: 0.9804
2023-07-14 00:43:47,057 epoch [397/800] time: 0.85s val loss: 0.1454 accuracy: 0.951 f1: 0.9498
2023-07-14 00:43:51,884 epoch [398/800] time: 4.83s train loss: 0.0658 accuracy: 0.9809 f1: 0.9808
2023-07-14 00:43:52,747 epoch [398/800] time: 0.86s val loss: 0.1463 accuracy: 0.9504 f1: 0.9492
2023-07-14 00:43:57,766 epoch [399/800] time: 5.02s train loss: 0.0663 accuracy: 0.9805 f1: 0.9803
2023-07-14 00:43:58,599 epoch [399/800] time: 0.83s val loss: 0.1453 accuracy: 0.9509 f1: 0.95
2023-07-14 00:44:03,430 epoch [400/800] time: 4.83s train loss: 0.0664 accuracy: 0.9802 f1: 0.9801
2023-07-14 00:44:04,284 epoch [400/800] time: 0.85s val loss: 0.1455 accuracy: 0.9508 f1: 0.9496
2023-07-14 00:44:09,161 epoch [401/800] time: 4.88s train loss: 0.0651 accuracy: 0.9811 f1: 0.981
2023-07-14 00:44:10,040 epoch [401/800] time: 0.88s val loss: 0.1455 accuracy: 0.9509 f1: 0.9497
2023-07-14 00:44:14,762 epoch [402/800] time: 4.72s train loss: 0.0659 accuracy: 0.9815 f1: 0.9813
2023-07-14 00:44:15,576 epoch [402/800] time: 0.81s val loss: 0.1467 accuracy: 0.9508 f1: 0.9497
2023-07-14 00:44:20,205 epoch [403/800] time: 4.63s train loss: 0.0658 accuracy: 0.9805 f1: 0.9803
2023-07-14 00:44:21,074 epoch [403/800] time: 0.87s val loss: 0.1468 accuracy: 0.95 f1: 0.9489
2023-07-14 00:44:25,637 epoch [404/800] time: 4.56s train loss: 0.0656 accuracy: 0.981 f1: 0.9808
2023-07-14 00:44:26,484 epoch [404/800] time: 0.85s val loss: 0.1457 accuracy: 0.9508 f1: 0.9497
2023-07-14 00:44:31,094 epoch [405/800] time: 4.61s train loss: 0.0685 accuracy: 0.9802 f1: 0.9801
2023-07-14 00:44:31,901 epoch [405/800] time: 0.81s val loss: 0.1495 accuracy: 0.948 f1: 0.9468
2023-07-14 00:44:36,551 epoch [406/800] time: 4.65s train loss: 0.0658 accuracy: 0.9804 f1: 0.9802
2023-07-14 00:44:37,395 epoch [406/800] time: 0.84s val loss: 0.146 accuracy: 0.951 f1: 0.9499
2023-07-14 00:44:42,012 epoch [407/800] time: 4.62s train loss: 0.0648 accuracy: 0.981 f1: 0.9809
2023-07-14 00:44:42,857 epoch [407/800] time: 0.84s val loss: 0.1448 accuracy: 0.9512 f1: 0.95
2023-07-14 00:44:47,546 epoch [408/800] time: 4.69s train loss: 0.0667 accuracy: 0.9806 f1: 0.9806
2023-07-14 00:44:48,349 epoch [408/800] time: 0.8s val loss: 0.1461 accuracy: 0.9502 f1: 0.9491
2023-07-14 00:44:53,136 epoch [409/800] time: 4.79s train loss: 0.0659 accuracy: 0.9806 f1: 0.9805
2023-07-14 00:44:53,981 epoch [409/800] time: 0.84s val loss: 0.1456 accuracy: 0.9507 f1: 0.9496
2023-07-14 00:44:58,698 epoch [410/800] time: 4.72s train loss: 0.0667 accuracy: 0.9808 f1: 0.9805
2023-07-14 00:44:59,545 epoch [410/800] time: 0.85s val loss: 0.1456 accuracy: 0.9507 f1: 0.9496
2023-07-14 00:45:04,364 epoch [411/800] time: 4.82s train loss: 0.0669 accuracy: 0.9802 f1: 0.98
2023-07-14 00:45:05,167 epoch [411/800] time: 0.8s val loss: 0.1456 accuracy: 0.951 f1: 0.9499
2023-07-14 00:45:09,729 epoch [412/800] time: 4.56s train loss: 0.0664 accuracy: 0.9808 f1: 0.9806
2023-07-14 00:45:10,578 epoch [412/800] time: 0.85s val loss: 0.1457 accuracy: 0.9507 f1: 0.9498
2023-07-14 00:45:15,199 epoch [413/800] time: 4.62s train loss: 0.0667 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:45:16,044 epoch [413/800] time: 0.84s val loss: 0.1458 accuracy: 0.9512 f1: 0.95
2023-07-14 00:45:20,619 epoch [414/800] time: 4.57s train loss: 0.0655 accuracy: 0.9808 f1: 0.9807
2023-07-14 00:45:21,423 epoch [414/800] time: 0.8s val loss: 0.146 accuracy: 0.9507 f1: 0.9496
2023-07-14 00:45:26,011 epoch [415/800] time: 4.59s train loss: 0.0675 accuracy: 0.98 f1: 0.9799
2023-07-14 00:45:26,857 epoch [415/800] time: 0.85s val loss: 0.1454 accuracy: 0.951 f1: 0.9498
2023-07-14 00:45:31,452 epoch [416/800] time: 4.6s train loss: 0.0663 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:45:32,297 epoch [416/800] time: 0.84s val loss: 0.1451 accuracy: 0.9506 f1: 0.9494
2023-07-14 00:45:36,976 epoch [417/800] time: 4.68s train loss: 0.0665 accuracy: 0.9802 f1: 0.9801
2023-07-14 00:45:37,781 epoch [417/800] time: 0.81s val loss: 0.1454 accuracy: 0.9503 f1: 0.9492
2023-07-14 00:45:42,544 epoch [418/800] time: 4.76s train loss: 0.0673 accuracy: 0.9803 f1: 0.9803
2023-07-14 00:45:43,396 epoch [418/800] time: 0.85s val loss: 0.1457 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:45:48,043 epoch [419/800] time: 4.65s train loss: 0.0667 accuracy: 0.9801 f1: 0.98
2023-07-14 00:45:48,902 epoch [419/800] time: 0.86s val loss: 0.1458 accuracy: 0.9503 f1: 0.9492
2023-07-14 00:45:53,920 epoch [420/800] time: 5.02s train loss: 0.0668 accuracy: 0.9808 f1: 0.9807
2023-07-14 00:45:54,784 epoch [420/800] time: 0.86s val loss: 0.146 accuracy: 0.9507 f1: 0.9496
2023-07-14 00:45:59,797 epoch [421/800] time: 5.01s train loss: 0.0667 accuracy: 0.9808 f1: 0.9806
2023-07-14 00:46:00,658 epoch [421/800] time: 0.86s val loss: 0.1451 accuracy: 0.9512 f1: 0.9501
2023-07-14 00:46:05,298 epoch [422/800] time: 4.64s train loss: 0.0652 accuracy: 0.981 f1: 0.9808
2023-07-14 00:46:06,232 epoch [422/800] time: 0.93s val loss: 0.1458 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:46:11,374 epoch [423/800] time: 5.14s train loss: 0.0667 accuracy: 0.9799 f1: 0.9799
2023-07-14 00:46:12,188 epoch [423/800] time: 0.81s val loss: 0.1462 accuracy: 0.9509 f1: 0.9498
2023-07-14 00:46:16,935 epoch [424/800] time: 4.75s train loss: 0.0661 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:46:17,789 epoch [424/800] time: 0.85s val loss: 0.1457 accuracy: 0.9505 f1: 0.9495
2023-07-14 00:46:22,491 epoch [425/800] time: 4.7s train loss: 0.0652 accuracy: 0.981 f1: 0.9809
2023-07-14 00:46:23,340 epoch [425/800] time: 0.85s val loss: 0.1451 accuracy: 0.9501 f1: 0.9491
2023-07-14 00:46:28,056 epoch [426/800] time: 4.72s train loss: 0.0662 accuracy: 0.9807 f1: 0.9805
2023-07-14 00:46:28,857 epoch [426/800] time: 0.8s val loss: 0.1459 accuracy: 0.9507 f1: 0.9497
2023-07-14 00:46:33,606 epoch [427/800] time: 4.75s train loss: 0.0659 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:46:34,450 epoch [427/800] time: 0.84s val loss: 0.1461 accuracy: 0.9508 f1: 0.9499
2023-07-14 00:46:39,213 epoch [428/800] time: 4.76s train loss: 0.068 accuracy: 0.9799 f1: 0.9798
2023-07-14 00:46:40,062 epoch [428/800] time: 0.85s val loss: 0.1474 accuracy: 0.9495 f1: 0.9483
2023-07-14 00:46:44,606 epoch [429/800] time: 4.54s train loss: 0.0664 accuracy: 0.9804 f1: 0.9802
2023-07-14 00:46:45,406 epoch [429/800] time: 0.8s val loss: 0.1458 accuracy: 0.9498 f1: 0.9487
2023-07-14 00:46:49,956 epoch [430/800] time: 4.55s train loss: 0.0668 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:46:50,802 epoch [430/800] time: 0.85s val loss: 0.1453 accuracy: 0.951 f1: 0.9499
2023-07-14 00:46:55,303 epoch [431/800] time: 4.5s train loss: 0.0656 accuracy: 0.9808 f1: 0.9807
2023-07-14 00:46:56,147 epoch [431/800] time: 0.84s val loss: 0.1456 accuracy: 0.9508 f1: 0.9498
2023-07-14 00:47:00,725 epoch [432/800] time: 4.58s train loss: 0.0672 accuracy: 0.9802 f1: 0.9801
2023-07-14 00:47:01,524 epoch [432/800] time: 0.8s val loss: 0.1461 accuracy: 0.9508 f1: 0.9497
2023-07-14 00:47:06,114 epoch [433/800] time: 4.59s train loss: 0.0666 accuracy: 0.9809 f1: 0.9807
2023-07-14 00:47:06,960 epoch [433/800] time: 0.85s val loss: 0.1468 accuracy: 0.9502 f1: 0.9491
2023-07-14 00:47:11,575 epoch [434/800] time: 4.61s train loss: 0.0671 accuracy: 0.9802 f1: 0.98
2023-07-14 00:47:12,416 epoch [434/800] time: 0.84s val loss: 0.1467 accuracy: 0.9503 f1: 0.949
2023-07-14 00:47:17,068 epoch [435/800] time: 4.65s train loss: 0.0661 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:47:17,868 epoch [435/800] time: 0.8s val loss: 0.145 accuracy: 0.9515 f1: 0.9505
2023-07-14 00:47:22,556 epoch [436/800] time: 4.69s train loss: 0.0662 accuracy: 0.9809 f1: 0.9807
2023-07-14 00:47:23,399 epoch [436/800] time: 0.84s val loss: 0.1461 accuracy: 0.9499 f1: 0.9487
2023-07-14 00:47:28,072 epoch [437/800] time: 4.67s train loss: 0.067 accuracy: 0.9805 f1: 0.9803
2023-07-14 00:47:28,915 epoch [437/800] time: 0.84s val loss: 0.1461 accuracy: 0.9505 f1: 0.9492
2023-07-14 00:47:33,628 epoch [438/800] time: 4.71s train loss: 0.0664 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:47:34,428 epoch [438/800] time: 0.8s val loss: 0.1457 accuracy: 0.9514 f1: 0.9504
2023-07-14 00:47:39,141 epoch [439/800] time: 4.71s train loss: 0.0668 accuracy: 0.9806 f1: 0.9804
2023-07-14 00:47:39,986 epoch [439/800] time: 0.84s val loss: 0.1462 accuracy: 0.9504 f1: 0.9495
2023-07-14 00:47:44,665 epoch [440/800] time: 4.68s train loss: 0.0662 accuracy: 0.9804 f1: 0.9802
2023-07-14 00:47:45,507 epoch [440/800] time: 0.84s val loss: 0.1456 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:47:50,273 epoch [441/800] time: 4.77s train loss: 0.0674 accuracy: 0.9809 f1: 0.9808
2023-07-14 00:47:51,072 epoch [441/800] time: 0.8s val loss: 0.1469 accuracy: 0.9496 f1: 0.9486
2023-07-14 00:47:55,807 epoch [442/800] time: 4.73s train loss: 0.0664 accuracy: 0.9809 f1: 0.9808
2023-07-14 00:47:56,676 epoch [442/800] time: 0.87s val loss: 0.1456 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:48:01,415 epoch [443/800] time: 4.74s train loss: 0.0664 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:48:02,269 epoch [443/800] time: 0.85s val loss: 0.1454 accuracy: 0.9509 f1: 0.9499
2023-07-14 00:48:07,050 epoch [444/800] time: 4.78s train loss: 0.0668 accuracy: 0.9803 f1: 0.9801
2023-07-14 00:48:07,855 epoch [444/800] time: 0.81s val loss: 0.1455 accuracy: 0.951 f1: 0.9499
2023-07-14 00:48:12,523 epoch [445/800] time: 4.67s train loss: 0.0674 accuracy: 0.98 f1: 0.9798
2023-07-14 00:48:13,366 epoch [445/800] time: 0.84s val loss: 0.1452 accuracy: 0.9508 f1: 0.9497
2023-07-14 00:48:17,992 epoch [446/800] time: 4.63s train loss: 0.0661 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:48:18,837 epoch [446/800] time: 0.84s val loss: 0.1458 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:48:23,488 epoch [447/800] time: 4.65s train loss: 0.0659 accuracy: 0.9809 f1: 0.9807
2023-07-14 00:48:24,287 epoch [447/800] time: 0.8s val loss: 0.1459 accuracy: 0.951 f1: 0.9501
2023-07-14 00:48:28,951 epoch [448/800] time: 4.66s train loss: 0.0662 accuracy: 0.9802 f1: 0.9801
2023-07-14 00:48:29,806 epoch [448/800] time: 0.85s val loss: 0.1463 accuracy: 0.9502 f1: 0.9491
2023-07-14 00:48:34,500 epoch [449/800] time: 4.69s train loss: 0.0692 accuracy: 0.9798 f1: 0.9798
2023-07-14 00:48:35,344 epoch [449/800] time: 0.84s val loss: 0.1465 accuracy: 0.9507 f1: 0.9497
2023-07-14 00:48:40,092 epoch [450/800] time: 4.75s train loss: 0.0667 accuracy: 0.9807 f1: 0.9807
2023-07-14 00:48:40,891 epoch [450/800] time: 0.8s val loss: 0.1469 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:48:45,658 epoch [451/800] time: 4.77s train loss: 0.0664 accuracy: 0.9804 f1: 0.9804
2023-07-14 00:48:46,502 epoch [451/800] time: 0.84s val loss: 0.1454 accuracy: 0.9504 f1: 0.949
2023-07-14 00:48:51,197 epoch [452/800] time: 4.69s train loss: 0.0665 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:48:52,041 epoch [452/800] time: 0.84s val loss: 0.1458 accuracy: 0.9508 f1: 0.9496
2023-07-14 00:48:56,586 epoch [453/800] time: 4.54s train loss: 0.069 accuracy: 0.9799 f1: 0.9798
2023-07-14 00:48:57,393 epoch [453/800] time: 0.81s val loss: 0.1474 accuracy: 0.9497 f1: 0.9485
2023-07-14 00:49:01,954 epoch [454/800] time: 4.56s train loss: 0.066 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:49:02,799 epoch [454/800] time: 0.85s val loss: 0.1461 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:49:07,361 epoch [455/800] time: 4.56s train loss: 0.0659 accuracy: 0.9808 f1: 0.9807
2023-07-14 00:49:08,205 epoch [455/800] time: 0.84s val loss: 0.1457 accuracy: 0.95 f1: 0.9489
2023-07-14 00:49:12,830 epoch [456/800] time: 4.63s train loss: 0.0673 accuracy: 0.98 f1: 0.9799
2023-07-14 00:49:13,631 epoch [456/800] time: 0.8s val loss: 0.1457 accuracy: 0.9506 f1: 0.9494
2023-07-14 00:49:18,232 epoch [457/800] time: 4.6s train loss: 0.0668 accuracy: 0.9804 f1: 0.9801
2023-07-14 00:49:19,101 epoch [457/800] time: 0.87s val loss: 0.1461 accuracy: 0.9506 f1: 0.9497
2023-07-14 00:49:23,828 epoch [458/800] time: 4.73s train loss: 0.0661 accuracy: 0.9805 f1: 0.9805
2023-07-14 00:49:24,687 epoch [458/800] time: 0.86s val loss: 0.1457 accuracy: 0.9506 f1: 0.9496
2023-07-14 00:49:29,412 epoch [459/800] time: 4.72s train loss: 0.0658 accuracy: 0.9813 f1: 0.9811
2023-07-14 00:49:30,213 epoch [459/800] time: 0.8s val loss: 0.1454 accuracy: 0.9511 f1: 0.9501
2023-07-14 00:49:35,459 epoch [460/800] time: 5.25s train loss: 0.0689 accuracy: 0.9798 f1: 0.9797
2023-07-14 00:49:36,391 epoch [460/800] time: 0.93s val loss: 0.146 accuracy: 0.9503 f1: 0.9491
2023-07-14 00:49:41,398 epoch [461/800] time: 5.01s train loss: 0.0668 accuracy: 0.9806 f1: 0.9805
2023-07-14 00:49:42,264 epoch [461/800] time: 0.87s val loss: 0.146 accuracy: 0.9501 f1: 0.9491
2023-07-14 00:49:47,304 epoch [462/800] time: 5.04s train loss: 0.0668 accuracy: 0.9806 f1: 0.9805
2023-07-14 00:49:48,218 epoch [462/800] time: 0.91s val loss: 0.1454 accuracy: 0.9504 f1: 0.9492
2023-07-14 00:49:53,431 epoch [463/800] time: 5.21s train loss: 0.0658 accuracy: 0.9804 f1: 0.9804
2023-07-14 00:49:54,317 epoch [463/800] time: 0.89s val loss: 0.1464 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:49:59,265 epoch [464/800] time: 4.95s train loss: 0.0662 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:50:00,158 epoch [464/800] time: 0.89s val loss: 0.1456 accuracy: 0.951 f1: 0.95
2023-07-14 00:50:05,486 epoch [465/800] time: 5.33s train loss: 0.0673 accuracy: 0.9803 f1: 0.9801
2023-07-14 00:50:06,376 epoch [465/800] time: 0.89s val loss: 0.1459 accuracy: 0.951 f1: 0.95
2023-07-14 00:50:11,474 epoch [466/800] time: 5.1s train loss: 0.0671 accuracy: 0.9799 f1: 0.9799
2023-07-14 00:50:12,363 epoch [466/800] time: 0.89s val loss: 0.1455 accuracy: 0.9508 f1: 0.9498
2023-07-14 00:50:17,380 epoch [467/800] time: 5.02s train loss: 0.066 accuracy: 0.9801 f1: 0.9801
2023-07-14 00:50:18,316 epoch [467/800] time: 0.94s val loss: 0.1452 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:50:23,506 epoch [468/800] time: 5.19s train loss: 0.0658 accuracy: 0.981 f1: 0.9809
2023-07-14 00:50:24,352 epoch [468/800] time: 0.84s val loss: 0.1455 accuracy: 0.9508 f1: 0.9497
2023-07-14 00:50:29,423 epoch [469/800] time: 5.07s train loss: 0.066 accuracy: 0.9808 f1: 0.9807
2023-07-14 00:50:30,324 epoch [469/800] time: 0.9s val loss: 0.1457 accuracy: 0.9506 f1: 0.9496
2023-07-14 00:50:35,290 epoch [470/800] time: 4.97s train loss: 0.0672 accuracy: 0.9806 f1: 0.9806
2023-07-14 00:50:36,190 epoch [470/800] time: 0.9s val loss: 0.1461 accuracy: 0.9506 f1: 0.9496
2023-07-14 00:50:41,318 epoch [471/800] time: 5.13s train loss: 0.0667 accuracy: 0.9803 f1: 0.9803
2023-07-14 00:50:42,161 epoch [471/800] time: 0.84s val loss: 0.1471 accuracy: 0.9502 f1: 0.9493
2023-07-14 00:50:47,224 epoch [472/800] time: 5.06s train loss: 0.0649 accuracy: 0.9811 f1: 0.9811
2023-07-14 00:50:48,087 epoch [472/800] time: 0.86s val loss: 0.1447 accuracy: 0.9508 f1: 0.9497
2023-07-14 00:50:53,112 epoch [473/800] time: 5.02s train loss: 0.0656 accuracy: 0.9814 f1: 0.9812
2023-07-14 00:50:53,982 epoch [473/800] time: 0.87s val loss: 0.1466 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:50:58,644 epoch [474/800] time: 4.66s train loss: 0.0662 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:50:59,449 epoch [474/800] time: 0.8s val loss: 0.1463 accuracy: 0.9496 f1: 0.9483
2023-07-14 00:51:04,057 epoch [475/800] time: 4.61s train loss: 0.0674 accuracy: 0.9799 f1: 0.9797
2023-07-14 00:51:04,902 epoch [475/800] time: 0.85s val loss: 0.1459 accuracy: 0.9508 f1: 0.9497
2023-07-14 00:51:09,434 epoch [476/800] time: 4.53s train loss: 0.066 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:51:10,286 epoch [476/800] time: 0.85s val loss: 0.1465 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:51:14,869 epoch [477/800] time: 4.58s train loss: 0.0661 accuracy: 0.9808 f1: 0.9806
2023-07-14 00:51:15,668 epoch [477/800] time: 0.8s val loss: 0.146 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:51:20,447 epoch [478/800] time: 4.78s train loss: 0.0659 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:51:21,301 epoch [478/800] time: 0.85s val loss: 0.1459 accuracy: 0.9509 f1: 0.9498
2023-07-14 00:51:25,808 epoch [479/800] time: 4.51s train loss: 0.0665 accuracy: 0.9801 f1: 0.98
2023-07-14 00:51:26,687 epoch [479/800] time: 0.88s val loss: 0.1464 accuracy: 0.9502 f1: 0.9491
2023-07-14 00:51:31,460 epoch [480/800] time: 4.77s train loss: 0.0655 accuracy: 0.9808 f1: 0.9806
2023-07-14 00:51:32,270 epoch [480/800] time: 0.81s val loss: 0.1473 accuracy: 0.95 f1: 0.9488
2023-07-14 00:51:36,973 epoch [481/800] time: 4.7s train loss: 0.0663 accuracy: 0.9803 f1: 0.9802
2023-07-14 00:51:37,825 epoch [481/800] time: 0.85s val loss: 0.1451 accuracy: 0.9505 f1: 0.9493
2023-07-14 00:51:42,733 epoch [482/800] time: 4.91s train loss: 0.0666 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:51:43,606 epoch [482/800] time: 0.87s val loss: 0.1459 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:51:48,438 epoch [483/800] time: 4.83s train loss: 0.0674 accuracy: 0.9798 f1: 0.9798
2023-07-14 00:51:49,246 epoch [483/800] time: 0.81s val loss: 0.1464 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:51:54,126 epoch [484/800] time: 4.88s train loss: 0.066 accuracy: 0.9806 f1: 0.9804
2023-07-14 00:51:55,005 epoch [484/800] time: 0.88s val loss: 0.1454 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:51:59,823 epoch [485/800] time: 4.82s train loss: 0.0666 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:52:00,686 epoch [485/800] time: 0.86s val loss: 0.1461 accuracy: 0.9512 f1: 0.95
2023-07-14 00:52:05,498 epoch [486/800] time: 4.81s train loss: 0.0674 accuracy: 0.9803 f1: 0.98
2023-07-14 00:52:06,315 epoch [486/800] time: 0.82s val loss: 0.1463 accuracy: 0.9502 f1: 0.949
2023-07-14 00:52:10,885 epoch [487/800] time: 4.57s train loss: 0.0671 accuracy: 0.9805 f1: 0.9805
2023-07-14 00:52:11,727 epoch [487/800] time: 0.84s val loss: 0.1457 accuracy: 0.9505 f1: 0.9495
2023-07-14 00:52:16,274 epoch [488/800] time: 4.55s train loss: 0.0676 accuracy: 0.9798 f1: 0.9797
2023-07-14 00:52:17,113 epoch [488/800] time: 0.84s val loss: 0.1453 accuracy: 0.9508 f1: 0.9498
2023-07-14 00:52:21,721 epoch [489/800] time: 4.61s train loss: 0.0662 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:52:22,519 epoch [489/800] time: 0.8s val loss: 0.1469 accuracy: 0.9501 f1: 0.9489
2023-07-14 00:52:27,161 epoch [490/800] time: 4.64s train loss: 0.0671 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:52:28,002 epoch [490/800] time: 0.84s val loss: 0.1464 accuracy: 0.9508 f1: 0.9498
2023-07-14 00:52:32,639 epoch [491/800] time: 4.64s train loss: 0.0663 accuracy: 0.9803 f1: 0.98
2023-07-14 00:52:33,479 epoch [491/800] time: 0.84s val loss: 0.1463 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:52:38,184 epoch [492/800] time: 4.7s train loss: 0.066 accuracy: 0.9801 f1: 0.9799
2023-07-14 00:52:38,981 epoch [492/800] time: 0.8s val loss: 0.1451 accuracy: 0.9513 f1: 0.9503
2023-07-14 00:52:43,721 epoch [493/800] time: 4.74s train loss: 0.0671 accuracy: 0.9809 f1: 0.9808
2023-07-14 00:52:44,561 epoch [493/800] time: 0.84s val loss: 0.1462 accuracy: 0.9507 f1: 0.9497
2023-07-14 00:52:49,206 epoch [494/800] time: 4.64s train loss: 0.0671 accuracy: 0.9801 f1: 0.9799
2023-07-14 00:52:50,046 epoch [494/800] time: 0.84s val loss: 0.1464 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:52:54,753 epoch [495/800] time: 4.71s train loss: 0.0661 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:52:55,550 epoch [495/800] time: 0.8s val loss: 0.1462 accuracy: 0.9504 f1: 0.9494
2023-07-14 00:53:00,275 epoch [496/800] time: 4.72s train loss: 0.0664 accuracy: 0.9806 f1: 0.9805
2023-07-14 00:53:01,128 epoch [496/800] time: 0.85s val loss: 0.1453 accuracy: 0.9508 f1: 0.9497
2023-07-14 00:53:05,650 epoch [497/800] time: 4.52s train loss: 0.0655 accuracy: 0.9809 f1: 0.9808
2023-07-14 00:53:06,497 epoch [497/800] time: 0.85s val loss: 0.1452 accuracy: 0.9507 f1: 0.9497
2023-07-14 00:53:11,131 epoch [498/800] time: 4.63s train loss: 0.0658 accuracy: 0.9806 f1: 0.9804
2023-07-14 00:53:11,928 epoch [498/800] time: 0.8s val loss: 0.1454 accuracy: 0.9508 f1: 0.9498
2023-07-14 00:53:16,524 epoch [499/800] time: 4.6s train loss: 0.0657 accuracy: 0.981 f1: 0.9809
2023-07-14 00:53:17,367 epoch [499/800] time: 0.84s val loss: 0.1451 accuracy: 0.951 f1: 0.9498
2023-07-14 00:53:22,036 epoch [500/800] time: 4.67s train loss: 0.067 accuracy: 0.9799 f1: 0.9798
2023-07-14 00:53:22,881 epoch [500/800] time: 0.84s val loss: 0.1455 accuracy: 0.9507 f1: 0.9496
2023-07-14 00:53:27,557 epoch [501/800] time: 4.68s train loss: 0.0682 accuracy: 0.9799 f1: 0.9799
2023-07-14 00:53:28,355 epoch [501/800] time: 0.8s val loss: 0.1463 accuracy: 0.9503 f1: 0.9493
2023-07-14 00:53:33,003 epoch [502/800] time: 4.65s train loss: 0.0661 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:53:33,845 epoch [502/800] time: 0.84s val loss: 0.1453 accuracy: 0.9507 f1: 0.9497
2023-07-14 00:53:38,696 epoch [503/800] time: 4.85s train loss: 0.0666 accuracy: 0.981 f1: 0.981
2023-07-14 00:53:39,558 epoch [503/800] time: 0.86s val loss: 0.1458 accuracy: 0.9503 f1: 0.9492
2023-07-14 00:53:44,338 epoch [504/800] time: 4.78s train loss: 0.0668 accuracy: 0.9799 f1: 0.9797
2023-07-14 00:53:45,143 epoch [504/800] time: 0.8s val loss: 0.1457 accuracy: 0.9509 f1: 0.9498
2023-07-14 00:53:49,988 epoch [505/800] time: 4.85s train loss: 0.0678 accuracy: 0.9798 f1: 0.9796
2023-07-14 00:53:50,883 epoch [505/800] time: 0.9s val loss: 0.1459 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:53:55,697 epoch [506/800] time: 4.81s train loss: 0.066 accuracy: 0.9809 f1: 0.9808
2023-07-14 00:53:56,552 epoch [506/800] time: 0.85s val loss: 0.1462 accuracy: 0.9513 f1: 0.9502
2023-07-14 00:54:01,252 epoch [507/800] time: 4.7s train loss: 0.0668 accuracy: 0.9802 f1: 0.9801
2023-07-14 00:54:02,079 epoch [507/800] time: 0.83s val loss: 0.1462 accuracy: 0.9508 f1: 0.9498
2023-07-14 00:54:07,193 epoch [508/800] time: 5.11s train loss: 0.0681 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:54:08,127 epoch [508/800] time: 0.93s val loss: 0.1455 accuracy: 0.9509 f1: 0.9498
2023-07-14 00:54:13,203 epoch [509/800] time: 5.08s train loss: 0.0679 accuracy: 0.9798 f1: 0.9797
2023-07-14 00:54:14,142 epoch [509/800] time: 0.94s val loss: 0.146 accuracy: 0.9507 f1: 0.9496
2023-07-14 00:54:19,469 epoch [510/800] time: 5.33s train loss: 0.069 accuracy: 0.98 f1: 0.9799
2023-07-14 00:54:20,332 epoch [510/800] time: 0.86s val loss: 0.1459 accuracy: 0.9509 f1: 0.9498
2023-07-14 00:54:25,553 epoch [511/800] time: 5.22s train loss: 0.0677 accuracy: 0.9802 f1: 0.9801
2023-07-14 00:54:26,466 epoch [511/800] time: 0.91s val loss: 0.1452 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:54:31,602 epoch [512/800] time: 5.14s train loss: 0.0659 accuracy: 0.9808 f1: 0.9807
2023-07-14 00:54:32,468 epoch [512/800] time: 0.87s val loss: 0.146 accuracy: 0.9504 f1: 0.9492
2023-07-14 00:54:37,530 epoch [513/800] time: 5.06s train loss: 0.0654 accuracy: 0.9808 f1: 0.9806
2023-07-14 00:54:38,364 epoch [513/800] time: 0.83s val loss: 0.1459 accuracy: 0.9501 f1: 0.9489
2023-07-14 00:54:43,289 epoch [514/800] time: 4.92s train loss: 0.067 accuracy: 0.9803 f1: 0.9803
2023-07-14 00:54:44,147 epoch [514/800] time: 0.86s val loss: 0.1464 accuracy: 0.9499 f1: 0.9487
2023-07-14 00:54:48,968 epoch [515/800] time: 4.82s train loss: 0.0668 accuracy: 0.9805 f1: 0.9803
2023-07-14 00:54:49,829 epoch [515/800] time: 0.86s val loss: 0.1458 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:54:54,598 epoch [516/800] time: 4.77s train loss: 0.0668 accuracy: 0.9799 f1: 0.9797
2023-07-14 00:54:55,421 epoch [516/800] time: 0.82s val loss: 0.1454 accuracy: 0.9507 f1: 0.9496
2023-07-14 00:55:00,419 epoch [517/800] time: 5.0s train loss: 0.0664 accuracy: 0.98 f1: 0.9797
2023-07-14 00:55:01,278 epoch [517/800] time: 0.86s val loss: 0.1457 accuracy: 0.9507 f1: 0.9496
2023-07-14 00:55:05,859 epoch [518/800] time: 4.58s train loss: 0.0647 accuracy: 0.9813 f1: 0.9812
2023-07-14 00:55:06,714 epoch [518/800] time: 0.85s val loss: 0.1459 accuracy: 0.9504 f1: 0.9494
2023-07-14 00:55:11,485 epoch [519/800] time: 4.77s train loss: 0.0664 accuracy: 0.9806 f1: 0.9804
2023-07-14 00:55:12,309 epoch [519/800] time: 0.82s val loss: 0.1465 accuracy: 0.9508 f1: 0.9497
2023-07-14 00:55:17,190 epoch [520/800] time: 4.88s train loss: 0.0664 accuracy: 0.9802 f1: 0.9802
2023-07-14 00:55:18,042 epoch [520/800] time: 0.85s val loss: 0.1452 accuracy: 0.9504 f1: 0.9492
2023-07-14 00:55:22,770 epoch [521/800] time: 4.73s train loss: 0.0647 accuracy: 0.9809 f1: 0.9808
2023-07-14 00:55:23,627 epoch [521/800] time: 0.86s val loss: 0.1449 accuracy: 0.9513 f1: 0.9503
2023-07-14 00:55:28,519 epoch [522/800] time: 4.89s train loss: 0.0664 accuracy: 0.9802 f1: 0.9801
2023-07-14 00:55:29,344 epoch [522/800] time: 0.82s val loss: 0.1452 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:55:34,204 epoch [523/800] time: 4.86s train loss: 0.0659 accuracy: 0.9809 f1: 0.9808
2023-07-14 00:55:35,061 epoch [523/800] time: 0.86s val loss: 0.146 accuracy: 0.9509 f1: 0.9498
2023-07-14 00:55:39,830 epoch [524/800] time: 4.77s train loss: 0.0667 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:55:40,692 epoch [524/800] time: 0.86s val loss: 0.1457 accuracy: 0.9507 f1: 0.9497
2023-07-14 00:55:45,743 epoch [525/800] time: 5.05s train loss: 0.0656 accuracy: 0.9809 f1: 0.9809
2023-07-14 00:55:46,586 epoch [525/800] time: 0.84s val loss: 0.1456 accuracy: 0.9505 f1: 0.9493
2023-07-14 00:55:51,745 epoch [526/800] time: 5.16s train loss: 0.0659 accuracy: 0.9802 f1: 0.9801
2023-07-14 00:55:52,686 epoch [526/800] time: 0.94s val loss: 0.1457 accuracy: 0.9509 f1: 0.9498
2023-07-14 00:55:57,801 epoch [527/800] time: 5.12s train loss: 0.0675 accuracy: 0.9801 f1: 0.98
2023-07-14 00:55:59,001 epoch [527/800] time: 1.2s val loss: 0.1467 accuracy: 0.9508 f1: 0.9499
2023-07-14 00:56:04,303 epoch [528/800] time: 5.3s train loss: 0.066 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:56:05,145 epoch [528/800] time: 0.84s val loss: 0.1454 accuracy: 0.9514 f1: 0.9503
2023-07-14 00:56:10,563 epoch [529/800] time: 5.42s train loss: 0.0666 accuracy: 0.9803 f1: 0.9803
2023-07-14 00:56:11,510 epoch [529/800] time: 0.95s val loss: 0.1453 accuracy: 0.9509 f1: 0.9499
2023-07-14 00:56:16,657 epoch [530/800] time: 5.15s train loss: 0.0668 accuracy: 0.9801 f1: 0.98
2023-07-14 00:56:17,541 epoch [530/800] time: 0.88s val loss: 0.1462 accuracy: 0.951 f1: 0.9499
2023-07-14 00:56:22,601 epoch [531/800] time: 5.06s train loss: 0.0675 accuracy: 0.9802 f1: 0.98
2023-07-14 00:56:23,420 epoch [531/800] time: 0.82s val loss: 0.1458 accuracy: 0.9512 f1: 0.95
2023-07-14 00:56:28,341 epoch [532/800] time: 4.92s train loss: 0.0666 accuracy: 0.9798 f1: 0.9797
2023-07-14 00:56:29,213 epoch [532/800] time: 0.87s val loss: 0.1454 accuracy: 0.9504 f1: 0.9495
2023-07-14 00:56:34,034 epoch [533/800] time: 4.82s train loss: 0.0659 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:56:34,936 epoch [533/800] time: 0.9s val loss: 0.1462 accuracy: 0.9497 f1: 0.9485
2023-07-14 00:56:39,805 epoch [534/800] time: 4.87s train loss: 0.0663 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:56:40,613 epoch [534/800] time: 0.81s val loss: 0.146 accuracy: 0.9505 f1: 0.9493
2023-07-14 00:56:45,449 epoch [535/800] time: 4.84s train loss: 0.0656 accuracy: 0.98 f1: 0.9799
2023-07-14 00:56:46,305 epoch [535/800] time: 0.86s val loss: 0.1453 accuracy: 0.9508 f1: 0.9498
2023-07-14 00:56:51,083 epoch [536/800] time: 4.78s train loss: 0.0661 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:56:51,935 epoch [536/800] time: 0.85s val loss: 0.1463 accuracy: 0.9503 f1: 0.9494
2023-07-14 00:56:56,631 epoch [537/800] time: 4.7s train loss: 0.0671 accuracy: 0.9806 f1: 0.9806
2023-07-14 00:56:57,444 epoch [537/800] time: 0.81s val loss: 0.1459 accuracy: 0.9505 f1: 0.9495
2023-07-14 00:57:02,139 epoch [538/800] time: 4.7s train loss: 0.0661 accuracy: 0.981 f1: 0.9809
2023-07-14 00:57:02,996 epoch [538/800] time: 0.86s val loss: 0.1461 accuracy: 0.9497 f1: 0.9484
2023-07-14 00:57:07,702 epoch [539/800] time: 4.71s train loss: 0.0658 accuracy: 0.9809 f1: 0.9807
2023-07-14 00:57:08,554 epoch [539/800] time: 0.85s val loss: 0.146 accuracy: 0.95 f1: 0.949
2023-07-14 00:57:13,344 epoch [540/800] time: 4.79s train loss: 0.0654 accuracy: 0.9808 f1: 0.9806
2023-07-14 00:57:14,148 epoch [540/800] time: 0.8s val loss: 0.1451 accuracy: 0.9509 f1: 0.9497
2023-07-14 00:57:18,935 epoch [541/800] time: 4.79s train loss: 0.0666 accuracy: 0.9808 f1: 0.9806
2023-07-14 00:57:19,785 epoch [541/800] time: 0.85s val loss: 0.1464 accuracy: 0.9502 f1: 0.9491
2023-07-14 00:57:24,537 epoch [542/800] time: 4.75s train loss: 0.0648 accuracy: 0.9807 f1: 0.9806
2023-07-14 00:57:25,380 epoch [542/800] time: 0.84s val loss: 0.1457 accuracy: 0.9505 f1: 0.9495
2023-07-14 00:57:30,047 epoch [543/800] time: 4.67s train loss: 0.0682 accuracy: 0.9799 f1: 0.9797
2023-07-14 00:57:30,850 epoch [543/800] time: 0.8s val loss: 0.1459 accuracy: 0.9505 f1: 0.9495
2023-07-14 00:57:35,524 epoch [544/800] time: 4.67s train loss: 0.0661 accuracy: 0.9801 f1: 0.98
2023-07-14 00:57:36,376 epoch [544/800] time: 0.85s val loss: 0.1455 accuracy: 0.9515 f1: 0.9503
2023-07-14 00:57:41,077 epoch [545/800] time: 4.7s train loss: 0.0671 accuracy: 0.9805 f1: 0.9803
2023-07-14 00:57:41,920 epoch [545/800] time: 0.84s val loss: 0.1452 accuracy: 0.9508 f1: 0.9497
2023-07-14 00:57:46,486 epoch [546/800] time: 4.57s train loss: 0.0671 accuracy: 0.9804 f1: 0.9802
2023-07-14 00:57:47,288 epoch [546/800] time: 0.8s val loss: 0.1477 accuracy: 0.9495 f1: 0.9483
2023-07-14 00:57:51,824 epoch [547/800] time: 4.54s train loss: 0.0692 accuracy: 0.9808 f1: 0.9808
2023-07-14 00:57:52,678 epoch [547/800] time: 0.85s val loss: 0.1459 accuracy: 0.9503 f1: 0.9493
2023-07-14 00:57:57,216 epoch [548/800] time: 4.54s train loss: 0.0655 accuracy: 0.981 f1: 0.981
2023-07-14 00:57:58,060 epoch [548/800] time: 0.84s val loss: 0.1457 accuracy: 0.9503 f1: 0.9492
2023-07-14 00:58:02,586 epoch [549/800] time: 4.53s train loss: 0.0672 accuracy: 0.9802 f1: 0.9802
2023-07-14 00:58:03,389 epoch [549/800] time: 0.8s val loss: 0.1461 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:58:08,067 epoch [550/800] time: 4.68s train loss: 0.0668 accuracy: 0.9798 f1: 0.9796
2023-07-14 00:58:08,911 epoch [550/800] time: 0.84s val loss: 0.1452 accuracy: 0.951 f1: 0.9499
2023-07-14 00:58:13,549 epoch [551/800] time: 4.64s train loss: 0.0658 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:58:14,392 epoch [551/800] time: 0.84s val loss: 0.1456 accuracy: 0.9512 f1: 0.9502
2023-07-14 00:58:18,944 epoch [552/800] time: 4.55s train loss: 0.0666 accuracy: 0.9799 f1: 0.9798
2023-07-14 00:58:19,750 epoch [552/800] time: 0.81s val loss: 0.1461 accuracy: 0.9503 f1: 0.9492
2023-07-14 00:58:24,321 epoch [553/800] time: 4.57s train loss: 0.0662 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:58:25,165 epoch [553/800] time: 0.84s val loss: 0.1453 accuracy: 0.9512 f1: 0.9501
2023-07-14 00:58:29,665 epoch [554/800] time: 4.5s train loss: 0.0689 accuracy: 0.9802 f1: 0.98
2023-07-14 00:58:30,520 epoch [554/800] time: 0.85s val loss: 0.1461 accuracy: 0.951 f1: 0.9499
2023-07-14 00:58:35,196 epoch [555/800] time: 4.68s train loss: 0.0671 accuracy: 0.9804 f1: 0.9802
2023-07-14 00:58:35,997 epoch [555/800] time: 0.8s val loss: 0.1451 accuracy: 0.9509 f1: 0.9499
2023-07-14 00:58:40,499 epoch [556/800] time: 4.5s train loss: 0.0666 accuracy: 0.9808 f1: 0.9806
2023-07-14 00:58:41,343 epoch [556/800] time: 0.84s val loss: 0.1462 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:58:45,810 epoch [557/800] time: 4.47s train loss: 0.066 accuracy: 0.9808 f1: 0.9806
2023-07-14 00:58:46,655 epoch [557/800] time: 0.84s val loss: 0.1456 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:58:51,154 epoch [558/800] time: 4.5s train loss: 0.0663 accuracy: 0.9804 f1: 0.9802
2023-07-14 00:58:51,956 epoch [558/800] time: 0.8s val loss: 0.1464 accuracy: 0.9497 f1: 0.9486
2023-07-14 00:58:56,626 epoch [559/800] time: 4.67s train loss: 0.0648 accuracy: 0.9811 f1: 0.9811
2023-07-14 00:58:57,471 epoch [559/800] time: 0.84s val loss: 0.1452 accuracy: 0.9509 f1: 0.9499
2023-07-14 00:59:01,930 epoch [560/800] time: 4.46s train loss: 0.0667 accuracy: 0.9804 f1: 0.9802
2023-07-14 00:59:02,778 epoch [560/800] time: 0.85s val loss: 0.1462 accuracy: 0.9504 f1: 0.9494
2023-07-14 00:59:07,278 epoch [561/800] time: 4.5s train loss: 0.0659 accuracy: 0.9806 f1: 0.9805
2023-07-14 00:59:08,078 epoch [561/800] time: 0.8s val loss: 0.1454 accuracy: 0.9504 f1: 0.9493
2023-07-14 00:59:12,586 epoch [562/800] time: 4.51s train loss: 0.067 accuracy: 0.9807 f1: 0.9805
2023-07-14 00:59:13,430 epoch [562/800] time: 0.84s val loss: 0.1467 accuracy: 0.9505 f1: 0.9496
2023-07-14 00:59:17,916 epoch [563/800] time: 4.49s train loss: 0.0659 accuracy: 0.9804 f1: 0.9803
2023-07-14 00:59:18,761 epoch [563/800] time: 0.85s val loss: 0.1456 accuracy: 0.9512 f1: 0.9501
2023-07-14 00:59:23,512 epoch [564/800] time: 4.75s train loss: 0.0676 accuracy: 0.9805 f1: 0.9804
2023-07-14 00:59:24,311 epoch [564/800] time: 0.8s val loss: 0.1457 accuracy: 0.951 f1: 0.9498
2023-07-14 00:59:29,097 epoch [565/800] time: 4.79s train loss: 0.0664 accuracy: 0.9801 f1: 0.98
2023-07-14 00:59:29,947 epoch [565/800] time: 0.85s val loss: 0.1451 accuracy: 0.9506 f1: 0.9495
2023-07-14 00:59:34,705 epoch [566/800] time: 4.76s train loss: 0.0659 accuracy: 0.9809 f1: 0.9809
2023-07-14 00:59:35,550 epoch [566/800] time: 0.84s val loss: 0.1466 accuracy: 0.9505 f1: 0.9494
2023-07-14 00:59:40,289 epoch [567/800] time: 4.74s train loss: 0.0654 accuracy: 0.981 f1: 0.9808
2023-07-14 00:59:41,091 epoch [567/800] time: 0.8s val loss: 0.1452 accuracy: 0.9508 f1: 0.9498
2023-07-14 00:59:45,881 epoch [568/800] time: 4.79s train loss: 0.0676 accuracy: 0.9808 f1: 0.9806
2023-07-14 00:59:46,728 epoch [568/800] time: 0.85s val loss: 0.1469 accuracy: 0.9495 f1: 0.9483
2023-07-14 00:59:51,475 epoch [569/800] time: 4.75s train loss: 0.0655 accuracy: 0.9809 f1: 0.9808
2023-07-14 00:59:52,320 epoch [569/800] time: 0.84s val loss: 0.1464 accuracy: 0.9509 f1: 0.9498
2023-07-14 00:59:57,075 epoch [570/800] time: 4.76s train loss: 0.0668 accuracy: 0.9803 f1: 0.9802
2023-07-14 00:59:57,875 epoch [570/800] time: 0.8s val loss: 0.1461 accuracy: 0.9506 f1: 0.9496
2023-07-14 01:00:02,594 epoch [571/800] time: 4.72s train loss: 0.0655 accuracy: 0.9808 f1: 0.9808
2023-07-14 01:00:03,437 epoch [571/800] time: 0.84s val loss: 0.1453 accuracy: 0.9505 f1: 0.9494
2023-07-14 01:00:08,151 epoch [572/800] time: 4.71s train loss: 0.0661 accuracy: 0.9807 f1: 0.9806
2023-07-14 01:00:08,993 epoch [572/800] time: 0.84s val loss: 0.1452 accuracy: 0.9512 f1: 0.95
2023-07-14 01:00:13,645 epoch [573/800] time: 4.65s train loss: 0.0676 accuracy: 0.9807 f1: 0.9807
2023-07-14 01:00:14,448 epoch [573/800] time: 0.8s val loss: 0.1456 accuracy: 0.9504 f1: 0.9493
2023-07-14 01:00:19,216 epoch [574/800] time: 4.77s train loss: 0.0667 accuracy: 0.9804 f1: 0.9804
2023-07-14 01:00:20,058 epoch [574/800] time: 0.84s val loss: 0.1478 accuracy: 0.9499 f1: 0.9488
2023-07-14 01:00:24,808 epoch [575/800] time: 4.75s train loss: 0.067 accuracy: 0.9803 f1: 0.9802
2023-07-14 01:00:25,652 epoch [575/800] time: 0.84s val loss: 0.1455 accuracy: 0.9502 f1: 0.949
2023-07-14 01:00:30,447 epoch [576/800] time: 4.79s train loss: 0.0674 accuracy: 0.9802 f1: 0.9801
2023-07-14 01:00:31,374 epoch [576/800] time: 0.93s val loss: 0.1455 accuracy: 0.9505 f1: 0.9494
2023-07-14 01:00:35,980 epoch [577/800] time: 4.61s train loss: 0.0668 accuracy: 0.9802 f1: 0.9801
2023-07-14 01:00:36,840 epoch [577/800] time: 0.86s val loss: 0.1459 accuracy: 0.9505 f1: 0.9496
2023-07-14 01:00:41,369 epoch [578/800] time: 4.53s train loss: 0.0667 accuracy: 0.98 f1: 0.9799
2023-07-14 01:00:42,213 epoch [578/800] time: 0.84s val loss: 0.1454 accuracy: 0.9511 f1: 0.95
2023-07-14 01:00:46,779 epoch [579/800] time: 4.57s train loss: 0.0664 accuracy: 0.9804 f1: 0.9803
2023-07-14 01:00:47,580 epoch [579/800] time: 0.8s val loss: 0.1459 accuracy: 0.9507 f1: 0.9498
2023-07-14 01:00:52,148 epoch [580/800] time: 4.57s train loss: 0.0666 accuracy: 0.9809 f1: 0.9808
2023-07-14 01:00:52,996 epoch [580/800] time: 0.85s val loss: 0.1461 accuracy: 0.9507 f1: 0.9497
2023-07-14 01:00:57,532 epoch [581/800] time: 4.54s train loss: 0.0654 accuracy: 0.9816 f1: 0.9814
2023-07-14 01:00:58,390 epoch [581/800] time: 0.85s val loss: 0.1466 accuracy: 0.9505 f1: 0.9493
2023-07-14 01:01:02,981 epoch [582/800] time: 4.59s train loss: 0.0655 accuracy: 0.9805 f1: 0.9804
2023-07-14 01:01:03,795 epoch [582/800] time: 0.81s val loss: 0.1453 accuracy: 0.9506 f1: 0.9495
2023-07-14 01:01:08,451 epoch [583/800] time: 4.66s train loss: 0.0665 accuracy: 0.9803 f1: 0.9802
2023-07-14 01:01:09,302 epoch [583/800] time: 0.85s val loss: 0.1453 accuracy: 0.9506 f1: 0.9494
2023-07-14 01:01:13,892 epoch [584/800] time: 4.59s train loss: 0.066 accuracy: 0.9802 f1: 0.98
2023-07-14 01:01:14,763 epoch [584/800] time: 0.87s val loss: 0.1454 accuracy: 0.9502 f1: 0.949
2023-07-14 01:01:19,447 epoch [585/800] time: 4.68s train loss: 0.0665 accuracy: 0.9806 f1: 0.9804
2023-07-14 01:01:20,269 epoch [585/800] time: 0.82s val loss: 0.1457 accuracy: 0.9506 f1: 0.9496
2023-07-14 01:01:25,193 epoch [586/800] time: 4.92s train loss: 0.0663 accuracy: 0.9805 f1: 0.9803
2023-07-14 01:01:26,060 epoch [586/800] time: 0.87s val loss: 0.1455 accuracy: 0.9505 f1: 0.9495
2023-07-14 01:01:30,915 epoch [587/800] time: 4.85s train loss: 0.0677 accuracy: 0.9793 f1: 0.9792
2023-07-14 01:01:31,771 epoch [587/800] time: 0.86s val loss: 0.1474 accuracy: 0.9503 f1: 0.9492
2023-07-14 01:01:36,794 epoch [588/800] time: 5.02s train loss: 0.0678 accuracy: 0.9797 f1: 0.9796
2023-07-14 01:01:37,626 epoch [588/800] time: 0.83s val loss: 0.1451 accuracy: 0.9505 f1: 0.9493
2023-07-14 01:01:42,512 epoch [589/800] time: 4.89s train loss: 0.0657 accuracy: 0.9809 f1: 0.981
2023-07-14 01:01:43,374 epoch [589/800] time: 0.86s val loss: 0.1458 accuracy: 0.9504 f1: 0.9492
2023-07-14 01:01:48,248 epoch [590/800] time: 4.87s train loss: 0.0669 accuracy: 0.9805 f1: 0.9804
2023-07-14 01:01:49,146 epoch [590/800] time: 0.9s val loss: 0.1463 accuracy: 0.9508 f1: 0.9498
2023-07-14 01:01:54,099 epoch [591/800] time: 4.95s train loss: 0.0661 accuracy: 0.9808 f1: 0.9808
2023-07-14 01:01:54,905 epoch [591/800] time: 0.81s val loss: 0.1457 accuracy: 0.9505 f1: 0.9494
2023-07-14 01:01:59,883 epoch [592/800] time: 4.98s train loss: 0.0662 accuracy: 0.9805 f1: 0.9803
2023-07-14 01:02:00,752 epoch [592/800] time: 0.87s val loss: 0.1454 accuracy: 0.9508 f1: 0.9497
2023-07-14 01:02:05,541 epoch [593/800] time: 4.79s train loss: 0.0663 accuracy: 0.9805 f1: 0.9803
2023-07-14 01:02:06,392 epoch [593/800] time: 0.85s val loss: 0.1461 accuracy: 0.9501 f1: 0.949
2023-07-14 01:02:11,467 epoch [594/800] time: 5.08s train loss: 0.0682 accuracy: 0.9796 f1: 0.9794
2023-07-14 01:02:12,329 epoch [594/800] time: 0.86s val loss: 0.1455 accuracy: 0.951 f1: 0.9499
2023-07-14 01:02:17,324 epoch [595/800] time: 5.0s train loss: 0.0664 accuracy: 0.9806 f1: 0.9805
2023-07-14 01:02:18,194 epoch [595/800] time: 0.87s val loss: 0.1468 accuracy: 0.9505 f1: 0.9494
2023-07-14 01:02:23,142 epoch [596/800] time: 4.95s train loss: 0.0663 accuracy: 0.981 f1: 0.9809
2023-07-14 01:02:24,029 epoch [596/800] time: 0.89s val loss: 0.1458 accuracy: 0.9504 f1: 0.9494
2023-07-14 01:02:28,997 epoch [597/800] time: 4.97s train loss: 0.0655 accuracy: 0.981 f1: 0.981
2023-07-14 01:02:29,802 epoch [597/800] time: 0.8s val loss: 0.1453 accuracy: 0.9501 f1: 0.949
2023-07-14 01:02:34,593 epoch [598/800] time: 4.79s train loss: 0.067 accuracy: 0.9803 f1: 0.9802
2023-07-14 01:02:35,459 epoch [598/800] time: 0.87s val loss: 0.1459 accuracy: 0.9502 f1: 0.9492
2023-07-14 01:02:40,258 epoch [599/800] time: 4.8s train loss: 0.0661 accuracy: 0.9808 f1: 0.9806
2023-07-14 01:02:41,116 epoch [599/800] time: 0.86s val loss: 0.1463 accuracy: 0.95 f1: 0.9489
2023-07-14 01:02:45,767 epoch [600/800] time: 4.65s train loss: 0.0682 accuracy: 0.9796 f1: 0.9795
2023-07-14 01:02:46,577 epoch [600/800] time: 0.81s val loss: 0.1466 accuracy: 0.9508 f1: 0.9499
2023-07-14 01:02:51,179 epoch [601/800] time: 4.6s train loss: 0.0674 accuracy: 0.9798 f1: 0.9798
2023-07-14 01:02:52,032 epoch [601/800] time: 0.85s val loss: 0.1462 accuracy: 0.9508 f1: 0.9498
2023-07-14 01:02:56,595 epoch [602/800] time: 4.56s train loss: 0.0668 accuracy: 0.9806 f1: 0.9805
2023-07-14 01:02:57,455 epoch [602/800] time: 0.86s val loss: 0.1461 accuracy: 0.95 f1: 0.9487
2023-07-14 01:03:02,096 epoch [603/800] time: 4.64s train loss: 0.0675 accuracy: 0.9801 f1: 0.98
2023-07-14 01:03:02,902 epoch [603/800] time: 0.81s val loss: 0.1468 accuracy: 0.9503 f1: 0.9491
2023-07-14 01:03:07,551 epoch [604/800] time: 4.65s train loss: 0.0665 accuracy: 0.9805 f1: 0.9804
2023-07-14 01:03:08,395 epoch [604/800] time: 0.84s val loss: 0.1466 accuracy: 0.9505 f1: 0.9493
2023-07-14 01:03:13,036 epoch [605/800] time: 4.64s train loss: 0.066 accuracy: 0.9809 f1: 0.9808
2023-07-14 01:03:13,891 epoch [605/800] time: 0.86s val loss: 0.1458 accuracy: 0.9512 f1: 0.95
2023-07-14 01:03:18,629 epoch [606/800] time: 4.74s train loss: 0.0656 accuracy: 0.9807 f1: 0.9807
2023-07-14 01:03:19,457 epoch [606/800] time: 0.83s val loss: 0.1458 accuracy: 0.951 f1: 0.9499
2023-07-14 01:03:24,156 epoch [607/800] time: 4.7s train loss: 0.0668 accuracy: 0.9801 f1: 0.9799
2023-07-14 01:03:25,007 epoch [607/800] time: 0.85s val loss: 0.1458 accuracy: 0.9507 f1: 0.9496
2023-07-14 01:03:29,843 epoch [608/800] time: 4.84s train loss: 0.067 accuracy: 0.9805 f1: 0.9804
2023-07-14 01:03:30,727 epoch [608/800] time: 0.88s val loss: 0.1459 accuracy: 0.9506 f1: 0.9494
2023-07-14 01:03:35,639 epoch [609/800] time: 4.91s train loss: 0.0666 accuracy: 0.9807 f1: 0.9805
2023-07-14 01:03:36,455 epoch [609/800] time: 0.82s val loss: 0.1451 accuracy: 0.9509 f1: 0.9498
2023-07-14 01:03:41,130 epoch [610/800] time: 4.67s train loss: 0.0666 accuracy: 0.9805 f1: 0.9803
2023-07-14 01:03:42,042 epoch [610/800] time: 0.91s val loss: 0.1457 accuracy: 0.9506 f1: 0.9496
2023-07-14 01:03:46,813 epoch [611/800] time: 4.77s train loss: 0.0662 accuracy: 0.9805 f1: 0.9802
2023-07-14 01:03:47,668 epoch [611/800] time: 0.85s val loss: 0.1459 accuracy: 0.9505 f1: 0.9494
2023-07-14 01:03:52,356 epoch [612/800] time: 4.69s train loss: 0.0658 accuracy: 0.9808 f1: 0.9806
2023-07-14 01:03:53,161 epoch [612/800] time: 0.8s val loss: 0.1457 accuracy: 0.9509 f1: 0.95
2023-07-14 01:03:57,864 epoch [613/800] time: 4.7s train loss: 0.0665 accuracy: 0.9806 f1: 0.9806
2023-07-14 01:03:58,725 epoch [613/800] time: 0.86s val loss: 0.1462 accuracy: 0.9503 f1: 0.9491
2023-07-14 01:04:04,058 epoch [614/800] time: 5.33s train loss: 0.0654 accuracy: 0.9808 f1: 0.9808
2023-07-14 01:04:05,079 epoch [614/800] time: 1.02s val loss: 0.1455 accuracy: 0.9502 f1: 0.949
2023-07-14 01:04:10,443 epoch [615/800] time: 5.36s train loss: 0.0673 accuracy: 0.9802 f1: 0.98
2023-07-14 01:04:11,252 epoch [615/800] time: 0.81s val loss: 0.1461 accuracy: 0.9503 f1: 0.9493
2023-07-14 01:04:16,174 epoch [616/800] time: 4.92s train loss: 0.0667 accuracy: 0.9806 f1: 0.9806
2023-07-14 01:04:17,034 epoch [616/800] time: 0.86s val loss: 0.148 accuracy: 0.9501 f1: 0.949
2023-07-14 01:04:21,619 epoch [617/800] time: 4.59s train loss: 0.0679 accuracy: 0.9805 f1: 0.9804
2023-07-14 01:04:22,487 epoch [617/800] time: 0.87s val loss: 0.1456 accuracy: 0.9502 f1: 0.9491
2023-07-14 01:04:27,056 epoch [618/800] time: 4.57s train loss: 0.0683 accuracy: 0.9802 f1: 0.9801
2023-07-14 01:04:27,855 epoch [618/800] time: 0.8s val loss: 0.1474 accuracy: 0.9497 f1: 0.9488
2023-07-14 01:04:32,430 epoch [619/800] time: 4.58s train loss: 0.0663 accuracy: 0.9804 f1: 0.9802
2023-07-14 01:04:33,296 epoch [619/800] time: 0.87s val loss: 0.1455 accuracy: 0.9503 f1: 0.9492
2023-07-14 01:04:37,849 epoch [620/800] time: 4.55s train loss: 0.0668 accuracy: 0.9806 f1: 0.9804
2023-07-14 01:04:38,716 epoch [620/800] time: 0.87s val loss: 0.1459 accuracy: 0.9495 f1: 0.9483
2023-07-14 01:04:43,661 epoch [621/800] time: 4.95s train loss: 0.0663 accuracy: 0.9806 f1: 0.9804
2023-07-14 01:04:44,483 epoch [621/800] time: 0.82s val loss: 0.1453 accuracy: 0.9507 f1: 0.9495
2023-07-14 01:04:49,178 epoch [622/800] time: 4.7s train loss: 0.0661 accuracy: 0.9807 f1: 0.9805
2023-07-14 01:04:50,030 epoch [622/800] time: 0.85s val loss: 0.1454 accuracy: 0.9508 f1: 0.9499
2023-07-14 01:04:54,815 epoch [623/800] time: 4.78s train loss: 0.0666 accuracy: 0.9808 f1: 0.9807
2023-07-14 01:04:55,663 epoch [623/800] time: 0.85s val loss: 0.1466 accuracy: 0.9499 f1: 0.9488
2023-07-14 01:05:00,228 epoch [624/800] time: 4.56s train loss: 0.0652 accuracy: 0.9802 f1: 0.9801
2023-07-14 01:05:01,038 epoch [624/800] time: 0.81s val loss: 0.1461 accuracy: 0.9506 f1: 0.9494
2023-07-14 01:05:05,622 epoch [625/800] time: 4.58s train loss: 0.0652 accuracy: 0.9809 f1: 0.9807
2023-07-14 01:05:06,474 epoch [625/800] time: 0.85s val loss: 0.1454 accuracy: 0.9508 f1: 0.9498
2023-07-14 01:05:11,095 epoch [626/800] time: 4.62s train loss: 0.0665 accuracy: 0.9801 f1: 0.98
2023-07-14 01:05:11,949 epoch [626/800] time: 0.85s val loss: 0.1456 accuracy: 0.9508 f1: 0.9498
2023-07-14 01:05:16,706 epoch [627/800] time: 4.76s train loss: 0.0664 accuracy: 0.98 f1: 0.9799
2023-07-14 01:05:17,509 epoch [627/800] time: 0.8s val loss: 0.1453 accuracy: 0.9506 f1: 0.9496
2023-07-14 01:05:22,334 epoch [628/800] time: 4.82s train loss: 0.0671 accuracy: 0.9797 f1: 0.9796
2023-07-14 01:05:23,189 epoch [628/800] time: 0.85s val loss: 0.1453 accuracy: 0.9509 f1: 0.9498
2023-07-14 01:05:27,946 epoch [629/800] time: 4.76s train loss: 0.066 accuracy: 0.9805 f1: 0.9803
2023-07-14 01:05:28,804 epoch [629/800] time: 0.86s val loss: 0.1452 accuracy: 0.9509 f1: 0.9498
2023-07-14 01:05:33,621 epoch [630/800] time: 4.82s train loss: 0.066 accuracy: 0.9809 f1: 0.9808
2023-07-14 01:05:34,426 epoch [630/800] time: 0.8s val loss: 0.1456 accuracy: 0.9502 f1: 0.9491
2023-07-14 01:05:39,277 epoch [631/800] time: 4.85s train loss: 0.0657 accuracy: 0.9811 f1: 0.9808
2023-07-14 01:05:40,130 epoch [631/800] time: 0.85s val loss: 0.1466 accuracy: 0.9501 f1: 0.949
2023-07-14 01:05:44,926 epoch [632/800] time: 4.8s train loss: 0.0661 accuracy: 0.9808 f1: 0.9806
2023-07-14 01:05:45,786 epoch [632/800] time: 0.86s val loss: 0.1453 accuracy: 0.9512 f1: 0.9501
2023-07-14 01:05:50,510 epoch [633/800] time: 4.72s train loss: 0.0656 accuracy: 0.9805 f1: 0.9804
2023-07-14 01:05:51,315 epoch [633/800] time: 0.8s val loss: 0.1463 accuracy: 0.9506 f1: 0.9494
2023-07-14 01:05:56,121 epoch [634/800] time: 4.81s train loss: 0.0656 accuracy: 0.9811 f1: 0.981
2023-07-14 01:05:56,966 epoch [634/800] time: 0.84s val loss: 0.1454 accuracy: 0.9506 f1: 0.9495
2023-07-14 01:06:01,719 epoch [635/800] time: 4.75s train loss: 0.0652 accuracy: 0.9806 f1: 0.9805
2023-07-14 01:06:02,564 epoch [635/800] time: 0.85s val loss: 0.1463 accuracy: 0.9505 f1: 0.9495
2023-07-14 01:06:07,310 epoch [636/800] time: 4.75s train loss: 0.0665 accuracy: 0.9803 f1: 0.9802
2023-07-14 01:06:08,111 epoch [636/800] time: 0.8s val loss: 0.1459 accuracy: 0.9506 f1: 0.9496
2023-07-14 01:06:12,894 epoch [637/800] time: 4.78s train loss: 0.0662 accuracy: 0.9806 f1: 0.9805
2023-07-14 01:06:13,740 epoch [637/800] time: 0.85s val loss: 0.1459 accuracy: 0.9506 f1: 0.9495
2023-07-14 01:06:18,467 epoch [638/800] time: 4.73s train loss: 0.0664 accuracy: 0.9811 f1: 0.981
2023-07-14 01:06:19,311 epoch [638/800] time: 0.84s val loss: 0.1461 accuracy: 0.9508 f1: 0.9498
2023-07-14 01:06:24,172 epoch [639/800] time: 4.86s train loss: 0.067 accuracy: 0.9799 f1: 0.9798
2023-07-14 01:06:24,977 epoch [639/800] time: 0.8s val loss: 0.1465 accuracy: 0.9504 f1: 0.9493
2023-07-14 01:06:29,879 epoch [640/800] time: 4.9s train loss: 0.0674 accuracy: 0.9803 f1: 0.9802
2023-07-14 01:06:30,800 epoch [640/800] time: 0.92s val loss: 0.1455 accuracy: 0.9503 f1: 0.9492
2023-07-14 01:06:35,817 epoch [641/800] time: 5.02s train loss: 0.0651 accuracy: 0.9813 f1: 0.9811
2023-07-14 01:06:36,674 epoch [641/800] time: 0.86s val loss: 0.1453 accuracy: 0.9513 f1: 0.9503
2023-07-14 01:06:41,624 epoch [642/800] time: 4.95s train loss: 0.0673 accuracy: 0.9808 f1: 0.9807
2023-07-14 01:06:42,477 epoch [642/800] time: 0.85s val loss: 0.1462 accuracy: 0.9501 f1: 0.9489
2023-07-14 01:06:47,583 epoch [643/800] time: 5.11s train loss: 0.0654 accuracy: 0.9811 f1: 0.9809
2023-07-14 01:06:48,517 epoch [643/800] time: 0.93s val loss: 0.1454 accuracy: 0.9505 f1: 0.9494
2023-07-14 01:06:53,703 epoch [644/800] time: 5.19s train loss: 0.066 accuracy: 0.9806 f1: 0.9805
2023-07-14 01:06:54,609 epoch [644/800] time: 0.91s val loss: 0.1456 accuracy: 0.9507 f1: 0.9495
2023-07-14 01:06:59,799 epoch [645/800] time: 5.19s train loss: 0.0664 accuracy: 0.9806 f1: 0.9804
2023-07-14 01:07:00,694 epoch [645/800] time: 0.89s val loss: 0.1452 accuracy: 0.9505 f1: 0.9495
2023-07-14 01:07:05,768 epoch [646/800] time: 5.07s train loss: 0.0666 accuracy: 0.9807 f1: 0.9806
2023-07-14 01:07:06,632 epoch [646/800] time: 0.86s val loss: 0.1459 accuracy: 0.9506 f1: 0.9495
2023-07-14 01:07:11,619 epoch [647/800] time: 4.99s train loss: 0.066 accuracy: 0.9808 f1: 0.9806
2023-07-14 01:07:12,572 epoch [647/800] time: 0.95s val loss: 0.1454 accuracy: 0.951 f1: 0.9499
2023-07-14 01:07:17,805 epoch [648/800] time: 5.23s train loss: 0.0661 accuracy: 0.9808 f1: 0.9808
2023-07-14 01:07:18,630 epoch [648/800] time: 0.82s val loss: 0.1455 accuracy: 0.9501 f1: 0.9489
2023-07-14 01:07:23,779 epoch [649/800] time: 5.15s train loss: 0.0657 accuracy: 0.9807 f1: 0.9805
2023-07-14 01:07:24,704 epoch [649/800] time: 0.93s val loss: 0.1455 accuracy: 0.9507 f1: 0.9496
2023-07-14 01:07:29,598 epoch [650/800] time: 4.89s train loss: 0.067 accuracy: 0.9799 f1: 0.98
2023-07-14 01:07:30,543 epoch [650/800] time: 0.94s val loss: 0.1462 accuracy: 0.9508 f1: 0.9497
2023-07-14 01:07:35,728 epoch [651/800] time: 5.18s train loss: 0.0666 accuracy: 0.9801 f1: 0.98
2023-07-14 01:07:36,631 epoch [651/800] time: 0.9s val loss: 0.1453 accuracy: 0.9512 f1: 0.9502
2023-07-14 01:07:41,686 epoch [652/800] time: 5.06s train loss: 0.0647 accuracy: 0.9814 f1: 0.9812
2023-07-14 01:07:42,635 epoch [652/800] time: 0.95s val loss: 0.1454 accuracy: 0.9508 f1: 0.9496
2023-07-14 01:07:47,784 epoch [653/800] time: 5.15s train loss: 0.0673 accuracy: 0.98 f1: 0.98
2023-07-14 01:07:48,747 epoch [653/800] time: 0.96s val loss: 0.1469 accuracy: 0.9504 f1: 0.9494
2023-07-14 01:07:53,883 epoch [654/800] time: 5.14s train loss: 0.0663 accuracy: 0.9804 f1: 0.9803
2023-07-14 01:07:54,698 epoch [654/800] time: 0.81s val loss: 0.1454 accuracy: 0.9505 f1: 0.9494
2023-07-14 01:07:59,690 epoch [655/800] time: 4.99s train loss: 0.0664 accuracy: 0.9805 f1: 0.9805
2023-07-14 01:08:00,585 epoch [655/800] time: 0.89s val loss: 0.1455 accuracy: 0.9506 f1: 0.9494
2023-07-14 01:08:05,589 epoch [656/800] time: 5.0s train loss: 0.0655 accuracy: 0.9808 f1: 0.9806
2023-07-14 01:08:06,465 epoch [656/800] time: 0.88s val loss: 0.1457 accuracy: 0.951 f1: 0.9499
2023-07-14 01:08:11,824 epoch [657/800] time: 5.36s train loss: 0.0673 accuracy: 0.9798 f1: 0.9797
2023-07-14 01:08:12,764 epoch [657/800] time: 0.94s val loss: 0.1448 accuracy: 0.9508 f1: 0.9498
2023-07-14 01:08:17,851 epoch [658/800] time: 5.09s train loss: 0.0667 accuracy: 0.98 f1: 0.9798
2023-07-14 01:08:18,764 epoch [658/800] time: 0.91s val loss: 0.1459 accuracy: 0.9503 f1: 0.9491
2023-07-14 01:08:23,828 epoch [659/800] time: 5.06s train loss: 0.0655 accuracy: 0.9807 f1: 0.9805
2023-07-14 01:08:25,108 epoch [659/800] time: 1.28s val loss: 0.145 accuracy: 0.951 f1: 0.9499
2023-07-14 01:08:30,387 epoch [660/800] time: 5.28s train loss: 0.0658 accuracy: 0.9809 f1: 0.9807
2023-07-14 01:08:31,209 epoch [660/800] time: 0.82s val loss: 0.1458 accuracy: 0.9505 f1: 0.9494
2023-07-14 01:08:35,959 epoch [661/800] time: 4.75s train loss: 0.0672 accuracy: 0.9801 f1: 0.98
2023-07-14 01:08:36,935 epoch [661/800] time: 0.98s val loss: 0.146 accuracy: 0.9509 f1: 0.9499
2023-07-14 01:08:41,866 epoch [662/800] time: 4.93s train loss: 0.0661 accuracy: 0.9805 f1: 0.9804
2023-07-14 01:08:42,728 epoch [662/800] time: 0.86s val loss: 0.1457 accuracy: 0.9505 f1: 0.9493
2023-07-14 01:08:47,406 epoch [663/800] time: 4.68s train loss: 0.0658 accuracy: 0.9808 f1: 0.9806
2023-07-14 01:08:48,224 epoch [663/800] time: 0.82s val loss: 0.1455 accuracy: 0.9504 f1: 0.9493
2023-07-14 01:08:53,260 epoch [664/800] time: 5.04s train loss: 0.0656 accuracy: 0.9802 f1: 0.98
2023-07-14 01:08:54,137 epoch [664/800] time: 0.88s val loss: 0.1453 accuracy: 0.9506 f1: 0.9495
2023-07-14 01:08:58,757 epoch [665/800] time: 4.62s train loss: 0.0664 accuracy: 0.9804 f1: 0.9803
2023-07-14 01:08:59,616 epoch [665/800] time: 0.86s val loss: 0.1457 accuracy: 0.9504 f1: 0.9493
2023-07-14 01:09:04,534 epoch [666/800] time: 4.92s train loss: 0.0665 accuracy: 0.9804 f1: 0.9802
2023-07-14 01:09:05,378 epoch [666/800] time: 0.84s val loss: 0.1461 accuracy: 0.9507 f1: 0.9497
2023-07-14 01:09:10,272 epoch [667/800] time: 4.89s train loss: 0.0674 accuracy: 0.9804 f1: 0.9802
2023-07-14 01:09:11,125 epoch [667/800] time: 0.85s val loss: 0.1453 accuracy: 0.9512 f1: 0.9501
2023-07-14 01:09:15,840 epoch [668/800] time: 4.71s train loss: 0.0692 accuracy: 0.9797 f1: 0.9795
2023-07-14 01:09:16,688 epoch [668/800] time: 0.85s val loss: 0.1458 accuracy: 0.9507 f1: 0.9497
2023-07-14 01:09:21,477 epoch [669/800] time: 4.79s train loss: 0.0665 accuracy: 0.9806 f1: 0.9805
2023-07-14 01:09:22,276 epoch [669/800] time: 0.8s val loss: 0.1457 accuracy: 0.9505 f1: 0.9494
2023-07-14 01:09:27,021 epoch [670/800] time: 4.74s train loss: 0.0668 accuracy: 0.9805 f1: 0.9803
2023-07-14 01:09:27,864 epoch [670/800] time: 0.84s val loss: 0.1466 accuracy: 0.9498 f1: 0.9487
2023-07-14 01:09:32,601 epoch [671/800] time: 4.74s train loss: 0.0656 accuracy: 0.9805 f1: 0.9802
2023-07-14 01:09:33,442 epoch [671/800] time: 0.84s val loss: 0.1454 accuracy: 0.9504 f1: 0.9494
2023-07-14 01:09:38,196 epoch [672/800] time: 4.75s train loss: 0.0678 accuracy: 0.9801 f1: 0.98
2023-07-14 01:09:38,996 epoch [672/800] time: 0.8s val loss: 0.1471 accuracy: 0.9506 f1: 0.9496
2023-07-14 01:09:43,782 epoch [673/800] time: 4.79s train loss: 0.0667 accuracy: 0.9811 f1: 0.981
2023-07-14 01:09:44,623 epoch [673/800] time: 0.84s val loss: 0.1454 accuracy: 0.9509 f1: 0.9498
2023-07-14 01:09:49,351 epoch [674/800] time: 4.73s train loss: 0.0654 accuracy: 0.9805 f1: 0.9804
2023-07-14 01:09:50,207 epoch [674/800] time: 0.86s val loss: 0.1454 accuracy: 0.9508 f1: 0.9498
2023-07-14 01:09:54,944 epoch [675/800] time: 4.74s train loss: 0.066 accuracy: 0.981 f1: 0.9809
2023-07-14 01:09:55,743 epoch [675/800] time: 0.8s val loss: 0.1451 accuracy: 0.9511 f1: 0.95
2023-07-14 01:10:00,673 epoch [676/800] time: 4.93s train loss: 0.0663 accuracy: 0.9801 f1: 0.98
2023-07-14 01:10:01,579 epoch [676/800] time: 0.91s val loss: 0.1457 accuracy: 0.9508 f1: 0.9498
2023-07-14 01:10:06,708 epoch [677/800] time: 5.13s train loss: 0.0656 accuracy: 0.9812 f1: 0.9811
2023-07-14 01:10:07,657 epoch [677/800] time: 0.95s val loss: 0.1458 accuracy: 0.9504 f1: 0.9494
2023-07-14 01:10:12,935 epoch [678/800] time: 5.28s train loss: 0.0673 accuracy: 0.9805 f1: 0.9804
2023-07-14 01:10:13,787 epoch [678/800] time: 0.85s val loss: 0.1477 accuracy: 0.95 f1: 0.9489
2023-07-14 01:10:19,408 epoch [679/800] time: 5.62s train loss: 0.0683 accuracy: 0.9803 f1: 0.9801
2023-07-14 01:10:20,404 epoch [679/800] time: 1.0s val loss: 0.1459 accuracy: 0.9498 f1: 0.9487
2023-07-14 01:10:25,803 epoch [680/800] time: 5.4s train loss: 0.0667 accuracy: 0.9809 f1: 0.9807
2023-07-14 01:10:26,779 epoch [680/800] time: 0.98s val loss: 0.1461 accuracy: 0.9503 f1: 0.9492
2023-07-14 01:10:31,877 epoch [681/800] time: 5.1s train loss: 0.0671 accuracy: 0.9805 f1: 0.9804
2023-07-14 01:10:32,757 epoch [681/800] time: 0.88s val loss: 0.1462 accuracy: 0.9504 f1: 0.9492
2023-07-14 01:10:37,960 epoch [682/800] time: 5.2s train loss: 0.0658 accuracy: 0.9809 f1: 0.9808
2023-07-14 01:10:38,866 epoch [682/800] time: 0.91s val loss: 0.1464 accuracy: 0.9507 f1: 0.9496
2023-07-14 01:10:43,895 epoch [683/800] time: 5.03s train loss: 0.0656 accuracy: 0.9807 f1: 0.9806
2023-07-14 01:10:44,794 epoch [683/800] time: 0.9s val loss: 0.1457 accuracy: 0.9504 f1: 0.9494
2023-07-14 01:10:49,683 epoch [684/800] time: 4.89s train loss: 0.0686 accuracy: 0.9807 f1: 0.9806
2023-07-14 01:10:50,510 epoch [684/800] time: 0.83s val loss: 0.1464 accuracy: 0.9503 f1: 0.9491
2023-07-14 01:10:55,325 epoch [685/800] time: 4.82s train loss: 0.0673 accuracy: 0.9802 f1: 0.9802
2023-07-14 01:10:56,191 epoch [685/800] time: 0.87s val loss: 0.1461 accuracy: 0.9505 f1: 0.9493
2023-07-14 01:11:00,836 epoch [686/800] time: 4.64s train loss: 0.0662 accuracy: 0.9802 f1: 0.9801
2023-07-14 01:11:01,720 epoch [686/800] time: 0.88s val loss: 0.1454 accuracy: 0.9508 f1: 0.9499
2023-07-14 01:11:06,453 epoch [687/800] time: 4.73s train loss: 0.0679 accuracy: 0.9799 f1: 0.9798
2023-07-14 01:11:07,260 epoch [687/800] time: 0.81s val loss: 0.1465 accuracy: 0.9502 f1: 0.9491
2023-07-14 01:11:11,939 epoch [688/800] time: 4.68s train loss: 0.067 accuracy: 0.9802 f1: 0.9801
2023-07-14 01:11:12,814 epoch [688/800] time: 0.87s val loss: 0.1463 accuracy: 0.9509 f1: 0.9498
2023-07-14 01:11:17,503 epoch [689/800] time: 4.69s train loss: 0.0666 accuracy: 0.9801 f1: 0.98
2023-07-14 01:11:18,347 epoch [689/800] time: 0.84s val loss: 0.1455 accuracy: 0.9511 f1: 0.9501
2023-07-14 01:11:23,072 epoch [690/800] time: 4.72s train loss: 0.066 accuracy: 0.98 f1: 0.9798
2023-07-14 01:11:23,873 epoch [690/800] time: 0.8s val loss: 0.1452 accuracy: 0.9507 f1: 0.9497
2023-07-14 01:11:28,637 epoch [691/800] time: 4.76s train loss: 0.0681 accuracy: 0.9797 f1: 0.9796
2023-07-14 01:11:29,482 epoch [691/800] time: 0.85s val loss: 0.1462 accuracy: 0.9508 f1: 0.9498
2023-07-14 01:11:33,981 epoch [692/800] time: 4.5s train loss: 0.067 accuracy: 0.9802 f1: 0.9801
2023-07-14 01:11:34,823 epoch [692/800] time: 0.84s val loss: 0.1461 accuracy: 0.9504 f1: 0.9493
2023-07-14 01:11:39,358 epoch [693/800] time: 4.53s train loss: 0.0672 accuracy: 0.9799 f1: 0.9797
2023-07-14 01:11:40,158 epoch [693/800] time: 0.8s val loss: 0.1464 accuracy: 0.9502 f1: 0.9491
2023-07-14 01:11:44,695 epoch [694/800] time: 4.54s train loss: 0.0663 accuracy: 0.9804 f1: 0.9802
2023-07-14 01:11:45,552 epoch [694/800] time: 0.86s val loss: 0.1453 accuracy: 0.9506 f1: 0.9497
2023-07-14 01:11:50,060 epoch [695/800] time: 4.51s train loss: 0.0663 accuracy: 0.9801 f1: 0.98
2023-07-14 01:11:50,913 epoch [695/800] time: 0.85s val loss: 0.1456 accuracy: 0.9508 f1: 0.9496
2023-07-14 01:11:55,481 epoch [696/800] time: 4.57s train loss: 0.0665 accuracy: 0.9809 f1: 0.9809
2023-07-14 01:11:56,281 epoch [696/800] time: 0.8s val loss: 0.1461 accuracy: 0.951 f1: 0.9499
2023-07-14 01:12:00,845 epoch [697/800] time: 4.56s train loss: 0.0662 accuracy: 0.9803 f1: 0.9802
2023-07-14 01:12:01,688 epoch [697/800] time: 0.84s val loss: 0.1457 accuracy: 0.9499 f1: 0.9487
2023-07-14 01:12:06,228 epoch [698/800] time: 4.54s train loss: 0.0668 accuracy: 0.9802 f1: 0.9801
2023-07-14 01:12:07,070 epoch [698/800] time: 0.84s val loss: 0.1458 accuracy: 0.9504 f1: 0.9492
2023-07-14 01:12:11,673 epoch [699/800] time: 4.6s train loss: 0.0664 accuracy: 0.9803 f1: 0.9801
2023-07-14 01:12:12,473 epoch [699/800] time: 0.8s val loss: 0.1454 accuracy: 0.9509 f1: 0.9498
2023-07-14 01:12:17,147 epoch [700/800] time: 4.67s train loss: 0.0664 accuracy: 0.9809 f1: 0.9808
2023-07-14 01:12:17,993 epoch [700/800] time: 0.85s val loss: 0.1451 accuracy: 0.9505 f1: 0.9495
2023-07-14 01:12:22,668 epoch [701/800] time: 4.67s train loss: 0.0662 accuracy: 0.9806 f1: 0.9803
2023-07-14 01:12:23,512 epoch [701/800] time: 0.84s val loss: 0.1458 accuracy: 0.951 f1: 0.95
2023-07-14 01:12:28,245 epoch [702/800] time: 4.73s train loss: 0.0664 accuracy: 0.9806 f1: 0.9805
2023-07-14 01:12:29,045 epoch [702/800] time: 0.8s val loss: 0.1457 accuracy: 0.9508 f1: 0.9498
2023-07-14 01:12:33,695 epoch [703/800] time: 4.65s train loss: 0.0657 accuracy: 0.9807 f1: 0.9806
2023-07-14 01:12:34,540 epoch [703/800] time: 0.84s val loss: 0.1455 accuracy: 0.9507 f1: 0.9497
2023-07-14 01:12:39,067 epoch [704/800] time: 4.53s train loss: 0.0666 accuracy: 0.9807 f1: 0.9805
2023-07-14 01:12:39,932 epoch [704/800] time: 0.86s val loss: 0.1456 accuracy: 0.9511 f1: 0.95
2023-07-14 01:12:44,592 epoch [705/800] time: 4.66s train loss: 0.0676 accuracy: 0.98 f1: 0.9798
2023-07-14 01:12:45,396 epoch [705/800] time: 0.8s val loss: 0.1455 accuracy: 0.9507 f1: 0.9497
2023-07-14 01:12:50,486 epoch [706/800] time: 5.09s train loss: 0.0662 accuracy: 0.9808 f1: 0.9807
2023-07-14 01:12:51,404 epoch [706/800] time: 0.92s val loss: 0.1454 accuracy: 0.9508 f1: 0.9497
2023-07-14 01:12:56,852 epoch [707/800] time: 5.45s train loss: 0.0659 accuracy: 0.9806 f1: 0.9804
2023-07-14 01:12:57,758 epoch [707/800] time: 0.91s val loss: 0.1471 accuracy: 0.9506 f1: 0.9496
2023-07-14 01:13:03,029 epoch [708/800] time: 5.27s train loss: 0.0665 accuracy: 0.9805 f1: 0.9805
2023-07-14 01:13:03,924 epoch [708/800] time: 0.9s val loss: 0.1454 accuracy: 0.9505 f1: 0.9494
2023-07-14 01:13:09,096 epoch [709/800] time: 5.17s train loss: 0.0662 accuracy: 0.9805 f1: 0.9804
2023-07-14 01:13:10,035 epoch [709/800] time: 0.94s val loss: 0.1451 accuracy: 0.951 f1: 0.9499
2023-07-14 01:13:15,152 epoch [710/800] time: 5.12s train loss: 0.0663 accuracy: 0.9805 f1: 0.9804
2023-07-14 01:13:16,056 epoch [710/800] time: 0.9s val loss: 0.1455 accuracy: 0.9506 f1: 0.9495
2023-07-14 01:13:21,072 epoch [711/800] time: 5.02s train loss: 0.0667 accuracy: 0.9804 f1: 0.9804
2023-07-14 01:13:21,894 epoch [711/800] time: 0.82s val loss: 0.1464 accuracy: 0.9509 f1: 0.9498
2023-07-14 01:13:26,865 epoch [712/800] time: 4.97s train loss: 0.0671 accuracy: 0.9803 f1: 0.9802
2023-07-14 01:13:27,764 epoch [712/800] time: 0.9s val loss: 0.1474 accuracy: 0.95 f1: 0.9491
2023-07-14 01:13:32,770 epoch [713/800] time: 5.01s train loss: 0.0666 accuracy: 0.98 f1: 0.9799
2023-07-14 01:13:33,637 epoch [713/800] time: 0.87s val loss: 0.1465 accuracy: 0.9506 f1: 0.9494
2023-07-14 01:13:38,532 epoch [714/800] time: 4.89s train loss: 0.0664 accuracy: 0.9802 f1: 0.9802
2023-07-14 01:13:39,336 epoch [714/800] time: 0.8s val loss: 0.1459 accuracy: 0.9511 f1: 0.95
2023-07-14 01:13:44,276 epoch [715/800] time: 4.94s train loss: 0.0674 accuracy: 0.9801 f1: 0.9799
2023-07-14 01:13:45,148 epoch [715/800] time: 0.87s val loss: 0.1462 accuracy: 0.9502 f1: 0.9492
2023-07-14 01:13:49,919 epoch [716/800] time: 4.77s train loss: 0.0663 accuracy: 0.9804 f1: 0.9803
2023-07-14 01:13:50,786 epoch [716/800] time: 0.87s val loss: 0.1458 accuracy: 0.9502 f1: 0.9494
2023-07-14 01:13:55,458 epoch [717/800] time: 4.67s train loss: 0.0661 accuracy: 0.9809 f1: 0.9808
2023-07-14 01:13:56,274 epoch [717/800] time: 0.82s val loss: 0.1465 accuracy: 0.9503 f1: 0.9493
2023-07-14 01:14:01,034 epoch [718/800] time: 4.76s train loss: 0.0655 accuracy: 0.9808 f1: 0.9807
2023-07-14 01:14:01,892 epoch [718/800] time: 0.86s val loss: 0.1453 accuracy: 0.9507 f1: 0.9496
2023-07-14 01:14:06,668 epoch [719/800] time: 4.78s train loss: 0.0679 accuracy: 0.9801 f1: 0.9799
2023-07-14 01:14:07,512 epoch [719/800] time: 0.84s val loss: 0.1479 accuracy: 0.9496 f1: 0.9485
2023-07-14 01:14:12,302 epoch [720/800] time: 4.79s train loss: 0.0658 accuracy: 0.9809 f1: 0.9809
2023-07-14 01:14:13,106 epoch [720/800] time: 0.8s val loss: 0.1455 accuracy: 0.9508 f1: 0.9498
2023-07-14 01:14:17,965 epoch [721/800] time: 4.86s train loss: 0.067 accuracy: 0.9804 f1: 0.9803
2023-07-14 01:14:18,908 epoch [721/800] time: 0.94s val loss: 0.1457 accuracy: 0.9505 f1: 0.9492
2023-07-14 01:14:23,950 epoch [722/800] time: 5.04s train loss: 0.0661 accuracy: 0.9805 f1: 0.9805
2023-07-14 01:14:24,903 epoch [722/800] time: 0.95s val loss: 0.1451 accuracy: 0.9505 f1: 0.9494
2023-07-14 01:14:29,958 epoch [723/800] time: 5.05s train loss: 0.0656 accuracy: 0.9806 f1: 0.9805
2023-07-14 01:14:30,847 epoch [723/800] time: 0.89s val loss: 0.1456 accuracy: 0.9509 f1: 0.9498
2023-07-14 01:14:35,839 epoch [724/800] time: 4.99s train loss: 0.0657 accuracy: 0.9808 f1: 0.9806
2023-07-14 01:14:36,699 epoch [724/800] time: 0.86s val loss: 0.1467 accuracy: 0.9503 f1: 0.9491
2023-07-14 01:14:41,565 epoch [725/800] time: 4.87s train loss: 0.0677 accuracy: 0.9798 f1: 0.9797
2023-07-14 01:14:42,424 epoch [725/800] time: 0.86s val loss: 0.1465 accuracy: 0.9499 f1: 0.9488
2023-07-14 01:14:47,297 epoch [726/800] time: 4.87s train loss: 0.0656 accuracy: 0.9805 f1: 0.9805
2023-07-14 01:14:48,112 epoch [726/800] time: 0.81s val loss: 0.1463 accuracy: 0.95 f1: 0.9489
2023-07-14 01:14:52,976 epoch [727/800] time: 4.86s train loss: 0.0676 accuracy: 0.9805 f1: 0.9804
2023-07-14 01:14:53,835 epoch [727/800] time: 0.86s val loss: 0.1463 accuracy: 0.9501 f1: 0.9491
2023-07-14 01:14:58,650 epoch [728/800] time: 4.81s train loss: 0.0655 accuracy: 0.9808 f1: 0.9807
2023-07-14 01:14:59,508 epoch [728/800] time: 0.86s val loss: 0.1453 accuracy: 0.9507 f1: 0.9497
2023-07-14 01:15:04,336 epoch [729/800] time: 4.83s train loss: 0.0659 accuracy: 0.9805 f1: 0.9803
2023-07-14 01:15:05,150 epoch [729/800] time: 0.81s val loss: 0.1465 accuracy: 0.9509 f1: 0.9497
2023-07-14 01:15:09,995 epoch [730/800] time: 4.84s train loss: 0.0661 accuracy: 0.9807 f1: 0.9805
2023-07-14 01:15:10,867 epoch [730/800] time: 0.87s val loss: 0.1451 accuracy: 0.9508 f1: 0.9498
2023-07-14 01:15:15,536 epoch [731/800] time: 4.67s train loss: 0.0655 accuracy: 0.9806 f1: 0.9804
2023-07-14 01:15:16,395 epoch [731/800] time: 0.86s val loss: 0.1454 accuracy: 0.9512 f1: 0.9501
2023-07-14 01:15:21,202 epoch [732/800] time: 4.81s train loss: 0.0666 accuracy: 0.9804 f1: 0.9803
2023-07-14 01:15:22,098 epoch [732/800] time: 0.9s val loss: 0.1453 accuracy: 0.951 f1: 0.9499
2023-07-14 01:15:26,867 epoch [733/800] time: 4.77s train loss: 0.0665 accuracy: 0.9808 f1: 0.9807
2023-07-14 01:15:27,726 epoch [733/800] time: 0.86s val loss: 0.1456 accuracy: 0.9506 f1: 0.9495
2023-07-14 01:15:32,379 epoch [734/800] time: 4.65s train loss: 0.0681 accuracy: 0.9805 f1: 0.9803
2023-07-14 01:15:33,244 epoch [734/800] time: 0.86s val loss: 0.147 accuracy: 0.9499 f1: 0.9488
2023-07-14 01:15:38,205 epoch [735/800] time: 4.96s train loss: 0.0663 accuracy: 0.9806 f1: 0.9805
2023-07-14 01:15:39,021 epoch [735/800] time: 0.82s val loss: 0.1452 accuracy: 0.9505 f1: 0.9494
2023-07-14 01:15:43,903 epoch [736/800] time: 4.88s train loss: 0.067 accuracy: 0.9805 f1: 0.9804
2023-07-14 01:15:44,766 epoch [736/800] time: 0.86s val loss: 0.1466 accuracy: 0.9502 f1: 0.9493
2023-07-14 01:15:49,632 epoch [737/800] time: 4.87s train loss: 0.0662 accuracy: 0.9807 f1: 0.9806
2023-07-14 01:15:50,495 epoch [737/800] time: 0.86s val loss: 0.1462 accuracy: 0.9499 f1: 0.9488
2023-07-14 01:15:55,384 epoch [738/800] time: 4.89s train loss: 0.0671 accuracy: 0.9802 f1: 0.98
2023-07-14 01:15:56,290 epoch [738/800] time: 0.91s val loss: 0.1454 accuracy: 0.9506 f1: 0.9496
2023-07-14 01:16:01,314 epoch [739/800] time: 5.02s train loss: 0.0659 accuracy: 0.9809 f1: 0.9807
2023-07-14 01:16:02,265 epoch [739/800] time: 0.95s val loss: 0.1457 accuracy: 0.9507 f1: 0.9496
2023-07-14 01:16:07,295 epoch [740/800] time: 5.03s train loss: 0.0663 accuracy: 0.9804 f1: 0.9803
2023-07-14 01:16:08,241 epoch [740/800] time: 0.94s val loss: 0.1451 accuracy: 0.9505 f1: 0.9494
2023-07-14 01:16:13,224 epoch [741/800] time: 4.98s train loss: 0.0654 accuracy: 0.981 f1: 0.981
2023-07-14 01:16:14,110 epoch [741/800] time: 0.89s val loss: 0.1454 accuracy: 0.9509 f1: 0.9499
2023-07-14 01:16:19,044 epoch [742/800] time: 4.93s train loss: 0.0654 accuracy: 0.9806 f1: 0.9805
2023-07-14 01:16:19,904 epoch [742/800] time: 0.86s val loss: 0.1458 accuracy: 0.9502 f1: 0.9493
2023-07-14 01:16:24,653 epoch [743/800] time: 4.75s train loss: 0.0668 accuracy: 0.9814 f1: 0.9812
2023-07-14 01:16:25,524 epoch [743/800] time: 0.87s val loss: 0.1462 accuracy: 0.9504 f1: 0.9494
2023-07-14 01:16:30,328 epoch [744/800] time: 4.8s train loss: 0.0657 accuracy: 0.9809 f1: 0.9808
2023-07-14 01:16:31,141 epoch [744/800] time: 0.81s val loss: 0.1457 accuracy: 0.9507 f1: 0.9495
2023-07-14 01:16:35,964 epoch [745/800] time: 4.82s train loss: 0.066 accuracy: 0.9808 f1: 0.9807
2023-07-14 01:16:36,824 epoch [745/800] time: 0.86s val loss: 0.1459 accuracy: 0.951 f1: 0.9499
2023-07-14 01:16:41,648 epoch [746/800] time: 4.82s train loss: 0.0675 accuracy: 0.9808 f1: 0.9808
2023-07-14 01:16:42,509 epoch [746/800] time: 0.86s val loss: 0.146 accuracy: 0.9507 f1: 0.9497
2023-07-14 01:16:47,285 epoch [747/800] time: 4.78s train loss: 0.0659 accuracy: 0.9806 f1: 0.9805
2023-07-14 01:16:48,096 epoch [747/800] time: 0.81s val loss: 0.1456 accuracy: 0.9509 f1: 0.95
2023-07-14 01:16:52,909 epoch [748/800] time: 4.81s train loss: 0.0676 accuracy: 0.9801 f1: 0.9801
2023-07-14 01:16:53,768 epoch [748/800] time: 0.86s val loss: 0.1455 accuracy: 0.9502 f1: 0.9492
2023-07-14 01:16:58,570 epoch [749/800] time: 4.8s train loss: 0.0658 accuracy: 0.9802 f1: 0.9801
2023-07-14 01:16:59,427 epoch [749/800] time: 0.86s val loss: 0.1463 accuracy: 0.9506 f1: 0.9494
2023-07-14 01:17:04,306 epoch [750/800] time: 4.88s train loss: 0.0675 accuracy: 0.9804 f1: 0.9803
2023-07-14 01:17:05,114 epoch [750/800] time: 0.81s val loss: 0.147 accuracy: 0.9504 f1: 0.9492
2023-07-14 01:17:10,135 epoch [751/800] time: 5.02s train loss: 0.0661 accuracy: 0.9803 f1: 0.9802
2023-07-14 01:17:10,994 epoch [751/800] time: 0.86s val loss: 0.1461 accuracy: 0.9508 f1: 0.9498
2023-07-14 01:17:16,057 epoch [752/800] time: 5.06s train loss: 0.0661 accuracy: 0.9805 f1: 0.9804
2023-07-14 01:17:16,922 epoch [752/800] time: 0.86s val loss: 0.1463 accuracy: 0.9504 f1: 0.9493
2023-07-14 01:17:21,898 epoch [753/800] time: 4.98s train loss: 0.0686 accuracy: 0.9802 f1: 0.98
2023-07-14 01:17:22,714 epoch [753/800] time: 0.82s val loss: 0.1466 accuracy: 0.9507 f1: 0.9496
2023-07-14 01:17:27,657 epoch [754/800] time: 4.94s train loss: 0.068 accuracy: 0.98 f1: 0.9799
2023-07-14 01:17:28,505 epoch [754/800] time: 0.85s val loss: 0.1461 accuracy: 0.9506 f1: 0.9496
2023-07-14 01:17:33,026 epoch [755/800] time: 4.52s train loss: 0.0671 accuracy: 0.9803 f1: 0.9801
2023-07-14 01:17:33,874 epoch [755/800] time: 0.85s val loss: 0.1461 accuracy: 0.9503 f1: 0.9493
2023-07-14 01:17:38,440 epoch [756/800] time: 4.57s train loss: 0.0661 accuracy: 0.9807 f1: 0.9806
2023-07-14 01:17:39,245 epoch [756/800] time: 0.8s val loss: 0.1469 accuracy: 0.9503 f1: 0.9491
2023-07-14 01:17:43,812 epoch [757/800] time: 4.57s train loss: 0.0665 accuracy: 0.9806 f1: 0.9804
2023-07-14 01:17:44,661 epoch [757/800] time: 0.85s val loss: 0.145 accuracy: 0.9506 f1: 0.9495
2023-07-14 01:17:49,194 epoch [758/800] time: 4.53s train loss: 0.0668 accuracy: 0.9807 f1: 0.9806
2023-07-14 01:17:50,042 epoch [758/800] time: 0.85s val loss: 0.1458 accuracy: 0.9507 f1: 0.9498
2023-07-14 01:17:54,646 epoch [759/800] time: 4.6s train loss: 0.0657 accuracy: 0.9813 f1: 0.9813
2023-07-14 01:17:55,485 epoch [759/800] time: 0.84s val loss: 0.1466 accuracy: 0.9504 f1: 0.9493
2023-07-14 01:18:00,044 epoch [760/800] time: 4.56s train loss: 0.0667 accuracy: 0.9806 f1: 0.9806
2023-07-14 01:18:00,890 epoch [760/800] time: 0.85s val loss: 0.1473 accuracy: 0.9496 f1: 0.9483
2023-07-14 01:18:05,434 epoch [761/800] time: 4.54s train loss: 0.0659 accuracy: 0.9804 f1: 0.9801
2023-07-14 01:18:06,282 epoch [761/800] time: 0.85s val loss: 0.1464 accuracy: 0.9509 f1: 0.9498
2023-07-14 01:18:10,844 epoch [762/800] time: 4.56s train loss: 0.0664 accuracy: 0.9806 f1: 0.9805
2023-07-14 01:18:11,649 epoch [762/800] time: 0.8s val loss: 0.1453 accuracy: 0.9507 f1: 0.9496
2023-07-14 01:18:16,251 epoch [763/800] time: 4.6s train loss: 0.0653 accuracy: 0.981 f1: 0.9809
2023-07-14 01:18:17,112 epoch [763/800] time: 0.86s val loss: 0.1452 accuracy: 0.9508 f1: 0.9497
2023-07-14 01:18:21,649 epoch [764/800] time: 4.54s train loss: 0.066 accuracy: 0.9807 f1: 0.9805
2023-07-14 01:18:22,503 epoch [764/800] time: 0.85s val loss: 0.1453 accuracy: 0.9509 f1: 0.9498
2023-07-14 01:18:27,080 epoch [765/800] time: 4.58s train loss: 0.0669 accuracy: 0.98 f1: 0.9799
2023-07-14 01:18:27,897 epoch [765/800] time: 0.82s val loss: 0.1457 accuracy: 0.9508 f1: 0.9497
2023-07-14 01:18:32,458 epoch [766/800] time: 4.56s train loss: 0.0664 accuracy: 0.9807 f1: 0.9806
2023-07-14 01:18:33,310 epoch [766/800] time: 0.85s val loss: 0.1452 accuracy: 0.9506 f1: 0.9494
2023-07-14 01:18:38,011 epoch [767/800] time: 4.7s train loss: 0.0659 accuracy: 0.9803 f1: 0.9802
2023-07-14 01:18:38,861 epoch [767/800] time: 0.85s val loss: 0.1461 accuracy: 0.9505 f1: 0.9492
2023-07-14 01:18:43,531 epoch [768/800] time: 4.67s train loss: 0.0662 accuracy: 0.9801 f1: 0.98
2023-07-14 01:18:44,336 epoch [768/800] time: 0.8s val loss: 0.1455 accuracy: 0.9509 f1: 0.9498
2023-07-14 01:18:49,284 epoch [769/800] time: 4.95s train loss: 0.0671 accuracy: 0.9802 f1: 0.9801
2023-07-14 01:18:50,187 epoch [769/800] time: 0.9s val loss: 0.1454 accuracy: 0.9511 f1: 0.95
2023-07-14 01:18:55,031 epoch [770/800] time: 4.84s train loss: 0.066 accuracy: 0.9808 f1: 0.9807
2023-07-14 01:18:55,920 epoch [770/800] time: 0.89s val loss: 0.1458 accuracy: 0.9506 f1: 0.9493
2023-07-14 01:19:00,943 epoch [771/800] time: 5.02s train loss: 0.0647 accuracy: 0.9807 f1: 0.9806
2023-07-14 01:19:01,847 epoch [771/800] time: 0.9s val loss: 0.1457 accuracy: 0.9506 f1: 0.9495
2023-07-14 01:19:06,928 epoch [772/800] time: 5.08s train loss: 0.0661 accuracy: 0.9802 f1: 0.98
2023-07-14 01:19:07,853 epoch [772/800] time: 0.92s val loss: 0.1459 accuracy: 0.9502 f1: 0.9492
2023-07-14 01:19:12,891 epoch [773/800] time: 5.04s train loss: 0.0651 accuracy: 0.9813 f1: 0.9812
2023-07-14 01:19:13,795 epoch [773/800] time: 0.9s val loss: 0.1451 accuracy: 0.9505 f1: 0.9494
2023-07-14 01:19:19,038 epoch [774/800] time: 5.24s train loss: 0.0666 accuracy: 0.9803 f1: 0.9801
2023-07-14 01:19:19,883 epoch [774/800] time: 0.84s val loss: 0.1457 accuracy: 0.9509 f1: 0.9498
2023-07-14 01:19:25,122 epoch [775/800] time: 5.24s train loss: 0.0662 accuracy: 0.9803 f1: 0.9802
2023-07-14 01:19:26,021 epoch [775/800] time: 0.9s val loss: 0.1458 accuracy: 0.9507 f1: 0.9497
2023-07-14 01:19:31,081 epoch [776/800] time: 5.06s train loss: 0.0664 accuracy: 0.98 f1: 0.98
2023-07-14 01:19:31,996 epoch [776/800] time: 0.91s val loss: 0.1458 accuracy: 0.9504 f1: 0.9493
2023-07-14 01:19:37,145 epoch [777/800] time: 5.15s train loss: 0.0654 accuracy: 0.9808 f1: 0.9807
2023-07-14 01:19:38,016 epoch [777/800] time: 0.87s val loss: 0.1454 accuracy: 0.9509 f1: 0.9497
2023-07-14 01:19:43,089 epoch [778/800] time: 5.07s train loss: 0.0667 accuracy: 0.9806 f1: 0.9805
2023-07-14 01:19:44,020 epoch [778/800] time: 0.93s val loss: 0.1463 accuracy: 0.95 f1: 0.949
2023-07-14 01:19:49,058 epoch [779/800] time: 5.04s train loss: 0.0661 accuracy: 0.9806 f1: 0.9806
2023-07-14 01:19:49,972 epoch [779/800] time: 0.91s val loss: 0.1452 accuracy: 0.9505 f1: 0.9494
2023-07-14 01:19:54,803 epoch [780/800] time: 4.83s train loss: 0.067 accuracy: 0.9801 f1: 0.9798
2023-07-14 01:19:55,617 epoch [780/800] time: 0.81s val loss: 0.1459 accuracy: 0.9505 f1: 0.9493
2023-07-14 01:20:00,551 epoch [781/800] time: 4.93s train loss: 0.0661 accuracy: 0.9803 f1: 0.9802
2023-07-14 01:20:01,428 epoch [781/800] time: 0.88s val loss: 0.146 accuracy: 0.9506 f1: 0.9497
2023-07-14 01:20:06,132 epoch [782/800] time: 4.7s train loss: 0.0683 accuracy: 0.9803 f1: 0.9802
2023-07-14 01:20:07,008 epoch [782/800] time: 0.88s val loss: 0.1463 accuracy: 0.9506 f1: 0.9495
2023-07-14 01:20:11,822 epoch [783/800] time: 4.81s train loss: 0.0673 accuracy: 0.9803 f1: 0.9801
2023-07-14 01:20:12,630 epoch [783/800] time: 0.81s val loss: 0.1457 accuracy: 0.951 f1: 0.95
2023-07-14 01:20:17,225 epoch [784/800] time: 4.59s train loss: 0.0666 accuracy: 0.9807 f1: 0.9807
2023-07-14 01:20:18,103 epoch [784/800] time: 0.88s val loss: 0.1454 accuracy: 0.9504 f1: 0.9494
2023-07-14 01:20:22,971 epoch [785/800] time: 4.87s train loss: 0.0674 accuracy: 0.9803 f1: 0.9801
2023-07-14 01:20:23,827 epoch [785/800] time: 0.86s val loss: 0.1466 accuracy: 0.95 f1: 0.9488
2023-07-14 01:20:28,493 epoch [786/800] time: 4.67s train loss: 0.067 accuracy: 0.9808 f1: 0.9807
2023-07-14 01:20:29,320 epoch [786/800] time: 0.83s val loss: 0.1463 accuracy: 0.9507 f1: 0.9497
2023-07-14 01:20:34,451 epoch [787/800] time: 5.13s train loss: 0.0693 accuracy: 0.9803 f1: 0.9801
2023-07-14 01:20:35,646 epoch [787/800] time: 1.19s val loss: 0.1465 accuracy: 0.9502 f1: 0.9491
2023-07-14 01:20:41,139 epoch [788/800] time: 5.49s train loss: 0.0665 accuracy: 0.9807 f1: 0.9806
2023-07-14 01:20:42,026 epoch [788/800] time: 0.89s val loss: 0.1465 accuracy: 0.9503 f1: 0.9492
2023-07-14 01:20:46,992 epoch [789/800] time: 4.97s train loss: 0.07 accuracy: 0.9802 f1: 0.9801
2023-07-14 01:20:47,825 epoch [789/800] time: 0.83s val loss: 0.1474 accuracy: 0.95 f1: 0.9489
2023-07-14 01:20:52,791 epoch [790/800] time: 4.97s train loss: 0.0667 accuracy: 0.9799 f1: 0.9798
2023-07-14 01:20:53,668 epoch [790/800] time: 0.88s val loss: 0.1451 accuracy: 0.9509 f1: 0.9499
2023-07-14 01:20:58,743 epoch [791/800] time: 5.08s train loss: 0.0661 accuracy: 0.9805 f1: 0.9804
2023-07-14 01:20:59,675 epoch [791/800] time: 0.93s val loss: 0.145 accuracy: 0.9508 f1: 0.9496
2023-07-14 01:21:05,005 epoch [792/800] time: 5.33s train loss: 0.0668 accuracy: 0.9801 f1: 0.9801
2023-07-14 01:21:05,841 epoch [792/800] time: 0.84s val loss: 0.1455 accuracy: 0.9503 f1: 0.9493
2023-07-14 01:21:10,813 epoch [793/800] time: 4.97s train loss: 0.0665 accuracy: 0.9804 f1: 0.9802
2023-07-14 01:21:11,696 epoch [793/800] time: 0.88s val loss: 0.1454 accuracy: 0.9514 f1: 0.9503
2023-07-14 01:21:16,765 epoch [794/800] time: 5.07s train loss: 0.0677 accuracy: 0.98 f1: 0.9798
2023-07-14 01:21:17,684 epoch [794/800] time: 0.92s val loss: 0.1458 accuracy: 0.9502 f1: 0.9493
2023-07-14 01:21:22,655 epoch [795/800] time: 4.97s train loss: 0.0661 accuracy: 0.981 f1: 0.9809
2023-07-14 01:21:23,488 epoch [795/800] time: 0.83s val loss: 0.1456 accuracy: 0.9509 f1: 0.9498
2023-07-14 01:21:28,516 epoch [796/800] time: 5.03s train loss: 0.0656 accuracy: 0.9808 f1: 0.9808
2023-07-14 01:21:29,381 epoch [796/800] time: 0.87s val loss: 0.1456 accuracy: 0.9512 f1: 0.9501
2023-07-14 01:21:34,098 epoch [797/800] time: 4.72s train loss: 0.0661 accuracy: 0.9805 f1: 0.9804
2023-07-14 01:21:34,979 epoch [797/800] time: 0.88s val loss: 0.1455 accuracy: 0.9508 f1: 0.9497
2023-07-14 01:21:39,984 epoch [798/800] time: 5.0s train loss: 0.0659 accuracy: 0.9807 f1: 0.9805
2023-07-14 01:21:40,814 epoch [798/800] time: 0.83s val loss: 0.1456 accuracy: 0.9512 f1: 0.9501
2023-07-14 01:21:45,724 epoch [799/800] time: 4.91s train loss: 0.0681 accuracy: 0.9798 f1: 0.9797
2023-07-14 01:21:46,594 epoch [799/800] time: 0.87s val loss: 0.1454 accuracy: 0.9507 f1: 0.9497
2023-07-14 01:21:51,207 epoch [800/800] time: 4.61s train loss: 0.0664 accuracy: 0.98 f1: 0.9799
2023-07-14 01:21:52,056 epoch [800/800] time: 0.85s val loss: 0.1453 accuracy: 0.9504 f1: 0.9494
2023-07-14 01:21:52,071 The model with best acc is saved: epoch 581, acc 0.98161875
2023-07-14 01:21:52,085 The model with best f1 is saved: epoch 581, f1 0.9814465432728017
2023-07-14 01:21:52,165 =======================================================
2023-07-14 01:21:52,165 Best acc classification report:
               precision    recall  f1-score   support

cluster_00205    0.90244   0.85648   0.87886       216
cluster_00222    0.81818   0.95858   0.88283       169
cluster_00232    0.92398   0.70536   0.80000       224
cluster_00246    0.68421   0.87565   0.76818       193
cluster_00259    0.87571   0.85635   0.86592       181
cluster_00261    0.93706   0.88158   0.90847       152
cluster_00262    0.89286   0.67873   0.77121       221
cluster_00267    0.90274   0.88922   0.89593       334
cluster_00275    0.86957   0.88889   0.87912       270
cluster_00276    0.79433   0.73684   0.76451       152
cluster_00278    0.90164   0.67901   0.77465       162
cluster_00287    0.66531   0.97024   0.78935       168
cluster_00291    0.86503   0.84940   0.85714       166
cluster_00293    0.83673   0.92830   0.88014       265
cluster_00294    0.76423   0.86239   0.81034       109
cluster_00296    0.76838   0.96759   0.85656       216
cluster_00298    0.85473   0.84053   0.84757       301
cluster_00299    0.78761   0.80180   0.79464       111
cluster_00300    0.71898   0.88739   0.79435       222
cluster_00303    0.88770   0.91209   0.89973       182
cluster_00304    0.80455   0.96721   0.87841       183
cluster_00319    0.80829   0.76471   0.78589       204
cluster_00322    0.73585   0.97806   0.83984       319
cluster_00333    0.88542   0.68548   0.77273       124
cluster_00338    0.86792   0.63448   0.73307       145
cluster_00340    0.91617   0.80526   0.85714       190
cluster_00344    0.83969   0.76389   0.80000       144
cluster_00346    0.78295   0.87069   0.82449       232
cluster_00350    0.82414   0.81570   0.81990       293
cluster_00352    0.82550   0.75460   0.78846       163
cluster_00359    0.88050   0.65421   0.75067       214
cluster_00360    0.86528   0.91257   0.88830       183
cluster_00361    0.88596   0.63522   0.73993       159
cluster_00365    0.95625   0.85475   0.90265       179
cluster_00368    0.77236   0.94527   0.85011       201
cluster_00373    0.73874   0.79227   0.76457       207
cluster_00374    0.93171   0.80252   0.86230       238
cluster_00375    0.82524   0.69388   0.75388       245
cluster_00377    0.84739   0.85772   0.85253       246
cluster_00380    0.84615   0.94444   0.89260       198
cluster_00385    0.83577   0.86742   0.85130       264
cluster_00388    0.73731   0.86364   0.79549       286
cluster_00389    0.83645   0.88177   0.85851       203
cluster_00390    0.90374   0.74449   0.81643       227
cluster_00394    0.86076   0.90066   0.88026       151
cluster_00400    0.75194   0.95098   0.83983       102
cluster_00401    0.90226   0.73171   0.80808       164
cluster_00405    0.74641   0.87640   0.80620       178
cluster_00407    0.82781   0.94340   0.88183       265
cluster_00408    0.94771   0.70048   0.80556       207
cluster_00409    0.68440   0.88128   0.77046       219
cluster_00412    0.92237   0.84167   0.88017       240
cluster_00445    0.89831   0.80916   0.85141       131
cluster_00473    0.93878   0.82143   0.87619       112
cluster_00585    0.82000   0.76995   0.79419       213
cluster_00589    0.65873   0.54605   0.59712       152
cluster_00591    0.81564   0.72637   0.76842       201
cluster_00593    0.69128   0.66026   0.67541       156
cluster_00596    0.64773   0.82014   0.72381       139
cluster_00603    0.73529   0.67568   0.70423       185
cluster_00604    0.92899   0.96319   0.94578       163
cluster_00607    0.86620   0.61809   0.72141       199
cluster_00612    0.78571   1.00000   0.88000       209
cluster_00616    0.86154   0.62454   0.72414       269
cluster_00619    0.69014   0.84000   0.75773       175
cluster_00629    0.64906   0.84314   0.73348       204
cluster_00630    0.86364   0.70370   0.77551       189
cluster_00635    0.83832   0.69652   0.76087       201
cluster_00637    0.84354   0.62944   0.72093       197
cluster_00639    0.90521   0.77959   0.83772       245
cluster_00642    0.77333   0.88776   0.82660       196
cluster_00645    0.79845   0.62805   0.70307       164
cluster_00647    0.73846   0.77838   0.75789       185
cluster_00652    0.69259   0.82743   0.75403       226
cluster_00653    0.76647   0.81529   0.79012       157
cluster_00656    0.78212   0.86957   0.82353       161
cluster_00657    0.82895   0.77778   0.80255       243
cluster_00661    0.64898   0.92982   0.76442       171
cluster_00662    0.84772   0.71064   0.77315       235
cluster_00667    0.80645   0.70423   0.75188       213
cluster_00762    0.85641   0.87435   0.86528       191
cluster_00201    0.99539   1.00000   0.99769       216
cluster_00217    0.81026   0.86813   0.83820       182
cluster_00239    0.93519   0.84874   0.88987       238
cluster_00320    0.85792   0.83957   0.84865       187
cluster_00391    0.85283   0.83088   0.84171       272
cluster_00398    0.89855   0.79487   0.84354       234
cluster_00415    0.85326   0.85326   0.85326       184
cluster_00477    0.72941   0.97895   0.83596       190
cluster_00478    0.92683   0.80423   0.86119       189
cluster_00479    0.98026   0.80978   0.88690       184
cluster_00078    0.72759   0.94196   0.82101       224
cluster_00079    0.67727   0.86127   0.75827       173
cluster_00083    0.76384   0.80859   0.78558       256
cluster_00090    0.56548   0.81897   0.66901       116
cluster_00094    0.66026   0.85833   0.74638       120
cluster_00096    0.87209   0.64655   0.74257       116
cluster_00101    0.84828   0.87234   0.86014       141
cluster_00086    0.78698   0.97436   0.87070       273
cluster_00095    0.84184   0.85938   0.85052       192
cluster_00097    0.91129   0.86260   0.88627       131
cluster_00106    0.94684   0.94684   0.94684       301
cluster_00553    0.87500   0.85909   0.86697       220
cluster_00554    0.82424   0.93151   0.87460       292
cluster_00569    0.91975   0.75253   0.82778       198
cluster_00015    0.95062   0.85556   0.90058        90
cluster_00017    0.83688   0.85818   0.84740       275
cluster_00018    0.89437   0.76506   0.82468       166
cluster_00023    0.92086   0.57143   0.70523       224
cluster_00025    0.79720   0.73077   0.76254       156
cluster_00030    0.85795   0.79058   0.82289       191
cluster_00035    0.72353   0.84828   0.78095       145
cluster_00039    0.68197   0.98113   0.80464       212
cluster_00042    0.90991   0.59412   0.71886       170
cluster_00046    0.89855   0.78481   0.83784       237
cluster_00055    0.89326   0.84127   0.86649       189
cluster_00059    0.92233   0.50802   0.65517       187
cluster_00061    0.90789   0.62443   0.73995       221
cluster_00274    0.89655   0.91228   0.90435       171
cluster_00308    0.78659   0.71667   0.75000       180
cluster_00337    0.87805   0.90000   0.88889       200
cluster_00362    0.87234   0.88172   0.87701       186
cluster_00369    0.93694   0.85246   0.89270       122
cluster_00392    0.82449   0.99020   0.89978       204
cluster_00414    0.81690   0.89922   0.85609       129
cluster_00419    0.80851   0.79832   0.80338       238
cluster_00420    0.71503   0.76667   0.73995       180
cluster_00421    0.93846   0.51695   0.66667       118
cluster_00422    0.65485   0.93898   0.77159       295
cluster_00427    0.71975   0.68072   0.69969       166
cluster_00430    0.62271   0.80952   0.70393       210
cluster_00431    0.86755   0.47810   0.61647       274
cluster_00436    0.95455   0.89840   0.92562       187
cluster_00439    0.80886   0.90402   0.85380       323
cluster_00444    0.93855   0.97110   0.95455       173
cluster_00447    0.71304   0.59420   0.64822       138
cluster_00448    0.83491   0.85507   0.84487       207
cluster_00450    0.54787   0.82731   0.65920       249
cluster_00456    0.83544   0.88000   0.85714       150
cluster_00458    0.67098   0.93502   0.78130       277
cluster_00460    0.87560   0.79221   0.83182       231
cluster_00463    0.76087   0.75000   0.75540       140
cluster_00467    0.74359   0.77852   0.76066       149
cluster_00483    0.78261   0.73171   0.75630       123
cluster_00484    0.90604   0.88816   0.89701       152
cluster_00007    0.81944   0.79195   0.80546       149
cluster_00036    0.79741   0.76763   0.78224       241
cluster_00054    1.00000   0.61475   0.76142       122
cluster_00062    0.65000   0.81250   0.72222       272
cluster_00064    0.94231   0.61250   0.74242       240
cluster_00065    0.96178   0.77436   0.85795       195
cluster_00067    0.76503   0.85890   0.80925       163
cluster_00071    0.80583   0.54248   0.64844       153
cluster_00075    0.82443   0.44813   0.58065       241
cluster_00084    0.85574   0.94565   0.89845       276
cluster_00093    0.70455   0.79082   0.74519       196
cluster_00001    0.81126   0.92453   0.86420       265
cluster_00002    0.90323   0.53846   0.67470       156
cluster_00003    0.71173   0.91176   0.79943       306
cluster_00006    0.87192   0.93158   0.90076       190
cluster_00008    0.82041   0.75000   0.78363       268
cluster_00010    0.74312   0.92571   0.82443       175
cluster_00012    0.84516   0.77515   0.80864       169
cluster_00019    0.93269   0.74046   0.82553       131
cluster_00022    0.84659   0.74500   0.79255       200
cluster_00026    0.92222   0.45355   0.60806       183
cluster_00029    0.90341   0.72603   0.80506       219
cluster_00031    0.74121   0.78378   0.76190       296
cluster_00043    0.87108   0.91912   0.89445       272
cluster_00051    0.94048   0.75238   0.83598       210
cluster_00052    0.67627   0.86402   0.75871       353
cluster_00073    0.80081   0.84549   0.82255       233
cluster_00076    0.82160   0.81395   0.81776       215
cluster_00082    0.85081   0.79026   0.81942       267
cluster_00107    0.96482   0.83478   0.89510       230
cluster_00432    0.87970   0.96694   0.92126       242
cluster_00440    0.80357   0.94142   0.86705       239
cluster_00455    0.87634   0.89560   0.88587       182
cluster_00714    0.82775   0.84804   0.83777       204
cluster_00791    0.82099   0.77778   0.79880       171
cluster_00119    0.94030   0.76518   0.84375       247
cluster_00121    0.96273   0.89080   0.92537       174
cluster_00155    0.93023   0.84507   0.88561       284
cluster_00556    0.80952   0.98222   0.88755       225
cluster_00557    0.91829   0.89057   0.90421       265
cluster_00689    0.96296   0.93274   0.94761       223
cluster_00692    0.97768   0.89754   0.93590       244
cluster_00718    0.90566   0.87671   0.89095       219
cluster_00725    0.93103   0.72193   0.81325       187
cluster_00727    0.84516   0.92254   0.88215       142
cluster_00729    0.95238   0.88435   0.91711       294
cluster_00733    1.00000   0.94737   0.97297       152
cluster_00738    0.87179   0.98837   0.92643       172
cluster_00740    0.97794   0.84177   0.90476       158
cluster_00744    0.85897   0.88546   0.87202       227
cluster_00753    0.87773   0.87391   0.87582       230
cluster_00777    0.83043   0.92271   0.87414       207
cluster_00795    0.79060   0.95855   0.86651       193

     accuracy                        0.82073     40000
    macro avg    0.83359   0.81536   0.81658     40000
 weighted avg    0.83293   0.82073   0.81907     40000

2023-07-14 01:21:52,165 =======================================================
2023-07-14 01:21:52,165 

2023-07-14 01:21:52,363 =======================================================
2023-07-14 01:21:52,363 Best f1 classification report:
               precision    recall  f1-score   support

cluster_00205    0.90244   0.85648   0.87886       216
cluster_00222    0.81818   0.95858   0.88283       169
cluster_00232    0.92398   0.70536   0.80000       224
cluster_00246    0.68421   0.87565   0.76818       193
cluster_00259    0.87571   0.85635   0.86592       181
cluster_00261    0.93706   0.88158   0.90847       152
cluster_00262    0.89286   0.67873   0.77121       221
cluster_00267    0.90274   0.88922   0.89593       334
cluster_00275    0.86957   0.88889   0.87912       270
cluster_00276    0.79433   0.73684   0.76451       152
cluster_00278    0.90164   0.67901   0.77465       162
cluster_00287    0.66531   0.97024   0.78935       168
cluster_00291    0.86503   0.84940   0.85714       166
cluster_00293    0.83673   0.92830   0.88014       265
cluster_00294    0.76423   0.86239   0.81034       109
cluster_00296    0.76838   0.96759   0.85656       216
cluster_00298    0.85473   0.84053   0.84757       301
cluster_00299    0.78761   0.80180   0.79464       111
cluster_00300    0.71898   0.88739   0.79435       222
cluster_00303    0.88770   0.91209   0.89973       182
cluster_00304    0.80455   0.96721   0.87841       183
cluster_00319    0.80829   0.76471   0.78589       204
cluster_00322    0.73585   0.97806   0.83984       319
cluster_00333    0.88542   0.68548   0.77273       124
cluster_00338    0.86792   0.63448   0.73307       145
cluster_00340    0.91617   0.80526   0.85714       190
cluster_00344    0.83969   0.76389   0.80000       144
cluster_00346    0.78295   0.87069   0.82449       232
cluster_00350    0.82414   0.81570   0.81990       293
cluster_00352    0.82550   0.75460   0.78846       163
cluster_00359    0.88050   0.65421   0.75067       214
cluster_00360    0.86528   0.91257   0.88830       183
cluster_00361    0.88596   0.63522   0.73993       159
cluster_00365    0.95625   0.85475   0.90265       179
cluster_00368    0.77236   0.94527   0.85011       201
cluster_00373    0.73874   0.79227   0.76457       207
cluster_00374    0.93171   0.80252   0.86230       238
cluster_00375    0.82524   0.69388   0.75388       245
cluster_00377    0.84739   0.85772   0.85253       246
cluster_00380    0.84615   0.94444   0.89260       198
cluster_00385    0.83577   0.86742   0.85130       264
cluster_00388    0.73731   0.86364   0.79549       286
cluster_00389    0.83645   0.88177   0.85851       203
cluster_00390    0.90374   0.74449   0.81643       227
cluster_00394    0.86076   0.90066   0.88026       151
cluster_00400    0.75194   0.95098   0.83983       102
cluster_00401    0.90226   0.73171   0.80808       164
cluster_00405    0.74641   0.87640   0.80620       178
cluster_00407    0.82781   0.94340   0.88183       265
cluster_00408    0.94771   0.70048   0.80556       207
cluster_00409    0.68440   0.88128   0.77046       219
cluster_00412    0.92237   0.84167   0.88017       240
cluster_00445    0.89831   0.80916   0.85141       131
cluster_00473    0.93878   0.82143   0.87619       112
cluster_00585    0.82000   0.76995   0.79419       213
cluster_00589    0.65873   0.54605   0.59712       152
cluster_00591    0.81564   0.72637   0.76842       201
cluster_00593    0.69128   0.66026   0.67541       156
cluster_00596    0.64773   0.82014   0.72381       139
cluster_00603    0.73529   0.67568   0.70423       185
cluster_00604    0.92899   0.96319   0.94578       163
cluster_00607    0.86620   0.61809   0.72141       199
cluster_00612    0.78571   1.00000   0.88000       209
cluster_00616    0.86154   0.62454   0.72414       269
cluster_00619    0.69014   0.84000   0.75773       175
cluster_00629    0.64906   0.84314   0.73348       204
cluster_00630    0.86364   0.70370   0.77551       189
cluster_00635    0.83832   0.69652   0.76087       201
cluster_00637    0.84354   0.62944   0.72093       197
cluster_00639    0.90521   0.77959   0.83772       245
cluster_00642    0.77333   0.88776   0.82660       196
cluster_00645    0.79845   0.62805   0.70307       164
cluster_00647    0.73846   0.77838   0.75789       185
cluster_00652    0.69259   0.82743   0.75403       226
cluster_00653    0.76647   0.81529   0.79012       157
cluster_00656    0.78212   0.86957   0.82353       161
cluster_00657    0.82895   0.77778   0.80255       243
cluster_00661    0.64898   0.92982   0.76442       171
cluster_00662    0.84772   0.71064   0.77315       235
cluster_00667    0.80645   0.70423   0.75188       213
cluster_00762    0.85641   0.87435   0.86528       191
cluster_00201    0.99539   1.00000   0.99769       216
cluster_00217    0.81026   0.86813   0.83820       182
cluster_00239    0.93519   0.84874   0.88987       238
cluster_00320    0.85792   0.83957   0.84865       187
cluster_00391    0.85283   0.83088   0.84171       272
cluster_00398    0.89855   0.79487   0.84354       234
cluster_00415    0.85326   0.85326   0.85326       184
cluster_00477    0.72941   0.97895   0.83596       190
cluster_00478    0.92683   0.80423   0.86119       189
cluster_00479    0.98026   0.80978   0.88690       184
cluster_00078    0.72759   0.94196   0.82101       224
cluster_00079    0.67727   0.86127   0.75827       173
cluster_00083    0.76384   0.80859   0.78558       256
cluster_00090    0.56548   0.81897   0.66901       116
cluster_00094    0.66026   0.85833   0.74638       120
cluster_00096    0.87209   0.64655   0.74257       116
cluster_00101    0.84828   0.87234   0.86014       141
cluster_00086    0.78698   0.97436   0.87070       273
cluster_00095    0.84184   0.85938   0.85052       192
cluster_00097    0.91129   0.86260   0.88627       131
cluster_00106    0.94684   0.94684   0.94684       301
cluster_00553    0.87500   0.85909   0.86697       220
cluster_00554    0.82424   0.93151   0.87460       292
cluster_00569    0.91975   0.75253   0.82778       198
cluster_00015    0.95062   0.85556   0.90058        90
cluster_00017    0.83688   0.85818   0.84740       275
cluster_00018    0.89437   0.76506   0.82468       166
cluster_00023    0.92086   0.57143   0.70523       224
cluster_00025    0.79720   0.73077   0.76254       156
cluster_00030    0.85795   0.79058   0.82289       191
cluster_00035    0.72353   0.84828   0.78095       145
cluster_00039    0.68197   0.98113   0.80464       212
cluster_00042    0.90991   0.59412   0.71886       170
cluster_00046    0.89855   0.78481   0.83784       237
cluster_00055    0.89326   0.84127   0.86649       189
cluster_00059    0.92233   0.50802   0.65517       187
cluster_00061    0.90789   0.62443   0.73995       221
cluster_00274    0.89655   0.91228   0.90435       171
cluster_00308    0.78659   0.71667   0.75000       180
cluster_00337    0.87805   0.90000   0.88889       200
cluster_00362    0.87234   0.88172   0.87701       186
cluster_00369    0.93694   0.85246   0.89270       122
cluster_00392    0.82449   0.99020   0.89978       204
cluster_00414    0.81690   0.89922   0.85609       129
cluster_00419    0.80851   0.79832   0.80338       238
cluster_00420    0.71503   0.76667   0.73995       180
cluster_00421    0.93846   0.51695   0.66667       118
cluster_00422    0.65485   0.93898   0.77159       295
cluster_00427    0.71975   0.68072   0.69969       166
cluster_00430    0.62271   0.80952   0.70393       210
cluster_00431    0.86755   0.47810   0.61647       274
cluster_00436    0.95455   0.89840   0.92562       187
cluster_00439    0.80886   0.90402   0.85380       323
cluster_00444    0.93855   0.97110   0.95455       173
cluster_00447    0.71304   0.59420   0.64822       138
cluster_00448    0.83491   0.85507   0.84487       207
cluster_00450    0.54787   0.82731   0.65920       249
cluster_00456    0.83544   0.88000   0.85714       150
cluster_00458    0.67098   0.93502   0.78130       277
cluster_00460    0.87560   0.79221   0.83182       231
cluster_00463    0.76087   0.75000   0.75540       140
cluster_00467    0.74359   0.77852   0.76066       149
cluster_00483    0.78261   0.73171   0.75630       123
cluster_00484    0.90604   0.88816   0.89701       152
cluster_00007    0.81944   0.79195   0.80546       149
cluster_00036    0.79741   0.76763   0.78224       241
cluster_00054    1.00000   0.61475   0.76142       122
cluster_00062    0.65000   0.81250   0.72222       272
cluster_00064    0.94231   0.61250   0.74242       240
cluster_00065    0.96178   0.77436   0.85795       195
cluster_00067    0.76503   0.85890   0.80925       163
cluster_00071    0.80583   0.54248   0.64844       153
cluster_00075    0.82443   0.44813   0.58065       241
cluster_00084    0.85574   0.94565   0.89845       276
cluster_00093    0.70455   0.79082   0.74519       196
cluster_00001    0.81126   0.92453   0.86420       265
cluster_00002    0.90323   0.53846   0.67470       156
cluster_00003    0.71173   0.91176   0.79943       306
cluster_00006    0.87192   0.93158   0.90076       190
cluster_00008    0.82041   0.75000   0.78363       268
cluster_00010    0.74312   0.92571   0.82443       175
cluster_00012    0.84516   0.77515   0.80864       169
cluster_00019    0.93269   0.74046   0.82553       131
cluster_00022    0.84659   0.74500   0.79255       200
cluster_00026    0.92222   0.45355   0.60806       183
cluster_00029    0.90341   0.72603   0.80506       219
cluster_00031    0.74121   0.78378   0.76190       296
cluster_00043    0.87108   0.91912   0.89445       272
cluster_00051    0.94048   0.75238   0.83598       210
cluster_00052    0.67627   0.86402   0.75871       353
cluster_00073    0.80081   0.84549   0.82255       233
cluster_00076    0.82160   0.81395   0.81776       215
cluster_00082    0.85081   0.79026   0.81942       267
cluster_00107    0.96482   0.83478   0.89510       230
cluster_00432    0.87970   0.96694   0.92126       242
cluster_00440    0.80357   0.94142   0.86705       239
cluster_00455    0.87634   0.89560   0.88587       182
cluster_00714    0.82775   0.84804   0.83777       204
cluster_00791    0.82099   0.77778   0.79880       171
cluster_00119    0.94030   0.76518   0.84375       247
cluster_00121    0.96273   0.89080   0.92537       174
cluster_00155    0.93023   0.84507   0.88561       284
cluster_00556    0.80952   0.98222   0.88755       225
cluster_00557    0.91829   0.89057   0.90421       265
cluster_00689    0.96296   0.93274   0.94761       223
cluster_00692    0.97768   0.89754   0.93590       244
cluster_00718    0.90566   0.87671   0.89095       219
cluster_00725    0.93103   0.72193   0.81325       187
cluster_00727    0.84516   0.92254   0.88215       142
cluster_00729    0.95238   0.88435   0.91711       294
cluster_00733    1.00000   0.94737   0.97297       152
cluster_00738    0.87179   0.98837   0.92643       172
cluster_00740    0.97794   0.84177   0.90476       158
cluster_00744    0.85897   0.88546   0.87202       227
cluster_00753    0.87773   0.87391   0.87582       230
cluster_00777    0.83043   0.92271   0.87414       207
cluster_00795    0.79060   0.95855   0.86651       193

     accuracy                        0.82073     40000
    macro avg    0.83359   0.81536   0.81658     40000
 weighted avg    0.83293   0.82073   0.81907     40000

2023-07-14 01:21:52,363 =======================================================
2023-07-14 01:21:52,363 

2023-07-14 01:21:53,085 =======================================================
2023-07-14 01:21:53,085 Best acc classification report:
               precision    recall  f1-score   support

cluster_00205    0.98166   0.98272   0.98219       926
cluster_00222    0.99081   0.98930   0.99005       654
cluster_00232    0.97333   0.97134   0.97234       977
cluster_00246    0.97211   0.97483   0.97346       715
cluster_00259    0.98243   0.97584   0.97912       745
cluster_00261    0.98759   0.99110   0.98934       562
cluster_00262    0.97603   0.97391   0.97497       920
cluster_00267    0.97851   0.98486   0.98167      1387
cluster_00275    0.97238   0.97483   0.97361      1192
cluster_00276    0.98270   0.99049   0.98658       631
cluster_00278    0.97698   0.95499   0.96586       711
cluster_00287    0.97923   0.97778   0.97850       675
cluster_00291    0.98849   0.97863   0.98354       702
cluster_00293    0.97639   0.98353   0.97995      1093
cluster_00294    0.98829   0.98140   0.98483       430
cluster_00296    0.98519   0.98519   0.98519       675
cluster_00298    0.97467   0.97169   0.97318      1307
cluster_00299    0.97541   0.95968   0.96748       496
cluster_00300    0.97029   0.97251   0.97140       873
cluster_00303    0.98340   0.98750   0.98545       720
cluster_00304    0.99163   0.98887   0.99025       719
cluster_00319    0.97457   0.97683   0.97569       863
cluster_00322    0.98326   0.97809   0.98067      1141
cluster_00333    0.96219   0.95318   0.95767       534
cluster_00338    0.97807   0.97664   0.97736       685
cluster_00340    0.97792   0.98175   0.97983       767
cluster_00344    0.95966   0.96453   0.96209       592
cluster_00346    0.98616   0.98406   0.98511       941
cluster_00350    0.97550   0.97816   0.97683      1099
cluster_00352    0.97838   0.96964   0.97399       560
cluster_00359    0.95932   0.96821   0.96374       755
cluster_00360    0.97458   0.97458   0.97458       826
cluster_00361    0.96494   0.96347   0.96420       657
cluster_00365    0.99040   0.98449   0.98743       838
cluster_00368    0.96809   0.97849   0.97326       837
cluster_00373    0.96974   0.96575   0.96774       730
cluster_00374    0.98650   0.97553   0.98098       899
cluster_00375    0.96923   0.96830   0.96877      1041
cluster_00377    0.96150   0.97303   0.96723      1001
cluster_00380    0.98433   0.98573   0.98503       701
cluster_00385    0.98801   0.98604   0.98703      1003
cluster_00388    0.97382   0.97629   0.97505      1181
cluster_00389    0.95812   0.94730   0.95268       797
cluster_00390    0.99194   0.98967   0.99080       871
cluster_00394    0.96914   0.97063   0.96988       647
cluster_00400    0.98026   0.98458   0.98242       454
cluster_00401    0.96934   0.96652   0.96793       687
cluster_00405    0.97152   0.97306   0.97229       631
cluster_00407    0.98448   0.98353   0.98400      1032
cluster_00408    0.96355   0.97130   0.96741       871
cluster_00409    0.96388   0.97597   0.96989       957
cluster_00412    0.97985   0.98193   0.98089       941
cluster_00445    0.96750   0.96935   0.96842       522
cluster_00473    0.97917   0.96509   0.97208       487
cluster_00585    0.97062   0.97062   0.97062       851
cluster_00589    0.98087   0.98258   0.98172       574
cluster_00591    0.98460   0.98840   0.98650       776
cluster_00593    0.98126   0.97133   0.97627       593
cluster_00596    0.97989   0.98349   0.98168       545
cluster_00603    0.97781   0.98053   0.97917       719
cluster_00604    0.98783   0.99127   0.98955       573
cluster_00607    0.98487   0.97503   0.97992       801
cluster_00612    0.99630   0.99018   0.99323       815
cluster_00616    0.97935   0.97722   0.97828       922
cluster_00619    0.96897   0.97447   0.97171       705
cluster_00629    0.98758   0.98647   0.98703       887
cluster_00630    0.98821   0.99054   0.98937       846
cluster_00635    0.98062   0.98444   0.98252       771
cluster_00637    0.96041   0.97032   0.96534       775
cluster_00639    0.98669   0.98569   0.98619       978
cluster_00642    0.98475   0.98690   0.98582       916
cluster_00645    0.97472   0.97063   0.97267       715
cluster_00647    0.96447   0.95839   0.96142       793
cluster_00652    0.97968   0.97858   0.97913       887
cluster_00653    0.99677   0.98880   0.99277       625
cluster_00656    0.98743   0.97922   0.98331       722
cluster_00657    0.96304   0.96304   0.96304       920
cluster_00661    0.98222   0.98898   0.98559       726
cluster_00662    0.98232   0.98814   0.98522      1012
cluster_00667    0.98319   0.99153   0.98734       826
cluster_00762    0.98400   0.99194   0.98795       744
cluster_00201    1.00000   1.00000   1.00000       831
cluster_00217    0.98599   0.98876   0.98738       712
cluster_00239    0.98967   0.98740   0.98853       873
cluster_00320    0.97991   0.97571   0.97781       700
cluster_00391    0.98100   0.98635   0.98367      1099
cluster_00398    0.98808   0.98223   0.98515      1013
cluster_00415    0.97940   0.98345   0.98142       725
cluster_00477    0.97316   0.98148   0.97730       702
cluster_00478    0.98525   0.98131   0.98328       749
cluster_00479    0.99515   0.98560   0.99035       625
cluster_00078    0.97619   0.97064   0.97341      1056
cluster_00079    0.95622   0.95622   0.95622       731
cluster_00083    0.97116   0.97530   0.97323      1174
cluster_00090    0.95955   0.97489   0.96716       438
cluster_00094    0.95155   0.95155   0.95155       516
cluster_00096    0.97934   0.98545   0.98238       481
cluster_00101    0.99042   0.98664   0.98853       524
cluster_00086    0.99740   0.99568   0.99654      1158
cluster_00095    0.99046   0.99165   0.99106       838
cluster_00097    0.98956   0.99789   0.99371       475
cluster_00106    0.99498   0.99249   0.99374      1199
cluster_00553    0.99392   0.99513   0.99452       821
cluster_00554    0.99317   0.99317   0.99317      1171
cluster_00569    0.98923   0.98570   0.98746       839
cluster_00015    0.99223   0.97455   0.98331       393
cluster_00017    0.97725   0.96536   0.97127      1068
cluster_00018    0.96743   0.98020   0.97377       606
cluster_00023    0.97031   0.97031   0.97031       943
cluster_00025    0.97689   0.98142   0.97915       646
cluster_00030    0.96719   0.95839   0.96277       769
cluster_00035    0.97418   0.98094   0.97755       577
cluster_00039    0.97297   0.97693   0.97495       737
cluster_00042    0.97211   0.97340   0.97276       752
cluster_00046    0.97174   0.98242   0.97705       910
cluster_00055    0.97098   0.98264   0.97678       749
cluster_00059    0.98007   0.97096   0.97550       861
cluster_00061    0.99339   0.99078   0.99208       759
cluster_00274    0.98479   0.98729   0.98604       787
cluster_00308    0.97372   0.96571   0.96970       729
cluster_00337    0.99439   0.99300   0.99369       714
cluster_00362    0.98452   0.98452   0.98452       775
cluster_00369    0.98646   0.99222   0.98933       514
cluster_00392    0.99052   0.99052   0.99052       844
cluster_00414    0.98367   0.98973   0.98669       487
cluster_00419    0.97260   0.97819   0.97539       871
cluster_00420    0.97622   0.98271   0.97946       752
cluster_00421    0.99358   0.98305   0.98829       472
cluster_00422    0.97452   0.96761   0.97105       988
cluster_00427    0.97545   0.97386   0.97465       612
cluster_00430    0.96204   0.96413   0.96308       920
cluster_00431    0.95709   0.97065   0.96382       988
cluster_00436    0.98978   0.99359   0.99168       780
cluster_00439    0.98979   0.98393   0.98685      1182
cluster_00444    0.99637   0.99879   0.99758       825
cluster_00447    0.98628   0.96965   0.97789       593
cluster_00448    0.98146   0.98634   0.98389       805
cluster_00450    0.97104   0.97955   0.97528      1027
cluster_00456    0.99060   0.98505   0.98782       535
cluster_00458    0.98130   0.97350   0.97738      1132
cluster_00460    0.98057   0.98184   0.98121       771
cluster_00463    0.97690   0.97851   0.97770       605
cluster_00467    0.98071   0.98865   0.98467       617
cluster_00483    0.98617   0.98812   0.98714       505
cluster_00484    0.98899   0.97645   0.98268       552
cluster_00007    0.98961   0.98815   0.98888       675
cluster_00036    0.97404   0.97686   0.97545      1037
cluster_00054    0.99042   0.98289   0.98664       526
cluster_00062    0.96273   0.96068   0.96170       941
cluster_00064    0.98088   0.97539   0.97813       894
cluster_00065    0.98128   0.98656   0.98391       744
cluster_00067    0.96864   0.96528   0.96696       576
cluster_00071    0.96881   0.95826   0.96350       551
cluster_00075    0.96682   0.96904   0.96793       872
cluster_00084    0.98563   0.97628   0.98093      1054
cluster_00093    0.97661   0.97770   0.97716       897
cluster_00001    0.98829   0.98926   0.98878      1024
cluster_00002    0.98671   0.97804   0.98235       683
cluster_00003    0.98203   0.97851   0.98027      1117
cluster_00006    0.99873   0.99494   0.99683       790
cluster_00008    0.98051   0.99143   0.98594      1167
cluster_00010    0.98282   0.98282   0.98282       873
cluster_00012    0.97956   0.98822   0.98387       679
cluster_00019    0.98720   0.99083   0.98901       545
cluster_00022    0.97230   0.96466   0.96846       764
cluster_00026    0.97571   0.97571   0.97571       741
cluster_00029    0.97078   0.97819   0.97447       917
cluster_00031    0.97800   0.97532   0.97666      1094
cluster_00043    0.99730   0.99730   0.99730      1110
cluster_00051    0.98588   0.99225   0.98905       774
cluster_00052    0.98087   0.97871   0.97979      1362
cluster_00073    0.98103   0.98519   0.98310       945
cluster_00076    0.98439   0.98330   0.98384       898
cluster_00082    0.98344   0.98429   0.98386      1146
cluster_00107    0.99323   0.99548   0.99435       884
cluster_00432    0.99708   0.99224   0.99465      1031
cluster_00440    0.99498   0.99101   0.99299      1001
cluster_00455    0.98549   0.99414   0.98980       683
cluster_00714    0.99668   0.99558   0.99613       904
cluster_00791    0.99435   0.99576   0.99505       707
cluster_00119    0.99421   0.99306   0.99364       865
cluster_00121    0.99733   0.99866   0.99799       747
cluster_00155    0.99713   0.99809   0.99761      1046
cluster_00556    1.00000   0.99339   0.99669       908
cluster_00557    0.99739   0.99826   0.99782      1147
cluster_00689    0.99894   0.99789   0.99842       948
cluster_00692    0.99568   0.99675   0.99621       924
cluster_00718    0.99185   0.99649   0.99417       855
cluster_00725    0.99856   0.99713   0.99784       696
cluster_00727    0.99495   0.99663   0.99579       593
cluster_00729    0.99554   0.99732   0.99643      1120
cluster_00733    0.99831   0.99831   0.99831       590
cluster_00738    1.00000   0.99690   0.99845       646
cluster_00740    0.99517   0.99677   0.99597       620
cluster_00744    0.99682   0.99576   0.99629       943
cluster_00753    0.99427   0.99541   0.99484       871
cluster_00777    0.99765   0.99882   0.99824       850
cluster_00795    0.99866   0.99599   0.99732       748

     accuracy                        0.98162    160000
    macro avg    0.98153   0.98138   0.98145    160000
 weighted avg    0.98164   0.98162   0.98162    160000

2023-07-14 01:21:53,085 =======================================================
2023-07-14 01:21:53,085 

2023-07-14 01:21:54,458 =======================================================
2023-07-14 01:21:54,458 Best f1 classification report:
               precision    recall  f1-score   support

cluster_00205    0.98166   0.98272   0.98219       926
cluster_00222    0.99081   0.98930   0.99005       654
cluster_00232    0.97333   0.97134   0.97234       977
cluster_00246    0.97211   0.97483   0.97346       715
cluster_00259    0.98243   0.97584   0.97912       745
cluster_00261    0.98759   0.99110   0.98934       562
cluster_00262    0.97603   0.97391   0.97497       920
cluster_00267    0.97851   0.98486   0.98167      1387
cluster_00275    0.97238   0.97483   0.97361      1192
cluster_00276    0.98270   0.99049   0.98658       631
cluster_00278    0.97698   0.95499   0.96586       711
cluster_00287    0.97923   0.97778   0.97850       675
cluster_00291    0.98849   0.97863   0.98354       702
cluster_00293    0.97639   0.98353   0.97995      1093
cluster_00294    0.98829   0.98140   0.98483       430
cluster_00296    0.98519   0.98519   0.98519       675
cluster_00298    0.97467   0.97169   0.97318      1307
cluster_00299    0.97541   0.95968   0.96748       496
cluster_00300    0.97029   0.97251   0.97140       873
cluster_00303    0.98340   0.98750   0.98545       720
cluster_00304    0.99163   0.98887   0.99025       719
cluster_00319    0.97457   0.97683   0.97569       863
cluster_00322    0.98326   0.97809   0.98067      1141
cluster_00333    0.96219   0.95318   0.95767       534
cluster_00338    0.97807   0.97664   0.97736       685
cluster_00340    0.97792   0.98175   0.97983       767
cluster_00344    0.95966   0.96453   0.96209       592
cluster_00346    0.98616   0.98406   0.98511       941
cluster_00350    0.97550   0.97816   0.97683      1099
cluster_00352    0.97838   0.96964   0.97399       560
cluster_00359    0.95932   0.96821   0.96374       755
cluster_00360    0.97458   0.97458   0.97458       826
cluster_00361    0.96494   0.96347   0.96420       657
cluster_00365    0.99040   0.98449   0.98743       838
cluster_00368    0.96809   0.97849   0.97326       837
cluster_00373    0.96974   0.96575   0.96774       730
cluster_00374    0.98650   0.97553   0.98098       899
cluster_00375    0.96923   0.96830   0.96877      1041
cluster_00377    0.96150   0.97303   0.96723      1001
cluster_00380    0.98433   0.98573   0.98503       701
cluster_00385    0.98801   0.98604   0.98703      1003
cluster_00388    0.97382   0.97629   0.97505      1181
cluster_00389    0.95812   0.94730   0.95268       797
cluster_00390    0.99194   0.98967   0.99080       871
cluster_00394    0.96914   0.97063   0.96988       647
cluster_00400    0.98026   0.98458   0.98242       454
cluster_00401    0.96934   0.96652   0.96793       687
cluster_00405    0.97152   0.97306   0.97229       631
cluster_00407    0.98448   0.98353   0.98400      1032
cluster_00408    0.96355   0.97130   0.96741       871
cluster_00409    0.96388   0.97597   0.96989       957
cluster_00412    0.97985   0.98193   0.98089       941
cluster_00445    0.96750   0.96935   0.96842       522
cluster_00473    0.97917   0.96509   0.97208       487
cluster_00585    0.97062   0.97062   0.97062       851
cluster_00589    0.98087   0.98258   0.98172       574
cluster_00591    0.98460   0.98840   0.98650       776
cluster_00593    0.98126   0.97133   0.97627       593
cluster_00596    0.97989   0.98349   0.98168       545
cluster_00603    0.97781   0.98053   0.97917       719
cluster_00604    0.98783   0.99127   0.98955       573
cluster_00607    0.98487   0.97503   0.97992       801
cluster_00612    0.99630   0.99018   0.99323       815
cluster_00616    0.97935   0.97722   0.97828       922
cluster_00619    0.96897   0.97447   0.97171       705
cluster_00629    0.98758   0.98647   0.98703       887
cluster_00630    0.98821   0.99054   0.98937       846
cluster_00635    0.98062   0.98444   0.98252       771
cluster_00637    0.96041   0.97032   0.96534       775
cluster_00639    0.98669   0.98569   0.98619       978
cluster_00642    0.98475   0.98690   0.98582       916
cluster_00645    0.97472   0.97063   0.97267       715
cluster_00647    0.96447   0.95839   0.96142       793
cluster_00652    0.97968   0.97858   0.97913       887
cluster_00653    0.99677   0.98880   0.99277       625
cluster_00656    0.98743   0.97922   0.98331       722
cluster_00657    0.96304   0.96304   0.96304       920
cluster_00661    0.98222   0.98898   0.98559       726
cluster_00662    0.98232   0.98814   0.98522      1012
cluster_00667    0.98319   0.99153   0.98734       826
cluster_00762    0.98400   0.99194   0.98795       744
cluster_00201    1.00000   1.00000   1.00000       831
cluster_00217    0.98599   0.98876   0.98738       712
cluster_00239    0.98967   0.98740   0.98853       873
cluster_00320    0.97991   0.97571   0.97781       700
cluster_00391    0.98100   0.98635   0.98367      1099
cluster_00398    0.98808   0.98223   0.98515      1013
cluster_00415    0.97940   0.98345   0.98142       725
cluster_00477    0.97316   0.98148   0.97730       702
cluster_00478    0.98525   0.98131   0.98328       749
cluster_00479    0.99515   0.98560   0.99035       625
cluster_00078    0.97619   0.97064   0.97341      1056
cluster_00079    0.95622   0.95622   0.95622       731
cluster_00083    0.97116   0.97530   0.97323      1174
cluster_00090    0.95955   0.97489   0.96716       438
cluster_00094    0.95155   0.95155   0.95155       516
cluster_00096    0.97934   0.98545   0.98238       481
cluster_00101    0.99042   0.98664   0.98853       524
cluster_00086    0.99740   0.99568   0.99654      1158
cluster_00095    0.99046   0.99165   0.99106       838
cluster_00097    0.98956   0.99789   0.99371       475
cluster_00106    0.99498   0.99249   0.99374      1199
cluster_00553    0.99392   0.99513   0.99452       821
cluster_00554    0.99317   0.99317   0.99317      1171
cluster_00569    0.98923   0.98570   0.98746       839
cluster_00015    0.99223   0.97455   0.98331       393
cluster_00017    0.97725   0.96536   0.97127      1068
cluster_00018    0.96743   0.98020   0.97377       606
cluster_00023    0.97031   0.97031   0.97031       943
cluster_00025    0.97689   0.98142   0.97915       646
cluster_00030    0.96719   0.95839   0.96277       769
cluster_00035    0.97418   0.98094   0.97755       577
cluster_00039    0.97297   0.97693   0.97495       737
cluster_00042    0.97211   0.97340   0.97276       752
cluster_00046    0.97174   0.98242   0.97705       910
cluster_00055    0.97098   0.98264   0.97678       749
cluster_00059    0.98007   0.97096   0.97550       861
cluster_00061    0.99339   0.99078   0.99208       759
cluster_00274    0.98479   0.98729   0.98604       787
cluster_00308    0.97372   0.96571   0.96970       729
cluster_00337    0.99439   0.99300   0.99369       714
cluster_00362    0.98452   0.98452   0.98452       775
cluster_00369    0.98646   0.99222   0.98933       514
cluster_00392    0.99052   0.99052   0.99052       844
cluster_00414    0.98367   0.98973   0.98669       487
cluster_00419    0.97260   0.97819   0.97539       871
cluster_00420    0.97622   0.98271   0.97946       752
cluster_00421    0.99358   0.98305   0.98829       472
cluster_00422    0.97452   0.96761   0.97105       988
cluster_00427    0.97545   0.97386   0.97465       612
cluster_00430    0.96204   0.96413   0.96308       920
cluster_00431    0.95709   0.97065   0.96382       988
cluster_00436    0.98978   0.99359   0.99168       780
cluster_00439    0.98979   0.98393   0.98685      1182
cluster_00444    0.99637   0.99879   0.99758       825
cluster_00447    0.98628   0.96965   0.97789       593
cluster_00448    0.98146   0.98634   0.98389       805
cluster_00450    0.97104   0.97955   0.97528      1027
cluster_00456    0.99060   0.98505   0.98782       535
cluster_00458    0.98130   0.97350   0.97738      1132
cluster_00460    0.98057   0.98184   0.98121       771
cluster_00463    0.97690   0.97851   0.97770       605
cluster_00467    0.98071   0.98865   0.98467       617
cluster_00483    0.98617   0.98812   0.98714       505
cluster_00484    0.98899   0.97645   0.98268       552
cluster_00007    0.98961   0.98815   0.98888       675
cluster_00036    0.97404   0.97686   0.97545      1037
cluster_00054    0.99042   0.98289   0.98664       526
cluster_00062    0.96273   0.96068   0.96170       941
cluster_00064    0.98088   0.97539   0.97813       894
cluster_00065    0.98128   0.98656   0.98391       744
cluster_00067    0.96864   0.96528   0.96696       576
cluster_00071    0.96881   0.95826   0.96350       551
cluster_00075    0.96682   0.96904   0.96793       872
cluster_00084    0.98563   0.97628   0.98093      1054
cluster_00093    0.97661   0.97770   0.97716       897
cluster_00001    0.98829   0.98926   0.98878      1024
cluster_00002    0.98671   0.97804   0.98235       683
cluster_00003    0.98203   0.97851   0.98027      1117
cluster_00006    0.99873   0.99494   0.99683       790
cluster_00008    0.98051   0.99143   0.98594      1167
cluster_00010    0.98282   0.98282   0.98282       873
cluster_00012    0.97956   0.98822   0.98387       679
cluster_00019    0.98720   0.99083   0.98901       545
cluster_00022    0.97230   0.96466   0.96846       764
cluster_00026    0.97571   0.97571   0.97571       741
cluster_00029    0.97078   0.97819   0.97447       917
cluster_00031    0.97800   0.97532   0.97666      1094
cluster_00043    0.99730   0.99730   0.99730      1110
cluster_00051    0.98588   0.99225   0.98905       774
cluster_00052    0.98087   0.97871   0.97979      1362
cluster_00073    0.98103   0.98519   0.98310       945
cluster_00076    0.98439   0.98330   0.98384       898
cluster_00082    0.98344   0.98429   0.98386      1146
cluster_00107    0.99323   0.99548   0.99435       884
cluster_00432    0.99708   0.99224   0.99465      1031
cluster_00440    0.99498   0.99101   0.99299      1001
cluster_00455    0.98549   0.99414   0.98980       683
cluster_00714    0.99668   0.99558   0.99613       904
cluster_00791    0.99435   0.99576   0.99505       707
cluster_00119    0.99421   0.99306   0.99364       865
cluster_00121    0.99733   0.99866   0.99799       747
cluster_00155    0.99713   0.99809   0.99761      1046
cluster_00556    1.00000   0.99339   0.99669       908
cluster_00557    0.99739   0.99826   0.99782      1147
cluster_00689    0.99894   0.99789   0.99842       948
cluster_00692    0.99568   0.99675   0.99621       924
cluster_00718    0.99185   0.99649   0.99417       855
cluster_00725    0.99856   0.99713   0.99784       696
cluster_00727    0.99495   0.99663   0.99579       593
cluster_00729    0.99554   0.99732   0.99643      1120
cluster_00733    0.99831   0.99831   0.99831       590
cluster_00738    1.00000   0.99690   0.99845       646
cluster_00740    0.99517   0.99677   0.99597       620
cluster_00744    0.99682   0.99576   0.99629       943
cluster_00753    0.99427   0.99541   0.99484       871
cluster_00777    0.99765   0.99882   0.99824       850
cluster_00795    0.99866   0.99599   0.99732       748

     accuracy                        0.98162    160000
    macro avg    0.98153   0.98138   0.98145    160000
 weighted avg    0.98164   0.98162   0.98162    160000

2023-07-14 01:21:54,458 =======================================================
2023-07-14 01:21:54,458 

2023-07-14 01:21:55,212 Total processing time is 4516.14s
2023-07-14 01:21:55,214 =======================================================
2023-07-14 01:21:55,214 Namespace(T_0=10, T_mult=2, best_metric='f1', decay_factor=0.5, epoch=800, eval_fold_zero=False, input_path='***', k_fold=5, lr=0.001, manualSeed=0, momentum=0, num_workers=4, opt='Adam', out_path='***', out_path_base='***', redistribute_class=True, scheduler='step', step_size=20, train_batch_size=2048, val_batch_size=1024, weight_decay=0.0)
2023-07-14 01:21:55,214 =======================================================
2023-07-14 01:21:55,214 Implement 3 fold experiment
2023-07-14 01:21:55,562 use [1, 2, 4, 5] fold as train data
2023-07-14 01:21:55,562 The size of feature for train is (160000, 15, 3)
2023-07-14 01:21:55,614 use 3 fold as validation data
2023-07-14 01:21:55,614 The size of feature for val is (40000, 15, 3)
2023-07-14 01:21:55,631 The training data size is:160000
2023-07-14 01:21:55,631 The validation data size is:40000
2023-07-14 01:21:55,631 The number of classes is:198
2023-07-14 01:21:55,632 The label names are: [b'cluster_00205', b'cluster_00222', b'cluster_00232', b'cluster_00246', b'cluster_00259', b'cluster_00261', b'cluster_00262', b'cluster_00267', b'cluster_00275', b'cluster_00276', b'cluster_00278', b'cluster_00287', b'cluster_00291', b'cluster_00293', b'cluster_00294', b'cluster_00296', b'cluster_00298', b'cluster_00299', b'cluster_00300', b'cluster_00303', b'cluster_00304', b'cluster_00319', b'cluster_00322', b'cluster_00333', b'cluster_00338', b'cluster_00340', b'cluster_00344', b'cluster_00346', b'cluster_00350', b'cluster_00352', b'cluster_00359', b'cluster_00360', b'cluster_00361', b'cluster_00365', b'cluster_00368', b'cluster_00373', b'cluster_00374', b'cluster_00375', b'cluster_00377', b'cluster_00380', b'cluster_00385', b'cluster_00388', b'cluster_00389', b'cluster_00390', b'cluster_00394', b'cluster_00400', b'cluster_00401', b'cluster_00405', b'cluster_00407', b'cluster_00408', b'cluster_00409', b'cluster_00412', b'cluster_00445', b'cluster_00473', b'cluster_00585', b'cluster_00589', b'cluster_00591', b'cluster_00593', b'cluster_00596', b'cluster_00603', b'cluster_00604', b'cluster_00607', b'cluster_00612', b'cluster_00616', b'cluster_00619', b'cluster_00629', b'cluster_00630', b'cluster_00635', b'cluster_00637', b'cluster_00639', b'cluster_00642', b'cluster_00645', b'cluster_00647', b'cluster_00652', b'cluster_00653', b'cluster_00656', b'cluster_00657', b'cluster_00661', b'cluster_00662', b'cluster_00667', b'cluster_00762', b'cluster_00201', b'cluster_00217', b'cluster_00239', b'cluster_00320', b'cluster_00391', b'cluster_00398', b'cluster_00415', b'cluster_00477', b'cluster_00478', b'cluster_00479', b'cluster_00078', b'cluster_00079', b'cluster_00083', b'cluster_00090', b'cluster_00094', b'cluster_00096', b'cluster_00101', b'cluster_00086', b'cluster_00095', b'cluster_00097', b'cluster_00106', b'cluster_00553', b'cluster_00554', b'cluster_00569', b'cluster_00015', b'cluster_00017', b'cluster_00018', b'cluster_00023', b'cluster_00025', b'cluster_00030', b'cluster_00035', b'cluster_00039', b'cluster_00042', b'cluster_00046', b'cluster_00055', b'cluster_00059', b'cluster_00061', b'cluster_00274', b'cluster_00308', b'cluster_00337', b'cluster_00362', b'cluster_00369', b'cluster_00392', b'cluster_00414', b'cluster_00419', b'cluster_00420', b'cluster_00421', b'cluster_00422', b'cluster_00427', b'cluster_00430', b'cluster_00431', b'cluster_00436', b'cluster_00439', b'cluster_00444', b'cluster_00447', b'cluster_00448', b'cluster_00450', b'cluster_00456', b'cluster_00458', b'cluster_00460', b'cluster_00463', b'cluster_00467', b'cluster_00483', b'cluster_00484', b'cluster_00007', b'cluster_00036', b'cluster_00054', b'cluster_00062', b'cluster_00064', b'cluster_00065', b'cluster_00067', b'cluster_00071', b'cluster_00075', b'cluster_00084', b'cluster_00093', b'cluster_00001', b'cluster_00002', b'cluster_00003', b'cluster_00006', b'cluster_00008', b'cluster_00010', b'cluster_00012', b'cluster_00019', b'cluster_00022', b'cluster_00026', b'cluster_00029', b'cluster_00031', b'cluster_00043', b'cluster_00051', b'cluster_00052', b'cluster_00073', b'cluster_00076', b'cluster_00082', b'cluster_00107', b'cluster_00432', b'cluster_00440', b'cluster_00455', b'cluster_00714', b'cluster_00791', b'cluster_00119', b'cluster_00121', b'cluster_00155', b'cluster_00556', b'cluster_00557', b'cluster_00689', b'cluster_00692', b'cluster_00718', b'cluster_00725', b'cluster_00727', b'cluster_00729', b'cluster_00733', b'cluster_00738', b'cluster_00740', b'cluster_00744', b'cluster_00753', b'cluster_00777', b'cluster_00795']
2023-07-14 01:22:00,185 epoch [1/800] time: 4.53s train loss: 2.3949 accuracy: 0.479 f1: 0.4546
2023-07-14 01:22:00,992 epoch [1/800] time: 0.8s val loss: 1.349 accuracy: 0.6964 f1: 0.6854
2023-07-14 01:22:05,530 epoch [2/800] time: 4.53s train loss: 0.8372 accuracy: 0.7639 f1: 0.7583
2023-07-14 01:22:06,378 epoch [2/800] time: 0.84s val loss: 0.7233 accuracy: 0.7759 f1: 0.7722
2023-07-14 01:22:10,887 epoch [3/800] time: 4.5s train loss: 0.6142 accuracy: 0.7985 f1: 0.7953
2023-07-14 01:22:11,737 epoch [3/800] time: 0.84s val loss: 0.6166 accuracy: 0.7838 f1: 0.7805
2023-07-14 01:22:16,232 epoch [4/800] time: 4.49s train loss: 0.5312 accuracy: 0.8157 f1: 0.8127
2023-07-14 01:22:17,081 epoch [4/800] time: 0.84s val loss: 0.5419 accuracy: 0.8034 f1: 0.7991
2023-07-14 01:22:21,621 epoch [5/800] time: 4.54s train loss: 0.48 accuracy: 0.8295 f1: 0.8274
2023-07-14 01:22:22,469 epoch [5/800] time: 0.84s val loss: 0.4754 accuracy: 0.8245 f1: 0.8227
2023-07-14 01:22:27,204 epoch [6/800] time: 4.74s train loss: 0.4477 accuracy: 0.8374 f1: 0.8356
2023-07-14 01:22:28,064 epoch [6/800] time: 0.85s val loss: 0.4727 accuracy: 0.8208 f1: 0.8174
2023-07-14 01:22:32,994 epoch [7/800] time: 4.93s train loss: 0.4201 accuracy: 0.8462 f1: 0.8444
2023-07-14 01:22:33,901 epoch [7/800] time: 0.9s val loss: 0.4745 accuracy: 0.8231 f1: 0.8221
2023-07-14 01:22:39,503 epoch [8/800] time: 5.6s train loss: 0.3947 accuracy: 0.854 f1: 0.852
2023-07-14 01:22:40,720 epoch [8/800] time: 1.21s val loss: 0.3727 accuracy: 0.8595 f1: 0.8564
2023-07-14 01:22:46,039 epoch [9/800] time: 5.31s train loss: 0.3725 accuracy: 0.8612 f1: 0.8591
2023-07-14 01:22:46,970 epoch [9/800] time: 0.92s val loss: 0.3946 accuracy: 0.8489 f1: 0.8464
2023-07-14 01:22:51,938 epoch [10/800] time: 4.97s train loss: 0.3693 accuracy: 0.8624 f1: 0.8606
2023-07-14 01:22:52,821 epoch [10/800] time: 0.88s val loss: 0.4928 accuracy: 0.8331 f1: 0.832
2023-07-14 01:22:58,178 epoch [11/800] time: 5.36s train loss: 0.352 accuracy: 0.869 f1: 0.8671
2023-07-14 01:22:59,170 epoch [11/800] time: 0.98s val loss: 0.3385 accuracy: 0.8696 f1: 0.8665
2023-07-14 01:23:04,362 epoch [12/800] time: 5.19s train loss: 0.3442 accuracy: 0.8694 f1: 0.8675
2023-07-14 01:23:05,199 epoch [12/800] time: 0.83s val loss: 0.3776 accuracy: 0.8547 f1: 0.8525
2023-07-14 01:23:10,293 epoch [13/800] time: 5.09s train loss: 0.339 accuracy: 0.8722 f1: 0.8708
2023-07-14 01:23:11,194 epoch [13/800] time: 0.89s val loss: 0.3382 accuracy: 0.8701 f1: 0.8691
2023-07-14 01:23:15,970 epoch [14/800] time: 4.78s train loss: 0.3309 accuracy: 0.8749 f1: 0.8733
2023-07-14 01:23:16,896 epoch [14/800] time: 0.92s val loss: 0.4056 accuracy: 0.8432 f1: 0.8446
2023-07-14 01:23:21,889 epoch [15/800] time: 4.99s train loss: 0.3257 accuracy: 0.8763 f1: 0.875
2023-07-14 01:23:22,703 epoch [15/800] time: 0.81s val loss: 0.3747 accuracy: 0.8564 f1: 0.855
2023-07-14 01:23:27,342 epoch [16/800] time: 4.64s train loss: 0.3113 accuracy: 0.8816 f1: 0.8803
2023-07-14 01:23:28,204 epoch [16/800] time: 0.86s val loss: 0.3993 accuracy: 0.8478 f1: 0.8478
2023-07-14 01:23:32,819 epoch [17/800] time: 4.61s train loss: 0.3117 accuracy: 0.8816 f1: 0.8804
2023-07-14 01:23:33,672 epoch [17/800] time: 0.85s val loss: 0.343 accuracy: 0.8675 f1: 0.8653
2023-07-14 01:23:38,325 epoch [18/800] time: 4.65s train loss: 0.3018 accuracy: 0.8848 f1: 0.8832
2023-07-14 01:23:39,131 epoch [18/800] time: 0.8s val loss: 0.3341 accuracy: 0.8694 f1: 0.8673
2023-07-14 01:23:43,831 epoch [19/800] time: 4.7s train loss: 0.3004 accuracy: 0.886 f1: 0.8848
2023-07-14 01:23:44,681 epoch [19/800] time: 0.84s val loss: 0.2855 accuracy: 0.8883 f1: 0.8869
2023-07-14 01:23:49,359 epoch [20/800] time: 4.67s train loss: 0.2934 accuracy: 0.8879 f1: 0.8866
2023-07-14 01:23:50,218 epoch [20/800] time: 0.86s val loss: 0.3551 accuracy: 0.8633 f1: 0.8625
2023-07-14 01:23:54,951 epoch [21/800] time: 4.73s train loss: 0.2399 accuracy: 0.9108 f1: 0.9098
2023-07-14 01:23:55,755 epoch [21/800] time: 0.8s val loss: 0.2437 accuracy: 0.9047 f1: 0.9035
2023-07-14 01:24:00,512 epoch [22/800] time: 4.76s train loss: 0.2213 accuracy: 0.9173 f1: 0.9163
2023-07-14 01:24:01,356 epoch [22/800] time: 0.84s val loss: 0.2603 accuracy: 0.8999 f1: 0.8983
2023-07-14 01:24:05,847 epoch [23/800] time: 4.49s train loss: 0.2203 accuracy: 0.9167 f1: 0.9158
2023-07-14 01:24:06,689 epoch [23/800] time: 0.84s val loss: 0.2705 accuracy: 0.8951 f1: 0.8934
2023-07-14 01:24:11,217 epoch [24/800] time: 4.53s train loss: 0.2141 accuracy: 0.9202 f1: 0.9192
2023-07-14 01:24:12,025 epoch [24/800] time: 0.8s val loss: 0.2484 accuracy: 0.9034 f1: 0.9025
2023-07-14 01:24:16,555 epoch [25/800] time: 4.53s train loss: 0.2208 accuracy: 0.9172 f1: 0.9164
2023-07-14 01:24:17,397 epoch [25/800] time: 0.84s val loss: 0.2653 accuracy: 0.8952 f1: 0.8944
2023-07-14 01:24:21,888 epoch [26/800] time: 4.49s train loss: 0.2184 accuracy: 0.9172 f1: 0.9161
2023-07-14 01:24:22,731 epoch [26/800] time: 0.84s val loss: 0.2797 accuracy: 0.8918 f1: 0.8907
2023-07-14 01:24:27,260 epoch [27/800] time: 4.53s train loss: 0.2112 accuracy: 0.9199 f1: 0.9189
2023-07-14 01:24:28,060 epoch [27/800] time: 0.8s val loss: 0.2407 accuracy: 0.9058 f1: 0.904
2023-07-14 01:24:32,587 epoch [28/800] time: 4.53s train loss: 0.2108 accuracy: 0.9212 f1: 0.9204
2023-07-14 01:24:33,433 epoch [28/800] time: 0.84s val loss: 0.2457 accuracy: 0.9037 f1: 0.9025
2023-07-14 01:24:38,054 epoch [29/800] time: 4.62s train loss: 0.2076 accuracy: 0.9224 f1: 0.9214
2023-07-14 01:24:38,918 epoch [29/800] time: 0.86s val loss: 0.25 accuracy: 0.9024 f1: 0.9008
2023-07-14 01:24:43,741 epoch [30/800] time: 4.82s train loss: 0.2073 accuracy: 0.9211 f1: 0.9204
2023-07-14 01:24:44,590 epoch [30/800] time: 0.85s val loss: 0.2839 accuracy: 0.8913 f1: 0.8903
2023-07-14 01:24:49,621 epoch [31/800] time: 5.03s train loss: 0.2055 accuracy: 0.9216 f1: 0.9207
2023-07-14 01:24:50,480 epoch [31/800] time: 0.86s val loss: 0.2478 accuracy: 0.9034 f1: 0.9011
2023-07-14 01:24:55,093 epoch [32/800] time: 4.61s train loss: 0.2049 accuracy: 0.9231 f1: 0.9218
2023-07-14 01:24:55,946 epoch [32/800] time: 0.85s val loss: 0.2973 accuracy: 0.8878 f1: 0.8862
2023-07-14 01:25:00,894 epoch [33/800] time: 4.95s train loss: 0.2053 accuracy: 0.9216 f1: 0.9209
2023-07-14 01:25:01,745 epoch [33/800] time: 0.85s val loss: 0.2367 accuracy: 0.9082 f1: 0.9064
2023-07-14 01:25:06,565 epoch [34/800] time: 4.82s train loss: 0.1911 accuracy: 0.9277 f1: 0.9266
2023-07-14 01:25:07,426 epoch [34/800] time: 0.85s val loss: 0.2295 accuracy: 0.9114 f1: 0.9103
2023-07-14 01:25:12,036 epoch [35/800] time: 4.61s train loss: 0.2016 accuracy: 0.923 f1: 0.9221
2023-07-14 01:25:12,902 epoch [35/800] time: 0.87s val loss: 0.2637 accuracy: 0.8969 f1: 0.8951
2023-07-14 01:25:17,590 epoch [36/800] time: 4.69s train loss: 0.1973 accuracy: 0.9249 f1: 0.924
2023-07-14 01:25:18,413 epoch [36/800] time: 0.82s val loss: 0.238 accuracy: 0.9092 f1: 0.9086
2023-07-14 01:25:22,976 epoch [37/800] time: 4.56s train loss: 0.1889 accuracy: 0.9286 f1: 0.9278
2023-07-14 01:25:23,820 epoch [37/800] time: 0.84s val loss: 0.2334 accuracy: 0.9089 f1: 0.908
2023-07-14 01:25:28,309 epoch [38/800] time: 4.49s train loss: 0.189 accuracy: 0.9281 f1: 0.9275
2023-07-14 01:25:29,156 epoch [38/800] time: 0.85s val loss: 0.2285 accuracy: 0.9117 f1: 0.9099
2023-07-14 01:25:33,710 epoch [39/800] time: 4.55s train loss: 0.188 accuracy: 0.9284 f1: 0.9275
2023-07-14 01:25:34,509 epoch [39/800] time: 0.8s val loss: 0.2238 accuracy: 0.9127 f1: 0.9115
2023-07-14 01:25:39,044 epoch [40/800] time: 4.53s train loss: 0.1863 accuracy: 0.9297 f1: 0.9288
2023-07-14 01:25:39,890 epoch [40/800] time: 0.84s val loss: 0.239 accuracy: 0.9077 f1: 0.9066
2023-07-14 01:25:44,387 epoch [41/800] time: 4.5s train loss: 0.1542 accuracy: 0.9437 f1: 0.943
2023-07-14 01:25:45,233 epoch [41/800] time: 0.84s val loss: 0.192 accuracy: 0.9255 f1: 0.924
2023-07-14 01:25:49,763 epoch [42/800] time: 4.53s train loss: 0.1456 accuracy: 0.9475 f1: 0.9469
2023-07-14 01:25:50,566 epoch [42/800] time: 0.8s val loss: 0.1977 accuracy: 0.9243 f1: 0.9227
2023-07-14 01:25:55,101 epoch [43/800] time: 4.53s train loss: 0.1455 accuracy: 0.947 f1: 0.9464
2023-07-14 01:25:55,942 epoch [43/800] time: 0.84s val loss: 0.181 accuracy: 0.9307 f1: 0.9293
2023-07-14 01:26:00,435 epoch [44/800] time: 4.49s train loss: 0.1454 accuracy: 0.9477 f1: 0.947
2023-07-14 01:26:01,282 epoch [44/800] time: 0.84s val loss: 0.174 accuracy: 0.934 f1: 0.9326
2023-07-14 01:26:05,814 epoch [45/800] time: 4.53s train loss: 0.1447 accuracy: 0.9473 f1: 0.9466
2023-07-14 01:26:06,613 epoch [45/800] time: 0.8s val loss: 0.2006 accuracy: 0.9225 f1: 0.9213
2023-07-14 01:26:11,147 epoch [46/800] time: 4.53s train loss: 0.1453 accuracy: 0.9469 f1: 0.9463
2023-07-14 01:26:11,989 epoch [46/800] time: 0.84s val loss: 0.1799 accuracy: 0.9315 f1: 0.9303
2023-07-14 01:26:16,661 epoch [47/800] time: 4.67s train loss: 0.143 accuracy: 0.9473 f1: 0.9469
2023-07-14 01:26:17,507 epoch [47/800] time: 0.85s val loss: 0.1886 accuracy: 0.9273 f1: 0.9257
2023-07-14 01:26:22,036 epoch [48/800] time: 4.53s train loss: 0.1394 accuracy: 0.9482 f1: 0.9476
2023-07-14 01:26:22,839 epoch [48/800] time: 0.8s val loss: 0.1769 accuracy: 0.9333 f1: 0.9319
2023-07-14 01:26:27,384 epoch [49/800] time: 4.54s train loss: 0.1391 accuracy: 0.9493 f1: 0.9487
2023-07-14 01:26:28,230 epoch [49/800] time: 0.84s val loss: 0.1843 accuracy: 0.929 f1: 0.9278
2023-07-14 01:26:32,738 epoch [50/800] time: 4.51s train loss: 0.1424 accuracy: 0.9473 f1: 0.9467
2023-07-14 01:26:33,581 epoch [50/800] time: 0.84s val loss: 0.1781 accuracy: 0.9326 f1: 0.9317
2023-07-14 01:26:38,120 epoch [51/800] time: 4.54s train loss: 0.1343 accuracy: 0.9509 f1: 0.9504
2023-07-14 01:26:38,925 epoch [51/800] time: 0.8s val loss: 0.1868 accuracy: 0.9293 f1: 0.9283
2023-07-14 01:26:43,475 epoch [52/800] time: 4.55s train loss: 0.1385 accuracy: 0.9489 f1: 0.9483
2023-07-14 01:26:44,318 epoch [52/800] time: 0.84s val loss: 0.1989 accuracy: 0.9247 f1: 0.9236
2023-07-14 01:26:48,930 epoch [53/800] time: 4.61s train loss: 0.1362 accuracy: 0.9499 f1: 0.9492
2023-07-14 01:26:49,773 epoch [53/800] time: 0.84s val loss: 0.2043 accuracy: 0.9233 f1: 0.9227
2023-07-14 01:26:54,370 epoch [54/800] time: 4.6s train loss: 0.143 accuracy: 0.947 f1: 0.9465
2023-07-14 01:26:55,171 epoch [54/800] time: 0.8s val loss: 0.1926 accuracy: 0.9278 f1: 0.9272
2023-07-14 01:26:59,785 epoch [55/800] time: 4.61s train loss: 0.1323 accuracy: 0.9519 f1: 0.9515
2023-07-14 01:27:00,634 epoch [55/800] time: 0.84s val loss: 0.1803 accuracy: 0.9309 f1: 0.9293
2023-07-14 01:27:05,244 epoch [56/800] time: 4.61s train loss: 0.132 accuracy: 0.9515 f1: 0.9508
2023-07-14 01:27:06,088 epoch [56/800] time: 0.84s val loss: 0.1684 accuracy: 0.9367 f1: 0.9358
2023-07-14 01:27:10,755 epoch [57/800] time: 4.67s train loss: 0.1313 accuracy: 0.953 f1: 0.9523
2023-07-14 01:27:11,558 epoch [57/800] time: 0.8s val loss: 0.1871 accuracy: 0.93 f1: 0.9286
2023-07-14 01:27:16,286 epoch [58/800] time: 4.73s train loss: 0.1363 accuracy: 0.9497 f1: 0.9492
2023-07-14 01:27:17,127 epoch [58/800] time: 0.84s val loss: 0.1761 accuracy: 0.9334 f1: 0.9329
2023-07-14 01:27:21,861 epoch [59/800] time: 4.73s train loss: 0.1265 accuracy: 0.9544 f1: 0.9539
2023-07-14 01:27:22,706 epoch [59/800] time: 0.84s val loss: 0.1815 accuracy: 0.9304 f1: 0.929
2023-07-14 01:27:27,391 epoch [60/800] time: 4.68s train loss: 0.1305 accuracy: 0.952 f1: 0.9516
2023-07-14 01:27:28,196 epoch [60/800] time: 0.81s val loss: 0.1839 accuracy: 0.9301 f1: 0.9293
2023-07-14 01:27:32,791 epoch [61/800] time: 4.59s train loss: 0.1124 accuracy: 0.9608 f1: 0.9605
2023-07-14 01:27:33,638 epoch [61/800] time: 0.84s val loss: 0.1552 accuracy: 0.9421 f1: 0.9407
2023-07-14 01:27:38,295 epoch [62/800] time: 4.66s train loss: 0.1051 accuracy: 0.9638 f1: 0.9634
2023-07-14 01:27:39,140 epoch [62/800] time: 0.84s val loss: 0.1551 accuracy: 0.9417 f1: 0.9407
2023-07-14 01:27:43,683 epoch [63/800] time: 4.54s train loss: 0.1038 accuracy: 0.9641 f1: 0.9638
2023-07-14 01:27:44,488 epoch [63/800] time: 0.8s val loss: 0.1558 accuracy: 0.9424 f1: 0.9411
2023-07-14 01:27:49,027 epoch [64/800] time: 4.54s train loss: 0.103 accuracy: 0.9643 f1: 0.964
2023-07-14 01:27:49,874 epoch [64/800] time: 0.84s val loss: 0.161 accuracy: 0.9407 f1: 0.9395
2023-07-14 01:27:54,549 epoch [65/800] time: 4.67s train loss: 0.1039 accuracy: 0.9634 f1: 0.963
2023-07-14 01:27:55,392 epoch [65/800] time: 0.84s val loss: 0.1503 accuracy: 0.945 f1: 0.9439
2023-07-14 01:28:00,139 epoch [66/800] time: 4.75s train loss: 0.1016 accuracy: 0.9649 f1: 0.9645
2023-07-14 01:28:00,941 epoch [66/800] time: 0.8s val loss: 0.1502 accuracy: 0.9456 f1: 0.9442
2023-07-14 01:28:05,684 epoch [67/800] time: 4.74s train loss: 0.1004 accuracy: 0.9653 f1: 0.9649
2023-07-14 01:28:06,575 epoch [67/800] time: 0.88s val loss: 0.1493 accuracy: 0.9455 f1: 0.9447
2023-07-14 01:28:11,614 epoch [68/800] time: 5.04s train loss: 0.1028 accuracy: 0.9651 f1: 0.9647
2023-07-14 01:28:12,460 epoch [68/800] time: 0.85s val loss: 0.1547 accuracy: 0.9427 f1: 0.9417
2023-07-14 01:28:17,099 epoch [69/800] time: 4.64s train loss: 0.1038 accuracy: 0.9643 f1: 0.9639
2023-07-14 01:28:17,899 epoch [69/800] time: 0.8s val loss: 0.1646 accuracy: 0.9393 f1: 0.9379
2023-07-14 01:28:22,594 epoch [70/800] time: 4.7s train loss: 0.1016 accuracy: 0.9645 f1: 0.964
2023-07-14 01:28:23,437 epoch [70/800] time: 0.84s val loss: 0.1544 accuracy: 0.9422 f1: 0.9407
2023-07-14 01:28:27,940 epoch [71/800] time: 4.5s train loss: 0.0982 accuracy: 0.9667 f1: 0.9662
2023-07-14 01:28:28,787 epoch [71/800] time: 0.84s val loss: 0.1559 accuracy: 0.9432 f1: 0.9421
2023-07-14 01:28:33,332 epoch [72/800] time: 4.55s train loss: 0.0985 accuracy: 0.9662 f1: 0.9658
2023-07-14 01:28:34,137 epoch [72/800] time: 0.8s val loss: 0.161 accuracy: 0.9395 f1: 0.9383
2023-07-14 01:28:38,690 epoch [73/800] time: 4.55s train loss: 0.0985 accuracy: 0.9661 f1: 0.9658
2023-07-14 01:28:39,543 epoch [73/800] time: 0.85s val loss: 0.1494 accuracy: 0.9451 f1: 0.944
2023-07-14 01:28:44,033 epoch [74/800] time: 4.49s train loss: 0.0951 accuracy: 0.9675 f1: 0.9672
2023-07-14 01:28:44,879 epoch [74/800] time: 0.84s val loss: 0.1576 accuracy: 0.9417 f1: 0.9407
2023-07-14 01:28:49,457 epoch [75/800] time: 4.58s train loss: 0.0963 accuracy: 0.9672 f1: 0.967
2023-07-14 01:28:50,258 epoch [75/800] time: 0.8s val loss: 0.1504 accuracy: 0.9452 f1: 0.9443
2023-07-14 01:28:54,795 epoch [76/800] time: 4.54s train loss: 0.0975 accuracy: 0.9662 f1: 0.9661
2023-07-14 01:28:55,637 epoch [76/800] time: 0.84s val loss: 0.1499 accuracy: 0.9453 f1: 0.9442
2023-07-14 01:29:00,150 epoch [77/800] time: 4.51s train loss: 0.0953 accuracy: 0.9672 f1: 0.9669
2023-07-14 01:29:01,000 epoch [77/800] time: 0.85s val loss: 0.1497 accuracy: 0.9455 f1: 0.9445
2023-07-14 01:29:05,533 epoch [78/800] time: 4.53s train loss: 0.0937 accuracy: 0.9687 f1: 0.9684
2023-07-14 01:29:06,340 epoch [78/800] time: 0.8s val loss: 0.1527 accuracy: 0.9432 f1: 0.9423
2023-07-14 01:29:10,874 epoch [79/800] time: 4.53s train loss: 0.0967 accuracy: 0.9669 f1: 0.9665
2023-07-14 01:29:11,716 epoch [79/800] time: 0.84s val loss: 0.15 accuracy: 0.9455 f1: 0.9439
2023-07-14 01:29:16,228 epoch [80/800] time: 4.51s train loss: 0.0936 accuracy: 0.9677 f1: 0.9674
2023-07-14 01:29:17,072 epoch [80/800] time: 0.84s val loss: 0.1503 accuracy: 0.9458 f1: 0.945
2023-07-14 01:29:21,605 epoch [81/800] time: 4.53s train loss: 0.0835 accuracy: 0.9724 f1: 0.9722
2023-07-14 01:29:22,408 epoch [81/800] time: 0.8s val loss: 0.14 accuracy: 0.9489 f1: 0.9479
2023-07-14 01:29:27,040 epoch [82/800] time: 4.63s train loss: 0.0839 accuracy: 0.9736 f1: 0.9734
2023-07-14 01:29:27,887 epoch [82/800] time: 0.84s val loss: 0.1424 accuracy: 0.9476 f1: 0.9464
2023-07-14 01:29:32,380 epoch [83/800] time: 4.49s train loss: 0.0822 accuracy: 0.9731 f1: 0.973
2023-07-14 01:29:33,223 epoch [83/800] time: 0.84s val loss: 0.1405 accuracy: 0.9487 f1: 0.9476
2023-07-14 01:29:37,839 epoch [84/800] time: 4.62s train loss: 0.0821 accuracy: 0.9738 f1: 0.9736
2023-07-14 01:29:38,643 epoch [84/800] time: 0.8s val loss: 0.1381 accuracy: 0.9512 f1: 0.9499
2023-07-14 01:29:43,176 epoch [85/800] time: 4.53s train loss: 0.0809 accuracy: 0.9738 f1: 0.9733
2023-07-14 01:29:44,036 epoch [85/800] time: 0.86s val loss: 0.1415 accuracy: 0.9486 f1: 0.9476
2023-07-14 01:29:48,560 epoch [86/800] time: 4.52s train loss: 0.0787 accuracy: 0.9747 f1: 0.9744
2023-07-14 01:29:49,406 epoch [86/800] time: 0.84s val loss: 0.1406 accuracy: 0.9497 f1: 0.9487
2023-07-14 01:29:53,947 epoch [87/800] time: 4.54s train loss: 0.0792 accuracy: 0.975 f1: 0.9748
2023-07-14 01:29:54,750 epoch [87/800] time: 0.8s val loss: 0.1385 accuracy: 0.9503 f1: 0.9489
2023-07-14 01:29:59,288 epoch [88/800] time: 4.54s train loss: 0.0808 accuracy: 0.9742 f1: 0.9739
2023-07-14 01:30:00,132 epoch [88/800] time: 0.84s val loss: 0.14 accuracy: 0.95 f1: 0.9487
2023-07-14 01:30:04,639 epoch [89/800] time: 4.51s train loss: 0.0801 accuracy: 0.9744 f1: 0.9743
2023-07-14 01:30:05,484 epoch [89/800] time: 0.84s val loss: 0.1368 accuracy: 0.9513 f1: 0.9502
2023-07-14 01:30:10,121 epoch [90/800] time: 4.64s train loss: 0.0796 accuracy: 0.9749 f1: 0.9745
2023-07-14 01:30:10,923 epoch [90/800] time: 0.8s val loss: 0.1389 accuracy: 0.9501 f1: 0.9488
2023-07-14 01:30:15,544 epoch [91/800] time: 4.62s train loss: 0.0797 accuracy: 0.9747 f1: 0.9745
2023-07-14 01:30:16,430 epoch [91/800] time: 0.89s val loss: 0.142 accuracy: 0.949 f1: 0.9476
2023-07-14 01:30:21,286 epoch [92/800] time: 4.86s train loss: 0.0782 accuracy: 0.9749 f1: 0.9747
2023-07-14 01:30:22,217 epoch [92/800] time: 0.93s val loss: 0.138 accuracy: 0.9509 f1: 0.9496
2023-07-14 01:30:27,229 epoch [93/800] time: 5.01s train loss: 0.0764 accuracy: 0.9751 f1: 0.9748
2023-07-14 01:30:28,068 epoch [93/800] time: 0.83s val loss: 0.1388 accuracy: 0.9513 f1: 0.9499
2023-07-14 01:30:32,956 epoch [94/800] time: 4.89s train loss: 0.0756 accuracy: 0.976 f1: 0.9758
2023-07-14 01:30:33,931 epoch [94/800] time: 0.97s val loss: 0.1367 accuracy: 0.9514 f1: 0.9501
2023-07-14 01:30:39,151 epoch [95/800] time: 5.22s train loss: 0.0775 accuracy: 0.9754 f1: 0.9753
2023-07-14 01:30:40,062 epoch [95/800] time: 0.91s val loss: 0.1415 accuracy: 0.9488 f1: 0.9477
2023-07-14 01:30:45,270 epoch [96/800] time: 5.21s train loss: 0.0755 accuracy: 0.9756 f1: 0.9754
2023-07-14 01:30:46,096 epoch [96/800] time: 0.83s val loss: 0.1389 accuracy: 0.9505 f1: 0.9496
2023-07-14 01:30:51,258 epoch [97/800] time: 5.16s train loss: 0.0753 accuracy: 0.9761 f1: 0.9759
2023-07-14 01:30:52,151 epoch [97/800] time: 0.89s val loss: 0.143 accuracy: 0.9489 f1: 0.9476
2023-07-14 01:30:57,040 epoch [98/800] time: 4.89s train loss: 0.0747 accuracy: 0.9761 f1: 0.9758
2023-07-14 01:30:57,893 epoch [98/800] time: 0.85s val loss: 0.1369 accuracy: 0.9512 f1: 0.9501
2023-07-14 01:31:02,857 epoch [99/800] time: 4.96s train loss: 0.0738 accuracy: 0.9768 f1: 0.9766
2023-07-14 01:31:03,681 epoch [99/800] time: 0.82s val loss: 0.1396 accuracy: 0.9498 f1: 0.9483
2023-07-14 01:31:08,556 epoch [100/800] time: 4.87s train loss: 0.0749 accuracy: 0.9763 f1: 0.976
2023-07-14 01:31:09,425 epoch [100/800] time: 0.87s val loss: 0.14 accuracy: 0.9503 f1: 0.9489
2023-07-14 01:31:14,212 epoch [101/800] time: 4.79s train loss: 0.0692 accuracy: 0.9794 f1: 0.9792
2023-07-14 01:31:15,102 epoch [101/800] time: 0.88s val loss: 0.1363 accuracy: 0.9517 f1: 0.9504
2023-07-14 01:31:19,955 epoch [102/800] time: 4.85s train loss: 0.0682 accuracy: 0.9797 f1: 0.9795
2023-07-14 01:31:20,774 epoch [102/800] time: 0.81s val loss: 0.136 accuracy: 0.9514 f1: 0.9501
2023-07-14 01:31:25,498 epoch [103/800] time: 4.72s train loss: 0.0704 accuracy: 0.9786 f1: 0.9784
2023-07-14 01:31:26,340 epoch [103/800] time: 0.84s val loss: 0.1342 accuracy: 0.9522 f1: 0.9509
2023-07-14 01:31:31,010 epoch [104/800] time: 4.67s train loss: 0.0692 accuracy: 0.9798 f1: 0.9797
2023-07-14 01:31:31,856 epoch [104/800] time: 0.84s val loss: 0.1351 accuracy: 0.9521 f1: 0.9509
2023-07-14 01:31:36,610 epoch [105/800] time: 4.75s train loss: 0.0696 accuracy: 0.9782 f1: 0.9781
2023-07-14 01:31:37,411 epoch [105/800] time: 0.8s val loss: 0.1338 accuracy: 0.9529 f1: 0.9516
2023-07-14 01:31:42,150 epoch [106/800] time: 4.74s train loss: 0.0671 accuracy: 0.9796 f1: 0.9794
2023-07-14 01:31:42,993 epoch [106/800] time: 0.84s val loss: 0.1343 accuracy: 0.9517 f1: 0.9503
2023-07-14 01:31:47,726 epoch [107/800] time: 4.73s train loss: 0.0683 accuracy: 0.9793 f1: 0.9791
2023-07-14 01:31:48,567 epoch [107/800] time: 0.84s val loss: 0.1337 accuracy: 0.9521 f1: 0.9509
2023-07-14 01:31:53,300 epoch [108/800] time: 4.73s train loss: 0.0686 accuracy: 0.9788 f1: 0.9786
2023-07-14 01:31:54,101 epoch [108/800] time: 0.8s val loss: 0.133 accuracy: 0.9524 f1: 0.9511
2023-07-14 01:31:58,879 epoch [109/800] time: 4.78s train loss: 0.0675 accuracy: 0.9799 f1: 0.9797
2023-07-14 01:31:59,724 epoch [109/800] time: 0.84s val loss: 0.1333 accuracy: 0.9534 f1: 0.9523
2023-07-14 01:32:04,446 epoch [110/800] time: 4.72s train loss: 0.0658 accuracy: 0.98 f1: 0.9799
2023-07-14 01:32:05,293 epoch [110/800] time: 0.84s val loss: 0.1338 accuracy: 0.9525 f1: 0.9514
2023-07-14 01:32:10,016 epoch [111/800] time: 4.72s train loss: 0.0676 accuracy: 0.9791 f1: 0.9789
2023-07-14 01:32:10,814 epoch [111/800] time: 0.8s val loss: 0.1338 accuracy: 0.9528 f1: 0.9518
2023-07-14 01:32:15,579 epoch [112/800] time: 4.76s train loss: 0.0672 accuracy: 0.9798 f1: 0.9796
2023-07-14 01:32:16,425 epoch [112/800] time: 0.85s val loss: 0.1336 accuracy: 0.9538 f1: 0.9525
2023-07-14 01:32:21,111 epoch [113/800] time: 4.69s train loss: 0.0661 accuracy: 0.9802 f1: 0.9801
2023-07-14 01:32:21,954 epoch [113/800] time: 0.84s val loss: 0.1339 accuracy: 0.9519 f1: 0.9506
2023-07-14 01:32:26,739 epoch [114/800] time: 4.79s train loss: 0.0677 accuracy: 0.979 f1: 0.9787
2023-07-14 01:32:27,538 epoch [114/800] time: 0.8s val loss: 0.1326 accuracy: 0.9539 f1: 0.9526
2023-07-14 01:32:32,274 epoch [115/800] time: 4.74s train loss: 0.0661 accuracy: 0.9805 f1: 0.9803
2023-07-14 01:32:33,125 epoch [115/800] time: 0.84s val loss: 0.1325 accuracy: 0.9528 f1: 0.9516
2023-07-14 01:32:37,965 epoch [116/800] time: 4.84s train loss: 0.0678 accuracy: 0.9801 f1: 0.9799
2023-07-14 01:32:38,846 epoch [116/800] time: 0.88s val loss: 0.1336 accuracy: 0.9528 f1: 0.9516
2023-07-14 01:32:43,628 epoch [117/800] time: 4.78s train loss: 0.0668 accuracy: 0.9801 f1: 0.9798
2023-07-14 01:32:44,465 epoch [117/800] time: 0.84s val loss: 0.1333 accuracy: 0.9531 f1: 0.9521
2023-07-14 01:32:49,545 epoch [118/800] time: 5.08s train loss: 0.0654 accuracy: 0.9803 f1: 0.9801
2023-07-14 01:32:50,493 epoch [118/800] time: 0.95s val loss: 0.1337 accuracy: 0.9528 f1: 0.9515
2023-07-14 01:32:55,653 epoch [119/800] time: 5.16s train loss: 0.0654 accuracy: 0.9807 f1: 0.9805
2023-07-14 01:32:56,553 epoch [119/800] time: 0.89s val loss: 0.1339 accuracy: 0.9526 f1: 0.9515
2023-07-14 01:33:01,553 epoch [120/800] time: 5.0s train loss: 0.0654 accuracy: 0.9805 f1: 0.9802
2023-07-14 01:33:02,477 epoch [120/800] time: 0.92s val loss: 0.1335 accuracy: 0.9526 f1: 0.9515
2023-07-14 01:33:07,629 epoch [121/800] time: 5.15s train loss: 0.0634 accuracy: 0.9818 f1: 0.9815
2023-07-14 01:33:08,505 epoch [121/800] time: 0.87s val loss: 0.1318 accuracy: 0.9545 f1: 0.9533
2023-07-14 01:33:13,418 epoch [122/800] time: 4.91s train loss: 0.0636 accuracy: 0.9815 f1: 0.9813
2023-07-14 01:33:14,301 epoch [122/800] time: 0.88s val loss: 0.1328 accuracy: 0.9534 f1: 0.9521
2023-07-14 01:33:19,640 epoch [123/800] time: 5.34s train loss: 0.0623 accuracy: 0.9818 f1: 0.9816
2023-07-14 01:33:20,530 epoch [123/800] time: 0.88s val loss: 0.1318 accuracy: 0.9531 f1: 0.9518
2023-07-14 01:33:25,605 epoch [124/800] time: 5.07s train loss: 0.0621 accuracy: 0.9818 f1: 0.9816
2023-07-14 01:33:26,475 epoch [124/800] time: 0.86s val loss: 0.1335 accuracy: 0.9526 f1: 0.9515
2023-07-14 01:33:31,532 epoch [125/800] time: 5.06s train loss: 0.0629 accuracy: 0.9814 f1: 0.9812
2023-07-14 01:33:32,493 epoch [125/800] time: 0.96s val loss: 0.1309 accuracy: 0.9542 f1: 0.9529
2023-07-14 01:33:37,566 epoch [126/800] time: 5.07s train loss: 0.0617 accuracy: 0.9823 f1: 0.982
2023-07-14 01:33:38,401 epoch [126/800] time: 0.83s val loss: 0.1325 accuracy: 0.953 f1: 0.9518
2023-07-14 01:33:43,280 epoch [127/800] time: 4.88s train loss: 0.0625 accuracy: 0.9819 f1: 0.9817
2023-07-14 01:33:44,148 epoch [127/800] time: 0.87s val loss: 0.1319 accuracy: 0.9537 f1: 0.9525
2023-07-14 01:33:49,207 epoch [128/800] time: 5.06s train loss: 0.0613 accuracy: 0.9818 f1: 0.9815
2023-07-14 01:33:50,098 epoch [128/800] time: 0.89s val loss: 0.1314 accuracy: 0.9543 f1: 0.9532
2023-07-14 01:33:55,004 epoch [129/800] time: 4.91s train loss: 0.0624 accuracy: 0.9821 f1: 0.9819
2023-07-14 01:33:55,812 epoch [129/800] time: 0.81s val loss: 0.1318 accuracy: 0.9541 f1: 0.953
2023-07-14 01:34:00,855 epoch [130/800] time: 5.04s train loss: 0.0632 accuracy: 0.982 f1: 0.9819
2023-07-14 01:34:01,768 epoch [130/800] time: 0.91s val loss: 0.1323 accuracy: 0.9535 f1: 0.9522
2023-07-14 01:34:06,704 epoch [131/800] time: 4.93s train loss: 0.0616 accuracy: 0.9824 f1: 0.9822
2023-07-14 01:34:07,569 epoch [131/800] time: 0.86s val loss: 0.1311 accuracy: 0.954 f1: 0.953
2023-07-14 01:34:12,297 epoch [132/800] time: 4.73s train loss: 0.0613 accuracy: 0.9821 f1: 0.9818
2023-07-14 01:34:13,174 epoch [132/800] time: 0.88s val loss: 0.1311 accuracy: 0.9538 f1: 0.9527
2023-07-14 01:34:18,326 epoch [133/800] time: 5.15s train loss: 0.0629 accuracy: 0.9815 f1: 0.9813
2023-07-14 01:34:19,200 epoch [133/800] time: 0.87s val loss: 0.1336 accuracy: 0.9527 f1: 0.9515
2023-07-14 01:34:23,908 epoch [134/800] time: 4.71s train loss: 0.0621 accuracy: 0.9819 f1: 0.9817
2023-07-14 01:34:24,766 epoch [134/800] time: 0.86s val loss: 0.1313 accuracy: 0.954 f1: 0.9529
2023-07-14 01:34:30,004 epoch [135/800] time: 5.24s train loss: 0.0608 accuracy: 0.9823 f1: 0.982
2023-07-14 01:34:30,840 epoch [135/800] time: 0.84s val loss: 0.1317 accuracy: 0.9538 f1: 0.9525
2023-07-14 01:34:35,886 epoch [136/800] time: 5.05s train loss: 0.0607 accuracy: 0.9825 f1: 0.9823
2023-07-14 01:34:36,757 epoch [136/800] time: 0.86s val loss: 0.1313 accuracy: 0.9541 f1: 0.9529
2023-07-14 01:34:41,442 epoch [137/800] time: 4.68s train loss: 0.0602 accuracy: 0.9826 f1: 0.9824
2023-07-14 01:34:42,296 epoch [137/800] time: 0.85s val loss: 0.1314 accuracy: 0.9534 f1: 0.9521
2023-07-14 01:34:46,917 epoch [138/800] time: 4.62s train loss: 0.06 accuracy: 0.9822 f1: 0.9821
2023-07-14 01:34:47,751 epoch [138/800] time: 0.83s val loss: 0.131 accuracy: 0.9543 f1: 0.9532
2023-07-14 01:34:52,669 epoch [139/800] time: 4.92s train loss: 0.0613 accuracy: 0.9821 f1: 0.9818
2023-07-14 01:34:53,534 epoch [139/800] time: 0.86s val loss: 0.131 accuracy: 0.9542 f1: 0.9531
2023-07-14 01:34:58,132 epoch [140/800] time: 4.6s train loss: 0.0612 accuracy: 0.9824 f1: 0.9822
2023-07-14 01:34:59,034 epoch [140/800] time: 0.9s val loss: 0.1308 accuracy: 0.9545 f1: 0.9532
2023-07-14 01:35:03,810 epoch [141/800] time: 4.78s train loss: 0.0604 accuracy: 0.9829 f1: 0.9826
2023-07-14 01:35:04,632 epoch [141/800] time: 0.82s val loss: 0.1309 accuracy: 0.9543 f1: 0.9529
2023-07-14 01:35:09,251 epoch [142/800] time: 4.62s train loss: 0.0591 accuracy: 0.9834 f1: 0.9831
2023-07-14 01:35:10,109 epoch [142/800] time: 0.85s val loss: 0.1306 accuracy: 0.9545 f1: 0.9532
2023-07-14 01:35:15,012 epoch [143/800] time: 4.9s train loss: 0.0596 accuracy: 0.983 f1: 0.9828
2023-07-14 01:35:15,887 epoch [143/800] time: 0.87s val loss: 0.1303 accuracy: 0.9545 f1: 0.9532
2023-07-14 01:35:20,785 epoch [144/800] time: 4.9s train loss: 0.0603 accuracy: 0.9829 f1: 0.9828
2023-07-14 01:35:21,592 epoch [144/800] time: 0.81s val loss: 0.131 accuracy: 0.9537 f1: 0.9524
2023-07-14 01:35:26,475 epoch [145/800] time: 4.88s train loss: 0.0596 accuracy: 0.9836 f1: 0.9834
2023-07-14 01:35:27,362 epoch [145/800] time: 0.88s val loss: 0.1308 accuracy: 0.9541 f1: 0.9529
2023-07-14 01:35:32,228 epoch [146/800] time: 4.87s train loss: 0.0589 accuracy: 0.9835 f1: 0.9833
2023-07-14 01:35:33,082 epoch [146/800] time: 0.85s val loss: 0.1303 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:35:37,845 epoch [147/800] time: 4.76s train loss: 0.0591 accuracy: 0.9832 f1: 0.9831
2023-07-14 01:35:38,664 epoch [147/800] time: 0.82s val loss: 0.1303 accuracy: 0.9543 f1: 0.9531
2023-07-14 01:35:43,411 epoch [148/800] time: 4.75s train loss: 0.058 accuracy: 0.9838 f1: 0.9837
2023-07-14 01:35:44,261 epoch [148/800] time: 0.84s val loss: 0.131 accuracy: 0.9541 f1: 0.9529
2023-07-14 01:35:49,019 epoch [149/800] time: 4.76s train loss: 0.0586 accuracy: 0.9835 f1: 0.9834
2023-07-14 01:35:49,870 epoch [149/800] time: 0.85s val loss: 0.1301 accuracy: 0.9544 f1: 0.9533
2023-07-14 01:35:54,479 epoch [150/800] time: 4.61s train loss: 0.0581 accuracy: 0.9838 f1: 0.9837
2023-07-14 01:35:55,287 epoch [150/800] time: 0.8s val loss: 0.1307 accuracy: 0.9544 f1: 0.9532
2023-07-14 01:35:59,929 epoch [151/800] time: 4.64s train loss: 0.058 accuracy: 0.9834 f1: 0.9832
2023-07-14 01:36:00,779 epoch [151/800] time: 0.85s val loss: 0.1305 accuracy: 0.9541 f1: 0.9529
2023-07-14 01:36:05,413 epoch [152/800] time: 4.63s train loss: 0.0594 accuracy: 0.9835 f1: 0.9833
2023-07-14 01:36:06,263 epoch [152/800] time: 0.85s val loss: 0.1308 accuracy: 0.9545 f1: 0.9531
2023-07-14 01:36:10,931 epoch [153/800] time: 4.67s train loss: 0.0579 accuracy: 0.9838 f1: 0.9836
2023-07-14 01:36:11,741 epoch [153/800] time: 0.81s val loss: 0.1294 accuracy: 0.9549 f1: 0.9537
2023-07-14 01:36:16,438 epoch [154/800] time: 4.7s train loss: 0.0567 accuracy: 0.9842 f1: 0.984
2023-07-14 01:36:17,289 epoch [154/800] time: 0.84s val loss: 0.1301 accuracy: 0.9548 f1: 0.9535
2023-07-14 01:36:21,832 epoch [155/800] time: 4.54s train loss: 0.0578 accuracy: 0.9835 f1: 0.9832
2023-07-14 01:36:22,678 epoch [155/800] time: 0.85s val loss: 0.1303 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:36:27,328 epoch [156/800] time: 4.65s train loss: 0.0582 accuracy: 0.9833 f1: 0.9832
2023-07-14 01:36:28,130 epoch [156/800] time: 0.8s val loss: 0.1306 accuracy: 0.9546 f1: 0.9535
2023-07-14 01:36:32,771 epoch [157/800] time: 4.64s train loss: 0.058 accuracy: 0.9844 f1: 0.9843
2023-07-14 01:36:33,617 epoch [157/800] time: 0.84s val loss: 0.1301 accuracy: 0.9543 f1: 0.9532
2023-07-14 01:36:38,191 epoch [158/800] time: 4.57s train loss: 0.0577 accuracy: 0.9837 f1: 0.9836
2023-07-14 01:36:39,035 epoch [158/800] time: 0.84s val loss: 0.1307 accuracy: 0.9547 f1: 0.9535
2023-07-14 01:36:43,808 epoch [159/800] time: 4.77s train loss: 0.0586 accuracy: 0.9834 f1: 0.9833
2023-07-14 01:36:44,608 epoch [159/800] time: 0.8s val loss: 0.1307 accuracy: 0.9536 f1: 0.9526
2023-07-14 01:36:49,328 epoch [160/800] time: 4.72s train loss: 0.0595 accuracy: 0.983 f1: 0.9828
2023-07-14 01:36:50,171 epoch [160/800] time: 0.84s val loss: 0.1308 accuracy: 0.9542 f1: 0.9529
2023-07-14 01:36:54,958 epoch [161/800] time: 4.79s train loss: 0.0579 accuracy: 0.9834 f1: 0.9833
2023-07-14 01:36:55,869 epoch [161/800] time: 0.91s val loss: 0.1299 accuracy: 0.955 f1: 0.9537
2023-07-14 01:37:00,855 epoch [162/800] time: 4.99s train loss: 0.0567 accuracy: 0.9844 f1: 0.9843
2023-07-14 01:37:01,703 epoch [162/800] time: 0.84s val loss: 0.1294 accuracy: 0.9549 f1: 0.9536
2023-07-14 01:37:06,818 epoch [163/800] time: 5.12s train loss: 0.0575 accuracy: 0.9838 f1: 0.9836
2023-07-14 01:37:07,748 epoch [163/800] time: 0.93s val loss: 0.1312 accuracy: 0.9542 f1: 0.9529
2023-07-14 01:37:13,298 epoch [164/800] time: 5.55s train loss: 0.0574 accuracy: 0.9843 f1: 0.9841
2023-07-14 01:37:14,204 epoch [164/800] time: 0.91s val loss: 0.1298 accuracy: 0.9543 f1: 0.9529
2023-07-14 01:37:19,172 epoch [165/800] time: 4.97s train loss: 0.0575 accuracy: 0.9837 f1: 0.9836
2023-07-14 01:37:20,030 epoch [165/800] time: 0.86s val loss: 0.13 accuracy: 0.9549 f1: 0.9537
2023-07-14 01:37:25,212 epoch [166/800] time: 5.18s train loss: 0.0576 accuracy: 0.9839 f1: 0.9837
2023-07-14 01:37:26,142 epoch [166/800] time: 0.93s val loss: 0.1315 accuracy: 0.9541 f1: 0.9528
2023-07-14 01:37:30,983 epoch [167/800] time: 4.84s train loss: 0.0578 accuracy: 0.9841 f1: 0.9841
2023-07-14 01:37:31,863 epoch [167/800] time: 0.88s val loss: 0.1301 accuracy: 0.9546 f1: 0.9534
2023-07-14 01:37:36,588 epoch [168/800] time: 4.73s train loss: 0.0569 accuracy: 0.9845 f1: 0.9844
2023-07-14 01:37:37,411 epoch [168/800] time: 0.82s val loss: 0.1299 accuracy: 0.9544 f1: 0.9532
2023-07-14 01:37:42,079 epoch [169/800] time: 4.67s train loss: 0.0565 accuracy: 0.9844 f1: 0.9843
2023-07-14 01:37:42,928 epoch [169/800] time: 0.85s val loss: 0.1298 accuracy: 0.9545 f1: 0.9534
2023-07-14 01:37:47,773 epoch [170/800] time: 4.84s train loss: 0.0562 accuracy: 0.9845 f1: 0.9843
2023-07-14 01:37:48,675 epoch [170/800] time: 0.9s val loss: 0.1298 accuracy: 0.9543 f1: 0.9531
2023-07-14 01:37:53,537 epoch [171/800] time: 4.86s train loss: 0.056 accuracy: 0.9843 f1: 0.9841
2023-07-14 01:37:54,349 epoch [171/800] time: 0.81s val loss: 0.13 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:37:59,225 epoch [172/800] time: 4.88s train loss: 0.0578 accuracy: 0.9837 f1: 0.9835
2023-07-14 01:38:00,087 epoch [172/800] time: 0.86s val loss: 0.1298 accuracy: 0.9542 f1: 0.9531
2023-07-14 01:38:04,835 epoch [173/800] time: 4.75s train loss: 0.0568 accuracy: 0.9845 f1: 0.9843
2023-07-14 01:38:05,688 epoch [173/800] time: 0.85s val loss: 0.1302 accuracy: 0.9543 f1: 0.953
2023-07-14 01:38:10,465 epoch [174/800] time: 4.78s train loss: 0.0562 accuracy: 0.9842 f1: 0.984
2023-07-14 01:38:11,267 epoch [174/800] time: 0.8s val loss: 0.1296 accuracy: 0.9544 f1: 0.9532
2023-07-14 01:38:15,824 epoch [175/800] time: 4.56s train loss: 0.0556 accuracy: 0.9841 f1: 0.9839
2023-07-14 01:38:16,671 epoch [175/800] time: 0.85s val loss: 0.1294 accuracy: 0.9551 f1: 0.9538
2023-07-14 01:38:21,178 epoch [176/800] time: 4.51s train loss: 0.0574 accuracy: 0.984 f1: 0.9839
2023-07-14 01:38:22,026 epoch [176/800] time: 0.85s val loss: 0.129 accuracy: 0.9553 f1: 0.954
2023-07-14 01:38:26,578 epoch [177/800] time: 4.55s train loss: 0.057 accuracy: 0.9837 f1: 0.9836
2023-07-14 01:38:27,381 epoch [177/800] time: 0.8s val loss: 0.1296 accuracy: 0.9545 f1: 0.9533
2023-07-14 01:38:31,938 epoch [178/800] time: 4.56s train loss: 0.0561 accuracy: 0.9844 f1: 0.9843
2023-07-14 01:38:32,788 epoch [178/800] time: 0.85s val loss: 0.1299 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:38:37,311 epoch [179/800] time: 4.52s train loss: 0.0561 accuracy: 0.9844 f1: 0.9842
2023-07-14 01:38:38,160 epoch [179/800] time: 0.85s val loss: 0.1304 accuracy: 0.9542 f1: 0.9529
2023-07-14 01:38:42,861 epoch [180/800] time: 4.7s train loss: 0.0568 accuracy: 0.9843 f1: 0.9841
2023-07-14 01:38:43,662 epoch [180/800] time: 0.8s val loss: 0.1298 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:38:48,327 epoch [181/800] time: 4.66s train loss: 0.0564 accuracy: 0.9842 f1: 0.984
2023-07-14 01:38:49,171 epoch [181/800] time: 0.84s val loss: 0.1302 accuracy: 0.9541 f1: 0.9528
2023-07-14 01:38:53,872 epoch [182/800] time: 4.7s train loss: 0.0568 accuracy: 0.9842 f1: 0.9841
2023-07-14 01:38:54,716 epoch [182/800] time: 0.84s val loss: 0.1304 accuracy: 0.9544 f1: 0.9532
2023-07-14 01:38:59,451 epoch [183/800] time: 4.74s train loss: 0.0565 accuracy: 0.9843 f1: 0.9842
2023-07-14 01:39:00,251 epoch [183/800] time: 0.8s val loss: 0.1299 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:39:04,931 epoch [184/800] time: 4.68s train loss: 0.0554 accuracy: 0.9847 f1: 0.9845
2023-07-14 01:39:05,777 epoch [184/800] time: 0.84s val loss: 0.1297 accuracy: 0.9547 f1: 0.9534
2023-07-14 01:39:10,415 epoch [185/800] time: 4.64s train loss: 0.0561 accuracy: 0.9844 f1: 0.9843
2023-07-14 01:39:11,259 epoch [185/800] time: 0.84s val loss: 0.1298 accuracy: 0.9545 f1: 0.9532
2023-07-14 01:39:16,016 epoch [186/800] time: 4.76s train loss: 0.0574 accuracy: 0.9841 f1: 0.9839
2023-07-14 01:39:16,816 epoch [186/800] time: 0.8s val loss: 0.1303 accuracy: 0.9542 f1: 0.9528
2023-07-14 01:39:21,556 epoch [187/800] time: 4.74s train loss: 0.0567 accuracy: 0.9842 f1: 0.984
2023-07-14 01:39:22,415 epoch [187/800] time: 0.86s val loss: 0.1295 accuracy: 0.9547 f1: 0.9535
2023-07-14 01:39:27,088 epoch [188/800] time: 4.67s train loss: 0.0557 accuracy: 0.9847 f1: 0.9846
2023-07-14 01:39:27,934 epoch [188/800] time: 0.84s val loss: 0.1297 accuracy: 0.9549 f1: 0.9537
2023-07-14 01:39:32,622 epoch [189/800] time: 4.69s train loss: 0.0562 accuracy: 0.9838 f1: 0.9837
2023-07-14 01:39:33,425 epoch [189/800] time: 0.8s val loss: 0.1297 accuracy: 0.9547 f1: 0.9535
2023-07-14 01:39:38,111 epoch [190/800] time: 4.69s train loss: 0.0573 accuracy: 0.9842 f1: 0.984
2023-07-14 01:39:38,956 epoch [190/800] time: 0.85s val loss: 0.1312 accuracy: 0.9542 f1: 0.9529
2023-07-14 01:39:43,577 epoch [191/800] time: 4.62s train loss: 0.0557 accuracy: 0.9844 f1: 0.9843
2023-07-14 01:39:44,422 epoch [191/800] time: 0.85s val loss: 0.1292 accuracy: 0.9548 f1: 0.9536
2023-07-14 01:39:49,067 epoch [192/800] time: 4.64s train loss: 0.0561 accuracy: 0.9843 f1: 0.9842
2023-07-14 01:39:49,873 epoch [192/800] time: 0.81s val loss: 0.1301 accuracy: 0.955 f1: 0.9537
2023-07-14 01:39:54,487 epoch [193/800] time: 4.61s train loss: 0.0553 accuracy: 0.9849 f1: 0.9847
2023-07-14 01:39:55,334 epoch [193/800] time: 0.84s val loss: 0.1293 accuracy: 0.9549 f1: 0.9536
2023-07-14 01:39:59,942 epoch [194/800] time: 4.61s train loss: 0.056 accuracy: 0.9841 f1: 0.9838
2023-07-14 01:40:00,786 epoch [194/800] time: 0.84s val loss: 0.1294 accuracy: 0.9547 f1: 0.9536
2023-07-14 01:40:05,435 epoch [195/800] time: 4.65s train loss: 0.056 accuracy: 0.984 f1: 0.9838
2023-07-14 01:40:06,236 epoch [195/800] time: 0.8s val loss: 0.1298 accuracy: 0.9544 f1: 0.9531
2023-07-14 01:40:10,880 epoch [196/800] time: 4.64s train loss: 0.0563 accuracy: 0.984 f1: 0.9839
2023-07-14 01:40:11,725 epoch [196/800] time: 0.84s val loss: 0.1293 accuracy: 0.955 f1: 0.9538
2023-07-14 01:40:16,572 epoch [197/800] time: 4.85s train loss: 0.0552 accuracy: 0.9846 f1: 0.9845
2023-07-14 01:40:17,442 epoch [197/800] time: 0.87s val loss: 0.1289 accuracy: 0.9552 f1: 0.9539
2023-07-14 01:40:22,511 epoch [198/800] time: 5.07s train loss: 0.0569 accuracy: 0.984 f1: 0.9839
2023-07-14 01:40:23,376 epoch [198/800] time: 0.86s val loss: 0.13 accuracy: 0.9544 f1: 0.9532
2023-07-14 01:40:28,680 epoch [199/800] time: 5.3s train loss: 0.0552 accuracy: 0.9846 f1: 0.9845
2023-07-14 01:40:29,620 epoch [199/800] time: 0.94s val loss: 0.1292 accuracy: 0.9549 f1: 0.9538
2023-07-14 01:40:34,711 epoch [200/800] time: 5.09s train loss: 0.0553 accuracy: 0.9851 f1: 0.9851
2023-07-14 01:40:35,619 epoch [200/800] time: 0.9s val loss: 0.1299 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:40:40,785 epoch [201/800] time: 5.17s train loss: 0.0553 accuracy: 0.9848 f1: 0.9846
2023-07-14 01:40:41,656 epoch [201/800] time: 0.87s val loss: 0.1296 accuracy: 0.955 f1: 0.9538
2023-07-14 01:40:46,948 epoch [202/800] time: 5.29s train loss: 0.0555 accuracy: 0.985 f1: 0.9848
2023-07-14 01:40:47,852 epoch [202/800] time: 0.9s val loss: 0.1295 accuracy: 0.9545 f1: 0.9533
2023-07-14 01:40:52,672 epoch [203/800] time: 4.82s train loss: 0.056 accuracy: 0.9849 f1: 0.9847
2023-07-14 01:40:53,543 epoch [203/800] time: 0.87s val loss: 0.1306 accuracy: 0.9544 f1: 0.9533
2023-07-14 01:40:58,228 epoch [204/800] time: 4.68s train loss: 0.0555 accuracy: 0.9848 f1: 0.9846
2023-07-14 01:40:59,046 epoch [204/800] time: 0.82s val loss: 0.1296 accuracy: 0.9546 f1: 0.9534
2023-07-14 01:41:03,877 epoch [205/800] time: 4.83s train loss: 0.0559 accuracy: 0.9847 f1: 0.9845
2023-07-14 01:41:04,742 epoch [205/800] time: 0.87s val loss: 0.1297 accuracy: 0.9544 f1: 0.9531
2023-07-14 01:41:09,339 epoch [206/800] time: 4.6s train loss: 0.0561 accuracy: 0.9842 f1: 0.984
2023-07-14 01:41:10,191 epoch [206/800] time: 0.85s val loss: 0.1298 accuracy: 0.9549 f1: 0.9537
2023-07-14 01:41:14,830 epoch [207/800] time: 4.64s train loss: 0.0555 accuracy: 0.985 f1: 0.9848
2023-07-14 01:41:15,634 epoch [207/800] time: 0.8s val loss: 0.1298 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:41:20,379 epoch [208/800] time: 4.74s train loss: 0.0555 accuracy: 0.9847 f1: 0.9846
2023-07-14 01:41:21,224 epoch [208/800] time: 0.84s val loss: 0.1294 accuracy: 0.9545 f1: 0.9533
2023-07-14 01:41:25,755 epoch [209/800] time: 4.53s train loss: 0.0561 accuracy: 0.984 f1: 0.9838
2023-07-14 01:41:26,622 epoch [209/800] time: 0.87s val loss: 0.1297 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:41:31,437 epoch [210/800] time: 4.81s train loss: 0.0549 accuracy: 0.9849 f1: 0.9848
2023-07-14 01:41:32,245 epoch [210/800] time: 0.81s val loss: 0.1297 accuracy: 0.9548 f1: 0.9535
2023-07-14 01:41:36,843 epoch [211/800] time: 4.6s train loss: 0.0551 accuracy: 0.985 f1: 0.9849
2023-07-14 01:41:37,695 epoch [211/800] time: 0.85s val loss: 0.1302 accuracy: 0.9548 f1: 0.9535
2023-07-14 01:41:42,272 epoch [212/800] time: 4.58s train loss: 0.0573 accuracy: 0.9841 f1: 0.984
2023-07-14 01:41:43,115 epoch [212/800] time: 0.84s val loss: 0.1304 accuracy: 0.954 f1: 0.9528
2023-07-14 01:41:47,651 epoch [213/800] time: 4.54s train loss: 0.0553 accuracy: 0.9849 f1: 0.9848
2023-07-14 01:41:48,455 epoch [213/800] time: 0.8s val loss: 0.1296 accuracy: 0.9546 f1: 0.9534
2023-07-14 01:41:52,990 epoch [214/800] time: 4.53s train loss: 0.0558 accuracy: 0.985 f1: 0.9848
2023-07-14 01:41:53,836 epoch [214/800] time: 0.85s val loss: 0.1293 accuracy: 0.9554 f1: 0.9543
2023-07-14 01:41:58,341 epoch [215/800] time: 4.5s train loss: 0.0559 accuracy: 0.9848 f1: 0.9845
2023-07-14 01:41:59,200 epoch [215/800] time: 0.86s val loss: 0.1289 accuracy: 0.9549 f1: 0.9537
2023-07-14 01:42:03,736 epoch [216/800] time: 4.54s train loss: 0.0556 accuracy: 0.9847 f1: 0.9847
2023-07-14 01:42:04,538 epoch [216/800] time: 0.8s val loss: 0.1297 accuracy: 0.9549 f1: 0.9537
2023-07-14 01:42:09,072 epoch [217/800] time: 4.53s train loss: 0.0545 accuracy: 0.9852 f1: 0.985
2023-07-14 01:42:09,918 epoch [217/800] time: 0.84s val loss: 0.1298 accuracy: 0.9549 f1: 0.9535
2023-07-14 01:42:14,423 epoch [218/800] time: 4.51s train loss: 0.0555 accuracy: 0.9848 f1: 0.9847
2023-07-14 01:42:15,271 epoch [218/800] time: 0.85s val loss: 0.1303 accuracy: 0.9549 f1: 0.9536
2023-07-14 01:42:19,815 epoch [219/800] time: 4.54s train loss: 0.0555 accuracy: 0.9844 f1: 0.9843
2023-07-14 01:42:20,616 epoch [219/800] time: 0.8s val loss: 0.1296 accuracy: 0.9547 f1: 0.9535
2023-07-14 01:42:25,164 epoch [220/800] time: 4.55s train loss: 0.056 accuracy: 0.9843 f1: 0.9841
2023-07-14 01:42:26,010 epoch [220/800] time: 0.85s val loss: 0.1295 accuracy: 0.9543 f1: 0.9531
2023-07-14 01:42:30,515 epoch [221/800] time: 4.5s train loss: 0.0548 accuracy: 0.9848 f1: 0.9847
2023-07-14 01:42:31,365 epoch [221/800] time: 0.85s val loss: 0.1293 accuracy: 0.9554 f1: 0.9542
2023-07-14 01:42:35,909 epoch [222/800] time: 4.54s train loss: 0.0544 accuracy: 0.9853 f1: 0.9851
2023-07-14 01:42:36,714 epoch [222/800] time: 0.8s val loss: 0.1298 accuracy: 0.9544 f1: 0.9533
2023-07-14 01:42:41,248 epoch [223/800] time: 4.53s train loss: 0.0555 accuracy: 0.9851 f1: 0.985
2023-07-14 01:42:42,095 epoch [223/800] time: 0.85s val loss: 0.1297 accuracy: 0.9545 f1: 0.9531
2023-07-14 01:42:46,590 epoch [224/800] time: 4.5s train loss: 0.0559 accuracy: 0.9846 f1: 0.9844
2023-07-14 01:42:47,433 epoch [224/800] time: 0.84s val loss: 0.13 accuracy: 0.9544 f1: 0.953
2023-07-14 01:42:52,202 epoch [225/800] time: 4.77s train loss: 0.0556 accuracy: 0.9849 f1: 0.9848
2023-07-14 01:42:53,002 epoch [225/800] time: 0.8s val loss: 0.1296 accuracy: 0.9551 f1: 0.9538
2023-07-14 01:42:57,533 epoch [226/800] time: 4.53s train loss: 0.0551 accuracy: 0.9847 f1: 0.9845
2023-07-14 01:42:58,376 epoch [226/800] time: 0.84s val loss: 0.1297 accuracy: 0.9548 f1: 0.9536
2023-07-14 01:43:02,886 epoch [227/800] time: 4.51s train loss: 0.0569 accuracy: 0.9844 f1: 0.9842
2023-07-14 01:43:03,729 epoch [227/800] time: 0.84s val loss: 0.1302 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:43:08,288 epoch [228/800] time: 4.56s train loss: 0.0544 accuracy: 0.9849 f1: 0.9847
2023-07-14 01:43:09,098 epoch [228/800] time: 0.81s val loss: 0.1294 accuracy: 0.9549 f1: 0.9536
2023-07-14 01:43:13,682 epoch [229/800] time: 4.58s train loss: 0.056 accuracy: 0.9844 f1: 0.9843
2023-07-14 01:43:14,526 epoch [229/800] time: 0.84s val loss: 0.1299 accuracy: 0.9548 f1: 0.9537
2023-07-14 01:43:19,032 epoch [230/800] time: 4.51s train loss: 0.0558 accuracy: 0.9848 f1: 0.9846
2023-07-14 01:43:19,876 epoch [230/800] time: 0.84s val loss: 0.1301 accuracy: 0.9556 f1: 0.9543
2023-07-14 01:43:24,467 epoch [231/800] time: 4.59s train loss: 0.0559 accuracy: 0.9843 f1: 0.9842
2023-07-14 01:43:25,278 epoch [231/800] time: 0.81s val loss: 0.1303 accuracy: 0.9546 f1: 0.9534
2023-07-14 01:43:29,892 epoch [232/800] time: 4.61s train loss: 0.0554 accuracy: 0.985 f1: 0.9848
2023-07-14 01:43:30,745 epoch [232/800] time: 0.85s val loss: 0.1302 accuracy: 0.9544 f1: 0.9532
2023-07-14 01:43:35,330 epoch [233/800] time: 4.59s train loss: 0.0547 accuracy: 0.9853 f1: 0.9851
2023-07-14 01:43:36,201 epoch [233/800] time: 0.87s val loss: 0.1307 accuracy: 0.9542 f1: 0.953
2023-07-14 01:43:40,778 epoch [234/800] time: 4.58s train loss: 0.0558 accuracy: 0.9845 f1: 0.9844
2023-07-14 01:43:41,582 epoch [234/800] time: 0.8s val loss: 0.1296 accuracy: 0.9547 f1: 0.9535
2023-07-14 01:43:46,124 epoch [235/800] time: 4.54s train loss: 0.0552 accuracy: 0.9849 f1: 0.9847
2023-07-14 01:43:46,982 epoch [235/800] time: 0.86s val loss: 0.1298 accuracy: 0.955 f1: 0.9537
2023-07-14 01:43:51,552 epoch [236/800] time: 4.57s train loss: 0.0546 accuracy: 0.985 f1: 0.9848
2023-07-14 01:43:52,404 epoch [236/800] time: 0.85s val loss: 0.1296 accuracy: 0.9549 f1: 0.9536
2023-07-14 01:43:57,016 epoch [237/800] time: 4.61s train loss: 0.0555 accuracy: 0.9848 f1: 0.9846
2023-07-14 01:43:57,831 epoch [237/800] time: 0.81s val loss: 0.1306 accuracy: 0.9543 f1: 0.953
2023-07-14 01:44:02,437 epoch [238/800] time: 4.61s train loss: 0.0555 accuracy: 0.985 f1: 0.9848
2023-07-14 01:44:03,289 epoch [238/800] time: 0.85s val loss: 0.1298 accuracy: 0.954 f1: 0.9527
2023-07-14 01:44:07,811 epoch [239/800] time: 4.52s train loss: 0.0551 accuracy: 0.9849 f1: 0.9847
2023-07-14 01:44:08,659 epoch [239/800] time: 0.85s val loss: 0.1294 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:44:13,453 epoch [240/800] time: 4.79s train loss: 0.0554 accuracy: 0.9849 f1: 0.9847
2023-07-14 01:44:14,260 epoch [240/800] time: 0.81s val loss: 0.1295 accuracy: 0.9547 f1: 0.9535
2023-07-14 01:44:18,888 epoch [241/800] time: 4.63s train loss: 0.0556 accuracy: 0.9845 f1: 0.9844
2023-07-14 01:44:19,750 epoch [241/800] time: 0.86s val loss: 0.1297 accuracy: 0.9555 f1: 0.9541
2023-07-14 01:44:24,482 epoch [242/800] time: 4.73s train loss: 0.0553 accuracy: 0.9848 f1: 0.9847
2023-07-14 01:44:25,353 epoch [242/800] time: 0.87s val loss: 0.1297 accuracy: 0.9549 f1: 0.9536
2023-07-14 01:44:30,177 epoch [243/800] time: 4.82s train loss: 0.0577 accuracy: 0.9842 f1: 0.9841
2023-07-14 01:44:30,983 epoch [243/800] time: 0.81s val loss: 0.1302 accuracy: 0.9543 f1: 0.9531
2023-07-14 01:44:35,738 epoch [244/800] time: 4.75s train loss: 0.055 accuracy: 0.9846 f1: 0.9845
2023-07-14 01:44:36,606 epoch [244/800] time: 0.87s val loss: 0.1295 accuracy: 0.9546 f1: 0.9534
2023-07-14 01:44:41,365 epoch [245/800] time: 4.76s train loss: 0.0562 accuracy: 0.984 f1: 0.9839
2023-07-14 01:44:42,229 epoch [245/800] time: 0.86s val loss: 0.1297 accuracy: 0.9549 f1: 0.9537
2023-07-14 01:44:47,013 epoch [246/800] time: 4.78s train loss: 0.0549 accuracy: 0.9849 f1: 0.9846
2023-07-14 01:44:47,830 epoch [246/800] time: 0.82s val loss: 0.1297 accuracy: 0.9547 f1: 0.9535
2023-07-14 01:44:52,640 epoch [247/800] time: 4.81s train loss: 0.0561 accuracy: 0.9846 f1: 0.9844
2023-07-14 01:44:53,506 epoch [247/800] time: 0.86s val loss: 0.1297 accuracy: 0.9547 f1: 0.9535
2023-07-14 01:44:58,218 epoch [248/800] time: 4.71s train loss: 0.0543 accuracy: 0.9852 f1: 0.985
2023-07-14 01:44:59,075 epoch [248/800] time: 0.86s val loss: 0.1296 accuracy: 0.9552 f1: 0.954
2023-07-14 01:45:03,900 epoch [249/800] time: 4.83s train loss: 0.0558 accuracy: 0.9845 f1: 0.9843
2023-07-14 01:45:04,713 epoch [249/800] time: 0.81s val loss: 0.1294 accuracy: 0.9554 f1: 0.9542
2023-07-14 01:45:09,529 epoch [250/800] time: 4.82s train loss: 0.0555 accuracy: 0.9851 f1: 0.9849
2023-07-14 01:45:10,395 epoch [250/800] time: 0.87s val loss: 0.1301 accuracy: 0.9544 f1: 0.9531
2023-07-14 01:45:15,161 epoch [251/800] time: 4.77s train loss: 0.056 accuracy: 0.9846 f1: 0.9845
2023-07-14 01:45:16,014 epoch [251/800] time: 0.85s val loss: 0.131 accuracy: 0.9538 f1: 0.9527
2023-07-14 01:45:20,774 epoch [252/800] time: 4.76s train loss: 0.0552 accuracy: 0.9851 f1: 0.985
2023-07-14 01:45:21,577 epoch [252/800] time: 0.8s val loss: 0.1297 accuracy: 0.9551 f1: 0.9539
2023-07-14 01:45:26,320 epoch [253/800] time: 4.74s train loss: 0.0543 accuracy: 0.9848 f1: 0.9847
2023-07-14 01:45:27,164 epoch [253/800] time: 0.84s val loss: 0.1291 accuracy: 0.9547 f1: 0.9535
2023-07-14 01:45:31,938 epoch [254/800] time: 4.77s train loss: 0.0551 accuracy: 0.9846 f1: 0.9844
2023-07-14 01:45:32,786 epoch [254/800] time: 0.85s val loss: 0.1294 accuracy: 0.9548 f1: 0.9536
2023-07-14 01:45:37,595 epoch [255/800] time: 4.81s train loss: 0.0552 accuracy: 0.9845 f1: 0.9843
2023-07-14 01:45:38,413 epoch [255/800] time: 0.82s val loss: 0.1296 accuracy: 0.9546 f1: 0.9534
2023-07-14 01:45:43,205 epoch [256/800] time: 4.79s train loss: 0.0546 accuracy: 0.9855 f1: 0.9853
2023-07-14 01:45:44,061 epoch [256/800] time: 0.85s val loss: 0.1303 accuracy: 0.9543 f1: 0.953
2023-07-14 01:45:48,793 epoch [257/800] time: 4.73s train loss: 0.0556 accuracy: 0.9846 f1: 0.9845
2023-07-14 01:45:49,651 epoch [257/800] time: 0.86s val loss: 0.1292 accuracy: 0.9549 f1: 0.9538
2023-07-14 01:45:54,390 epoch [258/800] time: 4.74s train loss: 0.0567 accuracy: 0.9839 f1: 0.9837
2023-07-14 01:45:55,199 epoch [258/800] time: 0.81s val loss: 0.13 accuracy: 0.9546 f1: 0.9534
2023-07-14 01:46:00,043 epoch [259/800] time: 4.84s train loss: 0.0566 accuracy: 0.9844 f1: 0.9842
2023-07-14 01:46:00,896 epoch [259/800] time: 0.85s val loss: 0.13 accuracy: 0.9548 f1: 0.9534
2023-07-14 01:46:05,931 epoch [260/800] time: 5.03s train loss: 0.0561 accuracy: 0.9846 f1: 0.9845
2023-07-14 01:46:06,830 epoch [260/800] time: 0.9s val loss: 0.1299 accuracy: 0.9552 f1: 0.954
2023-07-14 01:46:11,994 epoch [261/800] time: 5.16s train loss: 0.0553 accuracy: 0.9847 f1: 0.9845
2023-07-14 01:46:12,807 epoch [261/800] time: 0.81s val loss: 0.1299 accuracy: 0.9542 f1: 0.953
2023-07-14 01:46:17,623 epoch [262/800] time: 4.82s train loss: 0.0551 accuracy: 0.9852 f1: 0.985
2023-07-14 01:46:18,505 epoch [262/800] time: 0.88s val loss: 0.1305 accuracy: 0.9541 f1: 0.9529
2023-07-14 01:46:23,396 epoch [263/800] time: 4.89s train loss: 0.0555 accuracy: 0.9846 f1: 0.9844
2023-07-14 01:46:24,271 epoch [263/800] time: 0.87s val loss: 0.1297 accuracy: 0.9552 f1: 0.9538
2023-07-14 01:46:29,112 epoch [264/800] time: 4.84s train loss: 0.0557 accuracy: 0.9843 f1: 0.9842
2023-07-14 01:46:29,942 epoch [264/800] time: 0.83s val loss: 0.1295 accuracy: 0.9548 f1: 0.9536
2023-07-14 01:46:34,685 epoch [265/800] time: 4.74s train loss: 0.0558 accuracy: 0.9849 f1: 0.9847
2023-07-14 01:46:35,550 epoch [265/800] time: 0.87s val loss: 0.1303 accuracy: 0.9536 f1: 0.9523
2023-07-14 01:46:40,241 epoch [266/800] time: 4.69s train loss: 0.0567 accuracy: 0.9844 f1: 0.9843
2023-07-14 01:46:41,092 epoch [266/800] time: 0.85s val loss: 0.1297 accuracy: 0.9549 f1: 0.9537
2023-07-14 01:46:45,854 epoch [267/800] time: 4.76s train loss: 0.0563 accuracy: 0.9848 f1: 0.9846
2023-07-14 01:46:46,658 epoch [267/800] time: 0.8s val loss: 0.1296 accuracy: 0.9547 f1: 0.9534
2023-07-14 01:46:51,598 epoch [268/800] time: 4.94s train loss: 0.0574 accuracy: 0.9848 f1: 0.9846
2023-07-14 01:46:52,477 epoch [268/800] time: 0.88s val loss: 0.1314 accuracy: 0.9537 f1: 0.9524
2023-07-14 01:46:57,257 epoch [269/800] time: 4.78s train loss: 0.0564 accuracy: 0.9848 f1: 0.9846
2023-07-14 01:46:58,207 epoch [269/800] time: 0.95s val loss: 0.1317 accuracy: 0.9534 f1: 0.952
2023-07-14 01:47:03,095 epoch [270/800] time: 4.89s train loss: 0.0551 accuracy: 0.985 f1: 0.9848
2023-07-14 01:47:03,964 epoch [270/800] time: 0.87s val loss: 0.1295 accuracy: 0.9551 f1: 0.9538
2023-07-14 01:47:09,343 epoch [271/800] time: 5.38s train loss: 0.0563 accuracy: 0.9845 f1: 0.9844
2023-07-14 01:47:10,261 epoch [271/800] time: 0.92s val loss: 0.1298 accuracy: 0.9548 f1: 0.9536
2023-07-14 01:47:15,442 epoch [272/800] time: 5.18s train loss: 0.056 accuracy: 0.9846 f1: 0.9844
2023-07-14 01:47:16,413 epoch [272/800] time: 0.97s val loss: 0.1307 accuracy: 0.9541 f1: 0.9528
2023-07-14 01:47:21,616 epoch [273/800] time: 5.2s train loss: 0.055 accuracy: 0.9851 f1: 0.985
2023-07-14 01:47:22,460 epoch [273/800] time: 0.84s val loss: 0.1298 accuracy: 0.9546 f1: 0.9532
2023-07-14 01:47:27,608 epoch [274/800] time: 5.15s train loss: 0.0557 accuracy: 0.9845 f1: 0.9843
2023-07-14 01:47:28,832 epoch [274/800] time: 1.22s val loss: 0.1291 accuracy: 0.9548 f1: 0.9535
2023-07-14 01:47:33,819 epoch [275/800] time: 4.99s train loss: 0.0558 accuracy: 0.9847 f1: 0.9846
2023-07-14 01:47:34,735 epoch [275/800] time: 0.92s val loss: 0.1307 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:47:39,689 epoch [276/800] time: 4.95s train loss: 0.0542 accuracy: 0.9853 f1: 0.9852
2023-07-14 01:47:40,504 epoch [276/800] time: 0.82s val loss: 0.1295 accuracy: 0.9548 f1: 0.9538
2023-07-14 01:47:45,931 epoch [277/800] time: 5.43s train loss: 0.0549 accuracy: 0.9852 f1: 0.9851
2023-07-14 01:47:46,940 epoch [277/800] time: 1.01s val loss: 0.1292 accuracy: 0.9549 f1: 0.9536
2023-07-14 01:47:51,764 epoch [278/800] time: 4.82s train loss: 0.055 accuracy: 0.9851 f1: 0.9849
2023-07-14 01:47:52,627 epoch [278/800] time: 0.86s val loss: 0.1294 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:47:57,457 epoch [279/800] time: 4.83s train loss: 0.0552 accuracy: 0.9848 f1: 0.9846
2023-07-14 01:47:58,292 epoch [279/800] time: 0.83s val loss: 0.1298 accuracy: 0.9543 f1: 0.9531
2023-07-14 01:48:03,893 epoch [280/800] time: 5.6s train loss: 0.0552 accuracy: 0.9852 f1: 0.985
2023-07-14 01:48:05,022 epoch [280/800] time: 1.13s val loss: 0.1295 accuracy: 0.9548 f1: 0.9535
2023-07-14 01:48:10,904 epoch [281/800] time: 5.88s train loss: 0.0549 accuracy: 0.985 f1: 0.9849
2023-07-14 01:48:11,818 epoch [281/800] time: 0.91s val loss: 0.1297 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:48:16,917 epoch [282/800] time: 5.1s train loss: 0.0564 accuracy: 0.9846 f1: 0.9845
2023-07-14 01:48:17,759 epoch [282/800] time: 0.84s val loss: 0.1306 accuracy: 0.9543 f1: 0.953
2023-07-14 01:48:22,723 epoch [283/800] time: 4.96s train loss: 0.0544 accuracy: 0.985 f1: 0.9847
2023-07-14 01:48:23,621 epoch [283/800] time: 0.9s val loss: 0.129 accuracy: 0.9552 f1: 0.9539
2023-07-14 01:48:28,346 epoch [284/800] time: 4.72s train loss: 0.0563 accuracy: 0.9838 f1: 0.9837
2023-07-14 01:48:29,205 epoch [284/800] time: 0.86s val loss: 0.1294 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:48:34,054 epoch [285/800] time: 4.85s train loss: 0.0553 accuracy: 0.9851 f1: 0.985
2023-07-14 01:48:34,855 epoch [285/800] time: 0.8s val loss: 0.1292 accuracy: 0.9551 f1: 0.9539
2023-07-14 01:48:39,635 epoch [286/800] time: 4.78s train loss: 0.0572 accuracy: 0.9844 f1: 0.9842
2023-07-14 01:48:40,488 epoch [286/800] time: 0.85s val loss: 0.1309 accuracy: 0.9543 f1: 0.953
2023-07-14 01:48:45,227 epoch [287/800] time: 4.74s train loss: 0.0562 accuracy: 0.9842 f1: 0.984
2023-07-14 01:48:46,076 epoch [287/800] time: 0.85s val loss: 0.1295 accuracy: 0.9546 f1: 0.9534
2023-07-14 01:48:50,825 epoch [288/800] time: 4.75s train loss: 0.0545 accuracy: 0.9852 f1: 0.9851
2023-07-14 01:48:51,631 epoch [288/800] time: 0.81s val loss: 0.13 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:48:56,327 epoch [289/800] time: 4.7s train loss: 0.0551 accuracy: 0.9849 f1: 0.9847
2023-07-14 01:48:57,172 epoch [289/800] time: 0.84s val loss: 0.1301 accuracy: 0.9544 f1: 0.9533
2023-07-14 01:49:01,914 epoch [290/800] time: 4.74s train loss: 0.055 accuracy: 0.9852 f1: 0.9851
2023-07-14 01:49:02,769 epoch [290/800] time: 0.86s val loss: 0.1298 accuracy: 0.9548 f1: 0.9536
2023-07-14 01:49:07,542 epoch [291/800] time: 4.77s train loss: 0.0563 accuracy: 0.9846 f1: 0.9845
2023-07-14 01:49:08,352 epoch [291/800] time: 0.81s val loss: 0.1293 accuracy: 0.9549 f1: 0.9536
2023-07-14 01:49:13,094 epoch [292/800] time: 4.74s train loss: 0.0562 accuracy: 0.9845 f1: 0.9844
2023-07-14 01:49:13,949 epoch [292/800] time: 0.85s val loss: 0.1296 accuracy: 0.9547 f1: 0.9533
2023-07-14 01:49:18,484 epoch [293/800] time: 4.53s train loss: 0.0553 accuracy: 0.9846 f1: 0.9845
2023-07-14 01:49:19,348 epoch [293/800] time: 0.86s val loss: 0.1297 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:49:23,966 epoch [294/800] time: 4.62s train loss: 0.0557 accuracy: 0.985 f1: 0.9848
2023-07-14 01:49:24,773 epoch [294/800] time: 0.81s val loss: 0.1294 accuracy: 0.9547 f1: 0.9533
2023-07-14 01:49:29,482 epoch [295/800] time: 4.71s train loss: 0.0554 accuracy: 0.9847 f1: 0.9846
2023-07-14 01:49:30,342 epoch [295/800] time: 0.86s val loss: 0.1288 accuracy: 0.9548 f1: 0.9536
2023-07-14 01:49:35,028 epoch [296/800] time: 4.69s train loss: 0.0545 accuracy: 0.9853 f1: 0.9851
2023-07-14 01:49:35,876 epoch [296/800] time: 0.85s val loss: 0.1296 accuracy: 0.9545 f1: 0.9532
2023-07-14 01:49:40,558 epoch [297/800] time: 4.68s train loss: 0.0551 accuracy: 0.9843 f1: 0.9841
2023-07-14 01:49:41,357 epoch [297/800] time: 0.8s val loss: 0.1292 accuracy: 0.9552 f1: 0.9539
2023-07-14 01:49:46,116 epoch [298/800] time: 4.76s train loss: 0.0553 accuracy: 0.9849 f1: 0.9847
2023-07-14 01:49:46,971 epoch [298/800] time: 0.86s val loss: 0.1302 accuracy: 0.9549 f1: 0.9537
2023-07-14 01:49:51,722 epoch [299/800] time: 4.75s train loss: 0.054 accuracy: 0.9853 f1: 0.9852
2023-07-14 01:49:52,577 epoch [299/800] time: 0.85s val loss: 0.1298 accuracy: 0.9545 f1: 0.9533
2023-07-14 01:49:57,189 epoch [300/800] time: 4.61s train loss: 0.0547 accuracy: 0.9851 f1: 0.9849
2023-07-14 01:49:58,005 epoch [300/800] time: 0.82s val loss: 0.1292 accuracy: 0.955 f1: 0.9538
2023-07-14 01:50:02,599 epoch [301/800] time: 4.59s train loss: 0.0545 accuracy: 0.9854 f1: 0.9853
2023-07-14 01:50:03,472 epoch [301/800] time: 0.87s val loss: 0.1291 accuracy: 0.9554 f1: 0.9541
2023-07-14 01:50:08,275 epoch [302/800] time: 4.8s train loss: 0.0549 accuracy: 0.9849 f1: 0.9848
2023-07-14 01:50:09,154 epoch [302/800] time: 0.88s val loss: 0.1297 accuracy: 0.955 f1: 0.9537
2023-07-14 01:50:13,852 epoch [303/800] time: 4.7s train loss: 0.0555 accuracy: 0.9851 f1: 0.9849
2023-07-14 01:50:14,728 epoch [303/800] time: 0.88s val loss: 0.1295 accuracy: 0.9544 f1: 0.9531
2023-07-14 01:50:19,678 epoch [304/800] time: 4.95s train loss: 0.0571 accuracy: 0.9848 f1: 0.9845
2023-07-14 01:50:20,567 epoch [304/800] time: 0.89s val loss: 0.1325 accuracy: 0.9548 f1: 0.9534
2023-07-14 01:50:25,453 epoch [305/800] time: 4.89s train loss: 0.0555 accuracy: 0.9846 f1: 0.9844
2023-07-14 01:50:26,410 epoch [305/800] time: 0.96s val loss: 0.1297 accuracy: 0.9547 f1: 0.9535
2023-07-14 01:50:31,408 epoch [306/800] time: 5.0s train loss: 0.0556 accuracy: 0.9849 f1: 0.9848
2023-07-14 01:50:32,231 epoch [306/800] time: 0.82s val loss: 0.1303 accuracy: 0.9539 f1: 0.9526
2023-07-14 01:50:37,273 epoch [307/800] time: 5.04s train loss: 0.0562 accuracy: 0.9846 f1: 0.9844
2023-07-14 01:50:38,194 epoch [307/800] time: 0.92s val loss: 0.1301 accuracy: 0.9546 f1: 0.9534
2023-07-14 01:50:42,971 epoch [308/800] time: 4.78s train loss: 0.0554 accuracy: 0.9849 f1: 0.9848
2023-07-14 01:50:43,824 epoch [308/800] time: 0.85s val loss: 0.1297 accuracy: 0.9548 f1: 0.9536
2023-07-14 01:50:48,590 epoch [309/800] time: 4.77s train loss: 0.057 accuracy: 0.9845 f1: 0.9843
2023-07-14 01:50:49,401 epoch [309/800] time: 0.81s val loss: 0.1301 accuracy: 0.9547 f1: 0.9534
2023-07-14 01:50:54,166 epoch [310/800] time: 4.76s train loss: 0.0548 accuracy: 0.9853 f1: 0.9851
2023-07-14 01:50:55,012 epoch [310/800] time: 0.85s val loss: 0.1304 accuracy: 0.9544 f1: 0.9531
2023-07-14 01:50:59,707 epoch [311/800] time: 4.7s train loss: 0.0549 accuracy: 0.9853 f1: 0.9852
2023-07-14 01:51:00,557 epoch [311/800] time: 0.85s val loss: 0.1299 accuracy: 0.9547 f1: 0.9535
2023-07-14 01:51:05,312 epoch [312/800] time: 4.75s train loss: 0.0551 accuracy: 0.985 f1: 0.9848
2023-07-14 01:51:06,119 epoch [312/800] time: 0.81s val loss: 0.1303 accuracy: 0.9548 f1: 0.9536
2023-07-14 01:51:10,867 epoch [313/800] time: 4.75s train loss: 0.0552 accuracy: 0.9848 f1: 0.9847
2023-07-14 01:51:11,715 epoch [313/800] time: 0.85s val loss: 0.1301 accuracy: 0.955 f1: 0.9536
2023-07-14 01:51:16,682 epoch [314/800] time: 4.97s train loss: 0.0553 accuracy: 0.9848 f1: 0.9847
2023-07-14 01:51:17,628 epoch [314/800] time: 0.95s val loss: 0.1302 accuracy: 0.9543 f1: 0.953
2023-07-14 01:51:22,452 epoch [315/800] time: 4.82s train loss: 0.0561 accuracy: 0.9844 f1: 0.9842
2023-07-14 01:51:23,260 epoch [315/800] time: 0.81s val loss: 0.13 accuracy: 0.9549 f1: 0.9534
2023-07-14 01:51:28,220 epoch [316/800] time: 4.96s train loss: 0.055 accuracy: 0.9847 f1: 0.9847
2023-07-14 01:51:29,080 epoch [316/800] time: 0.86s val loss: 0.1298 accuracy: 0.9548 f1: 0.9535
2023-07-14 01:51:33,718 epoch [317/800] time: 4.64s train loss: 0.0553 accuracy: 0.9849 f1: 0.9847
2023-07-14 01:51:34,573 epoch [317/800] time: 0.86s val loss: 0.13 accuracy: 0.9546 f1: 0.9534
2023-07-14 01:51:39,278 epoch [318/800] time: 4.7s train loss: 0.0553 accuracy: 0.9845 f1: 0.9843
2023-07-14 01:51:40,116 epoch [318/800] time: 0.84s val loss: 0.1294 accuracy: 0.9549 f1: 0.9536
2023-07-14 01:51:44,927 epoch [319/800] time: 4.81s train loss: 0.0553 accuracy: 0.9849 f1: 0.9848
2023-07-14 01:51:45,785 epoch [319/800] time: 0.86s val loss: 0.1296 accuracy: 0.9548 f1: 0.9535
2023-07-14 01:51:50,626 epoch [320/800] time: 4.84s train loss: 0.055 accuracy: 0.9852 f1: 0.985
2023-07-14 01:51:51,493 epoch [320/800] time: 0.87s val loss: 0.1296 accuracy: 0.9546 f1: 0.9535
2023-07-14 01:51:56,356 epoch [321/800] time: 4.86s train loss: 0.0562 accuracy: 0.9843 f1: 0.984
2023-07-14 01:51:57,177 epoch [321/800] time: 0.82s val loss: 0.1295 accuracy: 0.9545 f1: 0.9531
2023-07-14 01:52:01,996 epoch [322/800] time: 4.82s train loss: 0.0537 accuracy: 0.9857 f1: 0.9854
2023-07-14 01:52:02,857 epoch [322/800] time: 0.85s val loss: 0.1288 accuracy: 0.955 f1: 0.9538
2023-07-14 01:52:07,556 epoch [323/800] time: 4.7s train loss: 0.0552 accuracy: 0.9844 f1: 0.9843
2023-07-14 01:52:08,403 epoch [323/800] time: 0.85s val loss: 0.1292 accuracy: 0.9547 f1: 0.9535
2023-07-14 01:52:13,192 epoch [324/800] time: 4.79s train loss: 0.056 accuracy: 0.985 f1: 0.9849
2023-07-14 01:52:14,020 epoch [324/800] time: 0.83s val loss: 0.1295 accuracy: 0.9546 f1: 0.9534
2023-07-14 01:52:18,793 epoch [325/800] time: 4.77s train loss: 0.0548 accuracy: 0.9849 f1: 0.9848
2023-07-14 01:52:19,648 epoch [325/800] time: 0.86s val loss: 0.1302 accuracy: 0.9543 f1: 0.9531
2023-07-14 01:52:24,491 epoch [326/800] time: 4.84s train loss: 0.0563 accuracy: 0.9854 f1: 0.9852
2023-07-14 01:52:25,568 epoch [326/800] time: 1.08s val loss: 0.1308 accuracy: 0.9544 f1: 0.953
2023-07-14 01:52:30,659 epoch [327/800] time: 5.09s train loss: 0.0561 accuracy: 0.9848 f1: 0.9848
2023-07-14 01:52:31,499 epoch [327/800] time: 0.84s val loss: 0.13 accuracy: 0.9547 f1: 0.9534
2023-07-14 01:52:37,038 epoch [328/800] time: 5.54s train loss: 0.0563 accuracy: 0.9846 f1: 0.9844
2023-07-14 01:52:38,106 epoch [328/800] time: 1.07s val loss: 0.1307 accuracy: 0.9541 f1: 0.9529
2023-07-14 01:52:43,729 epoch [329/800] time: 5.62s train loss: 0.0571 accuracy: 0.9837 f1: 0.9835
2023-07-14 01:52:44,652 epoch [329/800] time: 0.92s val loss: 0.1298 accuracy: 0.9546 f1: 0.9535
2023-07-14 01:52:49,676 epoch [330/800] time: 5.02s train loss: 0.0556 accuracy: 0.9849 f1: 0.9847
2023-07-14 01:52:50,509 epoch [330/800] time: 0.83s val loss: 0.1303 accuracy: 0.9541 f1: 0.9529
2023-07-14 01:52:55,599 epoch [331/800] time: 5.09s train loss: 0.0557 accuracy: 0.9849 f1: 0.9847
2023-07-14 01:52:56,470 epoch [331/800] time: 0.87s val loss: 0.1296 accuracy: 0.955 f1: 0.9537
2023-07-14 01:53:01,329 epoch [332/800] time: 4.86s train loss: 0.0545 accuracy: 0.9852 f1: 0.985
2023-07-14 01:53:02,188 epoch [332/800] time: 0.86s val loss: 0.1299 accuracy: 0.955 f1: 0.9538
2023-07-14 01:53:07,167 epoch [333/800] time: 4.98s train loss: 0.0549 accuracy: 0.9851 f1: 0.9848
2023-07-14 01:53:08,024 epoch [333/800] time: 0.86s val loss: 0.1293 accuracy: 0.9546 f1: 0.9532
2023-07-14 01:53:13,102 epoch [334/800] time: 5.08s train loss: 0.0555 accuracy: 0.984 f1: 0.9839
2023-07-14 01:53:14,058 epoch [334/800] time: 0.96s val loss: 0.1294 accuracy: 0.9549 f1: 0.9536
2023-07-14 01:53:19,296 epoch [335/800] time: 5.24s train loss: 0.0547 accuracy: 0.9854 f1: 0.9852
2023-07-14 01:53:20,244 epoch [335/800] time: 0.95s val loss: 0.1295 accuracy: 0.9551 f1: 0.9538
2023-07-14 01:53:25,206 epoch [336/800] time: 4.96s train loss: 0.0554 accuracy: 0.985 f1: 0.9848
2023-07-14 01:53:26,064 epoch [336/800] time: 0.86s val loss: 0.1294 accuracy: 0.9551 f1: 0.9539
2023-07-14 01:53:30,992 epoch [337/800] time: 4.93s train loss: 0.0549 accuracy: 0.9848 f1: 0.9846
2023-07-14 01:53:31,910 epoch [337/800] time: 0.92s val loss: 0.1301 accuracy: 0.9543 f1: 0.953
2023-07-14 01:53:36,785 epoch [338/800] time: 4.87s train loss: 0.0551 accuracy: 0.9852 f1: 0.9851
2023-07-14 01:53:37,656 epoch [338/800] time: 0.87s val loss: 0.1304 accuracy: 0.9541 f1: 0.953
2023-07-14 01:53:42,622 epoch [339/800] time: 4.97s train loss: 0.0556 accuracy: 0.9846 f1: 0.9844
2023-07-14 01:53:43,513 epoch [339/800] time: 0.89s val loss: 0.1294 accuracy: 0.9546 f1: 0.9532
2023-07-14 01:53:48,773 epoch [340/800] time: 5.26s train loss: 0.0547 accuracy: 0.9852 f1: 0.985
2023-07-14 01:53:49,724 epoch [340/800] time: 0.95s val loss: 0.1293 accuracy: 0.9547 f1: 0.9535
2023-07-14 01:53:54,774 epoch [341/800] time: 5.05s train loss: 0.0549 accuracy: 0.985 f1: 0.9847
2023-07-14 01:53:55,708 epoch [341/800] time: 0.93s val loss: 0.13 accuracy: 0.9548 f1: 0.9535
2023-07-14 01:54:00,942 epoch [342/800] time: 5.23s train loss: 0.0561 accuracy: 0.9848 f1: 0.9847
2023-07-14 01:54:01,859 epoch [342/800] time: 0.92s val loss: 0.1305 accuracy: 0.9544 f1: 0.9531
2023-07-14 01:54:07,270 epoch [343/800] time: 5.41s train loss: 0.0561 accuracy: 0.9845 f1: 0.9844
2023-07-14 01:54:08,218 epoch [343/800] time: 0.95s val loss: 0.1294 accuracy: 0.9545 f1: 0.9532
2023-07-14 01:54:13,232 epoch [344/800] time: 5.01s train loss: 0.0552 accuracy: 0.9848 f1: 0.9847
2023-07-14 01:54:14,139 epoch [344/800] time: 0.91s val loss: 0.1295 accuracy: 0.9542 f1: 0.953
2023-07-14 01:54:18,987 epoch [345/800] time: 4.85s train loss: 0.056 accuracy: 0.9846 f1: 0.9844
2023-07-14 01:54:19,814 epoch [345/800] time: 0.83s val loss: 0.1297 accuracy: 0.9549 f1: 0.9536
2023-07-14 01:54:24,686 epoch [346/800] time: 4.87s train loss: 0.0544 accuracy: 0.9855 f1: 0.9853
2023-07-14 01:54:25,571 epoch [346/800] time: 0.88s val loss: 0.1294 accuracy: 0.9555 f1: 0.9541
2023-07-14 01:54:30,266 epoch [347/800] time: 4.69s train loss: 0.0558 accuracy: 0.9846 f1: 0.9844
2023-07-14 01:54:31,116 epoch [347/800] time: 0.85s val loss: 0.1295 accuracy: 0.955 f1: 0.9537
2023-07-14 01:54:35,748 epoch [348/800] time: 4.63s train loss: 0.055 accuracy: 0.9849 f1: 0.9847
2023-07-14 01:54:36,579 epoch [348/800] time: 0.83s val loss: 0.13 accuracy: 0.9548 f1: 0.9536
2023-07-14 01:54:41,404 epoch [349/800] time: 4.82s train loss: 0.0544 accuracy: 0.9851 f1: 0.9849
2023-07-14 01:54:42,255 epoch [349/800] time: 0.85s val loss: 0.1297 accuracy: 0.9548 f1: 0.9535
2023-07-14 01:54:46,848 epoch [350/800] time: 4.59s train loss: 0.0549 accuracy: 0.9851 f1: 0.985
2023-07-14 01:54:47,699 epoch [350/800] time: 0.85s val loss: 0.1299 accuracy: 0.9546 f1: 0.9534
2023-07-14 01:54:52,460 epoch [351/800] time: 4.76s train loss: 0.0571 accuracy: 0.9847 f1: 0.9846
2023-07-14 01:54:53,272 epoch [351/800] time: 0.81s val loss: 0.1305 accuracy: 0.9539 f1: 0.9527
2023-07-14 01:54:58,060 epoch [352/800] time: 4.79s train loss: 0.0544 accuracy: 0.9851 f1: 0.985
2023-07-14 01:54:58,909 epoch [352/800] time: 0.85s val loss: 0.1295 accuracy: 0.9547 f1: 0.9535
2023-07-14 01:55:03,623 epoch [353/800] time: 4.71s train loss: 0.0552 accuracy: 0.9848 f1: 0.9847
2023-07-14 01:55:04,475 epoch [353/800] time: 0.85s val loss: 0.1301 accuracy: 0.9544 f1: 0.9529
2023-07-14 01:55:09,180 epoch [354/800] time: 4.7s train loss: 0.0556 accuracy: 0.9846 f1: 0.9844
2023-07-14 01:55:09,985 epoch [354/800] time: 0.8s val loss: 0.1296 accuracy: 0.9547 f1: 0.9535
2023-07-14 01:55:14,548 epoch [355/800] time: 4.56s train loss: 0.0569 accuracy: 0.985 f1: 0.9848
2023-07-14 01:55:15,397 epoch [355/800] time: 0.85s val loss: 0.131 accuracy: 0.9548 f1: 0.9535
2023-07-14 01:55:19,932 epoch [356/800] time: 4.53s train loss: 0.0545 accuracy: 0.9851 f1: 0.985
2023-07-14 01:55:20,778 epoch [356/800] time: 0.85s val loss: 0.1296 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:55:25,480 epoch [357/800] time: 4.7s train loss: 0.0557 accuracy: 0.9843 f1: 0.9842
2023-07-14 01:55:26,279 epoch [357/800] time: 0.8s val loss: 0.1296 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:55:31,032 epoch [358/800] time: 4.75s train loss: 0.0548 accuracy: 0.9853 f1: 0.9851
2023-07-14 01:55:31,874 epoch [358/800] time: 0.84s val loss: 0.1305 accuracy: 0.9536 f1: 0.9525
2023-07-14 01:55:36,583 epoch [359/800] time: 4.71s train loss: 0.0574 accuracy: 0.9851 f1: 0.985
2023-07-14 01:55:37,424 epoch [359/800] time: 0.84s val loss: 0.1308 accuracy: 0.9551 f1: 0.9539
2023-07-14 01:55:42,203 epoch [360/800] time: 4.78s train loss: 0.0574 accuracy: 0.9848 f1: 0.9846
2023-07-14 01:55:43,005 epoch [360/800] time: 0.8s val loss: 0.1307 accuracy: 0.9542 f1: 0.9529
2023-07-14 01:55:47,807 epoch [361/800] time: 4.8s train loss: 0.0543 accuracy: 0.9852 f1: 0.9851
2023-07-14 01:55:48,674 epoch [361/800] time: 0.87s val loss: 0.13 accuracy: 0.9545 f1: 0.9531
2023-07-14 01:55:53,328 epoch [362/800] time: 4.65s train loss: 0.0567 accuracy: 0.9845 f1: 0.9843
2023-07-14 01:55:54,174 epoch [362/800] time: 0.85s val loss: 0.1296 accuracy: 0.9551 f1: 0.9538
2023-07-14 01:55:58,911 epoch [363/800] time: 4.74s train loss: 0.0553 accuracy: 0.9846 f1: 0.9844
2023-07-14 01:55:59,751 epoch [363/800] time: 0.84s val loss: 0.1292 accuracy: 0.9552 f1: 0.9539
2023-07-14 01:56:04,671 epoch [364/800] time: 4.92s train loss: 0.0546 accuracy: 0.9847 f1: 0.9845
2023-07-14 01:56:05,521 epoch [364/800] time: 0.85s val loss: 0.13 accuracy: 0.9547 f1: 0.9533
2023-07-14 01:56:10,070 epoch [365/800] time: 4.55s train loss: 0.0554 accuracy: 0.985 f1: 0.9848
2023-07-14 01:56:10,922 epoch [365/800] time: 0.85s val loss: 0.1295 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:56:15,525 epoch [366/800] time: 4.6s train loss: 0.0564 accuracy: 0.9846 f1: 0.9844
2023-07-14 01:56:16,327 epoch [366/800] time: 0.8s val loss: 0.1298 accuracy: 0.9551 f1: 0.954
2023-07-14 01:56:20,882 epoch [367/800] time: 4.55s train loss: 0.0549 accuracy: 0.9851 f1: 0.985
2023-07-14 01:56:21,726 epoch [367/800] time: 0.84s val loss: 0.13 accuracy: 0.9546 f1: 0.9532
2023-07-14 01:56:26,245 epoch [368/800] time: 4.52s train loss: 0.0558 accuracy: 0.9844 f1: 0.9843
2023-07-14 01:56:27,090 epoch [368/800] time: 0.85s val loss: 0.1303 accuracy: 0.9546 f1: 0.9534
2023-07-14 01:56:31,857 epoch [369/800] time: 4.77s train loss: 0.0567 accuracy: 0.9847 f1: 0.9846
2023-07-14 01:56:32,666 epoch [369/800] time: 0.81s val loss: 0.1302 accuracy: 0.9546 f1: 0.9534
2023-07-14 01:56:37,497 epoch [370/800] time: 4.83s train loss: 0.0556 accuracy: 0.9846 f1: 0.9843
2023-07-14 01:56:38,350 epoch [370/800] time: 0.85s val loss: 0.1307 accuracy: 0.9548 f1: 0.9535
2023-07-14 01:56:43,114 epoch [371/800] time: 4.76s train loss: 0.0544 accuracy: 0.985 f1: 0.9849
2023-07-14 01:56:43,966 epoch [371/800] time: 0.85s val loss: 0.129 accuracy: 0.9545 f1: 0.9533
2023-07-14 01:56:48,761 epoch [372/800] time: 4.79s train loss: 0.0562 accuracy: 0.9848 f1: 0.9846
2023-07-14 01:56:49,573 epoch [372/800] time: 0.81s val loss: 0.1311 accuracy: 0.9539 f1: 0.9526
2023-07-14 01:56:54,380 epoch [373/800] time: 4.81s train loss: 0.0544 accuracy: 0.985 f1: 0.985
2023-07-14 01:56:55,231 epoch [373/800] time: 0.85s val loss: 0.1297 accuracy: 0.9547 f1: 0.9534
2023-07-14 01:57:00,023 epoch [374/800] time: 4.79s train loss: 0.0556 accuracy: 0.9844 f1: 0.9843
2023-07-14 01:57:00,875 epoch [374/800] time: 0.85s val loss: 0.1293 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:57:05,692 epoch [375/800] time: 4.82s train loss: 0.0557 accuracy: 0.9846 f1: 0.9844
2023-07-14 01:57:06,503 epoch [375/800] time: 0.81s val loss: 0.1295 accuracy: 0.9547 f1: 0.9536
2023-07-14 01:57:11,282 epoch [376/800] time: 4.78s train loss: 0.0547 accuracy: 0.9847 f1: 0.9846
2023-07-14 01:57:12,177 epoch [376/800] time: 0.9s val loss: 0.1294 accuracy: 0.9548 f1: 0.9536
2023-07-14 01:57:16,873 epoch [377/800] time: 4.7s train loss: 0.0549 accuracy: 0.9847 f1: 0.9845
2023-07-14 01:57:17,720 epoch [377/800] time: 0.85s val loss: 0.1292 accuracy: 0.9543 f1: 0.9531
2023-07-14 01:57:22,324 epoch [378/800] time: 4.6s train loss: 0.0566 accuracy: 0.9843 f1: 0.9841
2023-07-14 01:57:23,127 epoch [378/800] time: 0.8s val loss: 0.1302 accuracy: 0.9546 f1: 0.9532
2023-07-14 01:57:28,108 epoch [379/800] time: 4.98s train loss: 0.0559 accuracy: 0.9848 f1: 0.9846
2023-07-14 01:57:29,048 epoch [379/800] time: 0.94s val loss: 0.1308 accuracy: 0.9542 f1: 0.9529
2023-07-14 01:57:34,041 epoch [380/800] time: 4.99s train loss: 0.0559 accuracy: 0.9842 f1: 0.984
2023-07-14 01:57:34,912 epoch [380/800] time: 0.87s val loss: 0.1297 accuracy: 0.9547 f1: 0.9535
2023-07-14 01:57:39,870 epoch [381/800] time: 4.96s train loss: 0.0548 accuracy: 0.9852 f1: 0.9851
2023-07-14 01:57:40,733 epoch [381/800] time: 0.86s val loss: 0.1308 accuracy: 0.9543 f1: 0.9531
2023-07-14 01:57:45,745 epoch [382/800] time: 5.01s train loss: 0.0546 accuracy: 0.9849 f1: 0.9848
2023-07-14 01:57:46,617 epoch [382/800] time: 0.87s val loss: 0.1301 accuracy: 0.9546 f1: 0.9535
2023-07-14 01:57:51,466 epoch [383/800] time: 4.85s train loss: 0.0558 accuracy: 0.9849 f1: 0.9847
2023-07-14 01:57:52,321 epoch [383/800] time: 0.85s val loss: 0.1293 accuracy: 0.9543 f1: 0.953
2023-07-14 01:57:57,177 epoch [384/800] time: 4.86s train loss: 0.0554 accuracy: 0.9846 f1: 0.9845
2023-07-14 01:57:57,994 epoch [384/800] time: 0.82s val loss: 0.1297 accuracy: 0.9548 f1: 0.9536
2023-07-14 01:58:02,660 epoch [385/800] time: 4.67s train loss: 0.0551 accuracy: 0.9852 f1: 0.985
2023-07-14 01:58:03,506 epoch [385/800] time: 0.85s val loss: 0.1293 accuracy: 0.9546 f1: 0.9534
2023-07-14 01:58:08,225 epoch [386/800] time: 4.72s train loss: 0.055 accuracy: 0.9851 f1: 0.9849
2023-07-14 01:58:09,077 epoch [386/800] time: 0.85s val loss: 0.1295 accuracy: 0.9546 f1: 0.9534
2023-07-14 01:58:14,172 epoch [387/800] time: 5.09s train loss: 0.055 accuracy: 0.9848 f1: 0.9846
2023-07-14 01:58:14,993 epoch [387/800] time: 0.82s val loss: 0.1302 accuracy: 0.9547 f1: 0.9534
2023-07-14 01:58:19,708 epoch [388/800] time: 4.72s train loss: 0.0549 accuracy: 0.985 f1: 0.9849
2023-07-14 01:58:20,579 epoch [388/800] time: 0.87s val loss: 0.1299 accuracy: 0.9546 f1: 0.9534
2023-07-14 01:58:25,693 epoch [389/800] time: 5.11s train loss: 0.055 accuracy: 0.9849 f1: 0.9847
2023-07-14 01:58:26,602 epoch [389/800] time: 0.91s val loss: 0.1292 accuracy: 0.9548 f1: 0.9536
2023-07-14 01:58:31,511 epoch [390/800] time: 4.91s train loss: 0.0551 accuracy: 0.9849 f1: 0.9848
2023-07-14 01:58:32,321 epoch [390/800] time: 0.81s val loss: 0.1298 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:58:37,092 epoch [391/800] time: 4.77s train loss: 0.0548 accuracy: 0.9849 f1: 0.9847
2023-07-14 01:58:37,944 epoch [391/800] time: 0.85s val loss: 0.1296 accuracy: 0.9546 f1: 0.9534
2023-07-14 01:58:42,673 epoch [392/800] time: 4.73s train loss: 0.0564 accuracy: 0.9847 f1: 0.9844
2023-07-14 01:58:43,535 epoch [392/800] time: 0.86s val loss: 0.1308 accuracy: 0.9544 f1: 0.9532
2023-07-14 01:58:48,211 epoch [393/800] time: 4.68s train loss: 0.055 accuracy: 0.985 f1: 0.9848
2023-07-14 01:58:49,037 epoch [393/800] time: 0.83s val loss: 0.1297 accuracy: 0.9548 f1: 0.9535
2023-07-14 01:58:53,820 epoch [394/800] time: 4.78s train loss: 0.0561 accuracy: 0.9845 f1: 0.9843
2023-07-14 01:58:54,679 epoch [394/800] time: 0.86s val loss: 0.1302 accuracy: 0.9552 f1: 0.9539
2023-07-14 01:58:59,369 epoch [395/800] time: 4.69s train loss: 0.0574 accuracy: 0.9845 f1: 0.9844
2023-07-14 01:59:00,258 epoch [395/800] time: 0.89s val loss: 0.1307 accuracy: 0.9539 f1: 0.9527
2023-07-14 01:59:05,223 epoch [396/800] time: 4.97s train loss: 0.0556 accuracy: 0.9845 f1: 0.9843
2023-07-14 01:59:06,033 epoch [396/800] time: 0.81s val loss: 0.1297 accuracy: 0.9547 f1: 0.9535
2023-07-14 01:59:10,721 epoch [397/800] time: 4.69s train loss: 0.0545 accuracy: 0.9845 f1: 0.9844
2023-07-14 01:59:11,571 epoch [397/800] time: 0.85s val loss: 0.1303 accuracy: 0.954 f1: 0.9528
2023-07-14 01:59:16,143 epoch [398/800] time: 4.57s train loss: 0.056 accuracy: 0.9847 f1: 0.9846
2023-07-14 01:59:16,985 epoch [398/800] time: 0.84s val loss: 0.1307 accuracy: 0.9546 f1: 0.9532
2023-07-14 01:59:21,541 epoch [399/800] time: 4.56s train loss: 0.0549 accuracy: 0.9855 f1: 0.9852
2023-07-14 01:59:22,341 epoch [399/800] time: 0.8s val loss: 0.1303 accuracy: 0.9547 f1: 0.9533
2023-07-14 01:59:26,992 epoch [400/800] time: 4.65s train loss: 0.0534 accuracy: 0.9858 f1: 0.9856
2023-07-14 01:59:27,836 epoch [400/800] time: 0.84s val loss: 0.1294 accuracy: 0.9546 f1: 0.9534
2023-07-14 01:59:32,327 epoch [401/800] time: 4.49s train loss: 0.0571 accuracy: 0.9847 f1: 0.9844
2023-07-14 01:59:33,168 epoch [401/800] time: 0.84s val loss: 0.1304 accuracy: 0.9545 f1: 0.9533
2023-07-14 01:59:37,694 epoch [402/800] time: 4.53s train loss: 0.0556 accuracy: 0.9846 f1: 0.9845
2023-07-14 01:59:38,495 epoch [402/800] time: 0.8s val loss: 0.13 accuracy: 0.9546 f1: 0.9533
2023-07-14 01:59:43,030 epoch [403/800] time: 4.53s train loss: 0.057 accuracy: 0.9845 f1: 0.9844
2023-07-14 01:59:43,873 epoch [403/800] time: 0.84s val loss: 0.13 accuracy: 0.9548 f1: 0.9536
2023-07-14 01:59:48,370 epoch [404/800] time: 4.5s train loss: 0.0553 accuracy: 0.9848 f1: 0.9847
2023-07-14 01:59:49,210 epoch [404/800] time: 0.84s val loss: 0.129 accuracy: 0.9549 f1: 0.9536
2023-07-14 01:59:53,749 epoch [405/800] time: 4.54s train loss: 0.0551 accuracy: 0.9848 f1: 0.9847
2023-07-14 01:59:54,548 epoch [405/800] time: 0.8s val loss: 0.1297 accuracy: 0.9545 f1: 0.9532
2023-07-14 01:59:59,086 epoch [406/800] time: 4.54s train loss: 0.0551 accuracy: 0.9848 f1: 0.9846
2023-07-14 01:59:59,927 epoch [406/800] time: 0.84s val loss: 0.1294 accuracy: 0.9545 f1: 0.9533
2023-07-14 02:00:04,420 epoch [407/800] time: 4.49s train loss: 0.0548 accuracy: 0.9852 f1: 0.9851
2023-07-14 02:00:05,261 epoch [407/800] time: 0.84s val loss: 0.1295 accuracy: 0.9545 f1: 0.9533
2023-07-14 02:00:09,840 epoch [408/800] time: 4.58s train loss: 0.055 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:00:10,663 epoch [408/800] time: 0.82s val loss: 0.1295 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:00:15,335 epoch [409/800] time: 4.67s train loss: 0.0551 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:00:16,186 epoch [409/800] time: 0.85s val loss: 0.1293 accuracy: 0.9549 f1: 0.9536
2023-07-14 02:00:20,729 epoch [410/800] time: 4.54s train loss: 0.0565 accuracy: 0.9846 f1: 0.9843
2023-07-14 02:00:21,572 epoch [410/800] time: 0.84s val loss: 0.1299 accuracy: 0.9541 f1: 0.953
2023-07-14 02:00:26,100 epoch [411/800] time: 4.53s train loss: 0.0545 accuracy: 0.9855 f1: 0.9853
2023-07-14 02:00:26,899 epoch [411/800] time: 0.8s val loss: 0.1294 accuracy: 0.955 f1: 0.9537
2023-07-14 02:00:31,432 epoch [412/800] time: 4.53s train loss: 0.0554 accuracy: 0.985 f1: 0.9848
2023-07-14 02:00:32,273 epoch [412/800] time: 0.84s val loss: 0.1291 accuracy: 0.9549 f1: 0.9536
2023-07-14 02:00:37,270 epoch [413/800] time: 5.0s train loss: 0.0554 accuracy: 0.985 f1: 0.9848
2023-07-14 02:00:38,168 epoch [413/800] time: 0.9s val loss: 0.1294 accuracy: 0.955 f1: 0.9538
2023-07-14 02:00:43,006 epoch [414/800] time: 4.84s train loss: 0.0548 accuracy: 0.985 f1: 0.9848
2023-07-14 02:00:43,819 epoch [414/800] time: 0.81s val loss: 0.1297 accuracy: 0.9551 f1: 0.9539
2023-07-14 02:00:48,681 epoch [415/800] time: 4.86s train loss: 0.0548 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:00:49,608 epoch [415/800] time: 0.93s val loss: 0.1299 accuracy: 0.9545 f1: 0.9533
2023-07-14 02:00:54,628 epoch [416/800] time: 5.02s train loss: 0.0548 accuracy: 0.9851 f1: 0.9851
2023-07-14 02:00:55,518 epoch [416/800] time: 0.89s val loss: 0.1299 accuracy: 0.9544 f1: 0.9531
2023-07-14 02:01:00,291 epoch [417/800] time: 4.77s train loss: 0.0569 accuracy: 0.9843 f1: 0.9841
2023-07-14 02:01:01,131 epoch [417/800] time: 0.84s val loss: 0.1299 accuracy: 0.955 f1: 0.9538
2023-07-14 02:01:06,289 epoch [418/800] time: 5.16s train loss: 0.0553 accuracy: 0.9846 f1: 0.9844
2023-07-14 02:01:07,225 epoch [418/800] time: 0.94s val loss: 0.1299 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:01:12,074 epoch [419/800] time: 4.85s train loss: 0.0551 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:01:12,938 epoch [419/800] time: 0.86s val loss: 0.1306 accuracy: 0.9542 f1: 0.9531
2023-07-14 02:01:17,854 epoch [420/800] time: 4.92s train loss: 0.0558 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:01:18,710 epoch [420/800] time: 0.86s val loss: 0.1298 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:01:23,824 epoch [421/800] time: 5.11s train loss: 0.0559 accuracy: 0.9845 f1: 0.9844
2023-07-14 02:01:24,704 epoch [421/800] time: 0.88s val loss: 0.1289 accuracy: 0.9552 f1: 0.954
2023-07-14 02:01:29,545 epoch [422/800] time: 4.84s train loss: 0.0549 accuracy: 0.9853 f1: 0.9851
2023-07-14 02:01:30,406 epoch [422/800] time: 0.86s val loss: 0.1296 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:01:35,042 epoch [423/800] time: 4.64s train loss: 0.0548 accuracy: 0.9852 f1: 0.9849
2023-07-14 02:01:35,842 epoch [423/800] time: 0.8s val loss: 0.1292 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:01:40,383 epoch [424/800] time: 4.54s train loss: 0.0555 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:01:41,230 epoch [424/800] time: 0.85s val loss: 0.1297 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:01:45,733 epoch [425/800] time: 4.5s train loss: 0.0559 accuracy: 0.9846 f1: 0.9844
2023-07-14 02:01:46,577 epoch [425/800] time: 0.84s val loss: 0.1309 accuracy: 0.9545 f1: 0.9532
2023-07-14 02:01:51,394 epoch [426/800] time: 4.82s train loss: 0.056 accuracy: 0.9845 f1: 0.9843
2023-07-14 02:01:52,216 epoch [426/800] time: 0.82s val loss: 0.1299 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:01:56,905 epoch [427/800] time: 4.69s train loss: 0.0554 accuracy: 0.985 f1: 0.9849
2023-07-14 02:01:57,768 epoch [427/800] time: 0.86s val loss: 0.1306 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:02:02,411 epoch [428/800] time: 4.64s train loss: 0.0549 accuracy: 0.9852 f1: 0.9852
2023-07-14 02:02:03,297 epoch [428/800] time: 0.89s val loss: 0.1303 accuracy: 0.9543 f1: 0.953
2023-07-14 02:02:08,072 epoch [429/800] time: 4.77s train loss: 0.0551 accuracy: 0.9853 f1: 0.9852
2023-07-14 02:02:08,882 epoch [429/800] time: 0.81s val loss: 0.1296 accuracy: 0.9552 f1: 0.954
2023-07-14 02:02:13,516 epoch [430/800] time: 4.63s train loss: 0.0557 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:02:14,376 epoch [430/800] time: 0.86s val loss: 0.1298 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:02:19,356 epoch [431/800] time: 4.98s train loss: 0.0561 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:02:20,238 epoch [431/800] time: 0.88s val loss: 0.1301 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:02:25,569 epoch [432/800] time: 5.33s train loss: 0.055 accuracy: 0.9852 f1: 0.9849
2023-07-14 02:02:26,665 epoch [432/800] time: 1.1s val loss: 0.1294 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:02:31,792 epoch [433/800] time: 5.13s train loss: 0.0567 accuracy: 0.9845 f1: 0.9844
2023-07-14 02:02:32,691 epoch [433/800] time: 0.9s val loss: 0.1307 accuracy: 0.9553 f1: 0.954
2023-07-14 02:02:37,657 epoch [434/800] time: 4.97s train loss: 0.0563 accuracy: 0.985 f1: 0.9849
2023-07-14 02:02:38,552 epoch [434/800] time: 0.89s val loss: 0.1297 accuracy: 0.9543 f1: 0.9531
2023-07-14 02:02:43,554 epoch [435/800] time: 5.0s train loss: 0.0547 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:02:44,364 epoch [435/800] time: 0.81s val loss: 0.1294 accuracy: 0.9546 f1: 0.9535
2023-07-14 02:02:49,737 epoch [436/800] time: 5.37s train loss: 0.055 accuracy: 0.9849 f1: 0.9846
2023-07-14 02:02:50,685 epoch [436/800] time: 0.95s val loss: 0.1291 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:02:56,259 epoch [437/800] time: 5.57s train loss: 0.0554 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:02:57,243 epoch [437/800] time: 0.98s val loss: 0.1299 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:03:02,243 epoch [438/800] time: 5.0s train loss: 0.0551 accuracy: 0.9849 f1: 0.9846
2023-07-14 02:03:03,056 epoch [438/800] time: 0.81s val loss: 0.1299 accuracy: 0.9549 f1: 0.9537
2023-07-14 02:03:07,812 epoch [439/800] time: 4.76s train loss: 0.0559 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:03:08,685 epoch [439/800] time: 0.87s val loss: 0.1298 accuracy: 0.9544 f1: 0.9531
2023-07-14 02:03:13,418 epoch [440/800] time: 4.73s train loss: 0.0559 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:03:14,293 epoch [440/800] time: 0.87s val loss: 0.1298 accuracy: 0.9549 f1: 0.9538
2023-07-14 02:03:19,046 epoch [441/800] time: 4.75s train loss: 0.0551 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:03:19,858 epoch [441/800] time: 0.81s val loss: 0.1295 accuracy: 0.9551 f1: 0.9538
2023-07-14 02:03:24,787 epoch [442/800] time: 4.93s train loss: 0.0554 accuracy: 0.985 f1: 0.9848
2023-07-14 02:03:25,717 epoch [442/800] time: 0.93s val loss: 0.1297 accuracy: 0.9545 f1: 0.9532
2023-07-14 02:03:30,801 epoch [443/800] time: 5.08s train loss: 0.0545 accuracy: 0.985 f1: 0.9848
2023-07-14 02:03:31,704 epoch [443/800] time: 0.9s val loss: 0.13 accuracy: 0.955 f1: 0.9538
2023-07-14 02:03:36,582 epoch [444/800] time: 4.88s train loss: 0.0558 accuracy: 0.9846 f1: 0.9845
2023-07-14 02:03:37,412 epoch [444/800] time: 0.83s val loss: 0.1297 accuracy: 0.9544 f1: 0.9532
2023-07-14 02:03:42,193 epoch [445/800] time: 4.78s train loss: 0.0557 accuracy: 0.9844 f1: 0.9843
2023-07-14 02:03:43,121 epoch [445/800] time: 0.93s val loss: 0.1299 accuracy: 0.954 f1: 0.9529
2023-07-14 02:03:48,098 epoch [446/800] time: 4.98s train loss: 0.0546 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:03:48,966 epoch [446/800] time: 0.87s val loss: 0.1295 accuracy: 0.9545 f1: 0.9533
2023-07-14 02:03:53,807 epoch [447/800] time: 4.84s train loss: 0.0555 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:03:54,621 epoch [447/800] time: 0.81s val loss: 0.1293 accuracy: 0.9543 f1: 0.953
2023-07-14 02:03:59,803 epoch [448/800] time: 5.18s train loss: 0.0553 accuracy: 0.9848 f1: 0.9847
2023-07-14 02:04:00,691 epoch [448/800] time: 0.89s val loss: 0.1294 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:04:05,625 epoch [449/800] time: 4.93s train loss: 0.0552 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:04:06,481 epoch [449/800] time: 0.86s val loss: 0.1295 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:04:11,208 epoch [450/800] time: 4.73s train loss: 0.0547 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:04:12,021 epoch [450/800] time: 0.81s val loss: 0.1294 accuracy: 0.9548 f1: 0.9534
2023-07-14 02:04:16,660 epoch [451/800] time: 4.64s train loss: 0.0551 accuracy: 0.9848 f1: 0.9847
2023-07-14 02:04:17,526 epoch [451/800] time: 0.87s val loss: 0.1307 accuracy: 0.9547 f1: 0.9534
2023-07-14 02:04:22,410 epoch [452/800] time: 4.88s train loss: 0.0564 accuracy: 0.9846 f1: 0.9844
2023-07-14 02:04:23,283 epoch [452/800] time: 0.87s val loss: 0.1298 accuracy: 0.9544 f1: 0.9531
2023-07-14 02:04:28,075 epoch [453/800] time: 4.79s train loss: 0.0556 accuracy: 0.9848 f1: 0.9847
2023-07-14 02:04:28,889 epoch [453/800] time: 0.81s val loss: 0.1295 accuracy: 0.9553 f1: 0.954
2023-07-14 02:04:33,818 epoch [454/800] time: 4.93s train loss: 0.0563 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:04:34,710 epoch [454/800] time: 0.89s val loss: 0.1298 accuracy: 0.9545 f1: 0.9532
2023-07-14 02:04:39,542 epoch [455/800] time: 4.83s train loss: 0.0539 accuracy: 0.9852 f1: 0.985
2023-07-14 02:04:40,402 epoch [455/800] time: 0.86s val loss: 0.13 accuracy: 0.9549 f1: 0.9536
2023-07-14 02:04:45,295 epoch [456/800] time: 4.89s train loss: 0.0561 accuracy: 0.984 f1: 0.9839
2023-07-14 02:04:46,109 epoch [456/800] time: 0.81s val loss: 0.1303 accuracy: 0.9546 f1: 0.9532
2023-07-14 02:04:50,887 epoch [457/800] time: 4.78s train loss: 0.0559 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:04:51,746 epoch [457/800] time: 0.86s val loss: 0.1309 accuracy: 0.954 f1: 0.9529
2023-07-14 02:04:56,442 epoch [458/800] time: 4.7s train loss: 0.0548 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:04:57,304 epoch [458/800] time: 0.86s val loss: 0.1292 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:05:02,132 epoch [459/800] time: 4.83s train loss: 0.0559 accuracy: 0.9844 f1: 0.9843
2023-07-14 02:05:02,941 epoch [459/800] time: 0.81s val loss: 0.1302 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:05:07,755 epoch [460/800] time: 4.81s train loss: 0.0553 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:05:08,604 epoch [460/800] time: 0.85s val loss: 0.1296 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:05:13,408 epoch [461/800] time: 4.8s train loss: 0.0551 accuracy: 0.985 f1: 0.9849
2023-07-14 02:05:14,279 epoch [461/800] time: 0.87s val loss: 0.13 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:05:19,061 epoch [462/800] time: 4.78s train loss: 0.0546 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:05:19,982 epoch [462/800] time: 0.92s val loss: 0.1299 accuracy: 0.9544 f1: 0.9532
2023-07-14 02:05:24,834 epoch [463/800] time: 4.85s train loss: 0.0562 accuracy: 0.9845 f1: 0.9844
2023-07-14 02:05:25,748 epoch [463/800] time: 0.91s val loss: 0.1305 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:05:30,815 epoch [464/800] time: 5.07s train loss: 0.0546 accuracy: 0.985 f1: 0.9848
2023-07-14 02:05:31,678 epoch [464/800] time: 0.86s val loss: 0.1299 accuracy: 0.9548 f1: 0.9534
2023-07-14 02:05:36,526 epoch [465/800] time: 4.85s train loss: 0.0559 accuracy: 0.9844 f1: 0.9843
2023-07-14 02:05:37,332 epoch [465/800] time: 0.81s val loss: 0.1292 accuracy: 0.9547 f1: 0.9534
2023-07-14 02:05:42,349 epoch [466/800] time: 5.02s train loss: 0.0547 accuracy: 0.9852 f1: 0.985
2023-07-14 02:05:43,226 epoch [466/800] time: 0.88s val loss: 0.1305 accuracy: 0.954 f1: 0.9527
2023-07-14 02:05:48,034 epoch [467/800] time: 4.81s train loss: 0.0553 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:05:48,887 epoch [467/800] time: 0.85s val loss: 0.1295 accuracy: 0.9555 f1: 0.9542
2023-07-14 02:05:53,813 epoch [468/800] time: 4.93s train loss: 0.0557 accuracy: 0.985 f1: 0.9848
2023-07-14 02:05:54,652 epoch [468/800] time: 0.84s val loss: 0.1304 accuracy: 0.9545 f1: 0.9532
2023-07-14 02:05:59,603 epoch [469/800] time: 4.95s train loss: 0.0558 accuracy: 0.9845 f1: 0.9844
2023-07-14 02:06:00,461 epoch [469/800] time: 0.86s val loss: 0.1301 accuracy: 0.9552 f1: 0.9539
2023-07-14 02:06:05,205 epoch [470/800] time: 4.74s train loss: 0.0569 accuracy: 0.9844 f1: 0.9843
2023-07-14 02:06:06,065 epoch [470/800] time: 0.86s val loss: 0.1308 accuracy: 0.954 f1: 0.9529
2023-07-14 02:06:10,917 epoch [471/800] time: 4.85s train loss: 0.0552 accuracy: 0.9851 f1: 0.985
2023-07-14 02:06:11,738 epoch [471/800] time: 0.82s val loss: 0.13 accuracy: 0.9542 f1: 0.9529
2023-07-14 02:06:16,418 epoch [472/800] time: 4.68s train loss: 0.0548 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:06:17,272 epoch [472/800] time: 0.85s val loss: 0.1288 accuracy: 0.9549 f1: 0.9536
2023-07-14 02:06:21,866 epoch [473/800] time: 4.59s train loss: 0.0564 accuracy: 0.9847 f1: 0.9844
2023-07-14 02:06:22,719 epoch [473/800] time: 0.85s val loss: 0.13 accuracy: 0.9541 f1: 0.9527
2023-07-14 02:06:27,325 epoch [474/800] time: 4.6s train loss: 0.0562 accuracy: 0.9843 f1: 0.9843
2023-07-14 02:06:28,132 epoch [474/800] time: 0.81s val loss: 0.1299 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:06:32,828 epoch [475/800] time: 4.7s train loss: 0.0552 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:06:33,707 epoch [475/800] time: 0.88s val loss: 0.1293 accuracy: 0.9554 f1: 0.9541
2023-07-14 02:06:38,475 epoch [476/800] time: 4.77s train loss: 0.0545 accuracy: 0.9851 f1: 0.985
2023-07-14 02:06:39,335 epoch [476/800] time: 0.86s val loss: 0.1294 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:06:44,198 epoch [477/800] time: 4.86s train loss: 0.0557 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:06:45,003 epoch [477/800] time: 0.8s val loss: 0.13 accuracy: 0.9547 f1: 0.9534
2023-07-14 02:06:49,968 epoch [478/800] time: 4.97s train loss: 0.0547 accuracy: 0.985 f1: 0.9847
2023-07-14 02:06:50,856 epoch [478/800] time: 0.89s val loss: 0.1294 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:06:55,643 epoch [479/800] time: 4.79s train loss: 0.0547 accuracy: 0.9852 f1: 0.9851
2023-07-14 02:06:56,489 epoch [479/800] time: 0.85s val loss: 0.1294 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:07:01,265 epoch [480/800] time: 4.78s train loss: 0.0555 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:07:02,102 epoch [480/800] time: 0.84s val loss: 0.1294 accuracy: 0.955 f1: 0.9538
2023-07-14 02:07:07,028 epoch [481/800] time: 4.93s train loss: 0.0554 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:07:07,885 epoch [481/800] time: 0.86s val loss: 0.1297 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:07:12,403 epoch [482/800] time: 4.52s train loss: 0.0556 accuracy: 0.9848 f1: 0.9847
2023-07-14 02:07:13,255 epoch [482/800] time: 0.85s val loss: 0.1297 accuracy: 0.9544 f1: 0.9532
2023-07-14 02:07:17,998 epoch [483/800] time: 4.74s train loss: 0.0563 accuracy: 0.9846 f1: 0.9843
2023-07-14 02:07:18,840 epoch [483/800] time: 0.84s val loss: 0.1301 accuracy: 0.9545 f1: 0.9533
2023-07-14 02:07:24,422 epoch [484/800] time: 5.58s train loss: 0.0562 accuracy: 0.9848 f1: 0.9847
2023-07-14 02:07:25,360 epoch [484/800] time: 0.94s val loss: 0.1297 accuracy: 0.9549 f1: 0.9537
2023-07-14 02:07:30,835 epoch [485/800] time: 5.47s train loss: 0.0557 accuracy: 0.9846 f1: 0.9845
2023-07-14 02:07:31,761 epoch [485/800] time: 0.93s val loss: 0.1296 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:07:37,119 epoch [486/800] time: 5.36s train loss: 0.0552 accuracy: 0.985 f1: 0.9848
2023-07-14 02:07:37,987 epoch [486/800] time: 0.87s val loss: 0.1291 accuracy: 0.9554 f1: 0.9541
2023-07-14 02:07:43,153 epoch [487/800] time: 5.17s train loss: 0.0543 accuracy: 0.9855 f1: 0.9853
2023-07-14 02:07:44,095 epoch [487/800] time: 0.94s val loss: 0.1295 accuracy: 0.9552 f1: 0.954
2023-07-14 02:07:49,194 epoch [488/800] time: 5.1s train loss: 0.0565 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:07:50,098 epoch [488/800] time: 0.9s val loss: 0.1303 accuracy: 0.9544 f1: 0.9531
2023-07-14 02:07:54,891 epoch [489/800] time: 4.79s train loss: 0.0552 accuracy: 0.9848 f1: 0.9848
2023-07-14 02:07:55,703 epoch [489/800] time: 0.81s val loss: 0.1304 accuracy: 0.9537 f1: 0.9525
2023-07-14 02:08:00,401 epoch [490/800] time: 4.7s train loss: 0.0552 accuracy: 0.9844 f1: 0.9842
2023-07-14 02:08:01,254 epoch [490/800] time: 0.85s val loss: 0.1293 accuracy: 0.9551 f1: 0.9538
2023-07-14 02:08:05,817 epoch [491/800] time: 4.56s train loss: 0.0555 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:08:06,702 epoch [491/800] time: 0.89s val loss: 0.1298 accuracy: 0.9549 f1: 0.9537
2023-07-14 02:08:11,446 epoch [492/800] time: 4.74s train loss: 0.0545 accuracy: 0.985 f1: 0.9849
2023-07-14 02:08:12,273 epoch [492/800] time: 0.83s val loss: 0.1297 accuracy: 0.9547 f1: 0.9534
2023-07-14 02:08:16,899 epoch [493/800] time: 4.63s train loss: 0.0556 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:08:17,755 epoch [493/800] time: 0.86s val loss: 0.129 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:08:22,718 epoch [494/800] time: 4.96s train loss: 0.0553 accuracy: 0.9852 f1: 0.9851
2023-07-14 02:08:23,588 epoch [494/800] time: 0.87s val loss: 0.1294 accuracy: 0.9546 f1: 0.9535
2023-07-14 02:08:28,237 epoch [495/800] time: 4.65s train loss: 0.0545 accuracy: 0.9848 f1: 0.9847
2023-07-14 02:08:29,049 epoch [495/800] time: 0.81s val loss: 0.1293 accuracy: 0.9546 f1: 0.9535
2023-07-14 02:08:33,734 epoch [496/800] time: 4.68s train loss: 0.0549 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:08:34,591 epoch [496/800] time: 0.86s val loss: 0.13 accuracy: 0.9546 f1: 0.9535
2023-07-14 02:08:39,259 epoch [497/800] time: 4.67s train loss: 0.0561 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:08:40,160 epoch [497/800] time: 0.9s val loss: 0.1297 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:08:44,960 epoch [498/800] time: 4.8s train loss: 0.0564 accuracy: 0.9848 f1: 0.9847
2023-07-14 02:08:45,814 epoch [498/800] time: 0.85s val loss: 0.1303 accuracy: 0.9544 f1: 0.9532
2023-07-14 02:08:50,855 epoch [499/800] time: 5.04s train loss: 0.0543 accuracy: 0.9851 f1: 0.985
2023-07-14 02:08:51,708 epoch [499/800] time: 0.85s val loss: 0.1292 accuracy: 0.9551 f1: 0.9539
2023-07-14 02:08:56,994 epoch [500/800] time: 5.29s train loss: 0.0568 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:08:57,851 epoch [500/800] time: 0.86s val loss: 0.1297 accuracy: 0.9545 f1: 0.9533
2023-07-14 02:09:02,659 epoch [501/800] time: 4.81s train loss: 0.0541 accuracy: 0.9855 f1: 0.9853
2023-07-14 02:09:03,464 epoch [501/800] time: 0.8s val loss: 0.1287 accuracy: 0.9552 f1: 0.9539
2023-07-14 02:09:08,159 epoch [502/800] time: 4.69s train loss: 0.0555 accuracy: 0.985 f1: 0.9848
2023-07-14 02:09:09,003 epoch [502/800] time: 0.84s val loss: 0.1298 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:09:13,648 epoch [503/800] time: 4.65s train loss: 0.0561 accuracy: 0.9845 f1: 0.9843
2023-07-14 02:09:14,494 epoch [503/800] time: 0.85s val loss: 0.1305 accuracy: 0.9542 f1: 0.9528
2023-07-14 02:09:19,193 epoch [504/800] time: 4.7s train loss: 0.0555 accuracy: 0.985 f1: 0.9848
2023-07-14 02:09:19,994 epoch [504/800] time: 0.8s val loss: 0.1296 accuracy: 0.9543 f1: 0.9531
2023-07-14 02:09:24,678 epoch [505/800] time: 4.68s train loss: 0.055 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:09:25,520 epoch [505/800] time: 0.84s val loss: 0.1294 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:09:30,149 epoch [506/800] time: 4.63s train loss: 0.0551 accuracy: 0.9848 f1: 0.9847
2023-07-14 02:09:31,004 epoch [506/800] time: 0.85s val loss: 0.1296 accuracy: 0.9543 f1: 0.9532
2023-07-14 02:09:35,655 epoch [507/800] time: 4.65s train loss: 0.056 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:09:36,459 epoch [507/800] time: 0.8s val loss: 0.1296 accuracy: 0.9547 f1: 0.9534
2023-07-14 02:09:41,072 epoch [508/800] time: 4.61s train loss: 0.0548 accuracy: 0.985 f1: 0.9848
2023-07-14 02:09:41,915 epoch [508/800] time: 0.84s val loss: 0.1294 accuracy: 0.9546 f1: 0.9535
2023-07-14 02:09:46,523 epoch [509/800] time: 4.61s train loss: 0.0563 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:09:47,372 epoch [509/800] time: 0.85s val loss: 0.1297 accuracy: 0.9544 f1: 0.9533
2023-07-14 02:09:51,922 epoch [510/800] time: 4.55s train loss: 0.0552 accuracy: 0.985 f1: 0.9849
2023-07-14 02:09:52,721 epoch [510/800] time: 0.8s val loss: 0.1303 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:09:57,265 epoch [511/800] time: 4.54s train loss: 0.0544 accuracy: 0.985 f1: 0.9849
2023-07-14 02:09:58,107 epoch [511/800] time: 0.84s val loss: 0.1298 accuracy: 0.9543 f1: 0.9531
2023-07-14 02:10:02,620 epoch [512/800] time: 4.51s train loss: 0.056 accuracy: 0.9852 f1: 0.9851
2023-07-14 02:10:03,465 epoch [512/800] time: 0.84s val loss: 0.1306 accuracy: 0.9547 f1: 0.9534
2023-07-14 02:10:08,062 epoch [513/800] time: 4.6s train loss: 0.0553 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:10:08,864 epoch [513/800] time: 0.8s val loss: 0.1296 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:10:13,440 epoch [514/800] time: 4.58s train loss: 0.0548 accuracy: 0.985 f1: 0.9847
2023-07-14 02:10:14,295 epoch [514/800] time: 0.85s val loss: 0.1293 accuracy: 0.9547 f1: 0.9534
2023-07-14 02:10:18,855 epoch [515/800] time: 4.56s train loss: 0.0546 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:10:19,702 epoch [515/800] time: 0.85s val loss: 0.1295 accuracy: 0.9544 f1: 0.9531
2023-07-14 02:10:24,369 epoch [516/800] time: 4.67s train loss: 0.0563 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:10:25,167 epoch [516/800] time: 0.8s val loss: 0.1303 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:10:29,780 epoch [517/800] time: 4.61s train loss: 0.0553 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:10:30,631 epoch [517/800] time: 0.85s val loss: 0.1304 accuracy: 0.9543 f1: 0.9532
2023-07-14 02:10:35,285 epoch [518/800] time: 4.65s train loss: 0.0547 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:10:36,132 epoch [518/800] time: 0.85s val loss: 0.1292 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:10:40,798 epoch [519/800] time: 4.67s train loss: 0.0556 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:10:41,599 epoch [519/800] time: 0.8s val loss: 0.1301 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:10:46,240 epoch [520/800] time: 4.64s train loss: 0.0552 accuracy: 0.985 f1: 0.9848
2023-07-14 02:10:47,090 epoch [520/800] time: 0.85s val loss: 0.1302 accuracy: 0.9549 f1: 0.9536
2023-07-14 02:10:51,838 epoch [521/800] time: 4.75s train loss: 0.0559 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:10:52,687 epoch [521/800] time: 0.85s val loss: 0.1297 accuracy: 0.9548 f1: 0.9537
2023-07-14 02:10:57,456 epoch [522/800] time: 4.77s train loss: 0.0561 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:10:58,264 epoch [522/800] time: 0.81s val loss: 0.1297 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:11:03,058 epoch [523/800] time: 4.79s train loss: 0.0552 accuracy: 0.9846 f1: 0.9844
2023-07-14 02:11:03,911 epoch [523/800] time: 0.85s val loss: 0.1294 accuracy: 0.9549 f1: 0.9536
2023-07-14 02:11:08,634 epoch [524/800] time: 4.72s train loss: 0.0549 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:11:09,482 epoch [524/800] time: 0.85s val loss: 0.1298 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:11:14,218 epoch [525/800] time: 4.74s train loss: 0.0556 accuracy: 0.9848 f1: 0.9847
2023-07-14 02:11:15,026 epoch [525/800] time: 0.81s val loss: 0.1293 accuracy: 0.9543 f1: 0.9531
2023-07-14 02:11:19,806 epoch [526/800] time: 4.78s train loss: 0.0558 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:11:20,661 epoch [526/800] time: 0.85s val loss: 0.1299 accuracy: 0.9549 f1: 0.9538
2023-07-14 02:11:25,435 epoch [527/800] time: 4.77s train loss: 0.0552 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:11:26,289 epoch [527/800] time: 0.85s val loss: 0.1309 accuracy: 0.9536 f1: 0.9523
2023-07-14 02:11:30,881 epoch [528/800] time: 4.59s train loss: 0.0553 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:11:31,687 epoch [528/800] time: 0.81s val loss: 0.1292 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:11:36,284 epoch [529/800] time: 4.6s train loss: 0.0558 accuracy: 0.9845 f1: 0.9843
2023-07-14 02:11:37,132 epoch [529/800] time: 0.85s val loss: 0.13 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:11:41,723 epoch [530/800] time: 4.59s train loss: 0.0549 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:11:42,575 epoch [530/800] time: 0.85s val loss: 0.1299 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:11:47,214 epoch [531/800] time: 4.64s train loss: 0.0555 accuracy: 0.9844 f1: 0.9842
2023-07-14 02:11:48,025 epoch [531/800] time: 0.81s val loss: 0.1291 accuracy: 0.9551 f1: 0.9538
2023-07-14 02:11:52,669 epoch [532/800] time: 4.64s train loss: 0.0556 accuracy: 0.9844 f1: 0.9843
2023-07-14 02:11:53,524 epoch [532/800] time: 0.86s val loss: 0.1296 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:11:58,181 epoch [533/800] time: 4.66s train loss: 0.0557 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:11:59,029 epoch [533/800] time: 0.85s val loss: 0.1296 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:12:03,726 epoch [534/800] time: 4.7s train loss: 0.0547 accuracy: 0.985 f1: 0.9848
2023-07-14 02:12:04,539 epoch [534/800] time: 0.81s val loss: 0.1299 accuracy: 0.9544 f1: 0.9532
2023-07-14 02:12:09,290 epoch [535/800] time: 4.75s train loss: 0.0546 accuracy: 0.9854 f1: 0.9853
2023-07-14 02:12:10,141 epoch [535/800] time: 0.85s val loss: 0.1295 accuracy: 0.955 f1: 0.9538
2023-07-14 02:12:14,829 epoch [536/800] time: 4.69s train loss: 0.0555 accuracy: 0.9847 f1: 0.9844
2023-07-14 02:12:15,681 epoch [536/800] time: 0.85s val loss: 0.1301 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:12:20,413 epoch [537/800] time: 4.73s train loss: 0.0552 accuracy: 0.9852 f1: 0.985
2023-07-14 02:12:21,212 epoch [537/800] time: 0.8s val loss: 0.1295 accuracy: 0.9542 f1: 0.9529
2023-07-14 02:12:25,748 epoch [538/800] time: 4.54s train loss: 0.0561 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:12:26,609 epoch [538/800] time: 0.86s val loss: 0.1296 accuracy: 0.9549 f1: 0.9537
2023-07-14 02:12:31,168 epoch [539/800] time: 4.56s train loss: 0.0552 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:12:32,019 epoch [539/800] time: 0.85s val loss: 0.1299 accuracy: 0.9545 f1: 0.9532
2023-07-14 02:12:36,633 epoch [540/800] time: 4.61s train loss: 0.0549 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:12:37,437 epoch [540/800] time: 0.8s val loss: 0.1301 accuracy: 0.9545 f1: 0.9533
2023-07-14 02:12:42,065 epoch [541/800] time: 4.63s train loss: 0.0546 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:12:42,910 epoch [541/800] time: 0.84s val loss: 0.1291 accuracy: 0.9552 f1: 0.954
2023-07-14 02:12:47,470 epoch [542/800] time: 4.56s train loss: 0.0556 accuracy: 0.9846 f1: 0.9845
2023-07-14 02:12:48,328 epoch [542/800] time: 0.86s val loss: 0.1304 accuracy: 0.9543 f1: 0.953
2023-07-14 02:12:53,013 epoch [543/800] time: 4.68s train loss: 0.0548 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:12:53,820 epoch [543/800] time: 0.81s val loss: 0.1299 accuracy: 0.9543 f1: 0.9531
2023-07-14 02:12:58,538 epoch [544/800] time: 4.72s train loss: 0.0555 accuracy: 0.9852 f1: 0.9852
2023-07-14 02:12:59,389 epoch [544/800] time: 0.85s val loss: 0.1296 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:13:04,082 epoch [545/800] time: 4.69s train loss: 0.0563 accuracy: 0.9845 f1: 0.9843
2023-07-14 02:13:04,927 epoch [545/800] time: 0.84s val loss: 0.1295 accuracy: 0.9543 f1: 0.9531
2023-07-14 02:13:09,646 epoch [546/800] time: 4.72s train loss: 0.0557 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:13:10,456 epoch [546/800] time: 0.81s val loss: 0.1297 accuracy: 0.9544 f1: 0.9533
2023-07-14 02:13:15,257 epoch [547/800] time: 4.8s train loss: 0.0555 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:13:16,115 epoch [547/800] time: 0.86s val loss: 0.1294 accuracy: 0.9549 f1: 0.9537
2023-07-14 02:13:20,670 epoch [548/800] time: 4.55s train loss: 0.0551 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:13:21,523 epoch [548/800] time: 0.85s val loss: 0.1301 accuracy: 0.9545 f1: 0.9532
2023-07-14 02:13:26,275 epoch [549/800] time: 4.75s train loss: 0.0554 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:13:27,078 epoch [549/800] time: 0.8s val loss: 0.1295 accuracy: 0.9545 f1: 0.9534
2023-07-14 02:13:31,860 epoch [550/800] time: 4.78s train loss: 0.055 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:13:32,710 epoch [550/800] time: 0.85s val loss: 0.1294 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:13:37,466 epoch [551/800] time: 4.76s train loss: 0.0556 accuracy: 0.9854 f1: 0.9851
2023-07-14 02:13:38,405 epoch [551/800] time: 0.94s val loss: 0.1304 accuracy: 0.9542 f1: 0.9528
2023-07-14 02:13:43,272 epoch [552/800] time: 4.87s train loss: 0.0561 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:13:44,087 epoch [552/800] time: 0.81s val loss: 0.1293 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:13:48,956 epoch [553/800] time: 4.87s train loss: 0.056 accuracy: 0.985 f1: 0.9848
2023-07-14 02:13:49,828 epoch [553/800] time: 0.87s val loss: 0.1306 accuracy: 0.9542 f1: 0.953
2023-07-14 02:13:54,925 epoch [554/800] time: 5.1s train loss: 0.0554 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:13:55,822 epoch [554/800] time: 0.9s val loss: 0.1296 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:14:00,802 epoch [555/800] time: 4.98s train loss: 0.0547 accuracy: 0.9846 f1: 0.9845
2023-07-14 02:14:01,636 epoch [555/800] time: 0.83s val loss: 0.1291 accuracy: 0.9549 f1: 0.9538
2023-07-14 02:14:06,613 epoch [556/800] time: 4.98s train loss: 0.0555 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:14:07,544 epoch [556/800] time: 0.93s val loss: 0.1298 accuracy: 0.9544 f1: 0.9531
2023-07-14 02:14:12,583 epoch [557/800] time: 5.04s train loss: 0.055 accuracy: 0.985 f1: 0.9849
2023-07-14 02:14:13,453 epoch [557/800] time: 0.87s val loss: 0.1293 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:14:18,539 epoch [558/800] time: 5.09s train loss: 0.0549 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:14:19,391 epoch [558/800] time: 0.85s val loss: 0.1297 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:14:24,563 epoch [559/800] time: 5.17s train loss: 0.0544 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:14:25,436 epoch [559/800] time: 0.87s val loss: 0.1289 accuracy: 0.955 f1: 0.9538
2023-07-14 02:14:30,522 epoch [560/800] time: 5.09s train loss: 0.057 accuracy: 0.9841 f1: 0.984
2023-07-14 02:14:31,416 epoch [560/800] time: 0.89s val loss: 0.1292 accuracy: 0.9554 f1: 0.9541
2023-07-14 02:14:36,534 epoch [561/800] time: 5.12s train loss: 0.0555 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:14:37,416 epoch [561/800] time: 0.88s val loss: 0.1298 accuracy: 0.9549 f1: 0.9536
2023-07-14 02:14:42,842 epoch [562/800] time: 5.43s train loss: 0.0551 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:14:43,770 epoch [562/800] time: 0.93s val loss: 0.1295 accuracy: 0.954 f1: 0.9529
2023-07-14 02:14:48,697 epoch [563/800] time: 4.93s train loss: 0.057 accuracy: 0.984 f1: 0.9839
2023-07-14 02:14:49,560 epoch [563/800] time: 0.86s val loss: 0.1312 accuracy: 0.9545 f1: 0.9532
2023-07-14 02:14:54,631 epoch [564/800] time: 5.07s train loss: 0.0543 accuracy: 0.9854 f1: 0.9852
2023-07-14 02:14:55,490 epoch [564/800] time: 0.86s val loss: 0.129 accuracy: 0.9549 f1: 0.9536
2023-07-14 02:15:00,607 epoch [565/800] time: 5.12s train loss: 0.0549 accuracy: 0.9846 f1: 0.9845
2023-07-14 02:15:01,500 epoch [565/800] time: 0.89s val loss: 0.1294 accuracy: 0.9545 f1: 0.9533
2023-07-14 02:15:06,562 epoch [566/800] time: 5.06s train loss: 0.0544 accuracy: 0.985 f1: 0.9849
2023-07-14 02:15:07,454 epoch [566/800] time: 0.89s val loss: 0.1298 accuracy: 0.9545 f1: 0.9532
2023-07-14 02:15:12,604 epoch [567/800] time: 5.15s train loss: 0.0565 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:15:13,456 epoch [567/800] time: 0.85s val loss: 0.1311 accuracy: 0.954 f1: 0.9527
2023-07-14 02:15:18,566 epoch [568/800] time: 5.11s train loss: 0.0558 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:15:19,476 epoch [568/800] time: 0.91s val loss: 0.1309 accuracy: 0.9537 f1: 0.9526
2023-07-14 02:15:24,541 epoch [569/800] time: 5.06s train loss: 0.0556 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:15:25,440 epoch [569/800] time: 0.9s val loss: 0.1295 accuracy: 0.9553 f1: 0.954
2023-07-14 02:15:30,405 epoch [570/800] time: 4.96s train loss: 0.0559 accuracy: 0.9846 f1: 0.9845
2023-07-14 02:15:31,225 epoch [570/800] time: 0.82s val loss: 0.1296 accuracy: 0.9548 f1: 0.9537
2023-07-14 02:15:36,181 epoch [571/800] time: 4.96s train loss: 0.0554 accuracy: 0.9848 f1: 0.9847
2023-07-14 02:15:37,113 epoch [571/800] time: 0.93s val loss: 0.1302 accuracy: 0.9549 f1: 0.9534
2023-07-14 02:15:42,088 epoch [572/800] time: 4.98s train loss: 0.0561 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:15:42,955 epoch [572/800] time: 0.87s val loss: 0.13 accuracy: 0.9544 f1: 0.9532
2023-07-14 02:15:47,873 epoch [573/800] time: 4.92s train loss: 0.0564 accuracy: 0.9846 f1: 0.9844
2023-07-14 02:15:48,728 epoch [573/800] time: 0.85s val loss: 0.1301 accuracy: 0.9543 f1: 0.9531
2023-07-14 02:15:53,546 epoch [574/800] time: 4.82s train loss: 0.0551 accuracy: 0.9853 f1: 0.9851
2023-07-14 02:15:54,400 epoch [574/800] time: 0.85s val loss: 0.1292 accuracy: 0.9551 f1: 0.9538
2023-07-14 02:15:59,134 epoch [575/800] time: 4.73s train loss: 0.0549 accuracy: 0.9852 f1: 0.985
2023-07-14 02:16:00,017 epoch [575/800] time: 0.88s val loss: 0.1297 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:16:05,025 epoch [576/800] time: 5.01s train loss: 0.0549 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:16:05,859 epoch [576/800] time: 0.83s val loss: 0.13 accuracy: 0.9545 f1: 0.9533
2023-07-14 02:16:10,646 epoch [577/800] time: 4.79s train loss: 0.0544 accuracy: 0.9852 f1: 0.9849
2023-07-14 02:16:11,505 epoch [577/800] time: 0.86s val loss: 0.1296 accuracy: 0.9543 f1: 0.953
2023-07-14 02:16:16,488 epoch [578/800] time: 4.98s train loss: 0.0569 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:16:17,367 epoch [578/800] time: 0.88s val loss: 0.1309 accuracy: 0.9543 f1: 0.953
2023-07-14 02:16:22,290 epoch [579/800] time: 4.92s train loss: 0.0564 accuracy: 0.9852 f1: 0.9851
2023-07-14 02:16:23,101 epoch [579/800] time: 0.81s val loss: 0.1312 accuracy: 0.9543 f1: 0.9531
2023-07-14 02:16:28,021 epoch [580/800] time: 4.92s train loss: 0.0563 accuracy: 0.9843 f1: 0.984
2023-07-14 02:16:28,893 epoch [580/800] time: 0.87s val loss: 0.13 accuracy: 0.955 f1: 0.9538
2023-07-14 02:16:33,599 epoch [581/800] time: 4.71s train loss: 0.0562 accuracy: 0.9848 f1: 0.9847
2023-07-14 02:16:34,470 epoch [581/800] time: 0.87s val loss: 0.1309 accuracy: 0.9539 f1: 0.9528
2023-07-14 02:16:39,144 epoch [582/800] time: 4.67s train loss: 0.0548 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:16:40,039 epoch [582/800] time: 0.89s val loss: 0.129 accuracy: 0.9553 f1: 0.954
2023-07-14 02:16:45,082 epoch [583/800] time: 5.04s train loss: 0.0555 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:16:46,012 epoch [583/800] time: 0.93s val loss: 0.1297 accuracy: 0.955 f1: 0.9538
2023-07-14 02:16:51,164 epoch [584/800] time: 5.15s train loss: 0.0559 accuracy: 0.9845 f1: 0.9844
2023-07-14 02:16:52,103 epoch [584/800] time: 0.94s val loss: 0.1297 accuracy: 0.9549 f1: 0.9538
2023-07-14 02:16:57,517 epoch [585/800] time: 5.41s train loss: 0.0559 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:16:58,579 epoch [585/800] time: 1.06s val loss: 0.1303 accuracy: 0.9547 f1: 0.9534
2023-07-14 02:17:04,235 epoch [586/800] time: 5.66s train loss: 0.0552 accuracy: 0.9853 f1: 0.9851
2023-07-14 02:17:05,109 epoch [586/800] time: 0.87s val loss: 0.1296 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:17:10,329 epoch [587/800] time: 5.22s train loss: 0.055 accuracy: 0.985 f1: 0.9848
2023-07-14 02:17:11,385 epoch [587/800] time: 1.06s val loss: 0.1296 accuracy: 0.9553 f1: 0.954
2023-07-14 02:17:16,990 epoch [588/800] time: 5.6s train loss: 0.0553 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:17:17,815 epoch [588/800] time: 0.83s val loss: 0.1292 accuracy: 0.9544 f1: 0.9529
2023-07-14 02:17:23,463 epoch [589/800] time: 5.65s train loss: 0.0566 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:17:24,384 epoch [589/800] time: 0.92s val loss: 0.13 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:17:29,642 epoch [590/800] time: 5.26s train loss: 0.0554 accuracy: 0.9843 f1: 0.9841
2023-07-14 02:17:30,592 epoch [590/800] time: 0.95s val loss: 0.1294 accuracy: 0.9549 f1: 0.9536
2023-07-14 02:17:35,803 epoch [591/800] time: 5.21s train loss: 0.0549 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:17:36,692 epoch [591/800] time: 0.89s val loss: 0.1297 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:17:41,669 epoch [592/800] time: 4.98s train loss: 0.0555 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:17:42,537 epoch [592/800] time: 0.87s val loss: 0.1294 accuracy: 0.955 f1: 0.9537
2023-07-14 02:17:47,593 epoch [593/800] time: 5.06s train loss: 0.0546 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:17:48,497 epoch [593/800] time: 0.9s val loss: 0.1293 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:17:53,950 epoch [594/800] time: 5.45s train loss: 0.0552 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:17:54,799 epoch [594/800] time: 0.85s val loss: 0.1299 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:17:59,841 epoch [595/800] time: 5.04s train loss: 0.0558 accuracy: 0.9844 f1: 0.9843
2023-07-14 02:18:00,711 epoch [595/800] time: 0.87s val loss: 0.1298 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:18:05,586 epoch [596/800] time: 4.87s train loss: 0.0564 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:18:06,443 epoch [596/800] time: 0.86s val loss: 0.1309 accuracy: 0.9537 f1: 0.9525
2023-07-14 02:18:11,245 epoch [597/800] time: 4.8s train loss: 0.0559 accuracy: 0.9845 f1: 0.9844
2023-07-14 02:18:12,066 epoch [597/800] time: 0.82s val loss: 0.1313 accuracy: 0.9542 f1: 0.9529
2023-07-14 02:18:16,916 epoch [598/800] time: 4.85s train loss: 0.055 accuracy: 0.985 f1: 0.9848
2023-07-14 02:18:17,793 epoch [598/800] time: 0.88s val loss: 0.1303 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:18:22,524 epoch [599/800] time: 4.73s train loss: 0.056 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:18:23,365 epoch [599/800] time: 0.84s val loss: 0.13 accuracy: 0.9546 f1: 0.9532
2023-07-14 02:18:28,075 epoch [600/800] time: 4.71s train loss: 0.0568 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:18:28,890 epoch [600/800] time: 0.81s val loss: 0.13 accuracy: 0.9551 f1: 0.9538
2023-07-14 02:18:33,702 epoch [601/800] time: 4.81s train loss: 0.0557 accuracy: 0.9846 f1: 0.9844
2023-07-14 02:18:34,550 epoch [601/800] time: 0.85s val loss: 0.1298 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:18:39,317 epoch [602/800] time: 4.77s train loss: 0.0559 accuracy: 0.9851 f1: 0.985
2023-07-14 02:18:40,182 epoch [602/800] time: 0.87s val loss: 0.1302 accuracy: 0.9547 f1: 0.9534
2023-07-14 02:18:44,860 epoch [603/800] time: 4.68s train loss: 0.0557 accuracy: 0.9845 f1: 0.9843
2023-07-14 02:18:45,672 epoch [603/800] time: 0.81s val loss: 0.1296 accuracy: 0.955 f1: 0.9539
2023-07-14 02:18:50,345 epoch [604/800] time: 4.67s train loss: 0.0558 accuracy: 0.9849 f1: 0.9849
2023-07-14 02:18:51,200 epoch [604/800] time: 0.85s val loss: 0.1291 accuracy: 0.9551 f1: 0.9539
2023-07-14 02:18:55,745 epoch [605/800] time: 4.55s train loss: 0.0554 accuracy: 0.9852 f1: 0.985
2023-07-14 02:18:56,605 epoch [605/800] time: 0.86s val loss: 0.1302 accuracy: 0.9546 f1: 0.9535
2023-07-14 02:19:01,189 epoch [606/800] time: 4.58s train loss: 0.0551 accuracy: 0.9853 f1: 0.9851
2023-07-14 02:19:02,002 epoch [606/800] time: 0.81s val loss: 0.1294 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:19:06,583 epoch [607/800] time: 4.58s train loss: 0.0553 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:19:07,442 epoch [607/800] time: 0.86s val loss: 0.1291 accuracy: 0.9551 f1: 0.9539
2023-07-14 02:19:11,973 epoch [608/800] time: 4.53s train loss: 0.055 accuracy: 0.9846 f1: 0.9844
2023-07-14 02:19:12,827 epoch [608/800] time: 0.85s val loss: 0.1295 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:19:17,409 epoch [609/800] time: 4.58s train loss: 0.055 accuracy: 0.9851 f1: 0.985
2023-07-14 02:19:18,219 epoch [609/800] time: 0.81s val loss: 0.1295 accuracy: 0.9549 f1: 0.9535
2023-07-14 02:19:22,893 epoch [610/800] time: 4.67s train loss: 0.0553 accuracy: 0.9845 f1: 0.9844
2023-07-14 02:19:23,745 epoch [610/800] time: 0.85s val loss: 0.1294 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:19:28,379 epoch [611/800] time: 4.63s train loss: 0.0565 accuracy: 0.9844 f1: 0.9843
2023-07-14 02:19:29,227 epoch [611/800] time: 0.85s val loss: 0.13 accuracy: 0.9546 f1: 0.9536
2023-07-14 02:19:33,809 epoch [612/800] time: 4.58s train loss: 0.0553 accuracy: 0.9852 f1: 0.985
2023-07-14 02:19:34,614 epoch [612/800] time: 0.8s val loss: 0.1304 accuracy: 0.9547 f1: 0.9534
2023-07-14 02:19:39,199 epoch [613/800] time: 4.59s train loss: 0.0546 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:19:40,046 epoch [613/800] time: 0.85s val loss: 0.1297 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:19:44,562 epoch [614/800] time: 4.52s train loss: 0.0547 accuracy: 0.9851 f1: 0.9851
2023-07-14 02:19:45,418 epoch [614/800] time: 0.86s val loss: 0.1293 accuracy: 0.9551 f1: 0.9539
2023-07-14 02:19:50,009 epoch [615/800] time: 4.59s train loss: 0.0556 accuracy: 0.9847 f1: 0.9844
2023-07-14 02:19:50,813 epoch [615/800] time: 0.8s val loss: 0.1303 accuracy: 0.9542 f1: 0.9529
2023-07-14 02:19:55,398 epoch [616/800] time: 4.59s train loss: 0.0554 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:19:56,255 epoch [616/800] time: 0.86s val loss: 0.1292 accuracy: 0.9549 f1: 0.9537
2023-07-14 02:20:00,916 epoch [617/800] time: 4.66s train loss: 0.0559 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:20:01,777 epoch [617/800] time: 0.86s val loss: 0.1291 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:20:06,724 epoch [618/800] time: 4.95s train loss: 0.0569 accuracy: 0.9843 f1: 0.9841
2023-07-14 02:20:07,537 epoch [618/800] time: 0.81s val loss: 0.1299 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:20:12,366 epoch [619/800] time: 4.83s train loss: 0.0549 accuracy: 0.9854 f1: 0.9852
2023-07-14 02:20:13,226 epoch [619/800] time: 0.86s val loss: 0.1294 accuracy: 0.9545 f1: 0.9534
2023-07-14 02:20:18,155 epoch [620/800] time: 4.93s train loss: 0.0549 accuracy: 0.9851 f1: 0.985
2023-07-14 02:20:19,034 epoch [620/800] time: 0.88s val loss: 0.1305 accuracy: 0.9542 f1: 0.9529
2023-07-14 02:20:23,952 epoch [621/800] time: 4.92s train loss: 0.0549 accuracy: 0.985 f1: 0.9849
2023-07-14 02:20:24,768 epoch [621/800] time: 0.81s val loss: 0.1299 accuracy: 0.9543 f1: 0.953
2023-07-14 02:20:29,642 epoch [622/800] time: 4.87s train loss: 0.0556 accuracy: 0.9848 f1: 0.9845
2023-07-14 02:20:30,507 epoch [622/800] time: 0.86s val loss: 0.1297 accuracy: 0.9545 f1: 0.9534
2023-07-14 02:20:35,313 epoch [623/800] time: 4.81s train loss: 0.0561 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:20:36,169 epoch [623/800] time: 0.86s val loss: 0.1303 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:20:41,021 epoch [624/800] time: 4.85s train loss: 0.0564 accuracy: 0.9844 f1: 0.9843
2023-07-14 02:20:41,828 epoch [624/800] time: 0.81s val loss: 0.1301 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:20:46,564 epoch [625/800] time: 4.74s train loss: 0.0547 accuracy: 0.9852 f1: 0.985
2023-07-14 02:20:47,409 epoch [625/800] time: 0.84s val loss: 0.1293 accuracy: 0.9554 f1: 0.9543
2023-07-14 02:20:52,108 epoch [626/800] time: 4.7s train loss: 0.0552 accuracy: 0.9846 f1: 0.9843
2023-07-14 02:20:52,955 epoch [626/800] time: 0.85s val loss: 0.1296 accuracy: 0.9549 f1: 0.9536
2023-07-14 02:20:57,717 epoch [627/800] time: 4.76s train loss: 0.056 accuracy: 0.9844 f1: 0.9843
2023-07-14 02:20:58,516 epoch [627/800] time: 0.8s val loss: 0.1293 accuracy: 0.9549 f1: 0.9537
2023-07-14 02:21:03,246 epoch [628/800] time: 4.73s train loss: 0.0538 accuracy: 0.9855 f1: 0.9854
2023-07-14 02:21:04,093 epoch [628/800] time: 0.85s val loss: 0.1298 accuracy: 0.955 f1: 0.9538
2023-07-14 02:21:08,768 epoch [629/800] time: 4.67s train loss: 0.0547 accuracy: 0.9852 f1: 0.9851
2023-07-14 02:21:09,613 epoch [629/800] time: 0.85s val loss: 0.1301 accuracy: 0.955 f1: 0.9536
2023-07-14 02:21:14,319 epoch [630/800] time: 4.71s train loss: 0.0557 accuracy: 0.9843 f1: 0.9842
2023-07-14 02:21:15,119 epoch [630/800] time: 0.8s val loss: 0.1295 accuracy: 0.9545 f1: 0.9534
2023-07-14 02:21:19,883 epoch [631/800] time: 4.76s train loss: 0.056 accuracy: 0.9841 f1: 0.9839
2023-07-14 02:21:20,742 epoch [631/800] time: 0.86s val loss: 0.1296 accuracy: 0.9551 f1: 0.9539
2023-07-14 02:21:25,476 epoch [632/800] time: 4.73s train loss: 0.055 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:21:26,330 epoch [632/800] time: 0.85s val loss: 0.1295 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:21:31,079 epoch [633/800] time: 4.75s train loss: 0.0552 accuracy: 0.9847 f1: 0.9844
2023-07-14 02:21:31,886 epoch [633/800] time: 0.81s val loss: 0.1301 accuracy: 0.9542 f1: 0.953
2023-07-14 02:21:36,634 epoch [634/800] time: 4.75s train loss: 0.0558 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:21:37,480 epoch [634/800] time: 0.85s val loss: 0.13 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:21:42,153 epoch [635/800] time: 4.67s train loss: 0.0544 accuracy: 0.9856 f1: 0.9855
2023-07-14 02:21:43,000 epoch [635/800] time: 0.85s val loss: 0.1297 accuracy: 0.9553 f1: 0.954
2023-07-14 02:21:47,804 epoch [636/800] time: 4.8s train loss: 0.055 accuracy: 0.9848 f1: 0.9848
2023-07-14 02:21:48,614 epoch [636/800] time: 0.81s val loss: 0.1295 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:21:53,394 epoch [637/800] time: 4.78s train loss: 0.0555 accuracy: 0.985 f1: 0.9847
2023-07-14 02:21:54,249 epoch [637/800] time: 0.85s val loss: 0.1306 accuracy: 0.9548 f1: 0.9534
2023-07-14 02:21:58,972 epoch [638/800] time: 4.72s train loss: 0.055 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:21:59,828 epoch [638/800] time: 0.86s val loss: 0.1296 accuracy: 0.9541 f1: 0.9528
2023-07-14 02:22:04,578 epoch [639/800] time: 4.75s train loss: 0.055 accuracy: 0.9848 f1: 0.9847
2023-07-14 02:22:05,388 epoch [639/800] time: 0.81s val loss: 0.1298 accuracy: 0.9542 f1: 0.9529
2023-07-14 02:22:10,195 epoch [640/800] time: 4.81s train loss: 0.0555 accuracy: 0.985 f1: 0.9848
2023-07-14 02:22:11,052 epoch [640/800] time: 0.86s val loss: 0.1308 accuracy: 0.955 f1: 0.9536
2023-07-14 02:22:15,813 epoch [641/800] time: 4.76s train loss: 0.0553 accuracy: 0.9844 f1: 0.9842
2023-07-14 02:22:16,672 epoch [641/800] time: 0.86s val loss: 0.1297 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:22:21,548 epoch [642/800] time: 4.88s train loss: 0.0543 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:22:22,361 epoch [642/800] time: 0.81s val loss: 0.1299 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:22:27,128 epoch [643/800] time: 4.77s train loss: 0.0553 accuracy: 0.985 f1: 0.9848
2023-07-14 02:22:28,031 epoch [643/800] time: 0.9s val loss: 0.1302 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:22:32,743 epoch [644/800] time: 4.71s train loss: 0.0544 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:22:33,588 epoch [644/800] time: 0.85s val loss: 0.1291 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:22:38,253 epoch [645/800] time: 4.66s train loss: 0.0542 accuracy: 0.9855 f1: 0.9853
2023-07-14 02:22:39,057 epoch [645/800] time: 0.8s val loss: 0.1299 accuracy: 0.9549 f1: 0.9536
2023-07-14 02:22:44,349 epoch [646/800] time: 5.29s train loss: 0.0547 accuracy: 0.985 f1: 0.9848
2023-07-14 02:22:45,215 epoch [646/800] time: 0.87s val loss: 0.1305 accuracy: 0.9544 f1: 0.953
2023-07-14 02:22:49,993 epoch [647/800] time: 4.78s train loss: 0.0563 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:22:50,861 epoch [647/800] time: 0.87s val loss: 0.1298 accuracy: 0.9545 f1: 0.9534
2023-07-14 02:22:56,068 epoch [648/800] time: 5.21s train loss: 0.0555 accuracy: 0.9851 f1: 0.985
2023-07-14 02:22:56,914 epoch [648/800] time: 0.85s val loss: 0.1302 accuracy: 0.9542 f1: 0.953
2023-07-14 02:23:01,704 epoch [649/800] time: 4.79s train loss: 0.0559 accuracy: 0.9843 f1: 0.9842
2023-07-14 02:23:02,559 epoch [649/800] time: 0.85s val loss: 0.1298 accuracy: 0.9552 f1: 0.9539
2023-07-14 02:23:07,233 epoch [650/800] time: 4.67s train loss: 0.0552 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:23:08,090 epoch [650/800] time: 0.86s val loss: 0.1308 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:23:12,675 epoch [651/800] time: 4.59s train loss: 0.055 accuracy: 0.9854 f1: 0.9851
2023-07-14 02:23:13,493 epoch [651/800] time: 0.82s val loss: 0.1294 accuracy: 0.9549 f1: 0.9536
2023-07-14 02:23:18,080 epoch [652/800] time: 4.59s train loss: 0.0564 accuracy: 0.985 f1: 0.9848
2023-07-14 02:23:18,928 epoch [652/800] time: 0.85s val loss: 0.131 accuracy: 0.9544 f1: 0.9531
2023-07-14 02:23:23,517 epoch [653/800] time: 4.59s train loss: 0.0568 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:23:24,361 epoch [653/800] time: 0.84s val loss: 0.1297 accuracy: 0.9545 f1: 0.9533
2023-07-14 02:23:29,114 epoch [654/800] time: 4.75s train loss: 0.0555 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:23:29,916 epoch [654/800] time: 0.8s val loss: 0.1307 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:23:34,711 epoch [655/800] time: 4.79s train loss: 0.0555 accuracy: 0.9854 f1: 0.9853
2023-07-14 02:23:35,553 epoch [655/800] time: 0.84s val loss: 0.1292 accuracy: 0.9546 f1: 0.9535
2023-07-14 02:23:40,305 epoch [656/800] time: 4.75s train loss: 0.0557 accuracy: 0.9844 f1: 0.9843
2023-07-14 02:23:41,178 epoch [656/800] time: 0.87s val loss: 0.1292 accuracy: 0.955 f1: 0.9537
2023-07-14 02:23:45,796 epoch [657/800] time: 4.62s train loss: 0.0566 accuracy: 0.9844 f1: 0.9842
2023-07-14 02:23:46,603 epoch [657/800] time: 0.81s val loss: 0.131 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:23:51,364 epoch [658/800] time: 4.76s train loss: 0.0549 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:23:52,266 epoch [658/800] time: 0.9s val loss: 0.1289 accuracy: 0.9551 f1: 0.9539
2023-07-14 02:23:57,267 epoch [659/800] time: 5.0s train loss: 0.055 accuracy: 0.9848 f1: 0.9847
2023-07-14 02:23:58,134 epoch [659/800] time: 0.87s val loss: 0.1297 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:24:02,961 epoch [660/800] time: 4.83s train loss: 0.0547 accuracy: 0.9854 f1: 0.9852
2023-07-14 02:24:03,779 epoch [660/800] time: 0.82s val loss: 0.1292 accuracy: 0.9547 f1: 0.9534
2023-07-14 02:24:08,738 epoch [661/800] time: 4.96s train loss: 0.0552 accuracy: 0.985 f1: 0.9848
2023-07-14 02:24:09,625 epoch [661/800] time: 0.89s val loss: 0.1288 accuracy: 0.9551 f1: 0.954
2023-07-14 02:24:14,469 epoch [662/800] time: 4.84s train loss: 0.0557 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:24:15,336 epoch [662/800] time: 0.87s val loss: 0.1297 accuracy: 0.9545 f1: 0.9532
2023-07-14 02:24:20,208 epoch [663/800] time: 4.87s train loss: 0.0555 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:24:21,064 epoch [663/800] time: 0.86s val loss: 0.1309 accuracy: 0.9542 f1: 0.953
2023-07-14 02:24:25,972 epoch [664/800] time: 4.91s train loss: 0.0547 accuracy: 0.985 f1: 0.9849
2023-07-14 02:24:26,838 epoch [664/800] time: 0.87s val loss: 0.1295 accuracy: 0.9551 f1: 0.9538
2023-07-14 02:24:31,582 epoch [665/800] time: 4.74s train loss: 0.0565 accuracy: 0.9846 f1: 0.9845
2023-07-14 02:24:32,442 epoch [665/800] time: 0.86s val loss: 0.1312 accuracy: 0.9546 f1: 0.9531
2023-07-14 02:24:37,281 epoch [666/800] time: 4.84s train loss: 0.0546 accuracy: 0.9848 f1: 0.9845
2023-07-14 02:24:38,095 epoch [666/800] time: 0.81s val loss: 0.1297 accuracy: 0.9545 f1: 0.9533
2023-07-14 02:24:42,870 epoch [667/800] time: 4.78s train loss: 0.0562 accuracy: 0.9844 f1: 0.9843
2023-07-14 02:24:43,721 epoch [667/800] time: 0.85s val loss: 0.1298 accuracy: 0.9546 f1: 0.9536
2023-07-14 02:24:48,384 epoch [668/800] time: 4.66s train loss: 0.0572 accuracy: 0.9846 f1: 0.9844
2023-07-14 02:24:49,241 epoch [668/800] time: 0.86s val loss: 0.1312 accuracy: 0.9541 f1: 0.9528
2023-07-14 02:24:53,971 epoch [669/800] time: 4.73s train loss: 0.0556 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:24:54,790 epoch [669/800] time: 0.82s val loss: 0.1317 accuracy: 0.9539 f1: 0.9528
2023-07-14 02:24:59,589 epoch [670/800] time: 4.8s train loss: 0.0552 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:25:00,444 epoch [670/800] time: 0.85s val loss: 0.1293 accuracy: 0.9552 f1: 0.9539
2023-07-14 02:25:05,144 epoch [671/800] time: 4.7s train loss: 0.0553 accuracy: 0.9846 f1: 0.9844
2023-07-14 02:25:05,996 epoch [671/800] time: 0.85s val loss: 0.1295 accuracy: 0.9544 f1: 0.9532
2023-07-14 02:25:10,973 epoch [672/800] time: 4.98s train loss: 0.0558 accuracy: 0.9845 f1: 0.9843
2023-07-14 02:25:11,808 epoch [672/800] time: 0.83s val loss: 0.1295 accuracy: 0.9544 f1: 0.9533
2023-07-14 02:25:16,517 epoch [673/800] time: 4.71s train loss: 0.0561 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:25:17,376 epoch [673/800] time: 0.86s val loss: 0.1296 accuracy: 0.9546 f1: 0.9532
2023-07-14 02:25:22,239 epoch [674/800] time: 4.86s train loss: 0.0555 accuracy: 0.9846 f1: 0.9843
2023-07-14 02:25:23,156 epoch [674/800] time: 0.92s val loss: 0.1304 accuracy: 0.9544 f1: 0.9532
2023-07-14 02:25:28,053 epoch [675/800] time: 4.9s train loss: 0.0553 accuracy: 0.9851 f1: 0.985
2023-07-14 02:25:28,918 epoch [675/800] time: 0.86s val loss: 0.1299 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:25:33,800 epoch [676/800] time: 4.88s train loss: 0.0546 accuracy: 0.9855 f1: 0.9854
2023-07-14 02:25:34,737 epoch [676/800] time: 0.94s val loss: 0.1295 accuracy: 0.9546 f1: 0.9535
2023-07-14 02:25:39,755 epoch [677/800] time: 5.02s train loss: 0.0559 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:25:40,644 epoch [677/800] time: 0.89s val loss: 0.1296 accuracy: 0.9549 f1: 0.9537
2023-07-14 02:25:45,738 epoch [678/800] time: 5.09s train loss: 0.0552 accuracy: 0.9851 f1: 0.9848
2023-07-14 02:25:46,557 epoch [678/800] time: 0.82s val loss: 0.1293 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:25:51,797 epoch [679/800] time: 5.24s train loss: 0.055 accuracy: 0.985 f1: 0.9848
2023-07-14 02:25:52,695 epoch [679/800] time: 0.9s val loss: 0.1302 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:25:57,844 epoch [680/800] time: 5.15s train loss: 0.056 accuracy: 0.9852 f1: 0.985
2023-07-14 02:25:58,742 epoch [680/800] time: 0.9s val loss: 0.1302 accuracy: 0.9548 f1: 0.9537
2023-07-14 02:26:03,792 epoch [681/800] time: 5.05s train loss: 0.0558 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:26:04,634 epoch [681/800] time: 0.84s val loss: 0.1299 accuracy: 0.9546 f1: 0.9532
2023-07-14 02:26:09,686 epoch [682/800] time: 5.05s train loss: 0.055 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:26:10,581 epoch [682/800] time: 0.89s val loss: 0.1295 accuracy: 0.9549 f1: 0.9537
2023-07-14 02:26:15,518 epoch [683/800] time: 4.94s train loss: 0.0549 accuracy: 0.985 f1: 0.9848
2023-07-14 02:26:16,392 epoch [683/800] time: 0.87s val loss: 0.1296 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:26:21,487 epoch [684/800] time: 5.09s train loss: 0.0555 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:26:22,322 epoch [684/800] time: 0.83s val loss: 0.1294 accuracy: 0.9547 f1: 0.9536
2023-07-14 02:26:27,389 epoch [685/800] time: 5.07s train loss: 0.0558 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:26:28,261 epoch [685/800] time: 0.87s val loss: 0.1313 accuracy: 0.9543 f1: 0.9529
2023-07-14 02:26:33,210 epoch [686/800] time: 4.95s train loss: 0.056 accuracy: 0.9844 f1: 0.9841
2023-07-14 02:26:34,099 epoch [686/800] time: 0.89s val loss: 0.1309 accuracy: 0.9543 f1: 0.9531
2023-07-14 02:26:39,100 epoch [687/800] time: 5.0s train loss: 0.0545 accuracy: 0.9851 f1: 0.985
2023-07-14 02:26:39,941 epoch [687/800] time: 0.84s val loss: 0.1293 accuracy: 0.9552 f1: 0.9539
2023-07-14 02:26:44,833 epoch [688/800] time: 4.89s train loss: 0.0548 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:26:45,694 epoch [688/800] time: 0.86s val loss: 0.1292 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:26:50,438 epoch [689/800] time: 4.74s train loss: 0.0558 accuracy: 0.985 f1: 0.9849
2023-07-14 02:26:51,298 epoch [689/800] time: 0.86s val loss: 0.1293 accuracy: 0.9549 f1: 0.9537
2023-07-14 02:26:56,071 epoch [690/800] time: 4.77s train loss: 0.0557 accuracy: 0.9845 f1: 0.9843
2023-07-14 02:26:56,878 epoch [690/800] time: 0.81s val loss: 0.1299 accuracy: 0.955 f1: 0.9537
2023-07-14 02:27:01,692 epoch [691/800] time: 4.81s train loss: 0.0545 accuracy: 0.9852 f1: 0.985
2023-07-14 02:27:02,540 epoch [691/800] time: 0.85s val loss: 0.13 accuracy: 0.9552 f1: 0.9539
2023-07-14 02:27:07,242 epoch [692/800] time: 4.7s train loss: 0.055 accuracy: 0.985 f1: 0.9848
2023-07-14 02:27:08,117 epoch [692/800] time: 0.87s val loss: 0.1297 accuracy: 0.9541 f1: 0.9529
2023-07-14 02:27:12,964 epoch [693/800] time: 4.85s train loss: 0.0547 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:27:13,774 epoch [693/800] time: 0.81s val loss: 0.13 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:27:18,533 epoch [694/800] time: 4.76s train loss: 0.055 accuracy: 0.9845 f1: 0.9843
2023-07-14 02:27:19,443 epoch [694/800] time: 0.91s val loss: 0.1287 accuracy: 0.955 f1: 0.9539
2023-07-14 02:27:24,399 epoch [695/800] time: 4.96s train loss: 0.0557 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:27:25,259 epoch [695/800] time: 0.86s val loss: 0.1301 accuracy: 0.9544 f1: 0.9532
2023-07-14 02:27:30,251 epoch [696/800] time: 4.99s train loss: 0.0556 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:27:31,074 epoch [696/800] time: 0.82s val loss: 0.1301 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:27:36,133 epoch [697/800] time: 5.06s train loss: 0.0557 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:27:37,040 epoch [697/800] time: 0.91s val loss: 0.13 accuracy: 0.9545 f1: 0.9532
2023-07-14 02:27:41,741 epoch [698/800] time: 4.7s train loss: 0.055 accuracy: 0.9852 f1: 0.985
2023-07-14 02:27:42,595 epoch [698/800] time: 0.85s val loss: 0.13 accuracy: 0.9548 f1: 0.9537
2023-07-14 02:27:47,393 epoch [699/800] time: 4.8s train loss: 0.0549 accuracy: 0.9852 f1: 0.9851
2023-07-14 02:27:48,242 epoch [699/800] time: 0.85s val loss: 0.1299 accuracy: 0.9545 f1: 0.9532
2023-07-14 02:27:53,079 epoch [700/800] time: 4.84s train loss: 0.0554 accuracy: 0.9843 f1: 0.9841
2023-07-14 02:27:53,938 epoch [700/800] time: 0.86s val loss: 0.1292 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:27:58,791 epoch [701/800] time: 4.85s train loss: 0.0544 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:27:59,681 epoch [701/800] time: 0.89s val loss: 0.1292 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:28:04,556 epoch [702/800] time: 4.88s train loss: 0.055 accuracy: 0.9848 f1: 0.9847
2023-07-14 02:28:05,367 epoch [702/800] time: 0.81s val loss: 0.1296 accuracy: 0.9547 f1: 0.9534
2023-07-14 02:28:10,245 epoch [703/800] time: 4.88s train loss: 0.055 accuracy: 0.985 f1: 0.9849
2023-07-14 02:28:11,157 epoch [703/800] time: 0.91s val loss: 0.1297 accuracy: 0.9544 f1: 0.9532
2023-07-14 02:28:16,162 epoch [704/800] time: 5.0s train loss: 0.0568 accuracy: 0.9843 f1: 0.9842
2023-07-14 02:28:17,107 epoch [704/800] time: 0.94s val loss: 0.1305 accuracy: 0.955 f1: 0.9536
2023-07-14 02:28:22,218 epoch [705/800] time: 5.11s train loss: 0.0551 accuracy: 0.9851 f1: 0.985
2023-07-14 02:28:23,037 epoch [705/800] time: 0.82s val loss: 0.1295 accuracy: 0.9548 f1: 0.9534
2023-07-14 02:28:28,199 epoch [706/800] time: 5.16s train loss: 0.0548 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:28:29,107 epoch [706/800] time: 0.91s val loss: 0.1307 accuracy: 0.9545 f1: 0.9532
2023-07-14 02:28:34,070 epoch [707/800] time: 4.96s train loss: 0.057 accuracy: 0.9843 f1: 0.9841
2023-07-14 02:28:34,989 epoch [707/800] time: 0.92s val loss: 0.1301 accuracy: 0.9548 f1: 0.9534
2023-07-14 02:28:39,922 epoch [708/800] time: 4.93s train loss: 0.0559 accuracy: 0.985 f1: 0.985
2023-07-14 02:28:40,732 epoch [708/800] time: 0.81s val loss: 0.1297 accuracy: 0.9549 f1: 0.9537
2023-07-14 02:28:45,513 epoch [709/800] time: 4.78s train loss: 0.0546 accuracy: 0.985 f1: 0.9848
2023-07-14 02:28:46,425 epoch [709/800] time: 0.91s val loss: 0.1299 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:28:51,552 epoch [710/800] time: 5.13s train loss: 0.0558 accuracy: 0.9844 f1: 0.9842
2023-07-14 02:28:52,479 epoch [710/800] time: 0.93s val loss: 0.1294 accuracy: 0.9552 f1: 0.9539
2023-07-14 02:28:57,875 epoch [711/800] time: 5.4s train loss: 0.0558 accuracy: 0.9854 f1: 0.9853
2023-07-14 02:28:58,709 epoch [711/800] time: 0.83s val loss: 0.13 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:29:03,612 epoch [712/800] time: 4.9s train loss: 0.055 accuracy: 0.985 f1: 0.9848
2023-07-14 02:29:04,481 epoch [712/800] time: 0.87s val loss: 0.1307 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:29:09,231 epoch [713/800] time: 4.75s train loss: 0.0553 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:29:10,091 epoch [713/800] time: 0.86s val loss: 0.1305 accuracy: 0.954 f1: 0.9528
2023-07-14 02:29:14,758 epoch [714/800] time: 4.67s train loss: 0.0555 accuracy: 0.9845 f1: 0.9844
2023-07-14 02:29:15,564 epoch [714/800] time: 0.81s val loss: 0.13 accuracy: 0.9538 f1: 0.9526
2023-07-14 02:29:20,322 epoch [715/800] time: 4.76s train loss: 0.0552 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:29:21,164 epoch [715/800] time: 0.84s val loss: 0.1296 accuracy: 0.9546 f1: 0.9535
2023-07-14 02:29:25,804 epoch [716/800] time: 4.64s train loss: 0.0556 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:29:26,646 epoch [716/800] time: 0.84s val loss: 0.1295 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:29:31,332 epoch [717/800] time: 4.69s train loss: 0.0546 accuracy: 0.9853 f1: 0.9851
2023-07-14 02:29:32,133 epoch [717/800] time: 0.8s val loss: 0.1294 accuracy: 0.9554 f1: 0.954
2023-07-14 02:29:36,890 epoch [718/800] time: 4.76s train loss: 0.0561 accuracy: 0.9845 f1: 0.9844
2023-07-14 02:29:37,739 epoch [718/800] time: 0.85s val loss: 0.1298 accuracy: 0.9543 f1: 0.953
2023-07-14 02:29:42,408 epoch [719/800] time: 4.67s train loss: 0.055 accuracy: 0.9851 f1: 0.985
2023-07-14 02:29:43,250 epoch [719/800] time: 0.84s val loss: 0.1301 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:29:47,903 epoch [720/800] time: 4.65s train loss: 0.0553 accuracy: 0.9851 f1: 0.985
2023-07-14 02:29:48,707 epoch [720/800] time: 0.8s val loss: 0.1296 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:29:53,438 epoch [721/800] time: 4.73s train loss: 0.0549 accuracy: 0.9852 f1: 0.9851
2023-07-14 02:29:54,298 epoch [721/800] time: 0.86s val loss: 0.1298 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:29:59,261 epoch [722/800] time: 4.96s train loss: 0.0557 accuracy: 0.9844 f1: 0.9843
2023-07-14 02:30:00,176 epoch [722/800] time: 0.91s val loss: 0.1292 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:30:05,709 epoch [723/800] time: 5.53s train loss: 0.0538 accuracy: 0.9851 f1: 0.985
2023-07-14 02:30:06,537 epoch [723/800] time: 0.83s val loss: 0.1292 accuracy: 0.9548 f1: 0.9537
2023-07-14 02:30:11,584 epoch [724/800] time: 5.05s train loss: 0.0555 accuracy: 0.9851 f1: 0.9849
2023-07-14 02:30:12,501 epoch [724/800] time: 0.92s val loss: 0.13 accuracy: 0.9545 f1: 0.953
2023-07-14 02:30:17,490 epoch [725/800] time: 4.99s train loss: 0.0569 accuracy: 0.9845 f1: 0.9843
2023-07-14 02:30:18,469 epoch [725/800] time: 0.98s val loss: 0.1298 accuracy: 0.9549 f1: 0.9537
2023-07-14 02:30:23,547 epoch [726/800] time: 5.08s train loss: 0.0554 accuracy: 0.985 f1: 0.9848
2023-07-14 02:30:24,370 epoch [726/800] time: 0.82s val loss: 0.1302 accuracy: 0.9541 f1: 0.9528
2023-07-14 02:30:29,187 epoch [727/800] time: 4.82s train loss: 0.0557 accuracy: 0.9851 f1: 0.985
2023-07-14 02:30:30,108 epoch [727/800] time: 0.92s val loss: 0.1307 accuracy: 0.954 f1: 0.9528
2023-07-14 02:30:34,964 epoch [728/800] time: 4.86s train loss: 0.0556 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:30:35,824 epoch [728/800] time: 0.86s val loss: 0.129 accuracy: 0.9552 f1: 0.954
2023-07-14 02:30:40,912 epoch [729/800] time: 5.09s train loss: 0.0564 accuracy: 0.9841 f1: 0.984
2023-07-14 02:30:41,754 epoch [729/800] time: 0.84s val loss: 0.1306 accuracy: 0.9544 f1: 0.953
2023-07-14 02:30:46,603 epoch [730/800] time: 4.85s train loss: 0.0546 accuracy: 0.9852 f1: 0.985
2023-07-14 02:30:47,466 epoch [730/800] time: 0.86s val loss: 0.1301 accuracy: 0.9545 f1: 0.9533
2023-07-14 02:30:52,702 epoch [731/800] time: 5.24s train loss: 0.0557 accuracy: 0.9852 f1: 0.985
2023-07-14 02:30:53,594 epoch [731/800] time: 0.89s val loss: 0.1304 accuracy: 0.9544 f1: 0.953
2023-07-14 02:30:58,645 epoch [732/800] time: 5.05s train loss: 0.0547 accuracy: 0.985 f1: 0.9848
2023-07-14 02:30:59,459 epoch [732/800] time: 0.81s val loss: 0.1296 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:31:04,359 epoch [733/800] time: 4.9s train loss: 0.0546 accuracy: 0.985 f1: 0.9848
2023-07-14 02:31:05,222 epoch [733/800] time: 0.86s val loss: 0.1299 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:31:09,978 epoch [734/800] time: 4.76s train loss: 0.0556 accuracy: 0.985 f1: 0.9848
2023-07-14 02:31:10,842 epoch [734/800] time: 0.86s val loss: 0.1303 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:31:15,721 epoch [735/800] time: 4.88s train loss: 0.0541 accuracy: 0.9854 f1: 0.9853
2023-07-14 02:31:16,531 epoch [735/800] time: 0.81s val loss: 0.1298 accuracy: 0.955 f1: 0.9536
2023-07-14 02:31:21,179 epoch [736/800] time: 4.65s train loss: 0.0558 accuracy: 0.9846 f1: 0.9845
2023-07-14 02:31:22,061 epoch [736/800] time: 0.88s val loss: 0.1307 accuracy: 0.9545 f1: 0.9531
2023-07-14 02:31:26,974 epoch [737/800] time: 4.91s train loss: 0.0562 accuracy: 0.9844 f1: 0.9843
2023-07-14 02:31:27,844 epoch [737/800] time: 0.87s val loss: 0.1294 accuracy: 0.9553 f1: 0.954
2023-07-14 02:31:32,690 epoch [738/800] time: 4.85s train loss: 0.0552 accuracy: 0.9848 f1: 0.9847
2023-07-14 02:31:33,493 epoch [738/800] time: 0.8s val loss: 0.1293 accuracy: 0.9551 f1: 0.9539
2023-07-14 02:31:38,342 epoch [739/800] time: 4.85s train loss: 0.0554 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:31:39,228 epoch [739/800] time: 0.89s val loss: 0.1297 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:31:44,130 epoch [740/800] time: 4.9s train loss: 0.0559 accuracy: 0.9848 f1: 0.9847
2023-07-14 02:31:45,001 epoch [740/800] time: 0.87s val loss: 0.1298 accuracy: 0.9549 f1: 0.9536
2023-07-14 02:31:50,645 epoch [741/800] time: 5.64s train loss: 0.0558 accuracy: 0.9844 f1: 0.9842
2023-07-14 02:31:51,480 epoch [741/800] time: 0.83s val loss: 0.1299 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:31:57,157 epoch [742/800] time: 5.68s train loss: 0.0544 accuracy: 0.9853 f1: 0.9851
2023-07-14 02:31:58,032 epoch [742/800] time: 0.87s val loss: 0.1302 accuracy: 0.9544 f1: 0.953
2023-07-14 02:32:02,845 epoch [743/800] time: 4.81s train loss: 0.0556 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:32:03,705 epoch [743/800] time: 0.86s val loss: 0.1298 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:32:08,570 epoch [744/800] time: 4.86s train loss: 0.0555 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:32:09,395 epoch [744/800] time: 0.83s val loss: 0.1297 accuracy: 0.9544 f1: 0.9532
2023-07-14 02:32:14,194 epoch [745/800] time: 4.8s train loss: 0.0552 accuracy: 0.985 f1: 0.9848
2023-07-14 02:32:15,037 epoch [745/800] time: 0.84s val loss: 0.1298 accuracy: 0.9545 f1: 0.9533
2023-07-14 02:32:19,833 epoch [746/800] time: 4.8s train loss: 0.0558 accuracy: 0.9847 f1: 0.9844
2023-07-14 02:32:20,697 epoch [746/800] time: 0.86s val loss: 0.1298 accuracy: 0.9543 f1: 0.9531
2023-07-14 02:32:25,752 epoch [747/800] time: 5.05s train loss: 0.0558 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:32:26,573 epoch [747/800] time: 0.82s val loss: 0.1294 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:32:31,248 epoch [748/800] time: 4.68s train loss: 0.057 accuracy: 0.9839 f1: 0.9837
2023-07-14 02:32:32,114 epoch [748/800] time: 0.87s val loss: 0.1292 accuracy: 0.9549 f1: 0.9537
2023-07-14 02:32:36,832 epoch [749/800] time: 4.72s train loss: 0.0537 accuracy: 0.9856 f1: 0.9854
2023-07-14 02:32:37,689 epoch [749/800] time: 0.86s val loss: 0.1295 accuracy: 0.9549 f1: 0.9538
2023-07-14 02:32:42,332 epoch [750/800] time: 4.64s train loss: 0.0544 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:32:43,146 epoch [750/800] time: 0.81s val loss: 0.1296 accuracy: 0.9553 f1: 0.954
2023-07-14 02:32:47,894 epoch [751/800] time: 4.75s train loss: 0.0554 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:32:48,743 epoch [751/800] time: 0.85s val loss: 0.1296 accuracy: 0.9553 f1: 0.954
2023-07-14 02:32:54,555 epoch [752/800] time: 5.81s train loss: 0.0545 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:32:55,676 epoch [752/800] time: 1.12s val loss: 0.1296 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:33:00,379 epoch [753/800] time: 4.7s train loss: 0.0549 accuracy: 0.9851 f1: 0.985
2023-07-14 02:33:01,201 epoch [753/800] time: 0.82s val loss: 0.1305 accuracy: 0.9545 f1: 0.9534
2023-07-14 02:33:06,137 epoch [754/800] time: 4.94s train loss: 0.0546 accuracy: 0.9853 f1: 0.9851
2023-07-14 02:33:07,039 epoch [754/800] time: 0.9s val loss: 0.1297 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:33:11,950 epoch [755/800] time: 4.91s train loss: 0.0572 accuracy: 0.9844 f1: 0.9842
2023-07-14 02:33:12,821 epoch [755/800] time: 0.87s val loss: 0.1301 accuracy: 0.955 f1: 0.9538
2023-07-14 02:33:17,692 epoch [756/800] time: 4.87s train loss: 0.0538 accuracy: 0.9856 f1: 0.9855
2023-07-14 02:33:18,518 epoch [756/800] time: 0.83s val loss: 0.1301 accuracy: 0.9542 f1: 0.9529
2023-07-14 02:33:23,343 epoch [757/800] time: 4.82s train loss: 0.0551 accuracy: 0.9852 f1: 0.985
2023-07-14 02:33:24,203 epoch [757/800] time: 0.86s val loss: 0.1308 accuracy: 0.955 f1: 0.9537
2023-07-14 02:33:29,017 epoch [758/800] time: 4.81s train loss: 0.0553 accuracy: 0.985 f1: 0.9847
2023-07-14 02:33:29,887 epoch [758/800] time: 0.87s val loss: 0.1307 accuracy: 0.9545 f1: 0.9534
2023-07-14 02:33:34,742 epoch [759/800] time: 4.85s train loss: 0.0562 accuracy: 0.9853 f1: 0.9852
2023-07-14 02:33:35,548 epoch [759/800] time: 0.81s val loss: 0.1305 accuracy: 0.9541 f1: 0.9528
2023-07-14 02:33:40,419 epoch [760/800] time: 4.87s train loss: 0.0542 accuracy: 0.9851 f1: 0.985
2023-07-14 02:33:41,279 epoch [760/800] time: 0.86s val loss: 0.1297 accuracy: 0.9543 f1: 0.9531
2023-07-14 02:33:46,089 epoch [761/800] time: 4.81s train loss: 0.0549 accuracy: 0.9855 f1: 0.9853
2023-07-14 02:33:46,942 epoch [761/800] time: 0.85s val loss: 0.1315 accuracy: 0.9546 f1: 0.9532
2023-07-14 02:33:51,799 epoch [762/800] time: 4.86s train loss: 0.0557 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:33:52,619 epoch [762/800] time: 0.82s val loss: 0.1293 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:33:57,452 epoch [763/800] time: 4.83s train loss: 0.0562 accuracy: 0.9845 f1: 0.9844
2023-07-14 02:33:58,313 epoch [763/800] time: 0.86s val loss: 0.1306 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:34:03,200 epoch [764/800] time: 4.89s train loss: 0.0559 accuracy: 0.9844 f1: 0.9843
2023-07-14 02:34:04,060 epoch [764/800] time: 0.86s val loss: 0.1289 accuracy: 0.955 f1: 0.9539
2023-07-14 02:34:08,921 epoch [765/800] time: 4.86s train loss: 0.055 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:34:09,731 epoch [765/800] time: 0.81s val loss: 0.13 accuracy: 0.9543 f1: 0.953
2023-07-14 02:34:14,625 epoch [766/800] time: 4.89s train loss: 0.0545 accuracy: 0.985 f1: 0.9848
2023-07-14 02:34:15,480 epoch [766/800] time: 0.85s val loss: 0.1293 accuracy: 0.9551 f1: 0.9538
2023-07-14 02:34:20,225 epoch [767/800] time: 4.74s train loss: 0.0561 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:34:21,077 epoch [767/800] time: 0.85s val loss: 0.1303 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:34:25,892 epoch [768/800] time: 4.81s train loss: 0.055 accuracy: 0.985 f1: 0.9849
2023-07-14 02:34:26,696 epoch [768/800] time: 0.8s val loss: 0.1298 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:34:31,273 epoch [769/800] time: 4.58s train loss: 0.0545 accuracy: 0.985 f1: 0.9848
2023-07-14 02:34:32,139 epoch [769/800] time: 0.87s val loss: 0.129 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:34:36,717 epoch [770/800] time: 4.58s train loss: 0.0543 accuracy: 0.985 f1: 0.9849
2023-07-14 02:34:37,566 epoch [770/800] time: 0.85s val loss: 0.1296 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:34:42,468 epoch [771/800] time: 4.9s train loss: 0.0554 accuracy: 0.9851 f1: 0.985
2023-07-14 02:34:43,284 epoch [771/800] time: 0.82s val loss: 0.1298 accuracy: 0.9552 f1: 0.9539
2023-07-14 02:34:48,167 epoch [772/800] time: 4.88s train loss: 0.0551 accuracy: 0.9851 f1: 0.985
2023-07-14 02:34:49,038 epoch [772/800] time: 0.87s val loss: 0.1292 accuracy: 0.9547 f1: 0.9536
2023-07-14 02:34:53,929 epoch [773/800] time: 4.89s train loss: 0.0551 accuracy: 0.9851 f1: 0.985
2023-07-14 02:34:54,778 epoch [773/800] time: 0.85s val loss: 0.1315 accuracy: 0.9544 f1: 0.9531
2023-07-14 02:34:59,513 epoch [774/800] time: 4.74s train loss: 0.0549 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:35:00,314 epoch [774/800] time: 0.8s val loss: 0.1293 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:35:05,031 epoch [775/800] time: 4.72s train loss: 0.0558 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:35:05,883 epoch [775/800] time: 0.85s val loss: 0.1306 accuracy: 0.9545 f1: 0.9531
2023-07-14 02:35:10,632 epoch [776/800] time: 4.75s train loss: 0.0555 accuracy: 0.9845 f1: 0.9843
2023-07-14 02:35:11,503 epoch [776/800] time: 0.87s val loss: 0.1298 accuracy: 0.9545 f1: 0.9532
2023-07-14 02:35:17,341 epoch [777/800] time: 5.84s train loss: 0.0555 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:35:18,147 epoch [777/800] time: 0.81s val loss: 0.1303 accuracy: 0.9543 f1: 0.953
2023-07-14 02:35:23,005 epoch [778/800] time: 4.86s train loss: 0.0556 accuracy: 0.985 f1: 0.9848
2023-07-14 02:35:23,851 epoch [778/800] time: 0.85s val loss: 0.1296 accuracy: 0.9548 f1: 0.9536
2023-07-14 02:35:28,683 epoch [779/800] time: 4.83s train loss: 0.0555 accuracy: 0.9851 f1: 0.9848
2023-07-14 02:35:29,530 epoch [779/800] time: 0.85s val loss: 0.1299 accuracy: 0.9543 f1: 0.9531
2023-07-14 02:35:34,378 epoch [780/800] time: 4.85s train loss: 0.0543 accuracy: 0.9857 f1: 0.9855
2023-07-14 02:35:35,180 epoch [780/800] time: 0.8s val loss: 0.1298 accuracy: 0.9543 f1: 0.9532
2023-07-14 02:35:39,998 epoch [781/800] time: 4.82s train loss: 0.0563 accuracy: 0.9842 f1: 0.984
2023-07-14 02:35:40,844 epoch [781/800] time: 0.85s val loss: 0.1304 accuracy: 0.9547 f1: 0.9534
2023-07-14 02:35:45,544 epoch [782/800] time: 4.7s train loss: 0.0557 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:35:46,391 epoch [782/800] time: 0.85s val loss: 0.1294 accuracy: 0.9545 f1: 0.9533
2023-07-14 02:35:51,187 epoch [783/800] time: 4.8s train loss: 0.0555 accuracy: 0.9846 f1: 0.9844
2023-07-14 02:35:51,988 epoch [783/800] time: 0.8s val loss: 0.1291 accuracy: 0.9545 f1: 0.9533
2023-07-14 02:35:56,723 epoch [784/800] time: 4.73s train loss: 0.0554 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:35:57,584 epoch [784/800] time: 0.86s val loss: 0.1301 accuracy: 0.9553 f1: 0.9541
2023-07-14 02:36:02,321 epoch [785/800] time: 4.74s train loss: 0.0559 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:36:03,167 epoch [785/800] time: 0.85s val loss: 0.1297 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:36:07,859 epoch [786/800] time: 4.69s train loss: 0.055 accuracy: 0.9852 f1: 0.985
2023-07-14 02:36:08,663 epoch [786/800] time: 0.8s val loss: 0.1299 accuracy: 0.9543 f1: 0.953
2023-07-14 02:36:13,387 epoch [787/800] time: 4.72s train loss: 0.0558 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:36:14,234 epoch [787/800] time: 0.85s val loss: 0.1298 accuracy: 0.9547 f1: 0.9534
2023-07-14 02:36:19,119 epoch [788/800] time: 4.89s train loss: 0.0564 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:36:19,967 epoch [788/800] time: 0.85s val loss: 0.1308 accuracy: 0.9543 f1: 0.9531
2023-07-14 02:36:24,783 epoch [789/800] time: 4.82s train loss: 0.0559 accuracy: 0.9841 f1: 0.9839
2023-07-14 02:36:25,620 epoch [789/800] time: 0.84s val loss: 0.1293 accuracy: 0.9547 f1: 0.9535
2023-07-14 02:36:30,563 epoch [790/800] time: 4.94s train loss: 0.0556 accuracy: 0.9844 f1: 0.9843
2023-07-14 02:36:31,465 epoch [790/800] time: 0.9s val loss: 0.1294 accuracy: 0.9547 f1: 0.9536
2023-07-14 02:36:36,241 epoch [791/800] time: 4.78s train loss: 0.0552 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:36:37,088 epoch [791/800] time: 0.85s val loss: 0.1301 accuracy: 0.9545 f1: 0.9532
2023-07-14 02:36:41,897 epoch [792/800] time: 4.81s train loss: 0.0551 accuracy: 0.9848 f1: 0.9846
2023-07-14 02:36:42,707 epoch [792/800] time: 0.81s val loss: 0.13 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:36:47,678 epoch [793/800] time: 4.97s train loss: 0.0568 accuracy: 0.9843 f1: 0.9842
2023-07-14 02:36:48,537 epoch [793/800] time: 0.86s val loss: 0.1298 accuracy: 0.9545 f1: 0.9533
2023-07-14 02:36:53,397 epoch [794/800] time: 4.86s train loss: 0.0555 accuracy: 0.9849 f1: 0.9848
2023-07-14 02:36:54,325 epoch [794/800] time: 0.93s val loss: 0.1302 accuracy: 0.9548 f1: 0.9535
2023-07-14 02:36:59,279 epoch [795/800] time: 4.95s train loss: 0.0576 accuracy: 0.9845 f1: 0.9844
2023-07-14 02:37:00,099 epoch [795/800] time: 0.82s val loss: 0.1329 accuracy: 0.9536 f1: 0.9523
2023-07-14 02:37:05,030 epoch [796/800] time: 4.93s train loss: 0.0556 accuracy: 0.9851 f1: 0.985
2023-07-14 02:37:05,948 epoch [796/800] time: 0.92s val loss: 0.1295 accuracy: 0.9547 f1: 0.9534
2023-07-14 02:37:10,745 epoch [797/800] time: 4.8s train loss: 0.0546 accuracy: 0.9847 f1: 0.9845
2023-07-14 02:37:11,627 epoch [797/800] time: 0.88s val loss: 0.1306 accuracy: 0.9546 f1: 0.9533
2023-07-14 02:37:16,498 epoch [798/800] time: 4.87s train loss: 0.0557 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:37:17,323 epoch [798/800] time: 0.83s val loss: 0.13 accuracy: 0.9551 f1: 0.9538
2023-07-14 02:37:22,110 epoch [799/800] time: 4.79s train loss: 0.0565 accuracy: 0.9849 f1: 0.9847
2023-07-14 02:37:22,963 epoch [799/800] time: 0.85s val loss: 0.1309 accuracy: 0.9546 f1: 0.9534
2023-07-14 02:37:27,776 epoch [800/800] time: 4.81s train loss: 0.0553 accuracy: 0.9847 f1: 0.9846
2023-07-14 02:37:28,622 epoch [800/800] time: 0.85s val loss: 0.1293 accuracy: 0.9552 f1: 0.9539
2023-07-14 02:37:28,638 The model with best acc is saved: epoch 400, acc 0.98579375
2023-07-14 02:37:28,653 The model with best f1 is saved: epoch 400, f1 0.9856291279279639
2023-07-14 02:37:28,733 =======================================================
2023-07-14 02:37:28,733 Best acc classification report:
               precision    recall  f1-score   support

cluster_00205    0.90909   0.89286   0.90090       224
cluster_00222    0.94512   0.90116   0.92262       172
cluster_00232    0.89474   0.85000   0.87179       220
cluster_00246    0.83598   0.84492   0.84043       187
cluster_00259    0.91329   0.87778   0.89518       180
cluster_00261    0.92029   0.91367   0.91697       139
cluster_00262    0.95028   0.80000   0.86869       215
cluster_00267    0.98990   0.81667   0.89498       360
cluster_00275    0.93537   0.89286   0.91362       308
cluster_00276    0.90000   0.84906   0.87379       159
cluster_00278    0.89157   0.85057   0.87059       174
cluster_00287    0.89080   0.89595   0.89337       173
cluster_00291    0.95858   0.90503   0.93103       179
cluster_00293    0.89145   0.94097   0.91554       288
cluster_00294    0.95890   0.84337   0.89744        83
cluster_00296    0.95973   0.88820   0.92258       161
cluster_00298    0.93706   0.79762   0.86174       336
cluster_00299    0.73723   0.90991   0.81452       111
cluster_00300    0.84135   0.88384   0.86207       198
cluster_00303    0.98851   0.87310   0.92722       197
cluster_00304    0.93671   0.92500   0.93082       160
cluster_00319    0.88210   0.95735   0.91818       211
cluster_00322    0.85366   0.96552   0.90615       290
cluster_00333    0.79870   0.93893   0.86316       131
cluster_00338    0.82967   0.88824   0.85795       170
cluster_00340    0.82609   0.98958   0.90047       192
cluster_00344    0.71585   0.90345   0.79878       145
cluster_00346    0.94231   0.80992   0.87111       242
cluster_00350    0.94882   0.83972   0.89094       287
cluster_00352    0.87302   0.75862   0.81181       145
cluster_00359    0.80556   0.90625   0.85294       192
cluster_00360    0.88106   0.93458   0.90703       214
cluster_00361    0.80000   0.92903   0.85970       155
cluster_00365    0.89474   0.90909   0.90186       187
cluster_00368    0.89062   0.87692   0.88372       195
cluster_00373    0.83684   0.86885   0.85255       183
cluster_00374    0.88843   0.94714   0.91684       227
cluster_00375    0.82156   0.89474   0.85659       247
cluster_00377    0.90984   0.87059   0.88978       255
cluster_00380    0.85437   0.97238   0.90956       181
cluster_00385    0.84921   0.90678   0.87705       236
cluster_00388    0.93117   0.84559   0.88632       272
cluster_00389    0.91542   0.85581   0.88462       215
cluster_00390    0.92683   0.90047   0.91346       211
cluster_00394    0.90541   0.86452   0.88449       155
cluster_00400    0.94340   0.86207   0.90090       116
cluster_00401    0.97101   0.81212   0.88449       165
cluster_00405    0.87222   0.95732   0.91279       164
cluster_00407    0.94981   0.92135   0.93536       267
cluster_00408    0.80258   0.85780   0.82927       218
cluster_00409    0.94884   0.80000   0.86809       255
cluster_00412    0.88760   0.96624   0.92525       237
cluster_00445    0.90000   0.77953   0.83544       127
cluster_00473    0.92000   0.92000   0.92000       125
cluster_00585    0.86726   0.91163   0.88889       215
cluster_00589    0.83108   0.84247   0.83673       146
cluster_00591    0.89831   0.77941   0.83465       204
cluster_00593    0.91200   0.69939   0.79167       163
cluster_00596    0.79832   0.74219   0.76923       128
cluster_00603    0.87368   0.89247   0.88298       186
cluster_00604    0.99324   0.98000   0.98658       150
cluster_00607    0.88764   0.77833   0.82940       203
cluster_00612    0.90678   0.96833   0.93654       221
cluster_00616    0.72555   0.96234   0.82734       239
cluster_00619    0.87719   0.81967   0.84746       183
cluster_00629    0.91827   0.92271   0.92048       207
cluster_00630    0.94444   0.85780   0.89904       218
cluster_00635    0.86842   0.82090   0.84399       201
cluster_00637    0.83621   0.93720   0.88383       207
cluster_00639    0.82061   0.93074   0.87221       231
cluster_00642    0.96296   0.84211   0.89849       247
cluster_00645    0.73516   0.83854   0.78345       192
cluster_00647    0.75943   0.89444   0.82143       180
cluster_00652    0.81500   0.76526   0.78935       213
cluster_00653    0.96129   0.93711   0.94904       159
cluster_00656    0.98013   0.88095   0.92790       168
cluster_00657    0.88755   0.95671   0.92083       231
cluster_00661    0.93785   0.92222   0.92997       180
cluster_00662    0.85563   0.89668   0.87568       271
cluster_00667    0.88038   0.89756   0.88889       205
cluster_00762    0.91228   0.88636   0.89914       176
cluster_00201    0.99043   1.00000   0.99519       207
cluster_00217    0.92398   0.88268   0.90286       179
cluster_00239    0.92825   0.95392   0.94091       217
cluster_00320    0.91954   0.86957   0.89385       184
cluster_00391    0.92115   0.94485   0.93285       272
cluster_00398    0.90734   0.97107   0.93812       242
cluster_00415    0.84536   0.96471   0.90110       170
cluster_00477    0.79200   0.98507   0.87805       201
cluster_00478    0.91824   0.82486   0.86905       177
cluster_00479    0.98519   0.85806   0.91724       155
cluster_00078    0.91051   0.89313   0.90173       262
cluster_00079    0.75424   0.92228   0.82984       193
cluster_00083    0.82899   0.97279   0.89515       294
cluster_00090    0.88571   0.73228   0.80172       127
cluster_00094    0.92500   0.74497   0.82528       149
cluster_00096    0.84138   0.99187   0.91045       123
cluster_00101    0.98165   0.81679   0.89167       131
cluster_00086    0.89789   0.93407   0.91562       273
cluster_00095    0.85281   0.94258   0.89545       209
cluster_00097    0.83740   0.94495   0.88793       109
cluster_00106    0.97786   0.89527   0.93474       296
cluster_00553    0.95628   0.90674   0.93085       193
cluster_00554    0.92620   0.89007   0.90778       282
cluster_00569    0.88832   0.84951   0.86849       206
cluster_00015    0.94872   0.79570   0.86550        93
cluster_00017    0.81315   0.83333   0.82312       282
cluster_00018    0.63755   0.98649   0.77454       148
cluster_00023    0.72727   0.86957   0.79208       230
cluster_00025    0.92568   0.83030   0.87540       165
cluster_00030    0.79920   0.91705   0.85408       217
cluster_00035    0.81657   0.90789   0.85981       152
cluster_00039    0.74439   0.94857   0.83417       175
cluster_00042    0.90857   0.87845   0.89326       181
cluster_00046    0.93243   0.62443   0.74797       221
cluster_00055    0.91667   0.79006   0.84866       181
cluster_00059    0.83871   0.91919   0.87711       198
cluster_00061    0.91795   0.92746   0.92268       193
cluster_00274    0.99363   0.81250   0.89398       192
cluster_00308    0.81166   0.90955   0.85782       199
cluster_00337    0.90594   0.91500   0.91045       200
cluster_00362    0.79167   0.90957   0.84653       188
cluster_00369    0.96774   0.94488   0.95618       127
cluster_00392    0.95610   0.88288   0.91803       222
cluster_00414    1.00000   0.86486   0.92754       111
cluster_00419    0.85232   0.91818   0.88403       220
cluster_00420    0.87619   0.89756   0.88675       205
cluster_00421    0.98230   0.82836   0.89879       134
cluster_00422    0.85321   0.81938   0.83596       227
cluster_00427    0.90756   0.69231   0.78545       156
cluster_00430    0.78346   0.81557   0.79920       244
cluster_00431    0.84669   0.91353   0.87884       266
cluster_00436    0.89706   0.95312   0.92424       192
cluster_00439    0.95473   0.80836   0.87547       287
cluster_00444    0.97573   0.98529   0.98049       204
cluster_00447    0.79021   0.83704   0.81295       135
cluster_00448    0.78512   0.94059   0.85586       202
cluster_00450    0.80756   0.92157   0.86081       255
cluster_00456    0.87500   0.83803   0.85612       142
cluster_00458    0.83681   0.90943   0.87161       265
cluster_00460    0.99219   0.69022   0.81410       184
cluster_00463    0.86466   0.81560   0.83942       141
cluster_00467    0.95890   0.90323   0.93023       155
cluster_00483    0.93077   0.81208   0.86738       149
cluster_00484    0.85926   0.91339   0.88550       127
cluster_00007    0.94737   0.85207   0.89720       169
cluster_00036    0.84411   0.90984   0.87574       244
cluster_00054    0.97273   0.90678   0.93860       118
cluster_00062    0.79061   0.92405   0.85214       237
cluster_00064    0.90187   0.91905   0.91038       210
cluster_00065    0.98810   0.88770   0.93521       187
cluster_00067    0.92208   0.82081   0.86850       173
cluster_00071    0.94681   0.69531   0.80180       128
cluster_00075    0.83732   0.83333   0.83532       210
cluster_00084    0.94208   0.88087   0.91045       277
cluster_00093    0.92891   0.89091   0.90951       220
cluster_00001    0.87365   0.91321   0.89299       265
cluster_00002    0.84021   0.85340   0.84675       191
cluster_00003    0.90706   0.85315   0.87928       286
cluster_00006    0.95337   0.87204   0.91089       211
cluster_00008    0.91882   0.84122   0.87831       296
cluster_00010    0.91163   0.83404   0.87111       235
cluster_00012    0.84656   0.88398   0.86486       181
cluster_00019    0.87826   0.85593   0.86695       118
cluster_00022    0.74661   0.94828   0.83544       174
cluster_00026    0.90854   0.80108   0.85143       186
cluster_00029    0.78838   0.87558   0.82969       217
cluster_00031    0.79758   0.90722   0.84887       291
cluster_00043    0.96642   0.94182   0.95396       275
cluster_00051    0.97093   0.81463   0.88594       205
cluster_00052    0.81793   0.91212   0.86246       330
cluster_00073    0.95122   0.86283   0.90487       226
cluster_00076    0.90377   0.88163   0.89256       245
cluster_00082    0.93431   0.89825   0.91592       285
cluster_00107    0.96354   0.85253   0.90465       217
cluster_00432    0.92000   0.98291   0.95041       234
cluster_00440    0.95259   0.89837   0.92469       246
cluster_00455    0.90341   0.98148   0.94083       162
cluster_00714    0.97778   0.92437   0.95032       238
cluster_00791    0.92715   0.86957   0.89744       161
cluster_00119    0.93750   0.94170   0.93960       223
cluster_00121    0.98913   0.93814   0.96296       194
cluster_00155    0.91246   0.98905   0.94921       274
cluster_00556    0.96209   0.90625   0.93333       224
cluster_00557    0.95205   0.96864   0.96028       287
cluster_00689    0.97551   0.98354   0.97951       243
cluster_00692    0.99550   0.96087   0.97788       230
cluster_00718    0.84018   0.97354   0.90196       189
cluster_00725    0.91011   0.92045   0.91525       176
cluster_00727    0.85475   0.96835   0.90801       158
cluster_00729    0.94382   0.94030   0.94206       268
cluster_00733    1.00000   0.95070   0.97473       142
cluster_00738    0.92208   0.97260   0.94667       146
cluster_00740    0.99275   0.87821   0.93197       156
cluster_00744    0.96476   0.89754   0.92994       244
cluster_00753    0.93450   0.94690   0.94066       226
cluster_00777    0.93596   0.93137   0.93366       204
cluster_00795    0.95506   0.88542   0.91892       192

     accuracy                        0.88835     40000
    macro avg    0.89368   0.88603   0.88686     40000
 weighted avg    0.89435   0.88835   0.88854     40000

2023-07-14 02:37:28,733 =======================================================
2023-07-14 02:37:28,734 

2023-07-14 02:37:28,924 =======================================================
2023-07-14 02:37:28,924 Best f1 classification report:
               precision    recall  f1-score   support

cluster_00205    0.90909   0.89286   0.90090       224
cluster_00222    0.94512   0.90116   0.92262       172
cluster_00232    0.89474   0.85000   0.87179       220
cluster_00246    0.83598   0.84492   0.84043       187
cluster_00259    0.91329   0.87778   0.89518       180
cluster_00261    0.92029   0.91367   0.91697       139
cluster_00262    0.95028   0.80000   0.86869       215
cluster_00267    0.98990   0.81667   0.89498       360
cluster_00275    0.93537   0.89286   0.91362       308
cluster_00276    0.90000   0.84906   0.87379       159
cluster_00278    0.89157   0.85057   0.87059       174
cluster_00287    0.89080   0.89595   0.89337       173
cluster_00291    0.95858   0.90503   0.93103       179
cluster_00293    0.89145   0.94097   0.91554       288
cluster_00294    0.95890   0.84337   0.89744        83
cluster_00296    0.95973   0.88820   0.92258       161
cluster_00298    0.93706   0.79762   0.86174       336
cluster_00299    0.73723   0.90991   0.81452       111
cluster_00300    0.84135   0.88384   0.86207       198
cluster_00303    0.98851   0.87310   0.92722       197
cluster_00304    0.93671   0.92500   0.93082       160
cluster_00319    0.88210   0.95735   0.91818       211
cluster_00322    0.85366   0.96552   0.90615       290
cluster_00333    0.79870   0.93893   0.86316       131
cluster_00338    0.82967   0.88824   0.85795       170
cluster_00340    0.82609   0.98958   0.90047       192
cluster_00344    0.71585   0.90345   0.79878       145
cluster_00346    0.94231   0.80992   0.87111       242
cluster_00350    0.94882   0.83972   0.89094       287
cluster_00352    0.87302   0.75862   0.81181       145
cluster_00359    0.80556   0.90625   0.85294       192
cluster_00360    0.88106   0.93458   0.90703       214
cluster_00361    0.80000   0.92903   0.85970       155
cluster_00365    0.89474   0.90909   0.90186       187
cluster_00368    0.89062   0.87692   0.88372       195
cluster_00373    0.83684   0.86885   0.85255       183
cluster_00374    0.88843   0.94714   0.91684       227
cluster_00375    0.82156   0.89474   0.85659       247
cluster_00377    0.90984   0.87059   0.88978       255
cluster_00380    0.85437   0.97238   0.90956       181
cluster_00385    0.84921   0.90678   0.87705       236
cluster_00388    0.93117   0.84559   0.88632       272
cluster_00389    0.91542   0.85581   0.88462       215
cluster_00390    0.92683   0.90047   0.91346       211
cluster_00394    0.90541   0.86452   0.88449       155
cluster_00400    0.94340   0.86207   0.90090       116
cluster_00401    0.97101   0.81212   0.88449       165
cluster_00405    0.87222   0.95732   0.91279       164
cluster_00407    0.94981   0.92135   0.93536       267
cluster_00408    0.80258   0.85780   0.82927       218
cluster_00409    0.94884   0.80000   0.86809       255
cluster_00412    0.88760   0.96624   0.92525       237
cluster_00445    0.90000   0.77953   0.83544       127
cluster_00473    0.92000   0.92000   0.92000       125
cluster_00585    0.86726   0.91163   0.88889       215
cluster_00589    0.83108   0.84247   0.83673       146
cluster_00591    0.89831   0.77941   0.83465       204
cluster_00593    0.91200   0.69939   0.79167       163
cluster_00596    0.79832   0.74219   0.76923       128
cluster_00603    0.87368   0.89247   0.88298       186
cluster_00604    0.99324   0.98000   0.98658       150
cluster_00607    0.88764   0.77833   0.82940       203
cluster_00612    0.90678   0.96833   0.93654       221
cluster_00616    0.72555   0.96234   0.82734       239
cluster_00619    0.87719   0.81967   0.84746       183
cluster_00629    0.91827   0.92271   0.92048       207
cluster_00630    0.94444   0.85780   0.89904       218
cluster_00635    0.86842   0.82090   0.84399       201
cluster_00637    0.83621   0.93720   0.88383       207
cluster_00639    0.82061   0.93074   0.87221       231
cluster_00642    0.96296   0.84211   0.89849       247
cluster_00645    0.73516   0.83854   0.78345       192
cluster_00647    0.75943   0.89444   0.82143       180
cluster_00652    0.81500   0.76526   0.78935       213
cluster_00653    0.96129   0.93711   0.94904       159
cluster_00656    0.98013   0.88095   0.92790       168
cluster_00657    0.88755   0.95671   0.92083       231
cluster_00661    0.93785   0.92222   0.92997       180
cluster_00662    0.85563   0.89668   0.87568       271
cluster_00667    0.88038   0.89756   0.88889       205
cluster_00762    0.91228   0.88636   0.89914       176
cluster_00201    0.99043   1.00000   0.99519       207
cluster_00217    0.92398   0.88268   0.90286       179
cluster_00239    0.92825   0.95392   0.94091       217
cluster_00320    0.91954   0.86957   0.89385       184
cluster_00391    0.92115   0.94485   0.93285       272
cluster_00398    0.90734   0.97107   0.93812       242
cluster_00415    0.84536   0.96471   0.90110       170
cluster_00477    0.79200   0.98507   0.87805       201
cluster_00478    0.91824   0.82486   0.86905       177
cluster_00479    0.98519   0.85806   0.91724       155
cluster_00078    0.91051   0.89313   0.90173       262
cluster_00079    0.75424   0.92228   0.82984       193
cluster_00083    0.82899   0.97279   0.89515       294
cluster_00090    0.88571   0.73228   0.80172       127
cluster_00094    0.92500   0.74497   0.82528       149
cluster_00096    0.84138   0.99187   0.91045       123
cluster_00101    0.98165   0.81679   0.89167       131
cluster_00086    0.89789   0.93407   0.91562       273
cluster_00095    0.85281   0.94258   0.89545       209
cluster_00097    0.83740   0.94495   0.88793       109
cluster_00106    0.97786   0.89527   0.93474       296
cluster_00553    0.95628   0.90674   0.93085       193
cluster_00554    0.92620   0.89007   0.90778       282
cluster_00569    0.88832   0.84951   0.86849       206
cluster_00015    0.94872   0.79570   0.86550        93
cluster_00017    0.81315   0.83333   0.82312       282
cluster_00018    0.63755   0.98649   0.77454       148
cluster_00023    0.72727   0.86957   0.79208       230
cluster_00025    0.92568   0.83030   0.87540       165
cluster_00030    0.79920   0.91705   0.85408       217
cluster_00035    0.81657   0.90789   0.85981       152
cluster_00039    0.74439   0.94857   0.83417       175
cluster_00042    0.90857   0.87845   0.89326       181
cluster_00046    0.93243   0.62443   0.74797       221
cluster_00055    0.91667   0.79006   0.84866       181
cluster_00059    0.83871   0.91919   0.87711       198
cluster_00061    0.91795   0.92746   0.92268       193
cluster_00274    0.99363   0.81250   0.89398       192
cluster_00308    0.81166   0.90955   0.85782       199
cluster_00337    0.90594   0.91500   0.91045       200
cluster_00362    0.79167   0.90957   0.84653       188
cluster_00369    0.96774   0.94488   0.95618       127
cluster_00392    0.95610   0.88288   0.91803       222
cluster_00414    1.00000   0.86486   0.92754       111
cluster_00419    0.85232   0.91818   0.88403       220
cluster_00420    0.87619   0.89756   0.88675       205
cluster_00421    0.98230   0.82836   0.89879       134
cluster_00422    0.85321   0.81938   0.83596       227
cluster_00427    0.90756   0.69231   0.78545       156
cluster_00430    0.78346   0.81557   0.79920       244
cluster_00431    0.84669   0.91353   0.87884       266
cluster_00436    0.89706   0.95312   0.92424       192
cluster_00439    0.95473   0.80836   0.87547       287
cluster_00444    0.97573   0.98529   0.98049       204
cluster_00447    0.79021   0.83704   0.81295       135
cluster_00448    0.78512   0.94059   0.85586       202
cluster_00450    0.80756   0.92157   0.86081       255
cluster_00456    0.87500   0.83803   0.85612       142
cluster_00458    0.83681   0.90943   0.87161       265
cluster_00460    0.99219   0.69022   0.81410       184
cluster_00463    0.86466   0.81560   0.83942       141
cluster_00467    0.95890   0.90323   0.93023       155
cluster_00483    0.93077   0.81208   0.86738       149
cluster_00484    0.85926   0.91339   0.88550       127
cluster_00007    0.94737   0.85207   0.89720       169
cluster_00036    0.84411   0.90984   0.87574       244
cluster_00054    0.97273   0.90678   0.93860       118
cluster_00062    0.79061   0.92405   0.85214       237
cluster_00064    0.90187   0.91905   0.91038       210
cluster_00065    0.98810   0.88770   0.93521       187
cluster_00067    0.92208   0.82081   0.86850       173
cluster_00071    0.94681   0.69531   0.80180       128
cluster_00075    0.83732   0.83333   0.83532       210
cluster_00084    0.94208   0.88087   0.91045       277
cluster_00093    0.92891   0.89091   0.90951       220
cluster_00001    0.87365   0.91321   0.89299       265
cluster_00002    0.84021   0.85340   0.84675       191
cluster_00003    0.90706   0.85315   0.87928       286
cluster_00006    0.95337   0.87204   0.91089       211
cluster_00008    0.91882   0.84122   0.87831       296
cluster_00010    0.91163   0.83404   0.87111       235
cluster_00012    0.84656   0.88398   0.86486       181
cluster_00019    0.87826   0.85593   0.86695       118
cluster_00022    0.74661   0.94828   0.83544       174
cluster_00026    0.90854   0.80108   0.85143       186
cluster_00029    0.78838   0.87558   0.82969       217
cluster_00031    0.79758   0.90722   0.84887       291
cluster_00043    0.96642   0.94182   0.95396       275
cluster_00051    0.97093   0.81463   0.88594       205
cluster_00052    0.81793   0.91212   0.86246       330
cluster_00073    0.95122   0.86283   0.90487       226
cluster_00076    0.90377   0.88163   0.89256       245
cluster_00082    0.93431   0.89825   0.91592       285
cluster_00107    0.96354   0.85253   0.90465       217
cluster_00432    0.92000   0.98291   0.95041       234
cluster_00440    0.95259   0.89837   0.92469       246
cluster_00455    0.90341   0.98148   0.94083       162
cluster_00714    0.97778   0.92437   0.95032       238
cluster_00791    0.92715   0.86957   0.89744       161
cluster_00119    0.93750   0.94170   0.93960       223
cluster_00121    0.98913   0.93814   0.96296       194
cluster_00155    0.91246   0.98905   0.94921       274
cluster_00556    0.96209   0.90625   0.93333       224
cluster_00557    0.95205   0.96864   0.96028       287
cluster_00689    0.97551   0.98354   0.97951       243
cluster_00692    0.99550   0.96087   0.97788       230
cluster_00718    0.84018   0.97354   0.90196       189
cluster_00725    0.91011   0.92045   0.91525       176
cluster_00727    0.85475   0.96835   0.90801       158
cluster_00729    0.94382   0.94030   0.94206       268
cluster_00733    1.00000   0.95070   0.97473       142
cluster_00738    0.92208   0.97260   0.94667       146
cluster_00740    0.99275   0.87821   0.93197       156
cluster_00744    0.96476   0.89754   0.92994       244
cluster_00753    0.93450   0.94690   0.94066       226
cluster_00777    0.93596   0.93137   0.93366       204
cluster_00795    0.95506   0.88542   0.91892       192

     accuracy                        0.88835     40000
    macro avg    0.89368   0.88603   0.88686     40000
 weighted avg    0.89435   0.88835   0.88854     40000

2023-07-14 02:37:28,924 =======================================================
2023-07-14 02:37:28,924 

2023-07-14 02:37:29,641 =======================================================
2023-07-14 02:37:29,641 Best acc classification report:
               precision    recall  f1-score   support

cluster_00205    0.99344   0.98911   0.99127       918
cluster_00222    0.99538   0.99232   0.99385       651
cluster_00232    0.98161   0.97961   0.98061       981
cluster_00246    0.97507   0.97642   0.97574       721
cluster_00259    0.98136   0.98794   0.98464       746
cluster_00261    0.99476   0.98957   0.99215       575
cluster_00262    0.98265   0.97840   0.98052       926
cluster_00267    0.98393   0.98971   0.98681      1361
cluster_00275    0.97172   0.98267   0.97717      1154
cluster_00276    0.98226   0.97596   0.97910       624
cluster_00278    0.98281   0.98140   0.98210       699
cluster_00287    0.98507   0.98507   0.98507       670
cluster_00291    0.98555   0.98984   0.98769       689
cluster_00293    0.98414   0.98598   0.98506      1070
cluster_00294    0.98465   0.98465   0.98465       456
cluster_00296    0.99452   0.99452   0.99452       730
cluster_00298    0.98195   0.98349   0.98272      1272
cluster_00299    0.97988   0.98185   0.98087       496
cluster_00300    0.96575   0.97436   0.97003       897
cluster_00303    0.98161   0.98440   0.98300       705
cluster_00304    0.99326   0.99326   0.99326       742
cluster_00319    0.98824   0.98131   0.98476       856
cluster_00322    0.98714   0.98376   0.98545      1170
cluster_00333    0.97348   0.97533   0.97441       527
cluster_00338    0.97428   0.97576   0.97502       660
cluster_00340    0.98946   0.98170   0.98556       765
cluster_00344    0.96303   0.96954   0.96627       591
cluster_00346    0.98605   0.98711   0.98658       931
cluster_00350    0.98281   0.98281   0.98281      1105
cluster_00352    0.97917   0.97578   0.97747       578
cluster_00359    0.97801   0.97297   0.97548       777
cluster_00360    0.98741   0.98616   0.98678       795
cluster_00361    0.97991   0.95915   0.96942       661
cluster_00365    0.99149   0.98313   0.98730       830
cluster_00368    0.99283   0.98577   0.98929       843
cluster_00373    0.97487   0.97745   0.97616       754
cluster_00374    0.98678   0.98462   0.98570       910
cluster_00375    0.98164   0.97786   0.97975      1039
cluster_00377    0.97217   0.98589   0.97898       992
cluster_00380    0.98613   0.99025   0.98819       718
cluster_00385    0.98835   0.98739   0.98787      1031
cluster_00388    0.98564   0.97657   0.98108      1195
cluster_00389    0.96547   0.96178   0.96362       785
cluster_00390    0.99213   0.99549   0.99381       887
cluster_00394    0.98137   0.98289   0.98213       643
cluster_00400    0.98866   0.99091   0.98978       440
cluster_00401    0.98538   0.98251   0.98394       686
cluster_00405    0.97205   0.97054   0.97130       645
cluster_00407    0.99029   0.99029   0.99029      1030
cluster_00408    0.96752   0.96977   0.96864       860
cluster_00409    0.98026   0.97068   0.97545       921
cluster_00412    0.98008   0.99047   0.98525       944
cluster_00445    0.96395   0.96578   0.96486       526
cluster_00473    0.98301   0.97679   0.97989       474
cluster_00585    0.97424   0.97998   0.97710       849
cluster_00589    0.98625   0.98966   0.98795       580
cluster_00591    0.99607   0.98448   0.99024       773
cluster_00593    0.97445   0.97611   0.97528       586
cluster_00596    0.97683   0.98561   0.98120       556
cluster_00603    0.98483   0.99443   0.98960       718
cluster_00604    0.98642   0.99147   0.98894       586
cluster_00607    0.98371   0.98494   0.98433       797
cluster_00612    0.99004   0.99004   0.99004       803
cluster_00616    0.98319   0.98319   0.98319       952
cluster_00619    0.98263   0.97418   0.97839       697
cluster_00629    0.99096   0.99208   0.99152       884
cluster_00630    0.98524   0.98042   0.98282       817
cluster_00635    0.98836   0.99092   0.98964       771
cluster_00637    0.97255   0.97255   0.97255       765
cluster_00639    0.98994   0.99194   0.99094       992
cluster_00642    0.98844   0.98844   0.98844       865
cluster_00645    0.97685   0.98253   0.97968       687
cluster_00647    0.96894   0.97744   0.97318       798
cluster_00652    0.98326   0.97889   0.98107       900
cluster_00653    0.98565   0.99197   0.98880       623
cluster_00656    0.98322   0.98322   0.98322       715
cluster_00657    0.96791   0.97103   0.96947       932
cluster_00661    0.99020   0.98605   0.98812       717
cluster_00662    0.98873   0.98873   0.98873       976
cluster_00667    0.98570   0.99161   0.98864       834
cluster_00762    0.99079   0.99209   0.99144       759
cluster_00201    1.00000   1.00000   1.00000       840
cluster_00217    0.98738   0.98462   0.98599       715
cluster_00239    0.98993   0.98993   0.98993       894
cluster_00320    0.98569   0.98009   0.98288       703
cluster_00391    0.98374   0.99090   0.98731      1099
cluster_00398    0.99093   0.97811   0.98448      1005
cluster_00415    0.98509   0.98376   0.98443       739
cluster_00477    0.97278   0.98263   0.97768       691
cluster_00478    0.98689   0.98949   0.98819       761
cluster_00479    0.99384   0.98624   0.99002       654
cluster_00078    0.96696   0.97741   0.97215      1018
cluster_00079    0.96095   0.96906   0.96499       711
cluster_00083    0.96316   0.96655   0.96485      1136
cluster_00090    0.97150   0.95785   0.96462       427
cluster_00094    0.95652   0.94867   0.95258       487
cluster_00096    0.98097   0.97890   0.97994       474
cluster_00101    0.98324   0.98876   0.98599       534
cluster_00086    0.99654   0.99568   0.99611      1158
cluster_00095    0.99146   0.99026   0.99086       821
cluster_00097    0.99798   0.99598   0.99698       497
cluster_00106    0.99421   0.99751   0.99585      1204
cluster_00553    0.99294   0.99528   0.99411       848
cluster_00554    0.99321   0.99069   0.99195      1181
cluster_00569    0.99276   0.99037   0.99157       831
cluster_00015    0.99231   0.99231   0.99231       390
cluster_00017    0.97925   0.97832   0.97878      1061
cluster_00018    0.98226   0.97596   0.97910       624
cluster_00023    0.97447   0.97759   0.97603       937
cluster_00025    0.98898   0.98587   0.98742       637
cluster_00030    0.97696   0.97039   0.97367       743
cluster_00035    0.97574   0.98772   0.98169       570
cluster_00039    0.97809   0.98062   0.97935       774
cluster_00042    0.97211   0.98785   0.97992       741
cluster_00046    0.97634   0.98056   0.97845       926
cluster_00055    0.98541   0.98151   0.98345       757
cluster_00059    0.98472   0.98588   0.98530       850
cluster_00061    0.98986   0.99238   0.99112       787
cluster_00274    0.99343   0.98695   0.99018       766
cluster_00308    0.98442   0.97887   0.98164       710
cluster_00337    0.99300   0.99300   0.99300       714
cluster_00362    0.98839   0.99094   0.98966       773
cluster_00369    0.99023   0.99607   0.99314       509
cluster_00392    0.99154   0.99274   0.99214       826
cluster_00414    0.99012   0.99208   0.99110       505
cluster_00419    0.97991   0.98763   0.98375       889
cluster_00420    0.98753   0.98074   0.98413       727
cluster_00421    0.99127   0.99561   0.99344       456
cluster_00422    0.98199   0.98106   0.98153      1056
cluster_00427    0.98374   0.97267   0.97817       622
cluster_00430    0.97194   0.97743   0.97468       886
cluster_00431    0.97206   0.97791   0.97497       996
cluster_00436    0.99611   0.99097   0.99353       775
cluster_00439    0.98936   0.99261   0.99098      1218
cluster_00444    1.00000   0.99748   0.99874       794
cluster_00447    0.98490   0.98490   0.98490       596
cluster_00448    0.99018   0.99630   0.99323       810
cluster_00450    0.98218   0.97160   0.97686      1021
cluster_00456    0.99630   0.99079   0.99354       543
cluster_00458    0.98595   0.98164   0.98379      1144
cluster_00460    0.98175   0.98655   0.98415       818
cluster_00463    0.98673   0.98510   0.98592       604
cluster_00467    0.99669   0.98527   0.99095       611
cluster_00483    0.98747   0.98747   0.98747       479
cluster_00484    0.98614   0.98614   0.98614       577
cluster_00007    0.99538   0.98779   0.99157       655
cluster_00036    0.98346   0.97776   0.98060      1034
cluster_00054    0.99244   0.99057   0.99150       530
cluster_00062    0.96118   0.96414   0.96266       976
cluster_00064    0.98371   0.98052   0.98211       924
cluster_00065    0.99074   0.99601   0.99337       752
cluster_00067    0.98063   0.98410   0.98236       566
cluster_00071    0.97033   0.96528   0.96780       576
cluster_00075    0.97792   0.98117   0.97955       903
cluster_00084    0.98943   0.97816   0.98376      1053
cluster_00093    0.98504   0.98053   0.98278       873
cluster_00001    0.99216   0.98828   0.99022      1024
cluster_00002    0.98308   0.98611   0.98459       648
cluster_00003    0.97991   0.98681   0.98335      1137
cluster_00006    0.99482   0.99870   0.99676       769
cluster_00008    0.99035   0.99122   0.99079      1139
cluster_00010    0.98538   0.99508   0.99021       813
cluster_00012    0.98793   0.98201   0.98496       667
cluster_00019    0.99464   0.99821   0.99642       558
cluster_00022    0.98350   0.98101   0.98226       790
cluster_00026    0.99319   0.98780   0.99049       738
cluster_00029    0.97937   0.98150   0.98043       919
cluster_00031    0.98361   0.98271   0.98316      1099
cluster_00043    0.99910   0.99819   0.99864      1107
cluster_00051    0.99487   0.99615   0.99551       779
cluster_00052    0.98338   0.98267   0.98303      1385
cluster_00073    0.98846   0.98950   0.98898       952
cluster_00076    0.98393   0.98733   0.98562       868
cluster_00082    0.98933   0.98670   0.98802      1128
cluster_00107    0.99220   0.99331   0.99276       897
cluster_00432    0.99903   0.99423   0.99662      1039
cluster_00440    0.99497   0.99598   0.99548       994
cluster_00455    0.99573   0.99431   0.99502       703
cluster_00714    1.00000   0.99885   0.99942       870
cluster_00791    0.99166   0.99442   0.99304       717
cluster_00119    0.99551   0.99663   0.99607       889
cluster_00121    0.99588   0.99862   0.99725       727
cluster_00155    0.99810   0.99621   0.99716      1056
cluster_00556    0.99561   0.99780   0.99670       909
cluster_00557    0.99733   0.99644   0.99689      1125
cluster_00689    0.99892   0.99784   0.99838       928
cluster_00692    1.00000   0.99787   0.99893       938
cluster_00718    0.99887   0.99887   0.99887       885
cluster_00725    0.99858   0.99717   0.99788       707
cluster_00727    0.99141   1.00000   0.99569       577
cluster_00729    0.99652   0.99913   0.99782      1146
cluster_00733    1.00000   1.00000   1.00000       600
cluster_00738    0.99851   1.00000   0.99926       672
cluster_00740    1.00000   0.99518   0.99758       622
cluster_00744    0.99892   0.99676   0.99784       926
cluster_00753    0.99885   0.99657   0.99771       875
cluster_00777    0.99766   0.99766   0.99766       853
cluster_00795    0.99866   0.99866   0.99866       749

     accuracy                        0.98579    160000
    macro avg    0.98568   0.98559   0.98563    160000
 weighted avg    0.98581   0.98579   0.98579    160000

2023-07-14 02:37:29,641 =======================================================
2023-07-14 02:37:29,642 

2023-07-14 02:37:30,994 =======================================================
2023-07-14 02:37:30,994 Best f1 classification report:
               precision    recall  f1-score   support

cluster_00205    0.99344   0.98911   0.99127       918
cluster_00222    0.99538   0.99232   0.99385       651
cluster_00232    0.98161   0.97961   0.98061       981
cluster_00246    0.97507   0.97642   0.97574       721
cluster_00259    0.98136   0.98794   0.98464       746
cluster_00261    0.99476   0.98957   0.99215       575
cluster_00262    0.98265   0.97840   0.98052       926
cluster_00267    0.98393   0.98971   0.98681      1361
cluster_00275    0.97172   0.98267   0.97717      1154
cluster_00276    0.98226   0.97596   0.97910       624
cluster_00278    0.98281   0.98140   0.98210       699
cluster_00287    0.98507   0.98507   0.98507       670
cluster_00291    0.98555   0.98984   0.98769       689
cluster_00293    0.98414   0.98598   0.98506      1070
cluster_00294    0.98465   0.98465   0.98465       456
cluster_00296    0.99452   0.99452   0.99452       730
cluster_00298    0.98195   0.98349   0.98272      1272
cluster_00299    0.97988   0.98185   0.98087       496
cluster_00300    0.96575   0.97436   0.97003       897
cluster_00303    0.98161   0.98440   0.98300       705
cluster_00304    0.99326   0.99326   0.99326       742
cluster_00319    0.98824   0.98131   0.98476       856
cluster_00322    0.98714   0.98376   0.98545      1170
cluster_00333    0.97348   0.97533   0.97441       527
cluster_00338    0.97428   0.97576   0.97502       660
cluster_00340    0.98946   0.98170   0.98556       765
cluster_00344    0.96303   0.96954   0.96627       591
cluster_00346    0.98605   0.98711   0.98658       931
cluster_00350    0.98281   0.98281   0.98281      1105
cluster_00352    0.97917   0.97578   0.97747       578
cluster_00359    0.97801   0.97297   0.97548       777
cluster_00360    0.98741   0.98616   0.98678       795
cluster_00361    0.97991   0.95915   0.96942       661
cluster_00365    0.99149   0.98313   0.98730       830
cluster_00368    0.99283   0.98577   0.98929       843
cluster_00373    0.97487   0.97745   0.97616       754
cluster_00374    0.98678   0.98462   0.98570       910
cluster_00375    0.98164   0.97786   0.97975      1039
cluster_00377    0.97217   0.98589   0.97898       992
cluster_00380    0.98613   0.99025   0.98819       718
cluster_00385    0.98835   0.98739   0.98787      1031
cluster_00388    0.98564   0.97657   0.98108      1195
cluster_00389    0.96547   0.96178   0.96362       785
cluster_00390    0.99213   0.99549   0.99381       887
cluster_00394    0.98137   0.98289   0.98213       643
cluster_00400    0.98866   0.99091   0.98978       440
cluster_00401    0.98538   0.98251   0.98394       686
cluster_00405    0.97205   0.97054   0.97130       645
cluster_00407    0.99029   0.99029   0.99029      1030
cluster_00408    0.96752   0.96977   0.96864       860
cluster_00409    0.98026   0.97068   0.97545       921
cluster_00412    0.98008   0.99047   0.98525       944
cluster_00445    0.96395   0.96578   0.96486       526
cluster_00473    0.98301   0.97679   0.97989       474
cluster_00585    0.97424   0.97998   0.97710       849
cluster_00589    0.98625   0.98966   0.98795       580
cluster_00591    0.99607   0.98448   0.99024       773
cluster_00593    0.97445   0.97611   0.97528       586
cluster_00596    0.97683   0.98561   0.98120       556
cluster_00603    0.98483   0.99443   0.98960       718
cluster_00604    0.98642   0.99147   0.98894       586
cluster_00607    0.98371   0.98494   0.98433       797
cluster_00612    0.99004   0.99004   0.99004       803
cluster_00616    0.98319   0.98319   0.98319       952
cluster_00619    0.98263   0.97418   0.97839       697
cluster_00629    0.99096   0.99208   0.99152       884
cluster_00630    0.98524   0.98042   0.98282       817
cluster_00635    0.98836   0.99092   0.98964       771
cluster_00637    0.97255   0.97255   0.97255       765
cluster_00639    0.98994   0.99194   0.99094       992
cluster_00642    0.98844   0.98844   0.98844       865
cluster_00645    0.97685   0.98253   0.97968       687
cluster_00647    0.96894   0.97744   0.97318       798
cluster_00652    0.98326   0.97889   0.98107       900
cluster_00653    0.98565   0.99197   0.98880       623
cluster_00656    0.98322   0.98322   0.98322       715
cluster_00657    0.96791   0.97103   0.96947       932
cluster_00661    0.99020   0.98605   0.98812       717
cluster_00662    0.98873   0.98873   0.98873       976
cluster_00667    0.98570   0.99161   0.98864       834
cluster_00762    0.99079   0.99209   0.99144       759
cluster_00201    1.00000   1.00000   1.00000       840
cluster_00217    0.98738   0.98462   0.98599       715
cluster_00239    0.98993   0.98993   0.98993       894
cluster_00320    0.98569   0.98009   0.98288       703
cluster_00391    0.98374   0.99090   0.98731      1099
cluster_00398    0.99093   0.97811   0.98448      1005
cluster_00415    0.98509   0.98376   0.98443       739
cluster_00477    0.97278   0.98263   0.97768       691
cluster_00478    0.98689   0.98949   0.98819       761
cluster_00479    0.99384   0.98624   0.99002       654
cluster_00078    0.96696   0.97741   0.97215      1018
cluster_00079    0.96095   0.96906   0.96499       711
cluster_00083    0.96316   0.96655   0.96485      1136
cluster_00090    0.97150   0.95785   0.96462       427
cluster_00094    0.95652   0.94867   0.95258       487
cluster_00096    0.98097   0.97890   0.97994       474
cluster_00101    0.98324   0.98876   0.98599       534
cluster_00086    0.99654   0.99568   0.99611      1158
cluster_00095    0.99146   0.99026   0.99086       821
cluster_00097    0.99798   0.99598   0.99698       497
cluster_00106    0.99421   0.99751   0.99585      1204
cluster_00553    0.99294   0.99528   0.99411       848
cluster_00554    0.99321   0.99069   0.99195      1181
cluster_00569    0.99276   0.99037   0.99157       831
cluster_00015    0.99231   0.99231   0.99231       390
cluster_00017    0.97925   0.97832   0.97878      1061
cluster_00018    0.98226   0.97596   0.97910       624
cluster_00023    0.97447   0.97759   0.97603       937
cluster_00025    0.98898   0.98587   0.98742       637
cluster_00030    0.97696   0.97039   0.97367       743
cluster_00035    0.97574   0.98772   0.98169       570
cluster_00039    0.97809   0.98062   0.97935       774
cluster_00042    0.97211   0.98785   0.97992       741
cluster_00046    0.97634   0.98056   0.97845       926
cluster_00055    0.98541   0.98151   0.98345       757
cluster_00059    0.98472   0.98588   0.98530       850
cluster_00061    0.98986   0.99238   0.99112       787
cluster_00274    0.99343   0.98695   0.99018       766
cluster_00308    0.98442   0.97887   0.98164       710
cluster_00337    0.99300   0.99300   0.99300       714
cluster_00362    0.98839   0.99094   0.98966       773
cluster_00369    0.99023   0.99607   0.99314       509
cluster_00392    0.99154   0.99274   0.99214       826
cluster_00414    0.99012   0.99208   0.99110       505
cluster_00419    0.97991   0.98763   0.98375       889
cluster_00420    0.98753   0.98074   0.98413       727
cluster_00421    0.99127   0.99561   0.99344       456
cluster_00422    0.98199   0.98106   0.98153      1056
cluster_00427    0.98374   0.97267   0.97817       622
cluster_00430    0.97194   0.97743   0.97468       886
cluster_00431    0.97206   0.97791   0.97497       996
cluster_00436    0.99611   0.99097   0.99353       775
cluster_00439    0.98936   0.99261   0.99098      1218
cluster_00444    1.00000   0.99748   0.99874       794
cluster_00447    0.98490   0.98490   0.98490       596
cluster_00448    0.99018   0.99630   0.99323       810
cluster_00450    0.98218   0.97160   0.97686      1021
cluster_00456    0.99630   0.99079   0.99354       543
cluster_00458    0.98595   0.98164   0.98379      1144
cluster_00460    0.98175   0.98655   0.98415       818
cluster_00463    0.98673   0.98510   0.98592       604
cluster_00467    0.99669   0.98527   0.99095       611
cluster_00483    0.98747   0.98747   0.98747       479
cluster_00484    0.98614   0.98614   0.98614       577
cluster_00007    0.99538   0.98779   0.99157       655
cluster_00036    0.98346   0.97776   0.98060      1034
cluster_00054    0.99244   0.99057   0.99150       530
cluster_00062    0.96118   0.96414   0.96266       976
cluster_00064    0.98371   0.98052   0.98211       924
cluster_00065    0.99074   0.99601   0.99337       752
cluster_00067    0.98063   0.98410   0.98236       566
cluster_00071    0.97033   0.96528   0.96780       576
cluster_00075    0.97792   0.98117   0.97955       903
cluster_00084    0.98943   0.97816   0.98376      1053
cluster_00093    0.98504   0.98053   0.98278       873
cluster_00001    0.99216   0.98828   0.99022      1024
cluster_00002    0.98308   0.98611   0.98459       648
cluster_00003    0.97991   0.98681   0.98335      1137
cluster_00006    0.99482   0.99870   0.99676       769
cluster_00008    0.99035   0.99122   0.99079      1139
cluster_00010    0.98538   0.99508   0.99021       813
cluster_00012    0.98793   0.98201   0.98496       667
cluster_00019    0.99464   0.99821   0.99642       558
cluster_00022    0.98350   0.98101   0.98226       790
cluster_00026    0.99319   0.98780   0.99049       738
cluster_00029    0.97937   0.98150   0.98043       919
cluster_00031    0.98361   0.98271   0.98316      1099
cluster_00043    0.99910   0.99819   0.99864      1107
cluster_00051    0.99487   0.99615   0.99551       779
cluster_00052    0.98338   0.98267   0.98303      1385
cluster_00073    0.98846   0.98950   0.98898       952
cluster_00076    0.98393   0.98733   0.98562       868
cluster_00082    0.98933   0.98670   0.98802      1128
cluster_00107    0.99220   0.99331   0.99276       897
cluster_00432    0.99903   0.99423   0.99662      1039
cluster_00440    0.99497   0.99598   0.99548       994
cluster_00455    0.99573   0.99431   0.99502       703
cluster_00714    1.00000   0.99885   0.99942       870
cluster_00791    0.99166   0.99442   0.99304       717
cluster_00119    0.99551   0.99663   0.99607       889
cluster_00121    0.99588   0.99862   0.99725       727
cluster_00155    0.99810   0.99621   0.99716      1056
cluster_00556    0.99561   0.99780   0.99670       909
cluster_00557    0.99733   0.99644   0.99689      1125
cluster_00689    0.99892   0.99784   0.99838       928
cluster_00692    1.00000   0.99787   0.99893       938
cluster_00718    0.99887   0.99887   0.99887       885
cluster_00725    0.99858   0.99717   0.99788       707
cluster_00727    0.99141   1.00000   0.99569       577
cluster_00729    0.99652   0.99913   0.99782      1146
cluster_00733    1.00000   1.00000   1.00000       600
cluster_00738    0.99851   1.00000   0.99926       672
cluster_00740    1.00000   0.99518   0.99758       622
cluster_00744    0.99892   0.99676   0.99784       926
cluster_00753    0.99885   0.99657   0.99771       875
cluster_00777    0.99766   0.99766   0.99766       853
cluster_00795    0.99866   0.99866   0.99866       749

     accuracy                        0.98579    160000
    macro avg    0.98568   0.98559   0.98563    160000
 weighted avg    0.98581   0.98579   0.98579    160000

2023-07-14 02:37:30,994 =======================================================
2023-07-14 02:37:30,994 

2023-07-14 02:37:31,745 Total processing time is 4536.09s
2023-07-14 02:37:31,747 =======================================================
2023-07-14 02:37:31,747 Namespace(T_0=10, T_mult=2, best_metric='f1', decay_factor=0.5, epoch=800, eval_fold_zero=False, input_path='***', k_fold=5, lr=0.001, manualSeed=0, momentum=0, num_workers=4, opt='Adam', out_path='***', out_path_base='***', redistribute_class=True, scheduler='step', step_size=20, train_batch_size=2048, val_batch_size=1024, weight_decay=0.0)
2023-07-14 02:37:31,748 =======================================================
2023-07-14 02:37:31,748 Implement 4 fold experiment
2023-07-14 02:37:44,818 use [1, 2, 3, 5] fold as train data
2023-07-14 02:37:44,818 The size of feature for train is (160000, 15, 3)
2023-07-14 02:37:44,881 use 4 fold as validation data
2023-07-14 02:37:44,881 The size of feature for val is (40000, 15, 3)
2023-07-14 02:37:44,898 The training data size is:160000
2023-07-14 02:37:44,898 The validation data size is:40000
2023-07-14 02:37:44,898 The number of classes is:198
2023-07-14 02:37:44,900 The label names are: [b'cluster_00205', b'cluster_00222', b'cluster_00232', b'cluster_00246', b'cluster_00259', b'cluster_00261', b'cluster_00262', b'cluster_00267', b'cluster_00275', b'cluster_00276', b'cluster_00278', b'cluster_00287', b'cluster_00291', b'cluster_00293', b'cluster_00294', b'cluster_00296', b'cluster_00298', b'cluster_00299', b'cluster_00300', b'cluster_00303', b'cluster_00304', b'cluster_00319', b'cluster_00322', b'cluster_00333', b'cluster_00338', b'cluster_00340', b'cluster_00344', b'cluster_00346', b'cluster_00350', b'cluster_00352', b'cluster_00359', b'cluster_00360', b'cluster_00361', b'cluster_00365', b'cluster_00368', b'cluster_00373', b'cluster_00374', b'cluster_00375', b'cluster_00377', b'cluster_00380', b'cluster_00385', b'cluster_00388', b'cluster_00389', b'cluster_00390', b'cluster_00394', b'cluster_00400', b'cluster_00401', b'cluster_00405', b'cluster_00407', b'cluster_00408', b'cluster_00409', b'cluster_00412', b'cluster_00445', b'cluster_00473', b'cluster_00585', b'cluster_00589', b'cluster_00591', b'cluster_00593', b'cluster_00596', b'cluster_00603', b'cluster_00604', b'cluster_00607', b'cluster_00612', b'cluster_00616', b'cluster_00619', b'cluster_00629', b'cluster_00630', b'cluster_00635', b'cluster_00637', b'cluster_00639', b'cluster_00642', b'cluster_00645', b'cluster_00647', b'cluster_00652', b'cluster_00653', b'cluster_00656', b'cluster_00657', b'cluster_00661', b'cluster_00662', b'cluster_00667', b'cluster_00762', b'cluster_00201', b'cluster_00217', b'cluster_00239', b'cluster_00320', b'cluster_00391', b'cluster_00398', b'cluster_00415', b'cluster_00477', b'cluster_00478', b'cluster_00479', b'cluster_00078', b'cluster_00079', b'cluster_00083', b'cluster_00090', b'cluster_00094', b'cluster_00096', b'cluster_00101', b'cluster_00086', b'cluster_00095', b'cluster_00097', b'cluster_00106', b'cluster_00553', b'cluster_00554', b'cluster_00569', b'cluster_00015', b'cluster_00017', b'cluster_00018', b'cluster_00023', b'cluster_00025', b'cluster_00030', b'cluster_00035', b'cluster_00039', b'cluster_00042', b'cluster_00046', b'cluster_00055', b'cluster_00059', b'cluster_00061', b'cluster_00274', b'cluster_00308', b'cluster_00337', b'cluster_00362', b'cluster_00369', b'cluster_00392', b'cluster_00414', b'cluster_00419', b'cluster_00420', b'cluster_00421', b'cluster_00422', b'cluster_00427', b'cluster_00430', b'cluster_00431', b'cluster_00436', b'cluster_00439', b'cluster_00444', b'cluster_00447', b'cluster_00448', b'cluster_00450', b'cluster_00456', b'cluster_00458', b'cluster_00460', b'cluster_00463', b'cluster_00467', b'cluster_00483', b'cluster_00484', b'cluster_00007', b'cluster_00036', b'cluster_00054', b'cluster_00062', b'cluster_00064', b'cluster_00065', b'cluster_00067', b'cluster_00071', b'cluster_00075', b'cluster_00084', b'cluster_00093', b'cluster_00001', b'cluster_00002', b'cluster_00003', b'cluster_00006', b'cluster_00008', b'cluster_00010', b'cluster_00012', b'cluster_00019', b'cluster_00022', b'cluster_00026', b'cluster_00029', b'cluster_00031', b'cluster_00043', b'cluster_00051', b'cluster_00052', b'cluster_00073', b'cluster_00076', b'cluster_00082', b'cluster_00107', b'cluster_00432', b'cluster_00440', b'cluster_00455', b'cluster_00714', b'cluster_00791', b'cluster_00119', b'cluster_00121', b'cluster_00155', b'cluster_00556', b'cluster_00557', b'cluster_00689', b'cluster_00692', b'cluster_00718', b'cluster_00725', b'cluster_00727', b'cluster_00729', b'cluster_00733', b'cluster_00738', b'cluster_00740', b'cluster_00744', b'cluster_00753', b'cluster_00777', b'cluster_00795']
2023-07-14 02:37:49,900 epoch [1/800] time: 4.98s train loss: 2.4105 accuracy: 0.4774 f1: 0.4532
2023-07-14 02:37:50,707 epoch [1/800] time: 0.8s val loss: 1.3002 accuracy: 0.7101 f1: 0.7005
2023-07-14 02:37:55,552 epoch [2/800] time: 4.84s train loss: 0.8499 accuracy: 0.7601 f1: 0.754
2023-07-14 02:37:56,410 epoch [2/800] time: 0.85s val loss: 0.7592 accuracy: 0.7529 f1: 0.7483
2023-07-14 02:38:01,176 epoch [3/800] time: 4.77s train loss: 0.6177 accuracy: 0.7967 f1: 0.7931
2023-07-14 02:38:02,040 epoch [3/800] time: 0.86s val loss: 0.6238 accuracy: 0.7783 f1: 0.7729
2023-07-14 02:38:06,825 epoch [4/800] time: 4.78s train loss: 0.5539 accuracy: 0.8064 f1: 0.8035
2023-07-14 02:38:07,700 epoch [4/800] time: 0.87s val loss: 0.5614 accuracy: 0.7978 f1: 0.794
2023-07-14 02:38:12,529 epoch [5/800] time: 4.83s train loss: 0.487 accuracy: 0.8254 f1: 0.8229
2023-07-14 02:38:13,389 epoch [5/800] time: 0.85s val loss: 0.4741 accuracy: 0.8254 f1: 0.8238
2023-07-14 02:38:18,046 epoch [6/800] time: 4.65s train loss: 0.4544 accuracy: 0.8353 f1: 0.8328
2023-07-14 02:38:18,955 epoch [6/800] time: 0.9s val loss: 0.4563 accuracy: 0.8323 f1: 0.8297
2023-07-14 02:38:23,580 epoch [7/800] time: 4.63s train loss: 0.429 accuracy: 0.8425 f1: 0.8403
2023-07-14 02:38:24,502 epoch [7/800] time: 0.92s val loss: 0.459 accuracy: 0.8278 f1: 0.8248
2023-07-14 02:38:29,928 epoch [8/800] time: 5.42s train loss: 0.4055 accuracy: 0.8502 f1: 0.8485
2023-07-14 02:38:30,851 epoch [8/800] time: 0.92s val loss: 0.4406 accuracy: 0.8321 f1: 0.829
2023-07-14 02:38:35,726 epoch [9/800] time: 4.87s train loss: 0.4025 accuracy: 0.8505 f1: 0.8482
2023-07-14 02:38:36,599 epoch [9/800] time: 0.87s val loss: 0.3899 accuracy: 0.8511 f1: 0.8487
2023-07-14 02:38:41,799 epoch [10/800] time: 5.19s train loss: 0.3711 accuracy: 0.8625 f1: 0.8608
2023-07-14 02:38:42,722 epoch [10/800] time: 0.92s val loss: 0.446 accuracy: 0.8317 f1: 0.8313
2023-07-14 02:38:47,646 epoch [11/800] time: 4.92s train loss: 0.3586 accuracy: 0.8656 f1: 0.8637
2023-07-14 02:38:48,521 epoch [11/800] time: 0.87s val loss: 0.4488 accuracy: 0.8322 f1: 0.8298
2023-07-14 02:38:53,506 epoch [12/800] time: 4.99s train loss: 0.3621 accuracy: 0.8636 f1: 0.8622
2023-07-14 02:38:54,321 epoch [12/800] time: 0.81s val loss: 0.3974 accuracy: 0.8469 f1: 0.8418
2023-07-14 02:38:59,098 epoch [13/800] time: 4.78s train loss: 0.3524 accuracy: 0.8669 f1: 0.8655
2023-07-14 02:38:59,972 epoch [13/800] time: 0.87s val loss: 0.387 accuracy: 0.8517 f1: 0.8507
2023-07-14 02:39:04,880 epoch [14/800] time: 4.91s train loss: 0.3412 accuracy: 0.871 f1: 0.8694
2023-07-14 02:39:05,766 epoch [14/800] time: 0.88s val loss: 0.362 accuracy: 0.8593 f1: 0.8573
2023-07-14 02:39:10,646 epoch [15/800] time: 4.88s train loss: 0.3223 accuracy: 0.8774 f1: 0.8758
2023-07-14 02:39:11,462 epoch [15/800] time: 0.81s val loss: 0.3812 accuracy: 0.8524 f1: 0.8499
2023-07-14 02:39:16,343 epoch [16/800] time: 4.88s train loss: 0.3178 accuracy: 0.8792 f1: 0.8779
2023-07-14 02:39:17,211 epoch [16/800] time: 0.86s val loss: 0.3454 accuracy: 0.8652 f1: 0.8627
2023-07-14 02:39:22,149 epoch [17/800] time: 4.94s train loss: 0.3073 accuracy: 0.8836 f1: 0.8823
2023-07-14 02:39:23,014 epoch [17/800] time: 0.86s val loss: 0.4439 accuracy: 0.8361 f1: 0.833
2023-07-14 02:39:27,829 epoch [18/800] time: 4.81s train loss: 0.3111 accuracy: 0.881 f1: 0.8801
2023-07-14 02:39:28,639 epoch [18/800] time: 0.81s val loss: 0.3894 accuracy: 0.8536 f1: 0.8523
2023-07-14 02:39:33,565 epoch [19/800] time: 4.93s train loss: 0.3002 accuracy: 0.8851 f1: 0.8839
2023-07-14 02:39:34,447 epoch [19/800] time: 0.88s val loss: 0.3236 accuracy: 0.8766 f1: 0.8755
2023-07-14 02:39:39,204 epoch [20/800] time: 4.76s train loss: 0.3034 accuracy: 0.8836 f1: 0.8821
2023-07-14 02:39:40,060 epoch [20/800] time: 0.86s val loss: 0.3418 accuracy: 0.8685 f1: 0.8664
2023-07-14 02:39:44,860 epoch [21/800] time: 4.8s train loss: 0.2477 accuracy: 0.9067 f1: 0.9057
2023-07-14 02:39:45,668 epoch [21/800] time: 0.8s val loss: 0.2405 accuracy: 0.9066 f1: 0.9054
2023-07-14 02:39:50,462 epoch [22/800] time: 4.79s train loss: 0.2405 accuracy: 0.9083 f1: 0.9074
2023-07-14 02:39:51,314 epoch [22/800] time: 0.85s val loss: 0.2806 accuracy: 0.8901 f1: 0.8894
2023-07-14 02:39:56,159 epoch [23/800] time: 4.85s train loss: 0.2302 accuracy: 0.9128 f1: 0.9116
2023-07-14 02:39:57,027 epoch [23/800] time: 0.86s val loss: 0.2431 accuracy: 0.9063 f1: 0.9053
2023-07-14 02:40:01,822 epoch [24/800] time: 4.79s train loss: 0.2258 accuracy: 0.9145 f1: 0.9134
2023-07-14 02:40:02,635 epoch [24/800] time: 0.81s val loss: 0.2597 accuracy: 0.8988 f1: 0.8973
2023-07-14 02:40:07,538 epoch [25/800] time: 4.9s train loss: 0.2325 accuracy: 0.9112 f1: 0.9102
2023-07-14 02:40:08,426 epoch [25/800] time: 0.89s val loss: 0.2511 accuracy: 0.9023 f1: 0.9009
2023-07-14 02:40:13,322 epoch [26/800] time: 4.9s train loss: 0.2237 accuracy: 0.9154 f1: 0.9144
2023-07-14 02:40:14,200 epoch [26/800] time: 0.87s val loss: 0.2609 accuracy: 0.8999 f1: 0.898
2023-07-14 02:40:19,063 epoch [27/800] time: 4.86s train loss: 0.2275 accuracy: 0.9128 f1: 0.9119
2023-07-14 02:40:19,896 epoch [27/800] time: 0.83s val loss: 0.2479 accuracy: 0.9043 f1: 0.9033
2023-07-14 02:40:24,688 epoch [28/800] time: 4.79s train loss: 0.2167 accuracy: 0.918 f1: 0.9173
2023-07-14 02:40:25,536 epoch [28/800] time: 0.84s val loss: 0.2238 accuracy: 0.9151 f1: 0.9141
2023-07-14 02:40:30,260 epoch [29/800] time: 4.72s train loss: 0.2163 accuracy: 0.9175 f1: 0.9165
2023-07-14 02:40:31,106 epoch [29/800] time: 0.85s val loss: 0.2821 accuracy: 0.8899 f1: 0.8889
2023-07-14 02:40:35,793 epoch [30/800] time: 4.69s train loss: 0.2186 accuracy: 0.917 f1: 0.9161
2023-07-14 02:40:36,599 epoch [30/800] time: 0.81s val loss: 0.2444 accuracy: 0.9047 f1: 0.9038
2023-07-14 02:40:41,183 epoch [31/800] time: 4.58s train loss: 0.221 accuracy: 0.9159 f1: 0.9149
2023-07-14 02:40:42,032 epoch [31/800] time: 0.85s val loss: 0.2453 accuracy: 0.9046 f1: 0.9028
2023-07-14 02:40:46,700 epoch [32/800] time: 4.67s train loss: 0.2082 accuracy: 0.9211 f1: 0.9202
2023-07-14 02:40:47,583 epoch [32/800] time: 0.88s val loss: 0.2376 accuracy: 0.9082 f1: 0.9064
2023-07-14 02:40:52,449 epoch [33/800] time: 4.87s train loss: 0.213 accuracy: 0.9196 f1: 0.9187
2023-07-14 02:40:53,252 epoch [33/800] time: 0.8s val loss: 0.233 accuracy: 0.9094 f1: 0.9089
2023-07-14 02:40:57,900 epoch [34/800] time: 4.65s train loss: 0.2088 accuracy: 0.9206 f1: 0.9198
2023-07-14 02:40:58,764 epoch [34/800] time: 0.86s val loss: 0.2349 accuracy: 0.9092 f1: 0.9084
2023-07-14 02:41:03,362 epoch [35/800] time: 4.6s train loss: 0.2135 accuracy: 0.9188 f1: 0.9182
2023-07-14 02:41:04,202 epoch [35/800] time: 0.84s val loss: 0.2467 accuracy: 0.9062 f1: 0.9047
2023-07-14 02:41:08,870 epoch [36/800] time: 4.67s train loss: 0.2048 accuracy: 0.9217 f1: 0.9209
2023-07-14 02:41:09,720 epoch [36/800] time: 0.84s val loss: 0.2376 accuracy: 0.9076 f1: 0.9069
2023-07-14 02:41:14,336 epoch [37/800] time: 4.62s train loss: 0.2042 accuracy: 0.9227 f1: 0.922
2023-07-14 02:41:15,238 epoch [37/800] time: 0.89s val loss: 0.2858 accuracy: 0.8921 f1: 0.8911
2023-07-14 02:41:20,121 epoch [38/800] time: 4.88s train loss: 0.2068 accuracy: 0.9208 f1: 0.92
2023-07-14 02:41:20,979 epoch [38/800] time: 0.86s val loss: 0.2371 accuracy: 0.9086 f1: 0.907
2023-07-14 02:41:26,132 epoch [39/800] time: 5.15s train loss: 0.2019 accuracy: 0.9226 f1: 0.922
2023-07-14 02:41:26,986 epoch [39/800] time: 0.85s val loss: 0.3611 accuracy: 0.8723 f1: 0.872
2023-07-14 02:41:32,253 epoch [40/800] time: 5.27s train loss: 0.2026 accuracy: 0.922 f1: 0.9212
2023-07-14 02:41:33,121 epoch [40/800] time: 0.87s val loss: 0.2273 accuracy: 0.912 f1: 0.9105
2023-07-14 02:41:38,269 epoch [41/800] time: 5.15s train loss: 0.1661 accuracy: 0.9387 f1: 0.9382
2023-07-14 02:41:39,237 epoch [41/800] time: 0.96s val loss: 0.1912 accuracy: 0.9266 f1: 0.9255
2023-07-14 02:41:44,346 epoch [42/800] time: 5.11s train loss: 0.1622 accuracy: 0.94 f1: 0.9394
2023-07-14 02:41:45,178 epoch [42/800] time: 0.83s val loss: 0.1952 accuracy: 0.9245 f1: 0.9236
2023-07-14 02:41:50,397 epoch [43/800] time: 5.22s train loss: 0.1567 accuracy: 0.9428 f1: 0.9422
2023-07-14 02:41:51,358 epoch [43/800] time: 0.95s val loss: 0.1862 accuracy: 0.9297 f1: 0.9285
2023-07-14 02:41:56,609 epoch [44/800] time: 5.25s train loss: 0.1597 accuracy: 0.9414 f1: 0.9408
2023-07-14 02:41:57,523 epoch [44/800] time: 0.91s val loss: 0.1996 accuracy: 0.9228 f1: 0.9219
2023-07-14 02:42:02,553 epoch [45/800] time: 5.03s train loss: 0.16 accuracy: 0.9407 f1: 0.9402
2023-07-14 02:42:03,404 epoch [45/800] time: 0.85s val loss: 0.1864 accuracy: 0.93 f1: 0.9291
2023-07-14 02:42:08,617 epoch [46/800] time: 5.21s train loss: 0.1549 accuracy: 0.9427 f1: 0.9422
2023-07-14 02:42:09,541 epoch [46/800] time: 0.92s val loss: 0.1973 accuracy: 0.9234 f1: 0.9232
2023-07-14 02:42:14,309 epoch [47/800] time: 4.77s train loss: 0.1502 accuracy: 0.9442 f1: 0.9436
2023-07-14 02:42:15,171 epoch [47/800] time: 0.86s val loss: 0.1812 accuracy: 0.9311 f1: 0.9299
2023-07-14 02:42:20,098 epoch [48/800] time: 4.93s train loss: 0.1544 accuracy: 0.9425 f1: 0.9421
2023-07-14 02:42:20,908 epoch [48/800] time: 0.81s val loss: 0.2193 accuracy: 0.916 f1: 0.9148
2023-07-14 02:42:25,697 epoch [49/800] time: 4.79s train loss: 0.1528 accuracy: 0.9438 f1: 0.9434
2023-07-14 02:42:26,553 epoch [49/800] time: 0.86s val loss: 0.1871 accuracy: 0.928 f1: 0.927
2023-07-14 02:42:31,568 epoch [50/800] time: 5.01s train loss: 0.1481 accuracy: 0.9452 f1: 0.9447
2023-07-14 02:42:32,439 epoch [50/800] time: 0.86s val loss: 0.2007 accuracy: 0.9244 f1: 0.9229
2023-07-14 02:42:37,277 epoch [51/800] time: 4.84s train loss: 0.148 accuracy: 0.9456 f1: 0.9449
2023-07-14 02:42:38,094 epoch [51/800] time: 0.81s val loss: 0.1827 accuracy: 0.9304 f1: 0.9289
2023-07-14 02:42:43,087 epoch [52/800] time: 4.99s train loss: 0.153 accuracy: 0.9433 f1: 0.9425
2023-07-14 02:42:44,001 epoch [52/800] time: 0.91s val loss: 0.2134 accuracy: 0.9197 f1: 0.9189
2023-07-14 02:42:48,655 epoch [53/800] time: 4.65s train loss: 0.1471 accuracy: 0.9462 f1: 0.9459
2023-07-14 02:42:49,522 epoch [53/800] time: 0.86s val loss: 0.1868 accuracy: 0.9297 f1: 0.9289
2023-07-14 02:42:54,190 epoch [54/800] time: 4.67s train loss: 0.152 accuracy: 0.9435 f1: 0.9431
2023-07-14 02:42:55,086 epoch [54/800] time: 0.9s val loss: 0.1955 accuracy: 0.9242 f1: 0.9232
2023-07-14 02:43:00,158 epoch [55/800] time: 5.07s train loss: 0.1462 accuracy: 0.9457 f1: 0.945
2023-07-14 02:43:01,020 epoch [55/800] time: 0.86s val loss: 0.1967 accuracy: 0.9252 f1: 0.9244
2023-07-14 02:43:05,586 epoch [56/800] time: 4.57s train loss: 0.1428 accuracy: 0.9476 f1: 0.947
2023-07-14 02:43:06,445 epoch [56/800] time: 0.85s val loss: 0.1895 accuracy: 0.9279 f1: 0.9269
2023-07-14 02:43:11,529 epoch [57/800] time: 5.08s train loss: 0.1433 accuracy: 0.9466 f1: 0.946
2023-07-14 02:43:12,368 epoch [57/800] time: 0.84s val loss: 0.1868 accuracy: 0.9312 f1: 0.9303
2023-07-14 02:43:17,215 epoch [58/800] time: 4.85s train loss: 0.1374 accuracy: 0.9496 f1: 0.9493
2023-07-14 02:43:18,074 epoch [58/800] time: 0.85s val loss: 0.1965 accuracy: 0.9255 f1: 0.9257
2023-07-14 02:43:22,864 epoch [59/800] time: 4.79s train loss: 0.146 accuracy: 0.9463 f1: 0.9459
2023-07-14 02:43:23,710 epoch [59/800] time: 0.85s val loss: 0.2244 accuracy: 0.9169 f1: 0.916
2023-07-14 02:43:28,673 epoch [60/800] time: 4.96s train loss: 0.1406 accuracy: 0.9485 f1: 0.9481
2023-07-14 02:43:29,491 epoch [60/800] time: 0.82s val loss: 0.2031 accuracy: 0.9224 f1: 0.9213
2023-07-14 02:43:34,074 epoch [61/800] time: 4.58s train loss: 0.1234 accuracy: 0.9561 f1: 0.9555
2023-07-14 02:43:34,931 epoch [61/800] time: 0.85s val loss: 0.1587 accuracy: 0.9409 f1: 0.9399
2023-07-14 02:43:39,779 epoch [62/800] time: 4.85s train loss: 0.1161 accuracy: 0.9592 f1: 0.9589
2023-07-14 02:43:40,672 epoch [62/800] time: 0.89s val loss: 0.1623 accuracy: 0.9388 f1: 0.9379
2023-07-14 02:43:45,594 epoch [63/800] time: 4.92s train loss: 0.1174 accuracy: 0.9591 f1: 0.9586
2023-07-14 02:43:46,401 epoch [63/800] time: 0.81s val loss: 0.1659 accuracy: 0.9378 f1: 0.9367
2023-07-14 02:43:51,226 epoch [64/800] time: 4.82s train loss: 0.1129 accuracy: 0.9608 f1: 0.9604
2023-07-14 02:43:52,088 epoch [64/800] time: 0.86s val loss: 0.164 accuracy: 0.9375 f1: 0.9365
2023-07-14 02:43:57,001 epoch [65/800] time: 4.91s train loss: 0.114 accuracy: 0.9605 f1: 0.9602
2023-07-14 02:43:57,858 epoch [65/800] time: 0.86s val loss: 0.1681 accuracy: 0.9382 f1: 0.9374
2023-07-14 02:44:02,673 epoch [66/800] time: 4.81s train loss: 0.112 accuracy: 0.9611 f1: 0.9608
2023-07-14 02:44:03,482 epoch [66/800] time: 0.8s val loss: 0.1676 accuracy: 0.9379 f1: 0.9372
2023-07-14 02:44:08,280 epoch [67/800] time: 4.8s train loss: 0.1121 accuracy: 0.9606 f1: 0.9603
2023-07-14 02:44:09,125 epoch [67/800] time: 0.84s val loss: 0.1657 accuracy: 0.938 f1: 0.9373
2023-07-14 02:44:13,809 epoch [68/800] time: 4.68s train loss: 0.1158 accuracy: 0.959 f1: 0.9584
2023-07-14 02:44:14,650 epoch [68/800] time: 0.84s val loss: 0.1628 accuracy: 0.9381 f1: 0.937
2023-07-14 02:44:19,557 epoch [69/800] time: 4.91s train loss: 0.1103 accuracy: 0.9611 f1: 0.9607
2023-07-14 02:44:20,388 epoch [69/800] time: 0.83s val loss: 0.1652 accuracy: 0.9393 f1: 0.9388
2023-07-14 02:44:25,534 epoch [70/800] time: 5.15s train loss: 0.1096 accuracy: 0.962 f1: 0.9616
2023-07-14 02:44:26,581 epoch [70/800] time: 1.04s val loss: 0.159 accuracy: 0.9416 f1: 0.9405
2023-07-14 02:44:32,032 epoch [71/800] time: 5.45s train loss: 0.1088 accuracy: 0.9625 f1: 0.9623
2023-07-14 02:44:33,024 epoch [71/800] time: 0.99s val loss: 0.1655 accuracy: 0.9382 f1: 0.9374
2023-07-14 02:44:38,405 epoch [72/800] time: 5.38s train loss: 0.11 accuracy: 0.9614 f1: 0.9612
2023-07-14 02:44:39,261 epoch [72/800] time: 0.86s val loss: 0.1536 accuracy: 0.9423 f1: 0.9412
2023-07-14 02:44:44,743 epoch [73/800] time: 5.48s train loss: 0.1057 accuracy: 0.9629 f1: 0.9626
2023-07-14 02:44:45,687 epoch [73/800] time: 0.94s val loss: 0.1606 accuracy: 0.9384 f1: 0.9378
2023-07-14 02:44:50,922 epoch [74/800] time: 5.23s train loss: 0.1068 accuracy: 0.963 f1: 0.9627
2023-07-14 02:44:51,849 epoch [74/800] time: 0.92s val loss: 0.1762 accuracy: 0.9327 f1: 0.9317
2023-07-14 02:44:56,945 epoch [75/800] time: 5.1s train loss: 0.1114 accuracy: 0.9616 f1: 0.9613
2023-07-14 02:44:57,834 epoch [75/800] time: 0.89s val loss: 0.1757 accuracy: 0.9341 f1: 0.9335
2023-07-14 02:45:03,057 epoch [76/800] time: 5.22s train loss: 0.111 accuracy: 0.9607 f1: 0.9605
2023-07-14 02:45:04,032 epoch [76/800] time: 0.97s val loss: 0.1666 accuracy: 0.9392 f1: 0.9383
2023-07-14 02:45:09,408 epoch [77/800] time: 5.38s train loss: 0.1082 accuracy: 0.9623 f1: 0.9621
2023-07-14 02:45:10,310 epoch [77/800] time: 0.9s val loss: 0.1667 accuracy: 0.9392 f1: 0.9382
2023-07-14 02:45:15,633 epoch [78/800] time: 5.32s train loss: 0.1067 accuracy: 0.9627 f1: 0.9625
2023-07-14 02:45:16,516 epoch [78/800] time: 0.88s val loss: 0.1731 accuracy: 0.9366 f1: 0.9355
2023-07-14 02:45:21,744 epoch [79/800] time: 5.23s train loss: 0.1069 accuracy: 0.9626 f1: 0.9624
2023-07-14 02:45:22,627 epoch [79/800] time: 0.88s val loss: 0.1651 accuracy: 0.9381 f1: 0.9373
2023-07-14 02:45:27,503 epoch [80/800] time: 4.88s train loss: 0.1032 accuracy: 0.9644 f1: 0.9641
2023-07-14 02:45:28,399 epoch [80/800] time: 0.89s val loss: 0.1684 accuracy: 0.9367 f1: 0.9361
2023-07-14 02:45:33,331 epoch [81/800] time: 4.93s train loss: 0.0936 accuracy: 0.9685 f1: 0.9684
2023-07-14 02:45:34,149 epoch [81/800] time: 0.81s val loss: 0.15 accuracy: 0.9449 f1: 0.9442
2023-07-14 02:45:38,979 epoch [82/800] time: 4.83s train loss: 0.0934 accuracy: 0.9695 f1: 0.9691
2023-07-14 02:45:39,899 epoch [82/800] time: 0.91s val loss: 0.1514 accuracy: 0.9441 f1: 0.9433
2023-07-14 02:45:44,762 epoch [83/800] time: 4.86s train loss: 0.0932 accuracy: 0.9687 f1: 0.9685
2023-07-14 02:45:45,621 epoch [83/800] time: 0.86s val loss: 0.1521 accuracy: 0.9434 f1: 0.9425
2023-07-14 02:45:50,314 epoch [84/800] time: 4.69s train loss: 0.0923 accuracy: 0.9699 f1: 0.9697
2023-07-14 02:45:51,155 epoch [84/800] time: 0.83s val loss: 0.1499 accuracy: 0.944 f1: 0.9434
2023-07-14 02:45:56,236 epoch [85/800] time: 5.08s train loss: 0.0908 accuracy: 0.9704 f1: 0.9702
2023-07-14 02:45:57,117 epoch [85/800] time: 0.87s val loss: 0.1485 accuracy: 0.9458 f1: 0.945
2023-07-14 02:46:01,959 epoch [86/800] time: 4.84s train loss: 0.0897 accuracy: 0.9707 f1: 0.9706
2023-07-14 02:46:02,819 epoch [86/800] time: 0.85s val loss: 0.1487 accuracy: 0.9458 f1: 0.9448
2023-07-14 02:46:07,659 epoch [87/800] time: 4.84s train loss: 0.0893 accuracy: 0.9706 f1: 0.9704
2023-07-14 02:46:08,464 epoch [87/800] time: 0.8s val loss: 0.1534 accuracy: 0.9442 f1: 0.9433
2023-07-14 02:46:12,989 epoch [88/800] time: 4.53s train loss: 0.09 accuracy: 0.97 f1: 0.9697
2023-07-14 02:46:13,828 epoch [88/800] time: 0.84s val loss: 0.1517 accuracy: 0.9438 f1: 0.9429
2023-07-14 02:46:18,301 epoch [89/800] time: 4.47s train loss: 0.0892 accuracy: 0.9703 f1: 0.97
2023-07-14 02:46:19,143 epoch [89/800] time: 0.84s val loss: 0.1482 accuracy: 0.9468 f1: 0.9459
2023-07-14 02:46:23,658 epoch [90/800] time: 4.51s train loss: 0.0885 accuracy: 0.9709 f1: 0.9707
2023-07-14 02:46:24,459 epoch [90/800] time: 0.79s val loss: 0.1475 accuracy: 0.9458 f1: 0.945
2023-07-14 02:46:29,193 epoch [91/800] time: 4.73s train loss: 0.0893 accuracy: 0.9708 f1: 0.9707
2023-07-14 02:46:30,061 epoch [91/800] time: 0.87s val loss: 0.1486 accuracy: 0.9453 f1: 0.9446
2023-07-14 02:46:34,643 epoch [92/800] time: 4.58s train loss: 0.0883 accuracy: 0.9709 f1: 0.9707
2023-07-14 02:46:35,496 epoch [92/800] time: 0.85s val loss: 0.1482 accuracy: 0.9463 f1: 0.9455
2023-07-14 02:46:40,083 epoch [93/800] time: 4.59s train loss: 0.0897 accuracy: 0.9707 f1: 0.9705
2023-07-14 02:46:40,941 epoch [93/800] time: 0.86s val loss: 0.1488 accuracy: 0.9454 f1: 0.9447
2023-07-14 02:46:45,700 epoch [94/800] time: 4.76s train loss: 0.0877 accuracy: 0.9712 f1: 0.971
2023-07-14 02:46:46,557 epoch [94/800] time: 0.85s val loss: 0.1484 accuracy: 0.9465 f1: 0.9456
2023-07-14 02:46:51,080 epoch [95/800] time: 4.52s train loss: 0.0868 accuracy: 0.9713 f1: 0.9711
2023-07-14 02:46:51,935 epoch [95/800] time: 0.85s val loss: 0.1503 accuracy: 0.9465 f1: 0.9455
2023-07-14 02:46:56,773 epoch [96/800] time: 4.84s train loss: 0.0867 accuracy: 0.9717 f1: 0.9715
2023-07-14 02:46:57,602 epoch [96/800] time: 0.82s val loss: 0.1499 accuracy: 0.9461 f1: 0.9453
2023-07-14 02:47:02,240 epoch [97/800] time: 4.64s train loss: 0.087 accuracy: 0.971 f1: 0.9708
2023-07-14 02:47:03,089 epoch [97/800] time: 0.85s val loss: 0.1535 accuracy: 0.9441 f1: 0.9433
2023-07-14 02:47:07,588 epoch [98/800] time: 4.5s train loss: 0.0851 accuracy: 0.9721 f1: 0.9719
2023-07-14 02:47:08,476 epoch [98/800] time: 0.88s val loss: 0.1463 accuracy: 0.948 f1: 0.9473
2023-07-14 02:47:13,237 epoch [99/800] time: 4.76s train loss: 0.0838 accuracy: 0.9727 f1: 0.9725
2023-07-14 02:47:14,048 epoch [99/800] time: 0.8s val loss: 0.1511 accuracy: 0.9457 f1: 0.9449
2023-07-14 02:47:18,603 epoch [100/800] time: 4.56s train loss: 0.0843 accuracy: 0.9724 f1: 0.9724
2023-07-14 02:47:19,455 epoch [100/800] time: 0.85s val loss: 0.1505 accuracy: 0.9452 f1: 0.9444
2023-07-14 02:47:23,985 epoch [101/800] time: 4.53s train loss: 0.0797 accuracy: 0.9747 f1: 0.9746
2023-07-14 02:47:24,866 epoch [101/800] time: 0.88s val loss: 0.1457 accuracy: 0.9477 f1: 0.9469
2023-07-14 02:47:30,010 epoch [102/800] time: 5.14s train loss: 0.0772 accuracy: 0.9755 f1: 0.9753
2023-07-14 02:47:30,848 epoch [102/800] time: 0.83s val loss: 0.1431 accuracy: 0.9482 f1: 0.9473
2023-07-14 02:47:35,580 epoch [103/800] time: 4.73s train loss: 0.0777 accuracy: 0.9761 f1: 0.9759
2023-07-14 02:47:36,438 epoch [103/800] time: 0.85s val loss: 0.1443 accuracy: 0.9479 f1: 0.947
2023-07-14 02:47:41,243 epoch [104/800] time: 4.8s train loss: 0.0792 accuracy: 0.9748 f1: 0.9746
2023-07-14 02:47:42,157 epoch [104/800] time: 0.91s val loss: 0.1431 accuracy: 0.9479 f1: 0.9471
2023-07-14 02:47:47,351 epoch [105/800] time: 5.19s train loss: 0.0779 accuracy: 0.9763 f1: 0.976
2023-07-14 02:47:48,172 epoch [105/800] time: 0.81s val loss: 0.1431 accuracy: 0.9484 f1: 0.9476
2023-07-14 02:47:53,066 epoch [106/800] time: 4.89s train loss: 0.0778 accuracy: 0.9753 f1: 0.9751
2023-07-14 02:47:53,977 epoch [106/800] time: 0.91s val loss: 0.1432 accuracy: 0.9492 f1: 0.9482
2023-07-14 02:47:59,228 epoch [107/800] time: 5.25s train loss: 0.0771 accuracy: 0.9758 f1: 0.9756
2023-07-14 02:48:00,143 epoch [107/800] time: 0.91s val loss: 0.1437 accuracy: 0.9475 f1: 0.9466
2023-07-14 02:48:05,053 epoch [108/800] time: 4.91s train loss: 0.0787 accuracy: 0.9751 f1: 0.9749
2023-07-14 02:48:05,873 epoch [108/800] time: 0.82s val loss: 0.1441 accuracy: 0.9477 f1: 0.947
2023-07-14 02:48:11,105 epoch [109/800] time: 5.23s train loss: 0.0776 accuracy: 0.9753 f1: 0.9751
2023-07-14 02:48:12,087 epoch [109/800] time: 0.98s val loss: 0.1454 accuracy: 0.9478 f1: 0.9472
2023-07-14 02:48:17,257 epoch [110/800] time: 5.17s train loss: 0.0766 accuracy: 0.9768 f1: 0.9766
2023-07-14 02:48:18,122 epoch [110/800] time: 0.86s val loss: 0.142 accuracy: 0.9486 f1: 0.9479
2023-07-14 02:48:22,862 epoch [111/800] time: 4.74s train loss: 0.077 accuracy: 0.9762 f1: 0.9761
2023-07-14 02:48:23,754 epoch [111/800] time: 0.89s val loss: 0.1429 accuracy: 0.9484 f1: 0.9477
2023-07-14 02:48:28,944 epoch [112/800] time: 5.19s train loss: 0.075 accuracy: 0.9769 f1: 0.9768
2023-07-14 02:48:29,820 epoch [112/800] time: 0.87s val loss: 0.1428 accuracy: 0.9489 f1: 0.9483
2023-07-14 02:48:34,686 epoch [113/800] time: 4.87s train loss: 0.0755 accuracy: 0.9761 f1: 0.9759
2023-07-14 02:48:35,549 epoch [113/800] time: 0.86s val loss: 0.1428 accuracy: 0.9479 f1: 0.9472
2023-07-14 02:48:40,711 epoch [114/800] time: 5.16s train loss: 0.0759 accuracy: 0.9758 f1: 0.9756
2023-07-14 02:48:41,569 epoch [114/800] time: 0.86s val loss: 0.1438 accuracy: 0.9478 f1: 0.9471
2023-07-14 02:48:46,626 epoch [115/800] time: 5.06s train loss: 0.0742 accuracy: 0.9763 f1: 0.9762
2023-07-14 02:48:47,495 epoch [115/800] time: 0.87s val loss: 0.1457 accuracy: 0.9473 f1: 0.9465
2023-07-14 02:48:52,436 epoch [116/800] time: 4.94s train loss: 0.0758 accuracy: 0.9769 f1: 0.9768
2023-07-14 02:48:53,351 epoch [116/800] time: 0.91s val loss: 0.1438 accuracy: 0.9489 f1: 0.9481
2023-07-14 02:48:58,553 epoch [117/800] time: 5.2s train loss: 0.0771 accuracy: 0.9761 f1: 0.9762
2023-07-14 02:48:59,381 epoch [117/800] time: 0.83s val loss: 0.144 accuracy: 0.9487 f1: 0.9478
2023-07-14 02:49:04,328 epoch [118/800] time: 4.95s train loss: 0.0764 accuracy: 0.9757 f1: 0.9756
2023-07-14 02:49:05,196 epoch [118/800] time: 0.87s val loss: 0.143 accuracy: 0.9488 f1: 0.9481
2023-07-14 02:49:10,157 epoch [119/800] time: 4.96s train loss: 0.0758 accuracy: 0.9767 f1: 0.9767
2023-07-14 02:49:11,043 epoch [119/800] time: 0.89s val loss: 0.1429 accuracy: 0.9493 f1: 0.9483
2023-07-14 02:49:16,196 epoch [120/800] time: 5.15s train loss: 0.0744 accuracy: 0.9773 f1: 0.9772
2023-07-14 02:49:17,062 epoch [120/800] time: 0.86s val loss: 0.1419 accuracy: 0.9487 f1: 0.9479
2023-07-14 02:49:22,025 epoch [121/800] time: 4.96s train loss: 0.0737 accuracy: 0.9768 f1: 0.9766
2023-07-14 02:49:22,952 epoch [121/800] time: 0.93s val loss: 0.1423 accuracy: 0.9485 f1: 0.9477
2023-07-14 02:49:27,976 epoch [122/800] time: 5.02s train loss: 0.0724 accuracy: 0.9781 f1: 0.978
2023-07-14 02:49:28,886 epoch [122/800] time: 0.9s val loss: 0.1416 accuracy: 0.949 f1: 0.9482
2023-07-14 02:49:33,957 epoch [123/800] time: 5.07s train loss: 0.0716 accuracy: 0.978 f1: 0.9779
2023-07-14 02:49:34,774 epoch [123/800] time: 0.82s val loss: 0.1413 accuracy: 0.9485 f1: 0.9478
2023-07-14 02:49:39,830 epoch [124/800] time: 5.06s train loss: 0.0723 accuracy: 0.9782 f1: 0.9781
2023-07-14 02:49:40,711 epoch [124/800] time: 0.87s val loss: 0.141 accuracy: 0.9491 f1: 0.9483
2023-07-14 02:49:45,364 epoch [125/800] time: 4.65s train loss: 0.0716 accuracy: 0.9787 f1: 0.9786
2023-07-14 02:49:46,222 epoch [125/800] time: 0.85s val loss: 0.1405 accuracy: 0.9499 f1: 0.9491
2023-07-14 02:49:50,971 epoch [126/800] time: 4.75s train loss: 0.0716 accuracy: 0.978 f1: 0.9779
2023-07-14 02:49:51,807 epoch [126/800] time: 0.84s val loss: 0.1406 accuracy: 0.9502 f1: 0.9493
2023-07-14 02:49:56,502 epoch [127/800] time: 4.69s train loss: 0.0706 accuracy: 0.9793 f1: 0.9792
2023-07-14 02:49:57,363 epoch [127/800] time: 0.85s val loss: 0.1412 accuracy: 0.9503 f1: 0.9495
2023-07-14 02:50:01,893 epoch [128/800] time: 4.53s train loss: 0.0709 accuracy: 0.9787 f1: 0.9786
2023-07-14 02:50:02,756 epoch [128/800] time: 0.86s val loss: 0.1412 accuracy: 0.9494 f1: 0.9486
2023-07-14 02:50:07,324 epoch [129/800] time: 4.57s train loss: 0.0701 accuracy: 0.9784 f1: 0.9783
2023-07-14 02:50:08,130 epoch [129/800] time: 0.81s val loss: 0.1414 accuracy: 0.9494 f1: 0.9487
2023-07-14 02:50:12,858 epoch [130/800] time: 4.73s train loss: 0.0711 accuracy: 0.9786 f1: 0.9785
2023-07-14 02:50:13,725 epoch [130/800] time: 0.87s val loss: 0.1427 accuracy: 0.9485 f1: 0.9477
2023-07-14 02:50:18,304 epoch [131/800] time: 4.58s train loss: 0.0706 accuracy: 0.9787 f1: 0.9786
2023-07-14 02:50:19,157 epoch [131/800] time: 0.85s val loss: 0.1416 accuracy: 0.9488 f1: 0.9482
2023-07-14 02:50:23,812 epoch [132/800] time: 4.65s train loss: 0.0694 accuracy: 0.9794 f1: 0.9791
2023-07-14 02:50:24,671 epoch [132/800] time: 0.86s val loss: 0.1412 accuracy: 0.9495 f1: 0.9487
2023-07-14 02:50:29,419 epoch [133/800] time: 4.75s train loss: 0.07 accuracy: 0.9793 f1: 0.9791
2023-07-14 02:50:30,290 epoch [133/800] time: 0.87s val loss: 0.1414 accuracy: 0.9496 f1: 0.9488
2023-07-14 02:50:35,037 epoch [134/800] time: 4.75s train loss: 0.07 accuracy: 0.9791 f1: 0.979
2023-07-14 02:50:35,887 epoch [134/800] time: 0.85s val loss: 0.1414 accuracy: 0.9497 f1: 0.9488
2023-07-14 02:50:40,683 epoch [135/800] time: 4.8s train loss: 0.07 accuracy: 0.9791 f1: 0.9789
2023-07-14 02:50:41,509 epoch [135/800] time: 0.83s val loss: 0.1406 accuracy: 0.9498 f1: 0.949
2023-07-14 02:50:46,412 epoch [136/800] time: 4.9s train loss: 0.071 accuracy: 0.9781 f1: 0.9779
2023-07-14 02:50:47,263 epoch [136/800] time: 0.85s val loss: 0.1404 accuracy: 0.9496 f1: 0.9488
2023-07-14 02:50:51,987 epoch [137/800] time: 4.72s train loss: 0.0701 accuracy: 0.9783 f1: 0.9781
2023-07-14 02:50:52,846 epoch [137/800] time: 0.86s val loss: 0.14 accuracy: 0.9497 f1: 0.949
2023-07-14 02:50:57,747 epoch [138/800] time: 4.9s train loss: 0.0702 accuracy: 0.9792 f1: 0.9791
2023-07-14 02:50:58,620 epoch [138/800] time: 0.87s val loss: 0.1418 accuracy: 0.9499 f1: 0.9492
2023-07-14 02:51:03,809 epoch [139/800] time: 5.19s train loss: 0.0702 accuracy: 0.9792 f1: 0.9789
2023-07-14 02:51:04,744 epoch [139/800] time: 0.93s val loss: 0.1404 accuracy: 0.9495 f1: 0.9487
2023-07-14 02:51:09,940 epoch [140/800] time: 5.2s train loss: 0.0695 accuracy: 0.9785 f1: 0.9784
2023-07-14 02:51:10,898 epoch [140/800] time: 0.96s val loss: 0.1405 accuracy: 0.9506 f1: 0.9498
2023-07-14 02:51:16,086 epoch [141/800] time: 5.19s train loss: 0.0689 accuracy: 0.9793 f1: 0.9791
2023-07-14 02:51:16,927 epoch [141/800] time: 0.84s val loss: 0.1397 accuracy: 0.9505 f1: 0.9496
2023-07-14 02:51:21,989 epoch [142/800] time: 5.06s train loss: 0.0676 accuracy: 0.9799 f1: 0.9797
2023-07-14 02:51:22,962 epoch [142/800] time: 0.96s val loss: 0.1401 accuracy: 0.9496 f1: 0.9488
2023-07-14 02:51:28,230 epoch [143/800] time: 5.27s train loss: 0.0683 accuracy: 0.9795 f1: 0.9793
2023-07-14 02:51:29,175 epoch [143/800] time: 0.94s val loss: 0.1398 accuracy: 0.9504 f1: 0.9496
2023-07-14 02:51:34,280 epoch [144/800] time: 5.11s train loss: 0.0686 accuracy: 0.9799 f1: 0.9798
2023-07-14 02:51:35,113 epoch [144/800] time: 0.83s val loss: 0.1398 accuracy: 0.9508 f1: 0.9499
2023-07-14 02:51:40,116 epoch [145/800] time: 5.0s train loss: 0.0707 accuracy: 0.9797 f1: 0.9796
2023-07-14 02:51:41,002 epoch [145/800] time: 0.89s val loss: 0.1402 accuracy: 0.9505 f1: 0.9497
2023-07-14 02:51:45,760 epoch [146/800] time: 4.76s train loss: 0.068 accuracy: 0.9797 f1: 0.9795
2023-07-14 02:51:46,639 epoch [146/800] time: 0.88s val loss: 0.1393 accuracy: 0.9506 f1: 0.9498
2023-07-14 02:51:51,785 epoch [147/800] time: 5.15s train loss: 0.0673 accuracy: 0.9803 f1: 0.9801
2023-07-14 02:51:52,675 epoch [147/800] time: 0.88s val loss: 0.1395 accuracy: 0.9509 f1: 0.9501
2023-07-14 02:51:57,783 epoch [148/800] time: 5.11s train loss: 0.0669 accuracy: 0.9799 f1: 0.9797
2023-07-14 02:51:58,645 epoch [148/800] time: 0.86s val loss: 0.1397 accuracy: 0.95 f1: 0.9493
2023-07-14 02:52:03,257 epoch [149/800] time: 4.61s train loss: 0.0679 accuracy: 0.9795 f1: 0.9793
2023-07-14 02:52:04,115 epoch [149/800] time: 0.86s val loss: 0.1404 accuracy: 0.9502 f1: 0.9494
2023-07-14 02:52:09,104 epoch [150/800] time: 4.99s train loss: 0.0673 accuracy: 0.9804 f1: 0.9803
2023-07-14 02:52:09,964 epoch [150/800] time: 0.85s val loss: 0.1396 accuracy: 0.9506 f1: 0.9497
2023-07-14 02:52:14,954 epoch [151/800] time: 4.99s train loss: 0.068 accuracy: 0.9798 f1: 0.9797
2023-07-14 02:52:15,848 epoch [151/800] time: 0.89s val loss: 0.1393 accuracy: 0.9504 f1: 0.9495
2023-07-14 02:52:20,795 epoch [152/800] time: 4.95s train loss: 0.0679 accuracy: 0.98 f1: 0.9798
2023-07-14 02:52:21,692 epoch [152/800] time: 0.9s val loss: 0.14 accuracy: 0.9508 f1: 0.95
2023-07-14 02:52:26,793 epoch [153/800] time: 5.1s train loss: 0.0691 accuracy: 0.9799 f1: 0.9798
2023-07-14 02:52:27,626 epoch [153/800] time: 0.83s val loss: 0.1394 accuracy: 0.9501 f1: 0.9494
2023-07-14 02:52:32,683 epoch [154/800] time: 5.06s train loss: 0.0667 accuracy: 0.98 f1: 0.9797
2023-07-14 02:52:33,546 epoch [154/800] time: 0.86s val loss: 0.1396 accuracy: 0.9504 f1: 0.9497
2023-07-14 02:52:38,150 epoch [155/800] time: 4.6s train loss: 0.0664 accuracy: 0.9808 f1: 0.9807
2023-07-14 02:52:39,006 epoch [155/800] time: 0.85s val loss: 0.1396 accuracy: 0.9504 f1: 0.9495
2023-07-14 02:52:43,591 epoch [156/800] time: 4.58s train loss: 0.0664 accuracy: 0.9801 f1: 0.9799
2023-07-14 02:52:44,424 epoch [156/800] time: 0.83s val loss: 0.1399 accuracy: 0.9505 f1: 0.9497
2023-07-14 02:52:49,159 epoch [157/800] time: 4.73s train loss: 0.0665 accuracy: 0.9804 f1: 0.9802
2023-07-14 02:52:50,011 epoch [157/800] time: 0.85s val loss: 0.1395 accuracy: 0.9512 f1: 0.9503
2023-07-14 02:52:54,592 epoch [158/800] time: 4.58s train loss: 0.0682 accuracy: 0.9803 f1: 0.9803
2023-07-14 02:52:55,447 epoch [158/800] time: 0.85s val loss: 0.1411 accuracy: 0.9492 f1: 0.9482
2023-07-14 02:53:00,403 epoch [159/800] time: 4.96s train loss: 0.067 accuracy: 0.9802 f1: 0.9802
2023-07-14 02:53:01,216 epoch [159/800] time: 0.81s val loss: 0.1405 accuracy: 0.9501 f1: 0.9493
2023-07-14 02:53:05,935 epoch [160/800] time: 4.72s train loss: 0.0663 accuracy: 0.9805 f1: 0.9804
2023-07-14 02:53:06,790 epoch [160/800] time: 0.85s val loss: 0.1396 accuracy: 0.951 f1: 0.9502
2023-07-14 02:53:11,507 epoch [161/800] time: 4.72s train loss: 0.0659 accuracy: 0.9811 f1: 0.9811
2023-07-14 02:53:12,373 epoch [161/800] time: 0.86s val loss: 0.1402 accuracy: 0.9503 f1: 0.9495
2023-07-14 02:53:17,137 epoch [162/800] time: 4.76s train loss: 0.0657 accuracy: 0.9809 f1: 0.9807
2023-07-14 02:53:17,942 epoch [162/800] time: 0.8s val loss: 0.1385 accuracy: 0.9513 f1: 0.9505
2023-07-14 02:53:22,505 epoch [163/800] time: 4.56s train loss: 0.0656 accuracy: 0.9808 f1: 0.9807
2023-07-14 02:53:23,352 epoch [163/800] time: 0.85s val loss: 0.1395 accuracy: 0.9505 f1: 0.9498
2023-07-14 02:53:27,868 epoch [164/800] time: 4.52s train loss: 0.0664 accuracy: 0.9806 f1: 0.9804
2023-07-14 02:53:28,713 epoch [164/800] time: 0.84s val loss: 0.1394 accuracy: 0.9508 f1: 0.95
2023-07-14 02:53:33,244 epoch [165/800] time: 4.53s train loss: 0.0654 accuracy: 0.9808 f1: 0.9807
2023-07-14 02:53:34,045 epoch [165/800] time: 0.8s val loss: 0.1387 accuracy: 0.9512 f1: 0.9504
2023-07-14 02:53:38,567 epoch [166/800] time: 4.52s train loss: 0.0664 accuracy: 0.9805 f1: 0.9804
2023-07-14 02:53:39,408 epoch [166/800] time: 0.84s val loss: 0.1388 accuracy: 0.9514 f1: 0.9506
2023-07-14 02:53:43,917 epoch [167/800] time: 4.51s train loss: 0.0665 accuracy: 0.9802 f1: 0.9801
2023-07-14 02:53:44,758 epoch [167/800] time: 0.84s val loss: 0.1389 accuracy: 0.9508 f1: 0.95
2023-07-14 02:53:49,338 epoch [168/800] time: 4.58s train loss: 0.0645 accuracy: 0.9807 f1: 0.9806
2023-07-14 02:53:50,142 epoch [168/800] time: 0.8s val loss: 0.1401 accuracy: 0.9499 f1: 0.949
2023-07-14 02:53:54,758 epoch [169/800] time: 4.62s train loss: 0.066 accuracy: 0.9809 f1: 0.9808
2023-07-14 02:53:55,600 epoch [169/800] time: 0.84s val loss: 0.1393 accuracy: 0.951 f1: 0.9503
2023-07-14 02:54:00,190 epoch [170/800] time: 4.59s train loss: 0.0659 accuracy: 0.9802 f1: 0.9802
2023-07-14 02:54:01,044 epoch [170/800] time: 0.85s val loss: 0.1394 accuracy: 0.9505 f1: 0.9497
2023-07-14 02:54:05,722 epoch [171/800] time: 4.68s train loss: 0.0662 accuracy: 0.981 f1: 0.981
2023-07-14 02:54:06,533 epoch [171/800] time: 0.81s val loss: 0.1394 accuracy: 0.9507 f1: 0.95
2023-07-14 02:54:11,240 epoch [172/800] time: 4.71s train loss: 0.0662 accuracy: 0.9804 f1: 0.9802
2023-07-14 02:54:12,090 epoch [172/800] time: 0.85s val loss: 0.1391 accuracy: 0.9506 f1: 0.9498
2023-07-14 02:54:16,799 epoch [173/800] time: 4.71s train loss: 0.0659 accuracy: 0.9805 f1: 0.9803
2023-07-14 02:54:17,649 epoch [173/800] time: 0.85s val loss: 0.139 accuracy: 0.9505 f1: 0.9497
2023-07-14 02:54:22,657 epoch [174/800] time: 5.01s train loss: 0.0653 accuracy: 0.9811 f1: 0.981
2023-07-14 02:54:23,537 epoch [174/800] time: 0.88s val loss: 0.1397 accuracy: 0.9502 f1: 0.9492
2023-07-14 02:54:28,405 epoch [175/800] time: 4.87s train loss: 0.0663 accuracy: 0.9807 f1: 0.9806
2023-07-14 02:54:29,267 epoch [175/800] time: 0.86s val loss: 0.1398 accuracy: 0.9506 f1: 0.9498
2023-07-14 02:54:34,205 epoch [176/800] time: 4.94s train loss: 0.0656 accuracy: 0.9805 f1: 0.9804
2023-07-14 02:54:35,127 epoch [176/800] time: 0.92s val loss: 0.1384 accuracy: 0.9508 f1: 0.9501
2023-07-14 02:54:40,210 epoch [177/800] time: 5.08s train loss: 0.0658 accuracy: 0.9806 f1: 0.9805
2023-07-14 02:54:41,029 epoch [177/800] time: 0.82s val loss: 0.1397 accuracy: 0.9509 f1: 0.9501
2023-07-14 02:54:45,788 epoch [178/800] time: 4.76s train loss: 0.0645 accuracy: 0.9811 f1: 0.981
2023-07-14 02:54:46,650 epoch [178/800] time: 0.86s val loss: 0.1392 accuracy: 0.9508 f1: 0.95
2023-07-14 02:54:51,264 epoch [179/800] time: 4.61s train loss: 0.0653 accuracy: 0.981 f1: 0.9809
2023-07-14 02:54:52,113 epoch [179/800] time: 0.85s val loss: 0.1401 accuracy: 0.95 f1: 0.9491
2023-07-14 02:54:56,681 epoch [180/800] time: 4.57s train loss: 0.0658 accuracy: 0.9807 f1: 0.9805
2023-07-14 02:54:57,485 epoch [180/800] time: 0.8s val loss: 0.1393 accuracy: 0.95 f1: 0.9491
2023-07-14 02:55:02,051 epoch [181/800] time: 4.57s train loss: 0.0643 accuracy: 0.9818 f1: 0.9816
2023-07-14 02:55:02,900 epoch [181/800] time: 0.84s val loss: 0.1396 accuracy: 0.9502 f1: 0.9493
2023-07-14 02:55:07,759 epoch [182/800] time: 4.86s train loss: 0.0649 accuracy: 0.9814 f1: 0.9812
2023-07-14 02:55:08,620 epoch [182/800] time: 0.86s val loss: 0.1385 accuracy: 0.9509 f1: 0.9501
2023-07-14 02:55:13,227 epoch [183/800] time: 4.61s train loss: 0.0655 accuracy: 0.981 f1: 0.9809
2023-07-14 02:55:14,034 epoch [183/800] time: 0.81s val loss: 0.1394 accuracy: 0.95 f1: 0.9493
2023-07-14 02:55:18,819 epoch [184/800] time: 4.79s train loss: 0.0657 accuracy: 0.9807 f1: 0.9805
2023-07-14 02:55:19,698 epoch [184/800] time: 0.88s val loss: 0.1402 accuracy: 0.9496 f1: 0.9487
2023-07-14 02:55:24,356 epoch [185/800] time: 4.66s train loss: 0.0652 accuracy: 0.981 f1: 0.9808
2023-07-14 02:55:25,209 epoch [185/800] time: 0.85s val loss: 0.1401 accuracy: 0.9506 f1: 0.9497
2023-07-14 02:55:29,904 epoch [186/800] time: 4.69s train loss: 0.0652 accuracy: 0.9813 f1: 0.9812
2023-07-14 02:55:30,732 epoch [186/800] time: 0.83s val loss: 0.1396 accuracy: 0.9509 f1: 0.9502
2023-07-14 02:55:35,558 epoch [187/800] time: 4.83s train loss: 0.065 accuracy: 0.9814 f1: 0.9812
2023-07-14 02:55:36,424 epoch [187/800] time: 0.87s val loss: 0.139 accuracy: 0.9509 f1: 0.9501
2023-07-14 02:55:41,155 epoch [188/800] time: 4.73s train loss: 0.0654 accuracy: 0.9812 f1: 0.9809
2023-07-14 02:55:42,010 epoch [188/800] time: 0.85s val loss: 0.1398 accuracy: 0.9509 f1: 0.95
2023-07-14 02:55:46,812 epoch [189/800] time: 4.8s train loss: 0.0641 accuracy: 0.9817 f1: 0.9816
2023-07-14 02:55:47,631 epoch [189/800] time: 0.82s val loss: 0.1388 accuracy: 0.951 f1: 0.9502
2023-07-14 02:55:52,458 epoch [190/800] time: 4.83s train loss: 0.0659 accuracy: 0.9811 f1: 0.9809
2023-07-14 02:55:53,349 epoch [190/800] time: 0.89s val loss: 0.1405 accuracy: 0.9499 f1: 0.949
2023-07-14 02:55:58,220 epoch [191/800] time: 4.87s train loss: 0.0643 accuracy: 0.9817 f1: 0.9816
2023-07-14 02:55:59,085 epoch [191/800] time: 0.86s val loss: 0.1386 accuracy: 0.9509 f1: 0.9501
2023-07-14 02:56:03,873 epoch [192/800] time: 4.79s train loss: 0.0651 accuracy: 0.9807 f1: 0.9806
2023-07-14 02:56:04,682 epoch [192/800] time: 0.81s val loss: 0.1394 accuracy: 0.951 f1: 0.9501
2023-07-14 02:56:09,503 epoch [193/800] time: 4.82s train loss: 0.0651 accuracy: 0.9808 f1: 0.9807
2023-07-14 02:56:10,356 epoch [193/800] time: 0.85s val loss: 0.1396 accuracy: 0.9503 f1: 0.9495
2023-07-14 02:56:15,171 epoch [194/800] time: 4.81s train loss: 0.0648 accuracy: 0.981 f1: 0.9809
2023-07-14 02:56:16,055 epoch [194/800] time: 0.88s val loss: 0.1394 accuracy: 0.9507 f1: 0.9499
2023-07-14 02:56:20,947 epoch [195/800] time: 4.89s train loss: 0.0653 accuracy: 0.9809 f1: 0.9809
2023-07-14 02:56:21,753 epoch [195/800] time: 0.81s val loss: 0.1389 accuracy: 0.9506 f1: 0.9499
2023-07-14 02:56:26,545 epoch [196/800] time: 4.79s train loss: 0.0673 accuracy: 0.9808 f1: 0.9806
2023-07-14 02:56:27,428 epoch [196/800] time: 0.88s val loss: 0.1389 accuracy: 0.9508 f1: 0.95
2023-07-14 02:56:32,152 epoch [197/800] time: 4.72s train loss: 0.0652 accuracy: 0.9809 f1: 0.9808
2023-07-14 02:56:32,996 epoch [197/800] time: 0.84s val loss: 0.1388 accuracy: 0.9513 f1: 0.9505
2023-07-14 02:56:37,797 epoch [198/800] time: 4.8s train loss: 0.0654 accuracy: 0.9809 f1: 0.9809
2023-07-14 02:56:38,601 epoch [198/800] time: 0.8s val loss: 0.1394 accuracy: 0.9509 f1: 0.9502
2023-07-14 02:56:43,281 epoch [199/800] time: 4.68s train loss: 0.0669 accuracy: 0.9811 f1: 0.981
2023-07-14 02:56:44,130 epoch [199/800] time: 0.85s val loss: 0.1408 accuracy: 0.9504 f1: 0.9497
2023-07-14 02:56:48,860 epoch [200/800] time: 4.73s train loss: 0.0663 accuracy: 0.9815 f1: 0.9813
2023-07-14 02:56:49,711 epoch [200/800] time: 0.85s val loss: 0.14 accuracy: 0.9513 f1: 0.9505
2023-07-14 02:56:54,459 epoch [201/800] time: 4.75s train loss: 0.0638 accuracy: 0.9818 f1: 0.9817
2023-07-14 02:56:55,265 epoch [201/800] time: 0.8s val loss: 0.1396 accuracy: 0.9512 f1: 0.9505
2023-07-14 02:57:00,020 epoch [202/800] time: 4.75s train loss: 0.0644 accuracy: 0.9816 f1: 0.9814
2023-07-14 02:57:00,864 epoch [202/800] time: 0.84s val loss: 0.1385 accuracy: 0.9509 f1: 0.9501
2023-07-14 02:57:05,559 epoch [203/800] time: 4.7s train loss: 0.0657 accuracy: 0.9805 f1: 0.9804
2023-07-14 02:57:06,413 epoch [203/800] time: 0.85s val loss: 0.1387 accuracy: 0.9508 f1: 0.9501
2023-07-14 02:57:11,091 epoch [204/800] time: 4.68s train loss: 0.0637 accuracy: 0.9813 f1: 0.9811
2023-07-14 02:57:11,890 epoch [204/800] time: 0.8s val loss: 0.1396 accuracy: 0.9507 f1: 0.9499
2023-07-14 02:57:16,635 epoch [205/800] time: 4.74s train loss: 0.0642 accuracy: 0.9814 f1: 0.9813
2023-07-14 02:57:17,483 epoch [205/800] time: 0.85s val loss: 0.1399 accuracy: 0.9498 f1: 0.9489
2023-07-14 02:57:22,199 epoch [206/800] time: 4.72s train loss: 0.0655 accuracy: 0.9809 f1: 0.9808
2023-07-14 02:57:23,155 epoch [206/800] time: 0.96s val loss: 0.1391 accuracy: 0.9506 f1: 0.9498
2023-07-14 02:57:28,006 epoch [207/800] time: 4.85s train loss: 0.0645 accuracy: 0.9812 f1: 0.9811
2023-07-14 02:57:28,891 epoch [207/800] time: 0.88s val loss: 0.1389 accuracy: 0.951 f1: 0.9503
2023-07-14 02:57:33,859 epoch [208/800] time: 4.97s train loss: 0.0657 accuracy: 0.9811 f1: 0.981
2023-07-14 02:57:34,726 epoch [208/800] time: 0.87s val loss: 0.1393 accuracy: 0.9506 f1: 0.9498
2023-07-14 02:57:39,703 epoch [209/800] time: 4.98s train loss: 0.0651 accuracy: 0.9811 f1: 0.9811
2023-07-14 02:57:40,587 epoch [209/800] time: 0.88s val loss: 0.139 accuracy: 0.951 f1: 0.9504
2023-07-14 02:57:45,701 epoch [210/800] time: 5.11s train loss: 0.064 accuracy: 0.9816 f1: 0.9815
2023-07-14 02:57:46,548 epoch [210/800] time: 0.85s val loss: 0.1386 accuracy: 0.9509 f1: 0.95
2023-07-14 02:57:51,522 epoch [211/800] time: 4.97s train loss: 0.0666 accuracy: 0.9808 f1: 0.9808
2023-07-14 02:57:52,413 epoch [211/800] time: 0.89s val loss: 0.1407 accuracy: 0.95 f1: 0.9492
2023-07-14 02:57:57,444 epoch [212/800] time: 5.03s train loss: 0.0641 accuracy: 0.9811 f1: 0.9809
2023-07-14 02:57:58,411 epoch [212/800] time: 0.97s val loss: 0.1399 accuracy: 0.9501 f1: 0.9492
2023-07-14 02:58:03,553 epoch [213/800] time: 5.14s train loss: 0.0646 accuracy: 0.9812 f1: 0.981
2023-07-14 02:58:04,387 epoch [213/800] time: 0.83s val loss: 0.1399 accuracy: 0.9505 f1: 0.9498
2023-07-14 02:58:09,517 epoch [214/800] time: 5.13s train loss: 0.0641 accuracy: 0.9821 f1: 0.982
2023-07-14 02:58:10,425 epoch [214/800] time: 0.9s val loss: 0.1394 accuracy: 0.9504 f1: 0.9495
2023-07-14 02:58:15,659 epoch [215/800] time: 5.23s train loss: 0.0643 accuracy: 0.9812 f1: 0.9812
2023-07-14 02:58:16,561 epoch [215/800] time: 0.9s val loss: 0.139 accuracy: 0.9509 f1: 0.9502
2023-07-14 02:58:21,571 epoch [216/800] time: 5.01s train loss: 0.064 accuracy: 0.9819 f1: 0.9818
2023-07-14 02:58:22,401 epoch [216/800] time: 0.83s val loss: 0.1399 accuracy: 0.9509 f1: 0.9502
2023-07-14 02:58:27,469 epoch [217/800] time: 5.07s train loss: 0.0655 accuracy: 0.9805 f1: 0.9803
2023-07-14 02:58:28,336 epoch [217/800] time: 0.87s val loss: 0.1395 accuracy: 0.9507 f1: 0.9498
2023-07-14 02:58:33,130 epoch [218/800] time: 4.79s train loss: 0.0647 accuracy: 0.9817 f1: 0.9816
2023-07-14 02:58:33,990 epoch [218/800] time: 0.86s val loss: 0.1396 accuracy: 0.9508 f1: 0.9501
2023-07-14 02:58:38,830 epoch [219/800] time: 4.84s train loss: 0.0636 accuracy: 0.9817 f1: 0.9816
2023-07-14 02:58:39,651 epoch [219/800] time: 0.82s val loss: 0.1392 accuracy: 0.951 f1: 0.9502
2023-07-14 02:58:44,522 epoch [220/800] time: 4.87s train loss: 0.0658 accuracy: 0.9809 f1: 0.9809
2023-07-14 02:58:45,371 epoch [220/800] time: 0.85s val loss: 0.1397 accuracy: 0.9503 f1: 0.9494
2023-07-14 02:58:50,140 epoch [221/800] time: 4.77s train loss: 0.0651 accuracy: 0.9814 f1: 0.9813
2023-07-14 02:58:51,048 epoch [221/800] time: 0.91s val loss: 0.1388 accuracy: 0.951 f1: 0.9503
2023-07-14 02:58:55,978 epoch [222/800] time: 4.93s train loss: 0.0645 accuracy: 0.9815 f1: 0.9814
2023-07-14 02:58:56,782 epoch [222/800] time: 0.8s val loss: 0.1393 accuracy: 0.9508 f1: 0.95
2023-07-14 02:59:01,560 epoch [223/800] time: 4.78s train loss: 0.0642 accuracy: 0.9812 f1: 0.9811
2023-07-14 02:59:02,416 epoch [223/800] time: 0.86s val loss: 0.1394 accuracy: 0.9507 f1: 0.9498
2023-07-14 02:59:07,308 epoch [224/800] time: 4.89s train loss: 0.0636 accuracy: 0.9817 f1: 0.9815
2023-07-14 02:59:08,171 epoch [224/800] time: 0.86s val loss: 0.1387 accuracy: 0.9511 f1: 0.9504
2023-07-14 02:59:12,971 epoch [225/800] time: 4.8s train loss: 0.0649 accuracy: 0.9816 f1: 0.9814
2023-07-14 02:59:13,797 epoch [225/800] time: 0.83s val loss: 0.139 accuracy: 0.9508 f1: 0.95
2023-07-14 02:59:18,465 epoch [226/800] time: 4.67s train loss: 0.0647 accuracy: 0.9812 f1: 0.981
2023-07-14 02:59:19,313 epoch [226/800] time: 0.85s val loss: 0.1388 accuracy: 0.9511 f1: 0.9502
2023-07-14 02:59:24,021 epoch [227/800] time: 4.71s train loss: 0.064 accuracy: 0.9819 f1: 0.9818
2023-07-14 02:59:24,876 epoch [227/800] time: 0.86s val loss: 0.1393 accuracy: 0.9506 f1: 0.9498
2023-07-14 02:59:29,567 epoch [228/800] time: 4.69s train loss: 0.0642 accuracy: 0.9812 f1: 0.9811
2023-07-14 02:59:30,373 epoch [228/800] time: 0.81s val loss: 0.1391 accuracy: 0.9508 f1: 0.95
2023-07-14 02:59:35,207 epoch [229/800] time: 4.83s train loss: 0.0642 accuracy: 0.9813 f1: 0.9812
2023-07-14 02:59:36,088 epoch [229/800] time: 0.88s val loss: 0.1397 accuracy: 0.9505 f1: 0.9497
2023-07-14 02:59:40,892 epoch [230/800] time: 4.8s train loss: 0.0661 accuracy: 0.9812 f1: 0.981
2023-07-14 02:59:41,735 epoch [230/800] time: 0.84s val loss: 0.1392 accuracy: 0.9509 f1: 0.9502
2023-07-14 02:59:46,436 epoch [231/800] time: 4.7s train loss: 0.0647 accuracy: 0.9811 f1: 0.9809
2023-07-14 02:59:47,266 epoch [231/800] time: 0.83s val loss: 0.1397 accuracy: 0.9504 f1: 0.9497
2023-07-14 02:59:52,252 epoch [232/800] time: 4.99s train loss: 0.0645 accuracy: 0.9813 f1: 0.9812
2023-07-14 02:59:53,110 epoch [232/800] time: 0.86s val loss: 0.1401 accuracy: 0.9505 f1: 0.9497
2023-07-14 02:59:57,673 epoch [233/800] time: 4.56s train loss: 0.0646 accuracy: 0.9814 f1: 0.9811
2023-07-14 02:59:58,526 epoch [233/800] time: 0.85s val loss: 0.1398 accuracy: 0.9502 f1: 0.9493
2023-07-14 03:00:03,149 epoch [234/800] time: 4.62s train loss: 0.0636 accuracy: 0.9818 f1: 0.9816
2023-07-14 03:00:03,952 epoch [234/800] time: 0.8s val loss: 0.1391 accuracy: 0.9504 f1: 0.9496
2023-07-14 03:00:08,500 epoch [235/800] time: 4.55s train loss: 0.0633 accuracy: 0.982 f1: 0.982
2023-07-14 03:00:09,348 epoch [235/800] time: 0.85s val loss: 0.1388 accuracy: 0.9507 f1: 0.95
2023-07-14 03:00:14,077 epoch [236/800] time: 4.73s train loss: 0.0652 accuracy: 0.9809 f1: 0.9808
2023-07-14 03:00:14,922 epoch [236/800] time: 0.85s val loss: 0.1397 accuracy: 0.9502 f1: 0.9495
2023-07-14 03:00:19,590 epoch [237/800] time: 4.67s train loss: 0.0641 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:00:20,390 epoch [237/800] time: 0.8s val loss: 0.1397 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:00:25,142 epoch [238/800] time: 4.75s train loss: 0.0638 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:00:25,986 epoch [238/800] time: 0.84s val loss: 0.1405 accuracy: 0.95 f1: 0.9492
2023-07-14 03:00:30,550 epoch [239/800] time: 4.56s train loss: 0.0641 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:00:31,394 epoch [239/800] time: 0.84s val loss: 0.1399 accuracy: 0.9508 f1: 0.95
2023-07-14 03:00:36,091 epoch [240/800] time: 4.7s train loss: 0.0646 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:00:36,892 epoch [240/800] time: 0.8s val loss: 0.1399 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:00:41,662 epoch [241/800] time: 4.77s train loss: 0.0649 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:00:42,505 epoch [241/800] time: 0.84s val loss: 0.1397 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:00:47,101 epoch [242/800] time: 4.6s train loss: 0.0642 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:00:47,945 epoch [242/800] time: 0.84s val loss: 0.1398 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:00:52,660 epoch [243/800] time: 4.71s train loss: 0.066 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:00:53,462 epoch [243/800] time: 0.8s val loss: 0.1406 accuracy: 0.9506 f1: 0.9497
2023-07-14 03:00:58,227 epoch [244/800] time: 4.77s train loss: 0.0636 accuracy: 0.9819 f1: 0.9818
2023-07-14 03:00:59,071 epoch [244/800] time: 0.84s val loss: 0.1385 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:01:03,772 epoch [245/800] time: 4.7s train loss: 0.0644 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:01:04,618 epoch [245/800] time: 0.85s val loss: 0.1401 accuracy: 0.9501 f1: 0.9492
2023-07-14 03:01:09,377 epoch [246/800] time: 4.76s train loss: 0.0639 accuracy: 0.9812 f1: 0.9812
2023-07-14 03:01:10,179 epoch [246/800] time: 0.8s val loss: 0.1386 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:01:14,944 epoch [247/800] time: 4.77s train loss: 0.063 accuracy: 0.9817 f1: 0.9815
2023-07-14 03:01:15,800 epoch [247/800] time: 0.86s val loss: 0.1397 accuracy: 0.9504 f1: 0.9495
2023-07-14 03:01:20,551 epoch [248/800] time: 4.75s train loss: 0.0647 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:01:21,395 epoch [248/800] time: 0.84s val loss: 0.1392 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:01:26,178 epoch [249/800] time: 4.78s train loss: 0.0645 accuracy: 0.9812 f1: 0.981
2023-07-14 03:01:26,977 epoch [249/800] time: 0.8s val loss: 0.1395 accuracy: 0.9504 f1: 0.9495
2023-07-14 03:01:31,769 epoch [250/800] time: 4.79s train loss: 0.0643 accuracy: 0.9813 f1: 0.9813
2023-07-14 03:01:32,662 epoch [250/800] time: 0.89s val loss: 0.1397 accuracy: 0.9509 f1: 0.95
2023-07-14 03:01:38,661 epoch [251/800] time: 6.0s train loss: 0.0633 accuracy: 0.9814 f1: 0.9814
2023-07-14 03:01:39,574 epoch [251/800] time: 0.91s val loss: 0.139 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:01:44,728 epoch [252/800] time: 5.15s train loss: 0.0639 accuracy: 0.9813 f1: 0.9813
2023-07-14 03:01:45,624 epoch [252/800] time: 0.9s val loss: 0.1388 accuracy: 0.9508 f1: 0.95
2023-07-14 03:01:50,690 epoch [253/800] time: 5.07s train loss: 0.0659 accuracy: 0.9817 f1: 0.9815
2023-07-14 03:01:51,566 epoch [253/800] time: 0.88s val loss: 0.1397 accuracy: 0.9504 f1: 0.9496
2023-07-14 03:01:56,399 epoch [254/800] time: 4.83s train loss: 0.0633 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:01:57,348 epoch [254/800] time: 0.95s val loss: 0.1386 accuracy: 0.9506 f1: 0.9499
2023-07-14 03:02:02,283 epoch [255/800] time: 4.93s train loss: 0.0637 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:02:03,094 epoch [255/800] time: 0.81s val loss: 0.1386 accuracy: 0.9511 f1: 0.9504
2023-07-14 03:02:07,914 epoch [256/800] time: 4.82s train loss: 0.0639 accuracy: 0.9813 f1: 0.9813
2023-07-14 03:02:08,773 epoch [256/800] time: 0.86s val loss: 0.1385 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:02:13,603 epoch [257/800] time: 4.83s train loss: 0.0649 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:02:14,500 epoch [257/800] time: 0.9s val loss: 0.1385 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:02:19,336 epoch [258/800] time: 4.84s train loss: 0.0645 accuracy: 0.9814 f1: 0.9814
2023-07-14 03:02:20,156 epoch [258/800] time: 0.82s val loss: 0.1387 accuracy: 0.9505 f1: 0.9496
2023-07-14 03:02:25,118 epoch [259/800] time: 4.96s train loss: 0.0651 accuracy: 0.9805 f1: 0.9803
2023-07-14 03:02:25,987 epoch [259/800] time: 0.87s val loss: 0.1401 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:02:30,809 epoch [260/800] time: 4.82s train loss: 0.0637 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:02:31,685 epoch [260/800] time: 0.88s val loss: 0.1407 accuracy: 0.95 f1: 0.9491
2023-07-14 03:02:36,590 epoch [261/800] time: 4.9s train loss: 0.0643 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:02:37,399 epoch [261/800] time: 0.81s val loss: 0.139 accuracy: 0.9512 f1: 0.9504
2023-07-14 03:02:42,219 epoch [262/800] time: 4.82s train loss: 0.0644 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:02:43,070 epoch [262/800] time: 0.85s val loss: 0.1395 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:02:47,881 epoch [263/800] time: 4.81s train loss: 0.065 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:02:48,776 epoch [263/800] time: 0.9s val loss: 0.1394 accuracy: 0.9503 f1: 0.9494
2023-07-14 03:02:53,600 epoch [264/800] time: 4.82s train loss: 0.0635 accuracy: 0.9819 f1: 0.9818
2023-07-14 03:02:54,409 epoch [264/800] time: 0.81s val loss: 0.1391 accuracy: 0.9504 f1: 0.9496
2023-07-14 03:02:59,204 epoch [265/800] time: 4.79s train loss: 0.0646 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:03:00,063 epoch [265/800] time: 0.86s val loss: 0.1391 accuracy: 0.9509 f1: 0.9502
2023-07-14 03:03:04,852 epoch [266/800] time: 4.79s train loss: 0.0646 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:03:05,703 epoch [266/800] time: 0.85s val loss: 0.139 accuracy: 0.9512 f1: 0.9504
2023-07-14 03:03:10,566 epoch [267/800] time: 4.86s train loss: 0.0631 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:03:11,372 epoch [267/800] time: 0.8s val loss: 0.1392 accuracy: 0.9508 f1: 0.9499
2023-07-14 03:03:16,172 epoch [268/800] time: 4.8s train loss: 0.064 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:03:17,019 epoch [268/800] time: 0.85s val loss: 0.139 accuracy: 0.9512 f1: 0.9505
2023-07-14 03:03:21,740 epoch [269/800] time: 4.72s train loss: 0.0641 accuracy: 0.9811 f1: 0.981
2023-07-14 03:03:22,632 epoch [269/800] time: 0.89s val loss: 0.139 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:03:27,533 epoch [270/800] time: 4.9s train loss: 0.0646 accuracy: 0.9812 f1: 0.9812
2023-07-14 03:03:28,363 epoch [270/800] time: 0.83s val loss: 0.1393 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:03:33,326 epoch [271/800] time: 4.96s train loss: 0.0636 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:03:34,176 epoch [271/800] time: 0.85s val loss: 0.1385 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:03:38,756 epoch [272/800] time: 4.58s train loss: 0.0648 accuracy: 0.9813 f1: 0.9813
2023-07-14 03:03:39,655 epoch [272/800] time: 0.9s val loss: 0.1391 accuracy: 0.951 f1: 0.9502
2023-07-14 03:03:44,336 epoch [273/800] time: 4.68s train loss: 0.063 accuracy: 0.9817 f1: 0.9815
2023-07-14 03:03:45,136 epoch [273/800] time: 0.8s val loss: 0.1386 accuracy: 0.9513 f1: 0.9505
2023-07-14 03:03:49,734 epoch [274/800] time: 4.6s train loss: 0.0643 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:03:50,611 epoch [274/800] time: 0.88s val loss: 0.1392 accuracy: 0.9513 f1: 0.9505
2023-07-14 03:03:55,663 epoch [275/800] time: 5.05s train loss: 0.0649 accuracy: 0.981 f1: 0.9809
2023-07-14 03:03:56,618 epoch [275/800] time: 0.96s val loss: 0.1394 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:04:01,476 epoch [276/800] time: 4.86s train loss: 0.0639 accuracy: 0.9817 f1: 0.9815
2023-07-14 03:04:02,283 epoch [276/800] time: 0.81s val loss: 0.1391 accuracy: 0.9508 f1: 0.9499
2023-07-14 03:04:07,231 epoch [277/800] time: 4.95s train loss: 0.0639 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:04:08,080 epoch [277/800] time: 0.85s val loss: 0.1383 accuracy: 0.9507 f1: 0.95
2023-07-14 03:04:12,925 epoch [278/800] time: 4.84s train loss: 0.0643 accuracy: 0.9821 f1: 0.982
2023-07-14 03:04:13,804 epoch [278/800] time: 0.88s val loss: 0.1405 accuracy: 0.95 f1: 0.9492
2023-07-14 03:04:18,783 epoch [279/800] time: 4.98s train loss: 0.0637 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:04:19,596 epoch [279/800] time: 0.81s val loss: 0.139 accuracy: 0.9504 f1: 0.9495
2023-07-14 03:04:24,461 epoch [280/800] time: 4.86s train loss: 0.0637 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:04:25,319 epoch [280/800] time: 0.86s val loss: 0.1387 accuracy: 0.9508 f1: 0.9499
2023-07-14 03:04:30,354 epoch [281/800] time: 5.03s train loss: 0.0627 accuracy: 0.9815 f1: 0.9812
2023-07-14 03:04:31,210 epoch [281/800] time: 0.86s val loss: 0.139 accuracy: 0.9507 f1: 0.9498
2023-07-14 03:04:36,053 epoch [282/800] time: 4.84s train loss: 0.0649 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:04:36,861 epoch [282/800] time: 0.81s val loss: 0.139 accuracy: 0.9508 f1: 0.95
2023-07-14 03:04:41,795 epoch [283/800] time: 4.93s train loss: 0.0639 accuracy: 0.9819 f1: 0.9817
2023-07-14 03:04:42,683 epoch [283/800] time: 0.89s val loss: 0.14 accuracy: 0.9502 f1: 0.9494
2023-07-14 03:04:47,414 epoch [284/800] time: 4.73s train loss: 0.0642 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:04:48,308 epoch [284/800] time: 0.89s val loss: 0.1389 accuracy: 0.9509 f1: 0.95
2023-07-14 03:04:53,279 epoch [285/800] time: 4.97s train loss: 0.0644 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:04:54,139 epoch [285/800] time: 0.86s val loss: 0.1399 accuracy: 0.95 f1: 0.9491
2023-07-14 03:04:59,247 epoch [286/800] time: 5.11s train loss: 0.0628 accuracy: 0.9821 f1: 0.9819
2023-07-14 03:05:00,113 epoch [286/800] time: 0.87s val loss: 0.139 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:05:05,006 epoch [287/800] time: 4.89s train loss: 0.0666 accuracy: 0.981 f1: 0.9808
2023-07-14 03:05:05,884 epoch [287/800] time: 0.88s val loss: 0.1408 accuracy: 0.9502 f1: 0.9493
2023-07-14 03:05:10,817 epoch [288/800] time: 4.93s train loss: 0.0638 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:05:11,640 epoch [288/800] time: 0.82s val loss: 0.1396 accuracy: 0.9508 f1: 0.95
2023-07-14 03:05:16,360 epoch [289/800] time: 4.72s train loss: 0.0638 accuracy: 0.9818 f1: 0.9816
2023-07-14 03:05:17,230 epoch [289/800] time: 0.87s val loss: 0.1389 accuracy: 0.9514 f1: 0.9505
2023-07-14 03:05:22,018 epoch [290/800] time: 4.79s train loss: 0.0646 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:05:22,877 epoch [290/800] time: 0.86s val loss: 0.1398 accuracy: 0.9503 f1: 0.9495
2023-07-14 03:05:27,673 epoch [291/800] time: 4.8s train loss: 0.0638 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:05:28,484 epoch [291/800] time: 0.81s val loss: 0.1387 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:05:33,266 epoch [292/800] time: 4.78s train loss: 0.0637 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:05:34,151 epoch [292/800] time: 0.88s val loss: 0.1392 accuracy: 0.9506 f1: 0.9497
2023-07-14 03:05:38,827 epoch [293/800] time: 4.68s train loss: 0.0637 accuracy: 0.9811 f1: 0.9811
2023-07-14 03:05:39,690 epoch [293/800] time: 0.86s val loss: 0.14 accuracy: 0.9507 f1: 0.9498
2023-07-14 03:05:44,485 epoch [294/800] time: 4.79s train loss: 0.066 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:05:45,294 epoch [294/800] time: 0.81s val loss: 0.1403 accuracy: 0.9497 f1: 0.9488
2023-07-14 03:05:50,150 epoch [295/800] time: 4.86s train loss: 0.0641 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:05:51,007 epoch [295/800] time: 0.86s val loss: 0.1392 accuracy: 0.9514 f1: 0.9506
2023-07-14 03:05:55,817 epoch [296/800] time: 4.81s train loss: 0.0635 accuracy: 0.9817 f1: 0.9815
2023-07-14 03:05:56,675 epoch [296/800] time: 0.86s val loss: 0.1388 accuracy: 0.9502 f1: 0.9494
2023-07-14 03:06:01,499 epoch [297/800] time: 4.82s train loss: 0.0646 accuracy: 0.9812 f1: 0.981
2023-07-14 03:06:02,301 epoch [297/800] time: 0.8s val loss: 0.1396 accuracy: 0.9506 f1: 0.9496
2023-07-14 03:06:07,123 epoch [298/800] time: 4.82s train loss: 0.0645 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:06:07,974 epoch [298/800] time: 0.85s val loss: 0.1399 accuracy: 0.9508 f1: 0.95
2023-07-14 03:06:12,757 epoch [299/800] time: 4.78s train loss: 0.0622 accuracy: 0.9822 f1: 0.9822
2023-07-14 03:06:13,607 epoch [299/800] time: 0.84s val loss: 0.1393 accuracy: 0.9513 f1: 0.9506
2023-07-14 03:06:18,429 epoch [300/800] time: 4.82s train loss: 0.0638 accuracy: 0.9821 f1: 0.982
2023-07-14 03:06:19,232 epoch [300/800] time: 0.8s val loss: 0.1402 accuracy: 0.9508 f1: 0.95
2023-07-14 03:06:24,049 epoch [301/800] time: 4.82s train loss: 0.0642 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:06:24,908 epoch [301/800] time: 0.86s val loss: 0.1396 accuracy: 0.9507 f1: 0.9498
2023-07-14 03:06:29,825 epoch [302/800] time: 4.92s train loss: 0.0652 accuracy: 0.981 f1: 0.9808
2023-07-14 03:06:30,681 epoch [302/800] time: 0.86s val loss: 0.139 accuracy: 0.9504 f1: 0.9497
2023-07-14 03:06:35,566 epoch [303/800] time: 4.88s train loss: 0.0638 accuracy: 0.9817 f1: 0.9815
2023-07-14 03:06:36,455 epoch [303/800] time: 0.89s val loss: 0.1388 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:06:41,418 epoch [304/800] time: 4.96s train loss: 0.0634 accuracy: 0.9818 f1: 0.9816
2023-07-14 03:06:42,267 epoch [304/800] time: 0.85s val loss: 0.1407 accuracy: 0.9496 f1: 0.9487
2023-07-14 03:06:47,070 epoch [305/800] time: 4.8s train loss: 0.0646 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:06:47,989 epoch [305/800] time: 0.92s val loss: 0.1389 accuracy: 0.9514 f1: 0.9505
2023-07-14 03:06:53,095 epoch [306/800] time: 5.11s train loss: 0.0647 accuracy: 0.9811 f1: 0.981
2023-07-14 03:06:53,915 epoch [306/800] time: 0.82s val loss: 0.139 accuracy: 0.9507 f1: 0.9501
2023-07-14 03:06:58,730 epoch [307/800] time: 4.81s train loss: 0.0633 accuracy: 0.9817 f1: 0.9817
2023-07-14 03:06:59,587 epoch [307/800] time: 0.86s val loss: 0.1384 accuracy: 0.9514 f1: 0.9506
2023-07-14 03:07:04,718 epoch [308/800] time: 5.13s train loss: 0.0637 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:07:05,604 epoch [308/800] time: 0.89s val loss: 0.1392 accuracy: 0.9511 f1: 0.9503
2023-07-14 03:07:10,487 epoch [309/800] time: 4.88s train loss: 0.0639 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:07:11,318 epoch [309/800] time: 0.83s val loss: 0.1395 accuracy: 0.9504 f1: 0.9494
2023-07-14 03:07:16,486 epoch [310/800] time: 5.17s train loss: 0.065 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:07:17,399 epoch [310/800] time: 0.91s val loss: 0.1388 accuracy: 0.9507 f1: 0.9498
2023-07-14 03:07:22,349 epoch [311/800] time: 4.95s train loss: 0.0639 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:07:23,255 epoch [311/800] time: 0.91s val loss: 0.1388 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:07:28,379 epoch [312/800] time: 5.12s train loss: 0.0651 accuracy: 0.9811 f1: 0.981
2023-07-14 03:07:29,283 epoch [312/800] time: 0.9s val loss: 0.14 accuracy: 0.9511 f1: 0.9503
2023-07-14 03:07:34,454 epoch [313/800] time: 5.17s train loss: 0.0657 accuracy: 0.9812 f1: 0.981
2023-07-14 03:07:35,328 epoch [313/800] time: 0.87s val loss: 0.14 accuracy: 0.9504 f1: 0.9495
2023-07-14 03:07:40,381 epoch [314/800] time: 5.05s train loss: 0.0627 accuracy: 0.9819 f1: 0.9817
2023-07-14 03:07:41,314 epoch [314/800] time: 0.93s val loss: 0.1392 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:07:46,603 epoch [315/800] time: 5.29s train loss: 0.0647 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:07:47,423 epoch [315/800] time: 0.82s val loss: 0.1405 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:07:52,442 epoch [316/800] time: 5.02s train loss: 0.0653 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:07:53,335 epoch [316/800] time: 0.89s val loss: 0.1385 accuracy: 0.9511 f1: 0.9503
2023-07-14 03:07:58,416 epoch [317/800] time: 5.08s train loss: 0.0636 accuracy: 0.9818 f1: 0.9818
2023-07-14 03:07:59,318 epoch [317/800] time: 0.9s val loss: 0.1384 accuracy: 0.9513 f1: 0.9505
2023-07-14 03:08:04,451 epoch [318/800] time: 5.13s train loss: 0.064 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:08:05,266 epoch [318/800] time: 0.81s val loss: 0.14 accuracy: 0.9509 f1: 0.9502
2023-07-14 03:08:10,161 epoch [319/800] time: 4.89s train loss: 0.0652 accuracy: 0.9811 f1: 0.981
2023-07-14 03:08:11,054 epoch [319/800] time: 0.89s val loss: 0.1404 accuracy: 0.9504 f1: 0.9494
2023-07-14 03:08:16,144 epoch [320/800] time: 5.09s train loss: 0.0649 accuracy: 0.9811 f1: 0.981
2023-07-14 03:08:17,033 epoch [320/800] time: 0.89s val loss: 0.1397 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:08:21,916 epoch [321/800] time: 4.88s train loss: 0.0635 accuracy: 0.9819 f1: 0.9818
2023-07-14 03:08:22,726 epoch [321/800] time: 0.81s val loss: 0.1396 accuracy: 0.9508 f1: 0.95
2023-07-14 03:08:27,741 epoch [322/800] time: 5.01s train loss: 0.0635 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:08:28,665 epoch [322/800] time: 0.92s val loss: 0.139 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:08:33,592 epoch [323/800] time: 4.93s train loss: 0.0641 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:08:34,451 epoch [323/800] time: 0.86s val loss: 0.1399 accuracy: 0.9506 f1: 0.9499
2023-07-14 03:08:39,203 epoch [324/800] time: 4.75s train loss: 0.0642 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:08:40,010 epoch [324/800] time: 0.81s val loss: 0.1392 accuracy: 0.9506 f1: 0.9496
2023-07-14 03:08:44,961 epoch [325/800] time: 4.95s train loss: 0.0632 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:08:45,828 epoch [325/800] time: 0.87s val loss: 0.1387 accuracy: 0.9508 f1: 0.95
2023-07-14 03:08:50,484 epoch [326/800] time: 4.66s train loss: 0.0644 accuracy: 0.9811 f1: 0.981
2023-07-14 03:08:51,335 epoch [326/800] time: 0.85s val loss: 0.1405 accuracy: 0.9501 f1: 0.9492
2023-07-14 03:08:56,096 epoch [327/800] time: 4.76s train loss: 0.064 accuracy: 0.9819 f1: 0.9818
2023-07-14 03:08:56,939 epoch [327/800] time: 0.84s val loss: 0.1387 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:09:01,834 epoch [328/800] time: 4.89s train loss: 0.0631 accuracy: 0.9821 f1: 0.9821
2023-07-14 03:09:02,725 epoch [328/800] time: 0.89s val loss: 0.1389 accuracy: 0.9515 f1: 0.9508
2023-07-14 03:09:07,660 epoch [329/800] time: 4.93s train loss: 0.0644 accuracy: 0.9814 f1: 0.9812
2023-07-14 03:09:08,527 epoch [329/800] time: 0.87s val loss: 0.1392 accuracy: 0.9504 f1: 0.9496
2023-07-14 03:09:13,634 epoch [330/800] time: 5.11s train loss: 0.0638 accuracy: 0.9821 f1: 0.982
2023-07-14 03:09:14,459 epoch [330/800] time: 0.83s val loss: 0.1398 accuracy: 0.9507 f1: 0.95
2023-07-14 03:09:19,492 epoch [331/800] time: 5.03s train loss: 0.0639 accuracy: 0.9818 f1: 0.9818
2023-07-14 03:09:20,366 epoch [331/800] time: 0.87s val loss: 0.1393 accuracy: 0.9506 f1: 0.9497
2023-07-14 03:09:25,175 epoch [332/800] time: 4.81s train loss: 0.0659 accuracy: 0.9808 f1: 0.9806
2023-07-14 03:09:26,027 epoch [332/800] time: 0.85s val loss: 0.1391 accuracy: 0.951 f1: 0.9502
2023-07-14 03:09:30,871 epoch [333/800] time: 4.84s train loss: 0.0638 accuracy: 0.9821 f1: 0.9819
2023-07-14 03:09:31,704 epoch [333/800] time: 0.83s val loss: 0.1401 accuracy: 0.95 f1: 0.9492
2023-07-14 03:09:36,678 epoch [334/800] time: 4.97s train loss: 0.0633 accuracy: 0.9818 f1: 0.9816
2023-07-14 03:09:37,537 epoch [334/800] time: 0.86s val loss: 0.1384 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:09:42,293 epoch [335/800] time: 4.76s train loss: 0.0642 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:09:43,145 epoch [335/800] time: 0.85s val loss: 0.1393 accuracy: 0.9508 f1: 0.95
2023-07-14 03:09:48,073 epoch [336/800] time: 4.93s train loss: 0.0649 accuracy: 0.9812 f1: 0.9812
2023-07-14 03:09:48,897 epoch [336/800] time: 0.82s val loss: 0.1389 accuracy: 0.9513 f1: 0.9505
2023-07-14 03:09:53,650 epoch [337/800] time: 4.75s train loss: 0.0654 accuracy: 0.9807 f1: 0.9805
2023-07-14 03:09:54,503 epoch [337/800] time: 0.85s val loss: 0.1391 accuracy: 0.9502 f1: 0.9495
2023-07-14 03:09:59,253 epoch [338/800] time: 4.75s train loss: 0.0637 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:10:00,102 epoch [338/800] time: 0.85s val loss: 0.1388 accuracy: 0.9514 f1: 0.9506
2023-07-14 03:10:04,851 epoch [339/800] time: 4.75s train loss: 0.0636 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:10:05,658 epoch [339/800] time: 0.81s val loss: 0.1387 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:10:10,422 epoch [340/800] time: 4.76s train loss: 0.0649 accuracy: 0.982 f1: 0.9818
2023-07-14 03:10:11,269 epoch [340/800] time: 0.85s val loss: 0.1404 accuracy: 0.9504 f1: 0.9495
2023-07-14 03:10:15,976 epoch [341/800] time: 4.71s train loss: 0.0635 accuracy: 0.9819 f1: 0.9818
2023-07-14 03:10:16,839 epoch [341/800] time: 0.86s val loss: 0.1394 accuracy: 0.9508 f1: 0.9499
2023-07-14 03:10:21,578 epoch [342/800] time: 4.74s train loss: 0.0637 accuracy: 0.9814 f1: 0.9811
2023-07-14 03:10:22,375 epoch [342/800] time: 0.8s val loss: 0.1393 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:10:27,150 epoch [343/800] time: 4.77s train loss: 0.0636 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:10:28,009 epoch [343/800] time: 0.86s val loss: 0.1392 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:10:32,758 epoch [344/800] time: 4.75s train loss: 0.0633 accuracy: 0.9817 f1: 0.9815
2023-07-14 03:10:33,600 epoch [344/800] time: 0.84s val loss: 0.1394 accuracy: 0.9512 f1: 0.9504
2023-07-14 03:10:38,324 epoch [345/800] time: 4.72s train loss: 0.0633 accuracy: 0.9818 f1: 0.9815
2023-07-14 03:10:39,133 epoch [345/800] time: 0.81s val loss: 0.1391 accuracy: 0.9511 f1: 0.9502
2023-07-14 03:10:43,728 epoch [346/800] time: 4.59s train loss: 0.0656 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:10:44,578 epoch [346/800] time: 0.85s val loss: 0.1391 accuracy: 0.9514 f1: 0.9505
2023-07-14 03:10:49,507 epoch [347/800] time: 4.93s train loss: 0.063 accuracy: 0.9818 f1: 0.9816
2023-07-14 03:10:50,381 epoch [347/800] time: 0.87s val loss: 0.1395 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:10:55,061 epoch [348/800] time: 4.68s train loss: 0.0653 accuracy: 0.9818 f1: 0.9816
2023-07-14 03:10:55,863 epoch [348/800] time: 0.8s val loss: 0.1388 accuracy: 0.9515 f1: 0.9507
2023-07-14 03:11:00,694 epoch [349/800] time: 4.83s train loss: 0.0645 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:11:01,573 epoch [349/800] time: 0.88s val loss: 0.1386 accuracy: 0.9514 f1: 0.9507
2023-07-14 03:11:06,612 epoch [350/800] time: 5.04s train loss: 0.0634 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:11:07,522 epoch [350/800] time: 0.91s val loss: 0.1391 accuracy: 0.951 f1: 0.9503
2023-07-14 03:11:13,383 epoch [351/800] time: 5.86s train loss: 0.0646 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:11:14,345 epoch [351/800] time: 0.96s val loss: 0.1386 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:11:19,987 epoch [352/800] time: 5.64s train loss: 0.0641 accuracy: 0.9811 f1: 0.981
2023-07-14 03:11:21,077 epoch [352/800] time: 1.09s val loss: 0.1388 accuracy: 0.9506 f1: 0.9499
2023-07-14 03:11:26,246 epoch [353/800] time: 5.17s train loss: 0.0638 accuracy: 0.982 f1: 0.9819
2023-07-14 03:11:27,173 epoch [353/800] time: 0.93s val loss: 0.1394 accuracy: 0.95 f1: 0.9492
2023-07-14 03:11:32,470 epoch [354/800] time: 5.3s train loss: 0.0647 accuracy: 0.981 f1: 0.9807
2023-07-14 03:11:33,336 epoch [354/800] time: 0.87s val loss: 0.139 accuracy: 0.9511 f1: 0.9503
2023-07-14 03:11:38,203 epoch [355/800] time: 4.87s train loss: 0.0654 accuracy: 0.9812 f1: 0.981
2023-07-14 03:11:39,074 epoch [355/800] time: 0.87s val loss: 0.1391 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:11:43,613 epoch [356/800] time: 4.54s train loss: 0.0648 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:11:44,467 epoch [356/800] time: 0.85s val loss: 0.1391 accuracy: 0.9516 f1: 0.9509
2023-07-14 03:11:49,135 epoch [357/800] time: 4.67s train loss: 0.0639 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:11:49,966 epoch [357/800] time: 0.83s val loss: 0.1386 accuracy: 0.9514 f1: 0.9506
2023-07-14 03:11:54,733 epoch [358/800] time: 4.77s train loss: 0.0634 accuracy: 0.9821 f1: 0.982
2023-07-14 03:11:55,617 epoch [358/800] time: 0.88s val loss: 0.1398 accuracy: 0.9508 f1: 0.95
2023-07-14 03:12:00,485 epoch [359/800] time: 4.87s train loss: 0.0642 accuracy: 0.9812 f1: 0.981
2023-07-14 03:12:01,360 epoch [359/800] time: 0.87s val loss: 0.1395 accuracy: 0.9505 f1: 0.9496
2023-07-14 03:12:06,104 epoch [360/800] time: 4.74s train loss: 0.0653 accuracy: 0.981 f1: 0.9809
2023-07-14 03:12:06,910 epoch [360/800] time: 0.81s val loss: 0.1392 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:12:11,898 epoch [361/800] time: 4.99s train loss: 0.0638 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:12:12,776 epoch [361/800] time: 0.88s val loss: 0.1413 accuracy: 0.9497 f1: 0.9488
2023-07-14 03:12:17,762 epoch [362/800] time: 4.99s train loss: 0.0652 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:12:18,683 epoch [362/800] time: 0.92s val loss: 0.1399 accuracy: 0.95 f1: 0.9492
2023-07-14 03:12:23,693 epoch [363/800] time: 5.01s train loss: 0.0647 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:12:24,563 epoch [363/800] time: 0.87s val loss: 0.1389 accuracy: 0.9511 f1: 0.9504
2023-07-14 03:12:29,589 epoch [364/800] time: 5.03s train loss: 0.0637 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:12:30,477 epoch [364/800] time: 0.89s val loss: 0.1391 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:12:36,162 epoch [365/800] time: 5.68s train loss: 0.0643 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:12:37,236 epoch [365/800] time: 1.07s val loss: 0.1392 accuracy: 0.9505 f1: 0.9496
2023-07-14 03:12:43,019 epoch [366/800] time: 5.78s train loss: 0.0643 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:12:43,847 epoch [366/800] time: 0.83s val loss: 0.1402 accuracy: 0.9509 f1: 0.9503
2023-07-14 03:12:48,899 epoch [367/800] time: 5.05s train loss: 0.0641 accuracy: 0.9818 f1: 0.9816
2023-07-14 03:12:49,793 epoch [367/800] time: 0.89s val loss: 0.1392 accuracy: 0.9507 f1: 0.95
2023-07-14 03:12:54,695 epoch [368/800] time: 4.9s train loss: 0.063 accuracy: 0.982 f1: 0.9818
2023-07-14 03:12:55,572 epoch [368/800] time: 0.88s val loss: 0.1389 accuracy: 0.9512 f1: 0.9503
2023-07-14 03:13:00,368 epoch [369/800] time: 4.8s train loss: 0.0648 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:13:01,186 epoch [369/800] time: 0.82s val loss: 0.1394 accuracy: 0.9504 f1: 0.9497
2023-07-14 03:13:06,746 epoch [370/800] time: 5.56s train loss: 0.0639 accuracy: 0.9814 f1: 0.9812
2023-07-14 03:13:07,942 epoch [370/800] time: 1.2s val loss: 0.1392 accuracy: 0.9509 f1: 0.9503
2023-07-14 03:13:14,147 epoch [371/800] time: 6.2s train loss: 0.0651 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:13:15,354 epoch [371/800] time: 1.21s val loss: 0.1391 accuracy: 0.9511 f1: 0.9503
2023-07-14 03:13:21,121 epoch [372/800] time: 5.77s train loss: 0.0639 accuracy: 0.9818 f1: 0.9816
2023-07-14 03:13:21,955 epoch [372/800] time: 0.83s val loss: 0.1395 accuracy: 0.95 f1: 0.9492
2023-07-14 03:13:26,793 epoch [373/800] time: 4.84s train loss: 0.0636 accuracy: 0.9818 f1: 0.9816
2023-07-14 03:13:27,657 epoch [373/800] time: 0.86s val loss: 0.1394 accuracy: 0.9503 f1: 0.9493
2023-07-14 03:13:32,463 epoch [374/800] time: 4.81s train loss: 0.0635 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:13:33,354 epoch [374/800] time: 0.89s val loss: 0.1391 accuracy: 0.9506 f1: 0.9497
2023-07-14 03:13:38,295 epoch [375/800] time: 4.94s train loss: 0.0637 accuracy: 0.9818 f1: 0.9815
2023-07-14 03:13:39,105 epoch [375/800] time: 0.81s val loss: 0.1392 accuracy: 0.9504 f1: 0.9496
2023-07-14 03:13:44,124 epoch [376/800] time: 5.02s train loss: 0.0639 accuracy: 0.9823 f1: 0.9822
2023-07-14 03:13:44,988 epoch [376/800] time: 0.86s val loss: 0.1399 accuracy: 0.9511 f1: 0.9503
2023-07-14 03:13:49,642 epoch [377/800] time: 4.65s train loss: 0.064 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:13:50,496 epoch [377/800] time: 0.85s val loss: 0.1389 accuracy: 0.9513 f1: 0.9504
2023-07-14 03:13:55,186 epoch [378/800] time: 4.69s train loss: 0.0635 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:13:55,994 epoch [378/800] time: 0.81s val loss: 0.1389 accuracy: 0.9511 f1: 0.9502
2023-07-14 03:14:01,303 epoch [379/800] time: 5.31s train loss: 0.0652 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:14:02,253 epoch [379/800] time: 0.95s val loss: 0.1391 accuracy: 0.9506 f1: 0.95
2023-07-14 03:14:07,156 epoch [380/800] time: 4.9s train loss: 0.0631 accuracy: 0.9821 f1: 0.982
2023-07-14 03:14:08,048 epoch [380/800] time: 0.89s val loss: 0.1388 accuracy: 0.9509 f1: 0.9502
2023-07-14 03:14:13,056 epoch [381/800] time: 5.01s train loss: 0.0632 accuracy: 0.9823 f1: 0.9821
2023-07-14 03:14:13,886 epoch [381/800] time: 0.83s val loss: 0.1399 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:14:18,710 epoch [382/800] time: 4.82s train loss: 0.0644 accuracy: 0.9815 f1: 0.9815
2023-07-14 03:14:19,618 epoch [382/800] time: 0.91s val loss: 0.1406 accuracy: 0.9504 f1: 0.9495
2023-07-14 03:14:24,591 epoch [383/800] time: 4.97s train loss: 0.0641 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:14:25,451 epoch [383/800] time: 0.86s val loss: 0.1408 accuracy: 0.9499 f1: 0.9491
2023-07-14 03:14:30,289 epoch [384/800] time: 4.84s train loss: 0.0637 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:14:31,099 epoch [384/800] time: 0.81s val loss: 0.1388 accuracy: 0.9508 f1: 0.9499
2023-07-14 03:14:35,929 epoch [385/800] time: 4.83s train loss: 0.0639 accuracy: 0.9815 f1: 0.9815
2023-07-14 03:14:36,782 epoch [385/800] time: 0.85s val loss: 0.1386 accuracy: 0.951 f1: 0.9502
2023-07-14 03:14:41,697 epoch [386/800] time: 4.91s train loss: 0.063 accuracy: 0.9826 f1: 0.9826
2023-07-14 03:14:42,601 epoch [386/800] time: 0.9s val loss: 0.1388 accuracy: 0.9507 f1: 0.95
2023-07-14 03:14:47,463 epoch [387/800] time: 4.86s train loss: 0.0635 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:14:48,272 epoch [387/800] time: 0.81s val loss: 0.1384 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:14:53,059 epoch [388/800] time: 4.79s train loss: 0.0645 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:14:53,982 epoch [388/800] time: 0.92s val loss: 0.141 accuracy: 0.9502 f1: 0.9495
2023-07-14 03:14:58,781 epoch [389/800] time: 4.8s train loss: 0.0642 accuracy: 0.9811 f1: 0.9809
2023-07-14 03:14:59,633 epoch [389/800] time: 0.85s val loss: 0.1392 accuracy: 0.9507 f1: 0.95
2023-07-14 03:15:04,342 epoch [390/800] time: 4.71s train loss: 0.0651 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:15:05,146 epoch [390/800] time: 0.8s val loss: 0.1399 accuracy: 0.9506 f1: 0.9497
2023-07-14 03:15:09,865 epoch [391/800] time: 4.72s train loss: 0.0654 accuracy: 0.9814 f1: 0.9814
2023-07-14 03:15:10,705 epoch [391/800] time: 0.84s val loss: 0.1398 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:15:15,328 epoch [392/800] time: 4.62s train loss: 0.0643 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:15:16,197 epoch [392/800] time: 0.87s val loss: 0.139 accuracy: 0.9508 f1: 0.95
2023-07-14 03:15:20,775 epoch [393/800] time: 4.58s train loss: 0.0647 accuracy: 0.981 f1: 0.9809
2023-07-14 03:15:21,580 epoch [393/800] time: 0.8s val loss: 0.1403 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:15:26,293 epoch [394/800] time: 4.71s train loss: 0.0652 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:15:27,174 epoch [394/800] time: 0.88s val loss: 0.1393 accuracy: 0.9511 f1: 0.9503
2023-07-14 03:15:31,817 epoch [395/800] time: 4.64s train loss: 0.0647 accuracy: 0.9808 f1: 0.9806
2023-07-14 03:15:32,670 epoch [395/800] time: 0.85s val loss: 0.1386 accuracy: 0.9507 f1: 0.9498
2023-07-14 03:15:37,229 epoch [396/800] time: 4.56s train loss: 0.0642 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:15:38,043 epoch [396/800] time: 0.81s val loss: 0.1389 accuracy: 0.9509 f1: 0.95
2023-07-14 03:15:42,593 epoch [397/800] time: 4.55s train loss: 0.0649 accuracy: 0.9807 f1: 0.9805
2023-07-14 03:15:43,433 epoch [397/800] time: 0.84s val loss: 0.1401 accuracy: 0.9504 f1: 0.9495
2023-07-14 03:15:47,919 epoch [398/800] time: 4.49s train loss: 0.0636 accuracy: 0.9814 f1: 0.9812
2023-07-14 03:15:48,761 epoch [398/800] time: 0.84s val loss: 0.1394 accuracy: 0.951 f1: 0.9504
2023-07-14 03:15:53,287 epoch [399/800] time: 4.53s train loss: 0.064 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:15:54,087 epoch [399/800] time: 0.8s val loss: 0.1394 accuracy: 0.9503 f1: 0.9493
2023-07-14 03:15:58,609 epoch [400/800] time: 4.52s train loss: 0.0641 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:15:59,450 epoch [400/800] time: 0.84s val loss: 0.1389 accuracy: 0.951 f1: 0.9503
2023-07-14 03:16:03,962 epoch [401/800] time: 4.51s train loss: 0.064 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:16:04,806 epoch [401/800] time: 0.84s val loss: 0.1396 accuracy: 0.9509 f1: 0.95
2023-07-14 03:16:09,405 epoch [402/800] time: 4.6s train loss: 0.0641 accuracy: 0.9811 f1: 0.981
2023-07-14 03:16:10,206 epoch [402/800] time: 0.8s val loss: 0.1397 accuracy: 0.9508 f1: 0.95
2023-07-14 03:16:15,159 epoch [403/800] time: 4.95s train loss: 0.0644 accuracy: 0.982 f1: 0.9818
2023-07-14 03:16:16,052 epoch [403/800] time: 0.89s val loss: 0.14 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:16:21,148 epoch [404/800] time: 5.1s train loss: 0.0633 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:16:22,021 epoch [404/800] time: 0.87s val loss: 0.1388 accuracy: 0.9505 f1: 0.9496
2023-07-14 03:16:26,890 epoch [405/800] time: 4.87s train loss: 0.064 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:16:27,767 epoch [405/800] time: 0.88s val loss: 0.1392 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:16:33,028 epoch [406/800] time: 5.26s train loss: 0.0638 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:16:33,945 epoch [406/800] time: 0.92s val loss: 0.1389 accuracy: 0.9513 f1: 0.9506
2023-07-14 03:16:38,913 epoch [407/800] time: 4.97s train loss: 0.065 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:16:39,782 epoch [407/800] time: 0.87s val loss: 0.1419 accuracy: 0.9495 f1: 0.9486
2023-07-14 03:16:44,957 epoch [408/800] time: 5.17s train loss: 0.0644 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:16:45,862 epoch [408/800] time: 0.9s val loss: 0.1393 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:16:50,979 epoch [409/800] time: 5.12s train loss: 0.0637 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:16:51,854 epoch [409/800] time: 0.87s val loss: 0.1388 accuracy: 0.9506 f1: 0.9499
2023-07-14 03:16:56,841 epoch [410/800] time: 4.99s train loss: 0.0649 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:16:57,752 epoch [410/800] time: 0.91s val loss: 0.1396 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:17:02,947 epoch [411/800] time: 5.19s train loss: 0.0662 accuracy: 0.9811 f1: 0.981
2023-07-14 03:17:03,795 epoch [411/800] time: 0.85s val loss: 0.1412 accuracy: 0.9502 f1: 0.9495
2023-07-14 03:17:08,722 epoch [412/800] time: 4.93s train loss: 0.0646 accuracy: 0.9808 f1: 0.9807
2023-07-14 03:17:09,578 epoch [412/800] time: 0.86s val loss: 0.1394 accuracy: 0.9504 f1: 0.9497
2023-07-14 03:17:14,405 epoch [413/800] time: 4.83s train loss: 0.0627 accuracy: 0.9819 f1: 0.9818
2023-07-14 03:17:15,260 epoch [413/800] time: 0.85s val loss: 0.1389 accuracy: 0.951 f1: 0.9502
2023-07-14 03:17:20,014 epoch [414/800] time: 4.75s train loss: 0.064 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:17:20,822 epoch [414/800] time: 0.81s val loss: 0.1388 accuracy: 0.9504 f1: 0.9496
2023-07-14 03:17:25,753 epoch [415/800] time: 4.93s train loss: 0.0643 accuracy: 0.981 f1: 0.981
2023-07-14 03:17:26,627 epoch [415/800] time: 0.87s val loss: 0.1391 accuracy: 0.9506 f1: 0.9499
2023-07-14 03:17:31,280 epoch [416/800] time: 4.65s train loss: 0.0649 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:17:32,133 epoch [416/800] time: 0.85s val loss: 0.139 accuracy: 0.951 f1: 0.9502
2023-07-14 03:17:36,852 epoch [417/800] time: 4.72s train loss: 0.0642 accuracy: 0.9818 f1: 0.9816
2023-07-14 03:17:37,689 epoch [417/800] time: 0.84s val loss: 0.1403 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:17:42,600 epoch [418/800] time: 4.91s train loss: 0.0648 accuracy: 0.9814 f1: 0.9814
2023-07-14 03:17:43,455 epoch [418/800] time: 0.85s val loss: 0.1403 accuracy: 0.9498 f1: 0.949
2023-07-14 03:17:48,045 epoch [419/800] time: 4.59s train loss: 0.0641 accuracy: 0.9819 f1: 0.9817
2023-07-14 03:17:48,901 epoch [419/800] time: 0.86s val loss: 0.1399 accuracy: 0.9503 f1: 0.9494
2023-07-14 03:17:53,742 epoch [420/800] time: 4.84s train loss: 0.0642 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:17:54,563 epoch [420/800] time: 0.82s val loss: 0.1408 accuracy: 0.9496 f1: 0.9487
2023-07-14 03:17:59,368 epoch [421/800] time: 4.8s train loss: 0.0645 accuracy: 0.981 f1: 0.9808
2023-07-14 03:18:00,229 epoch [421/800] time: 0.86s val loss: 0.1392 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:18:04,997 epoch [422/800] time: 4.77s train loss: 0.0636 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:18:05,879 epoch [422/800] time: 0.88s val loss: 0.1394 accuracy: 0.9505 f1: 0.9496
2023-07-14 03:18:10,955 epoch [423/800] time: 5.08s train loss: 0.0638 accuracy: 0.982 f1: 0.9819
2023-07-14 03:18:11,788 epoch [423/800] time: 0.83s val loss: 0.1406 accuracy: 0.9501 f1: 0.9492
2023-07-14 03:18:16,894 epoch [424/800] time: 5.11s train loss: 0.0636 accuracy: 0.9819 f1: 0.9817
2023-07-14 03:18:17,766 epoch [424/800] time: 0.87s val loss: 0.1393 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:18:22,705 epoch [425/800] time: 4.94s train loss: 0.0632 accuracy: 0.9821 f1: 0.982
2023-07-14 03:18:23,618 epoch [425/800] time: 0.91s val loss: 0.1387 accuracy: 0.9508 f1: 0.95
2023-07-14 03:18:28,640 epoch [426/800] time: 5.02s train loss: 0.0634 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:18:29,474 epoch [426/800] time: 0.83s val loss: 0.1392 accuracy: 0.951 f1: 0.9501
2023-07-14 03:18:34,269 epoch [427/800] time: 4.79s train loss: 0.0639 accuracy: 0.9816 f1: 0.9813
2023-07-14 03:18:35,191 epoch [427/800] time: 0.92s val loss: 0.1387 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:18:40,348 epoch [428/800] time: 5.16s train loss: 0.0638 accuracy: 0.9814 f1: 0.9812
2023-07-14 03:18:41,287 epoch [428/800] time: 0.94s val loss: 0.1385 accuracy: 0.9512 f1: 0.9504
2023-07-14 03:18:46,402 epoch [429/800] time: 5.12s train loss: 0.0638 accuracy: 0.9818 f1: 0.9816
2023-07-14 03:18:47,246 epoch [429/800] time: 0.84s val loss: 0.1395 accuracy: 0.9504 f1: 0.9496
2023-07-14 03:18:52,430 epoch [430/800] time: 5.18s train loss: 0.0639 accuracy: 0.9819 f1: 0.9819
2023-07-14 03:18:53,305 epoch [430/800] time: 0.87s val loss: 0.1392 accuracy: 0.9504 f1: 0.9495
2023-07-14 03:18:58,346 epoch [431/800] time: 5.04s train loss: 0.0635 accuracy: 0.982 f1: 0.9819
2023-07-14 03:18:59,246 epoch [431/800] time: 0.9s val loss: 0.1391 accuracy: 0.9503 f1: 0.9496
2023-07-14 03:19:04,296 epoch [432/800] time: 5.05s train loss: 0.064 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:19:05,138 epoch [432/800] time: 0.84s val loss: 0.1391 accuracy: 0.9512 f1: 0.9505
2023-07-14 03:19:10,103 epoch [433/800] time: 4.96s train loss: 0.0644 accuracy: 0.9814 f1: 0.9812
2023-07-14 03:19:10,976 epoch [433/800] time: 0.87s val loss: 0.139 accuracy: 0.951 f1: 0.9502
2023-07-14 03:19:15,645 epoch [434/800] time: 4.67s train loss: 0.0643 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:19:16,540 epoch [434/800] time: 0.9s val loss: 0.1389 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:19:21,488 epoch [435/800] time: 4.95s train loss: 0.0649 accuracy: 0.9815 f1: 0.9815
2023-07-14 03:19:22,298 epoch [435/800] time: 0.81s val loss: 0.1405 accuracy: 0.95 f1: 0.9492
2023-07-14 03:19:27,030 epoch [436/800] time: 4.73s train loss: 0.0646 accuracy: 0.9812 f1: 0.981
2023-07-14 03:19:27,884 epoch [436/800] time: 0.85s val loss: 0.1398 accuracy: 0.9508 f1: 0.9499
2023-07-14 03:19:32,664 epoch [437/800] time: 4.78s train loss: 0.0645 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:19:33,521 epoch [437/800] time: 0.86s val loss: 0.1392 accuracy: 0.9507 f1: 0.9498
2023-07-14 03:19:38,352 epoch [438/800] time: 4.83s train loss: 0.0635 accuracy: 0.9818 f1: 0.9815
2023-07-14 03:19:39,171 epoch [438/800] time: 0.82s val loss: 0.1388 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:19:44,003 epoch [439/800] time: 4.83s train loss: 0.0652 accuracy: 0.9811 f1: 0.9809
2023-07-14 03:19:44,854 epoch [439/800] time: 0.85s val loss: 0.1401 accuracy: 0.9505 f1: 0.9496
2023-07-14 03:19:49,598 epoch [440/800] time: 4.74s train loss: 0.0643 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:19:50,460 epoch [440/800] time: 0.86s val loss: 0.1398 accuracy: 0.9502 f1: 0.9494
2023-07-14 03:19:55,241 epoch [441/800] time: 4.78s train loss: 0.0647 accuracy: 0.9818 f1: 0.9815
2023-07-14 03:19:56,044 epoch [441/800] time: 0.8s val loss: 0.139 accuracy: 0.9506 f1: 0.9499
2023-07-14 03:20:01,154 epoch [442/800] time: 5.11s train loss: 0.0652 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:20:02,074 epoch [442/800] time: 0.92s val loss: 0.1404 accuracy: 0.95 f1: 0.9491
2023-07-14 03:20:07,155 epoch [443/800] time: 5.08s train loss: 0.0644 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:20:08,099 epoch [443/800] time: 0.94s val loss: 0.1396 accuracy: 0.9503 f1: 0.9494
2023-07-14 03:20:13,472 epoch [444/800] time: 5.37s train loss: 0.0643 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:20:14,319 epoch [444/800] time: 0.85s val loss: 0.1395 accuracy: 0.9503 f1: 0.9494
2023-07-14 03:20:19,555 epoch [445/800] time: 5.24s train loss: 0.0633 accuracy: 0.9819 f1: 0.9819
2023-07-14 03:20:20,504 epoch [445/800] time: 0.95s val loss: 0.1386 accuracy: 0.9508 f1: 0.95
2023-07-14 03:20:25,628 epoch [446/800] time: 5.12s train loss: 0.0635 accuracy: 0.9819 f1: 0.9817
2023-07-14 03:20:26,589 epoch [446/800] time: 0.96s val loss: 0.1394 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:20:31,985 epoch [447/800] time: 5.4s train loss: 0.0645 accuracy: 0.9809 f1: 0.9809
2023-07-14 03:20:32,833 epoch [447/800] time: 0.85s val loss: 0.1395 accuracy: 0.9507 f1: 0.95
2023-07-14 03:20:37,960 epoch [448/800] time: 5.13s train loss: 0.0647 accuracy: 0.9812 f1: 0.981
2023-07-14 03:20:38,942 epoch [448/800] time: 0.98s val loss: 0.1393 accuracy: 0.9516 f1: 0.9508
2023-07-14 03:20:43,944 epoch [449/800] time: 5.0s train loss: 0.0642 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:20:44,850 epoch [449/800] time: 0.91s val loss: 0.1408 accuracy: 0.9498 f1: 0.9491
2023-07-14 03:20:49,560 epoch [450/800] time: 4.71s train loss: 0.0648 accuracy: 0.9807 f1: 0.9805
2023-07-14 03:20:50,367 epoch [450/800] time: 0.81s val loss: 0.1394 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:20:55,253 epoch [451/800] time: 4.89s train loss: 0.0642 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:20:56,178 epoch [451/800] time: 0.92s val loss: 0.1397 accuracy: 0.9501 f1: 0.9492
2023-07-14 03:21:01,292 epoch [452/800] time: 5.11s train loss: 0.0645 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:21:02,239 epoch [452/800] time: 0.95s val loss: 0.1392 accuracy: 0.951 f1: 0.9502
2023-07-14 03:21:07,299 epoch [453/800] time: 5.06s train loss: 0.064 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:21:08,169 epoch [453/800] time: 0.87s val loss: 0.1391 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:21:13,628 epoch [454/800] time: 5.46s train loss: 0.0651 accuracy: 0.9811 f1: 0.981
2023-07-14 03:21:14,829 epoch [454/800] time: 1.2s val loss: 0.1399 accuracy: 0.9506 f1: 0.9496
2023-07-14 03:21:20,601 epoch [455/800] time: 5.77s train loss: 0.0643 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:21:21,535 epoch [455/800] time: 0.93s val loss: 0.1389 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:21:26,377 epoch [456/800] time: 4.84s train loss: 0.0645 accuracy: 0.9809 f1: 0.9808
2023-07-14 03:21:27,190 epoch [456/800] time: 0.81s val loss: 0.1393 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:21:31,937 epoch [457/800] time: 4.75s train loss: 0.0646 accuracy: 0.9818 f1: 0.9815
2023-07-14 03:21:32,789 epoch [457/800] time: 0.85s val loss: 0.1404 accuracy: 0.9505 f1: 0.9496
2023-07-14 03:21:37,448 epoch [458/800] time: 4.66s train loss: 0.0644 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:21:38,303 epoch [458/800] time: 0.85s val loss: 0.1393 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:21:43,008 epoch [459/800] time: 4.7s train loss: 0.0649 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:21:43,817 epoch [459/800] time: 0.81s val loss: 0.1397 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:21:48,508 epoch [460/800] time: 4.69s train loss: 0.064 accuracy: 0.9812 f1: 0.981
2023-07-14 03:21:49,359 epoch [460/800] time: 0.85s val loss: 0.1392 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:21:54,028 epoch [461/800] time: 4.67s train loss: 0.0651 accuracy: 0.981 f1: 0.9809
2023-07-14 03:21:54,879 epoch [461/800] time: 0.85s val loss: 0.1398 accuracy: 0.9504 f1: 0.9495
2023-07-14 03:21:59,555 epoch [462/800] time: 4.68s train loss: 0.0643 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:22:00,365 epoch [462/800] time: 0.81s val loss: 0.1399 accuracy: 0.9503 f1: 0.9496
2023-07-14 03:22:05,054 epoch [463/800] time: 4.69s train loss: 0.0629 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:22:05,902 epoch [463/800] time: 0.85s val loss: 0.1392 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:22:10,566 epoch [464/800] time: 4.66s train loss: 0.0638 accuracy: 0.9817 f1: 0.9815
2023-07-14 03:22:11,411 epoch [464/800] time: 0.84s val loss: 0.1397 accuracy: 0.9507 f1: 0.95
2023-07-14 03:22:16,107 epoch [465/800] time: 4.7s train loss: 0.0637 accuracy: 0.9817 f1: 0.9815
2023-07-14 03:22:16,906 epoch [465/800] time: 0.8s val loss: 0.1393 accuracy: 0.9504 f1: 0.9496
2023-07-14 03:22:21,475 epoch [466/800] time: 4.57s train loss: 0.064 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:22:22,315 epoch [466/800] time: 0.84s val loss: 0.1385 accuracy: 0.9506 f1: 0.9497
2023-07-14 03:22:26,878 epoch [467/800] time: 4.56s train loss: 0.0639 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:22:27,736 epoch [467/800] time: 0.86s val loss: 0.1391 accuracy: 0.9507 f1: 0.9501
2023-07-14 03:22:32,448 epoch [468/800] time: 4.71s train loss: 0.0645 accuracy: 0.9817 f1: 0.9815
2023-07-14 03:22:33,250 epoch [468/800] time: 0.8s val loss: 0.1389 accuracy: 0.9509 f1: 0.95
2023-07-14 03:22:37,863 epoch [469/800] time: 4.61s train loss: 0.0635 accuracy: 0.9818 f1: 0.9818
2023-07-14 03:22:38,708 epoch [469/800] time: 0.84s val loss: 0.1389 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:22:43,314 epoch [470/800] time: 4.61s train loss: 0.0636 accuracy: 0.9819 f1: 0.9818
2023-07-14 03:22:44,160 epoch [470/800] time: 0.85s val loss: 0.1386 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:22:48,850 epoch [471/800] time: 4.69s train loss: 0.0635 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:22:49,654 epoch [471/800] time: 0.8s val loss: 0.1396 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:22:54,398 epoch [472/800] time: 4.74s train loss: 0.064 accuracy: 0.9815 f1: 0.9815
2023-07-14 03:22:55,247 epoch [472/800] time: 0.85s val loss: 0.1394 accuracy: 0.9507 f1: 0.95
2023-07-14 03:23:00,193 epoch [473/800] time: 4.95s train loss: 0.0645 accuracy: 0.9812 f1: 0.981
2023-07-14 03:23:01,046 epoch [473/800] time: 0.85s val loss: 0.1387 accuracy: 0.9508 f1: 0.95
2023-07-14 03:23:05,698 epoch [474/800] time: 4.65s train loss: 0.0637 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:23:06,500 epoch [474/800] time: 0.8s val loss: 0.1399 accuracy: 0.9504 f1: 0.9496
2023-07-14 03:23:11,468 epoch [475/800] time: 4.97s train loss: 0.0656 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:23:12,371 epoch [475/800] time: 0.9s val loss: 0.1399 accuracy: 0.9503 f1: 0.9496
2023-07-14 03:23:17,456 epoch [476/800] time: 5.08s train loss: 0.0654 accuracy: 0.9808 f1: 0.9807
2023-07-14 03:23:18,327 epoch [476/800] time: 0.87s val loss: 0.1388 accuracy: 0.9515 f1: 0.9508
2023-07-14 03:23:23,394 epoch [477/800] time: 5.07s train loss: 0.0634 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:23:24,284 epoch [477/800] time: 0.89s val loss: 0.139 accuracy: 0.9508 f1: 0.95
2023-07-14 03:23:29,458 epoch [478/800] time: 5.17s train loss: 0.0638 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:23:30,351 epoch [478/800] time: 0.89s val loss: 0.1384 accuracy: 0.9508 f1: 0.95
2023-07-14 03:23:35,434 epoch [479/800] time: 5.08s train loss: 0.0634 accuracy: 0.9814 f1: 0.9812
2023-07-14 03:23:36,434 epoch [479/800] time: 1.0s val loss: 0.1401 accuracy: 0.9502 f1: 0.9495
2023-07-14 03:23:41,714 epoch [480/800] time: 5.28s train loss: 0.0643 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:23:42,625 epoch [480/800] time: 0.91s val loss: 0.1389 accuracy: 0.9505 f1: 0.9498
2023-07-14 03:23:47,765 epoch [481/800] time: 5.14s train loss: 0.0627 accuracy: 0.9823 f1: 0.9822
2023-07-14 03:23:48,658 epoch [481/800] time: 0.89s val loss: 0.1388 accuracy: 0.951 f1: 0.9504
2023-07-14 03:23:53,869 epoch [482/800] time: 5.21s train loss: 0.0633 accuracy: 0.9821 f1: 0.982
2023-07-14 03:23:54,779 epoch [482/800] time: 0.91s val loss: 0.1387 accuracy: 0.9513 f1: 0.9504
2023-07-14 03:23:59,964 epoch [483/800] time: 5.19s train loss: 0.0655 accuracy: 0.9818 f1: 0.9818
2023-07-14 03:24:00,783 epoch [483/800] time: 0.82s val loss: 0.1405 accuracy: 0.9494 f1: 0.9485
2023-07-14 03:24:05,967 epoch [484/800] time: 5.18s train loss: 0.0644 accuracy: 0.981 f1: 0.9809
2023-07-14 03:24:06,890 epoch [484/800] time: 0.92s val loss: 0.1394 accuracy: 0.9514 f1: 0.9506
2023-07-14 03:24:11,884 epoch [485/800] time: 4.99s train loss: 0.0646 accuracy: 0.9812 f1: 0.981
2023-07-14 03:24:12,750 epoch [485/800] time: 0.87s val loss: 0.1387 accuracy: 0.9507 f1: 0.9501
2023-07-14 03:24:17,744 epoch [486/800] time: 4.99s train loss: 0.0634 accuracy: 0.9821 f1: 0.982
2023-07-14 03:24:18,588 epoch [486/800] time: 0.84s val loss: 0.1401 accuracy: 0.9502 f1: 0.9493
2023-07-14 03:24:23,680 epoch [487/800] time: 5.09s train loss: 0.0649 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:24:24,539 epoch [487/800] time: 0.86s val loss: 0.1407 accuracy: 0.9497 f1: 0.9488
2023-07-14 03:24:29,436 epoch [488/800] time: 4.9s train loss: 0.0647 accuracy: 0.9819 f1: 0.9818
2023-07-14 03:24:30,351 epoch [488/800] time: 0.91s val loss: 0.141 accuracy: 0.9495 f1: 0.9487
2023-07-14 03:24:35,427 epoch [489/800] time: 5.08s train loss: 0.0657 accuracy: 0.9814 f1: 0.9812
2023-07-14 03:24:36,250 epoch [489/800] time: 0.82s val loss: 0.1393 accuracy: 0.9509 f1: 0.9504
2023-07-14 03:24:41,055 epoch [490/800] time: 4.8s train loss: 0.0638 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:24:41,909 epoch [490/800] time: 0.85s val loss: 0.1395 accuracy: 0.9508 f1: 0.95
2023-07-14 03:24:46,621 epoch [491/800] time: 4.71s train loss: 0.0641 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:24:47,506 epoch [491/800] time: 0.88s val loss: 0.1393 accuracy: 0.9505 f1: 0.9495
2023-07-14 03:24:52,287 epoch [492/800] time: 4.78s train loss: 0.0639 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:24:53,096 epoch [492/800] time: 0.81s val loss: 0.1392 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:24:57,941 epoch [493/800] time: 4.84s train loss: 0.0639 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:24:58,824 epoch [493/800] time: 0.88s val loss: 0.1385 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:25:03,841 epoch [494/800] time: 5.02s train loss: 0.0639 accuracy: 0.9813 f1: 0.9813
2023-07-14 03:25:04,739 epoch [494/800] time: 0.9s val loss: 0.1393 accuracy: 0.9514 f1: 0.9506
2023-07-14 03:25:09,729 epoch [495/800] time: 4.99s train loss: 0.0637 accuracy: 0.9819 f1: 0.9818
2023-07-14 03:25:10,554 epoch [495/800] time: 0.82s val loss: 0.1392 accuracy: 0.9511 f1: 0.9503
2023-07-14 03:25:15,626 epoch [496/800] time: 5.07s train loss: 0.0636 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:25:16,526 epoch [496/800] time: 0.9s val loss: 0.1393 accuracy: 0.9508 f1: 0.9502
2023-07-14 03:25:22,160 epoch [497/800] time: 5.63s train loss: 0.0631 accuracy: 0.9823 f1: 0.9822
2023-07-14 03:25:23,089 epoch [497/800] time: 0.93s val loss: 0.1385 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:25:28,343 epoch [498/800] time: 5.25s train loss: 0.0635 accuracy: 0.9817 f1: 0.9817
2023-07-14 03:25:29,206 epoch [498/800] time: 0.86s val loss: 0.1387 accuracy: 0.951 f1: 0.9502
2023-07-14 03:25:34,276 epoch [499/800] time: 5.07s train loss: 0.0647 accuracy: 0.9809 f1: 0.9808
2023-07-14 03:25:35,194 epoch [499/800] time: 0.92s val loss: 0.1392 accuracy: 0.9509 f1: 0.9502
2023-07-14 03:25:40,292 epoch [500/800] time: 5.1s train loss: 0.0635 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:25:41,221 epoch [500/800] time: 0.93s val loss: 0.14 accuracy: 0.9503 f1: 0.9495
2023-07-14 03:25:46,280 epoch [501/800] time: 5.06s train loss: 0.0644 accuracy: 0.981 f1: 0.9808
2023-07-14 03:25:47,097 epoch [501/800] time: 0.82s val loss: 0.1391 accuracy: 0.9513 f1: 0.9505
2023-07-14 03:25:52,136 epoch [502/800] time: 5.04s train loss: 0.0657 accuracy: 0.9809 f1: 0.9807
2023-07-14 03:25:53,016 epoch [502/800] time: 0.88s val loss: 0.1393 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:25:57,977 epoch [503/800] time: 4.96s train loss: 0.0643 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:25:58,841 epoch [503/800] time: 0.86s val loss: 0.1395 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:26:03,861 epoch [504/800] time: 5.02s train loss: 0.065 accuracy: 0.9816 f1: 0.9816
2023-07-14 03:26:04,681 epoch [504/800] time: 0.82s val loss: 0.1399 accuracy: 0.9513 f1: 0.9506
2023-07-14 03:26:09,502 epoch [505/800] time: 4.82s train loss: 0.0648 accuracy: 0.9811 f1: 0.981
2023-07-14 03:26:10,395 epoch [505/800] time: 0.89s val loss: 0.139 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:26:15,349 epoch [506/800] time: 4.95s train loss: 0.065 accuracy: 0.9808 f1: 0.9806
2023-07-14 03:26:16,267 epoch [506/800] time: 0.92s val loss: 0.1393 accuracy: 0.9507 f1: 0.95
2023-07-14 03:26:21,413 epoch [507/800] time: 5.15s train loss: 0.0645 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:26:22,278 epoch [507/800] time: 0.86s val loss: 0.139 accuracy: 0.9508 f1: 0.95
2023-07-14 03:26:27,438 epoch [508/800] time: 5.16s train loss: 0.0645 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:26:28,352 epoch [508/800] time: 0.91s val loss: 0.1393 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:26:33,583 epoch [509/800] time: 5.23s train loss: 0.0643 accuracy: 0.9811 f1: 0.9809
2023-07-14 03:26:34,497 epoch [509/800] time: 0.91s val loss: 0.1394 accuracy: 0.9505 f1: 0.9496
2023-07-14 03:26:39,473 epoch [510/800] time: 4.98s train loss: 0.0641 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:26:40,335 epoch [510/800] time: 0.86s val loss: 0.1393 accuracy: 0.9513 f1: 0.9506
2023-07-14 03:26:45,503 epoch [511/800] time: 5.17s train loss: 0.0643 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:26:46,432 epoch [511/800] time: 0.93s val loss: 0.1401 accuracy: 0.9503 f1: 0.9495
2023-07-14 03:26:51,454 epoch [512/800] time: 5.02s train loss: 0.0645 accuracy: 0.9819 f1: 0.9818
2023-07-14 03:26:52,332 epoch [512/800] time: 0.88s val loss: 0.1399 accuracy: 0.9499 f1: 0.949
2023-07-14 03:26:57,187 epoch [513/800] time: 4.85s train loss: 0.0635 accuracy: 0.9817 f1: 0.9815
2023-07-14 03:26:57,996 epoch [513/800] time: 0.81s val loss: 0.139 accuracy: 0.9507 f1: 0.95
2023-07-14 03:27:02,867 epoch [514/800] time: 4.87s train loss: 0.064 accuracy: 0.9819 f1: 0.9817
2023-07-14 03:27:03,760 epoch [514/800] time: 0.89s val loss: 0.1402 accuracy: 0.9502 f1: 0.9495
2023-07-14 03:27:08,592 epoch [515/800] time: 4.83s train loss: 0.0629 accuracy: 0.9818 f1: 0.9816
2023-07-14 03:27:09,453 epoch [515/800] time: 0.86s val loss: 0.1386 accuracy: 0.951 f1: 0.9502
2023-07-14 03:27:14,080 epoch [516/800] time: 4.63s train loss: 0.0659 accuracy: 0.9813 f1: 0.981
2023-07-14 03:27:14,893 epoch [516/800] time: 0.81s val loss: 0.1388 accuracy: 0.9507 f1: 0.95
2023-07-14 03:27:19,963 epoch [517/800] time: 5.07s train loss: 0.0654 accuracy: 0.9806 f1: 0.9804
2023-07-14 03:27:20,854 epoch [517/800] time: 0.89s val loss: 0.1392 accuracy: 0.9509 f1: 0.9502
2023-07-14 03:27:25,673 epoch [518/800] time: 4.82s train loss: 0.063 accuracy: 0.9818 f1: 0.9818
2023-07-14 03:27:26,527 epoch [518/800] time: 0.85s val loss: 0.1394 accuracy: 0.9503 f1: 0.9495
2023-07-14 03:27:31,402 epoch [519/800] time: 4.87s train loss: 0.0644 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:27:32,206 epoch [519/800] time: 0.8s val loss: 0.1404 accuracy: 0.9498 f1: 0.9492
2023-07-14 03:27:36,925 epoch [520/800] time: 4.72s train loss: 0.0644 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:27:37,775 epoch [520/800] time: 0.85s val loss: 0.1389 accuracy: 0.9511 f1: 0.9503
2023-07-14 03:27:42,510 epoch [521/800] time: 4.73s train loss: 0.0637 accuracy: 0.9818 f1: 0.9818
2023-07-14 03:27:43,365 epoch [521/800] time: 0.85s val loss: 0.1392 accuracy: 0.951 f1: 0.9503
2023-07-14 03:27:48,154 epoch [522/800] time: 4.79s train loss: 0.0637 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:27:48,954 epoch [522/800] time: 0.8s val loss: 0.1393 accuracy: 0.9508 f1: 0.95
2023-07-14 03:27:53,563 epoch [523/800] time: 4.61s train loss: 0.0651 accuracy: 0.9808 f1: 0.9806
2023-07-14 03:27:54,403 epoch [523/800] time: 0.84s val loss: 0.14 accuracy: 0.9502 f1: 0.9494
2023-07-14 03:27:58,992 epoch [524/800] time: 4.59s train loss: 0.0644 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:27:59,831 epoch [524/800] time: 0.84s val loss: 0.1399 accuracy: 0.9504 f1: 0.9495
2023-07-14 03:28:04,519 epoch [525/800] time: 4.69s train loss: 0.064 accuracy: 0.9811 f1: 0.981
2023-07-14 03:28:05,323 epoch [525/800] time: 0.8s val loss: 0.139 accuracy: 0.9508 f1: 0.95
2023-07-14 03:28:10,004 epoch [526/800] time: 4.68s train loss: 0.0643 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:28:10,843 epoch [526/800] time: 0.84s val loss: 0.1405 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:28:15,524 epoch [527/800] time: 4.68s train loss: 0.0646 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:28:16,366 epoch [527/800] time: 0.84s val loss: 0.1396 accuracy: 0.9501 f1: 0.9493
2023-07-14 03:28:21,117 epoch [528/800] time: 4.75s train loss: 0.0653 accuracy: 0.981 f1: 0.9808
2023-07-14 03:28:21,918 epoch [528/800] time: 0.8s val loss: 0.1392 accuracy: 0.9508 f1: 0.95
2023-07-14 03:28:26,697 epoch [529/800] time: 4.78s train loss: 0.0641 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:28:27,540 epoch [529/800] time: 0.84s val loss: 0.1387 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:28:32,217 epoch [530/800] time: 4.68s train loss: 0.0645 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:28:33,059 epoch [530/800] time: 0.84s val loss: 0.14 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:28:37,841 epoch [531/800] time: 4.78s train loss: 0.0647 accuracy: 0.9817 f1: 0.9817
2023-07-14 03:28:38,641 epoch [531/800] time: 0.8s val loss: 0.1389 accuracy: 0.9509 f1: 0.9502
2023-07-14 03:28:43,494 epoch [532/800] time: 4.85s train loss: 0.064 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:28:44,402 epoch [532/800] time: 0.91s val loss: 0.1392 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:28:49,175 epoch [533/800] time: 4.77s train loss: 0.0638 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:28:50,026 epoch [533/800] time: 0.85s val loss: 0.1385 accuracy: 0.9514 f1: 0.9506
2023-07-14 03:28:54,803 epoch [534/800] time: 4.78s train loss: 0.0645 accuracy: 0.9812 f1: 0.981
2023-07-14 03:28:55,693 epoch [534/800] time: 0.89s val loss: 0.1395 accuracy: 0.951 f1: 0.9504
2023-07-14 03:29:00,703 epoch [535/800] time: 5.01s train loss: 0.0643 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:29:01,557 epoch [535/800] time: 0.85s val loss: 0.1385 accuracy: 0.9511 f1: 0.9503
2023-07-14 03:29:06,341 epoch [536/800] time: 4.78s train loss: 0.0646 accuracy: 0.9811 f1: 0.981
2023-07-14 03:29:07,201 epoch [536/800] time: 0.86s val loss: 0.1387 accuracy: 0.9512 f1: 0.9504
2023-07-14 03:29:11,943 epoch [537/800] time: 4.74s train loss: 0.0648 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:29:12,747 epoch [537/800] time: 0.8s val loss: 0.1403 accuracy: 0.9507 f1: 0.95
2023-07-14 03:29:17,517 epoch [538/800] time: 4.77s train loss: 0.0633 accuracy: 0.9825 f1: 0.9824
2023-07-14 03:29:18,364 epoch [538/800] time: 0.85s val loss: 0.1399 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:29:23,361 epoch [539/800] time: 5.0s train loss: 0.0654 accuracy: 0.9815 f1: 0.9815
2023-07-14 03:29:24,254 epoch [539/800] time: 0.89s val loss: 0.1405 accuracy: 0.9502 f1: 0.9493
2023-07-14 03:29:29,149 epoch [540/800] time: 4.89s train loss: 0.0638 accuracy: 0.9811 f1: 0.9809
2023-07-14 03:29:29,957 epoch [540/800] time: 0.81s val loss: 0.1393 accuracy: 0.9513 f1: 0.9506
2023-07-14 03:29:34,886 epoch [541/800] time: 4.93s train loss: 0.0656 accuracy: 0.9807 f1: 0.9805
2023-07-14 03:29:35,819 epoch [541/800] time: 0.93s val loss: 0.1396 accuracy: 0.9507 f1: 0.9498
2023-07-14 03:29:40,837 epoch [542/800] time: 5.02s train loss: 0.0639 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:29:41,704 epoch [542/800] time: 0.87s val loss: 0.1385 accuracy: 0.9502 f1: 0.9495
2023-07-14 03:29:46,475 epoch [543/800] time: 4.77s train loss: 0.065 accuracy: 0.981 f1: 0.9808
2023-07-14 03:29:47,295 epoch [543/800] time: 0.82s val loss: 0.1396 accuracy: 0.9506 f1: 0.9497
2023-07-14 03:29:52,281 epoch [544/800] time: 4.99s train loss: 0.064 accuracy: 0.9814 f1: 0.9814
2023-07-14 03:29:53,147 epoch [544/800] time: 0.87s val loss: 0.1388 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:29:57,855 epoch [545/800] time: 4.71s train loss: 0.0651 accuracy: 0.9808 f1: 0.9806
2023-07-14 03:29:58,710 epoch [545/800] time: 0.86s val loss: 0.1396 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:30:03,471 epoch [546/800] time: 4.76s train loss: 0.0638 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:30:04,274 epoch [546/800] time: 0.8s val loss: 0.14 accuracy: 0.9504 f1: 0.9498
2023-07-14 03:30:08,950 epoch [547/800] time: 4.68s train loss: 0.0666 accuracy: 0.9812 f1: 0.9812
2023-07-14 03:30:09,797 epoch [547/800] time: 0.85s val loss: 0.1407 accuracy: 0.9506 f1: 0.9497
2023-07-14 03:30:14,423 epoch [548/800] time: 4.63s train loss: 0.0637 accuracy: 0.9815 f1: 0.9812
2023-07-14 03:30:15,269 epoch [548/800] time: 0.85s val loss: 0.1394 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:30:19,865 epoch [549/800] time: 4.6s train loss: 0.0643 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:30:20,668 epoch [549/800] time: 0.8s val loss: 0.1392 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:30:25,509 epoch [550/800] time: 4.84s train loss: 0.0632 accuracy: 0.982 f1: 0.9819
2023-07-14 03:30:26,371 epoch [550/800] time: 0.86s val loss: 0.1385 accuracy: 0.9514 f1: 0.9507
2023-07-14 03:30:31,074 epoch [551/800] time: 4.7s train loss: 0.0629 accuracy: 0.9818 f1: 0.9816
2023-07-14 03:30:31,929 epoch [551/800] time: 0.85s val loss: 0.1394 accuracy: 0.9504 f1: 0.9494
2023-07-14 03:30:36,557 epoch [552/800] time: 4.63s train loss: 0.0644 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:30:37,360 epoch [552/800] time: 0.8s val loss: 0.1392 accuracy: 0.9505 f1: 0.9496
2023-07-14 03:30:41,843 epoch [553/800] time: 4.48s train loss: 0.0641 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:30:42,688 epoch [553/800] time: 0.84s val loss: 0.1388 accuracy: 0.9507 f1: 0.95
2023-07-14 03:30:47,175 epoch [554/800] time: 4.49s train loss: 0.0643 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:30:48,021 epoch [554/800] time: 0.85s val loss: 0.1392 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:30:52,671 epoch [555/800] time: 4.65s train loss: 0.0651 accuracy: 0.981 f1: 0.9809
2023-07-14 03:30:53,473 epoch [555/800] time: 0.8s val loss: 0.1391 accuracy: 0.9504 f1: 0.9496
2023-07-14 03:30:58,155 epoch [556/800] time: 4.68s train loss: 0.0646 accuracy: 0.981 f1: 0.9809
2023-07-14 03:30:59,002 epoch [556/800] time: 0.85s val loss: 0.1389 accuracy: 0.9506 f1: 0.9499
2023-07-14 03:31:03,561 epoch [557/800] time: 4.56s train loss: 0.0639 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:31:04,408 epoch [557/800] time: 0.85s val loss: 0.1392 accuracy: 0.9512 f1: 0.9504
2023-07-14 03:31:09,013 epoch [558/800] time: 4.6s train loss: 0.0642 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:31:09,820 epoch [558/800] time: 0.81s val loss: 0.1401 accuracy: 0.9498 f1: 0.949
2023-07-14 03:31:14,535 epoch [559/800] time: 4.72s train loss: 0.0648 accuracy: 0.9811 f1: 0.981
2023-07-14 03:31:15,374 epoch [559/800] time: 0.84s val loss: 0.141 accuracy: 0.9503 f1: 0.9494
2023-07-14 03:31:20,121 epoch [560/800] time: 4.75s train loss: 0.0651 accuracy: 0.981 f1: 0.9808
2023-07-14 03:31:20,959 epoch [560/800] time: 0.84s val loss: 0.1398 accuracy: 0.9508 f1: 0.95
2023-07-14 03:31:25,736 epoch [561/800] time: 4.78s train loss: 0.0633 accuracy: 0.9821 f1: 0.982
2023-07-14 03:31:26,533 epoch [561/800] time: 0.8s val loss: 0.1397 accuracy: 0.951 f1: 0.9502
2023-07-14 03:31:31,296 epoch [562/800] time: 4.76s train loss: 0.0638 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:31:32,134 epoch [562/800] time: 0.84s val loss: 0.1392 accuracy: 0.951 f1: 0.9503
2023-07-14 03:31:37,115 epoch [563/800] time: 4.98s train loss: 0.0646 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:31:37,986 epoch [563/800] time: 0.87s val loss: 0.1401 accuracy: 0.9502 f1: 0.9494
2023-07-14 03:31:42,842 epoch [564/800] time: 4.86s train loss: 0.0643 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:31:43,645 epoch [564/800] time: 0.8s val loss: 0.1389 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:31:48,705 epoch [565/800] time: 5.06s train loss: 0.0638 accuracy: 0.9817 f1: 0.9815
2023-07-14 03:31:49,671 epoch [565/800] time: 0.97s val loss: 0.1396 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:31:54,665 epoch [566/800] time: 4.99s train loss: 0.0638 accuracy: 0.9811 f1: 0.981
2023-07-14 03:31:55,538 epoch [566/800] time: 0.87s val loss: 0.1385 accuracy: 0.9505 f1: 0.9496
2023-07-14 03:32:00,617 epoch [567/800] time: 5.08s train loss: 0.0639 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:32:01,509 epoch [567/800] time: 0.89s val loss: 0.1387 accuracy: 0.9514 f1: 0.9506
2023-07-14 03:32:06,734 epoch [568/800] time: 5.22s train loss: 0.0638 accuracy: 0.9821 f1: 0.982
2023-07-14 03:32:07,614 epoch [568/800] time: 0.88s val loss: 0.1387 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:32:12,598 epoch [569/800] time: 4.98s train loss: 0.0644 accuracy: 0.9812 f1: 0.981
2023-07-14 03:32:13,501 epoch [569/800] time: 0.9s val loss: 0.1391 accuracy: 0.9512 f1: 0.9504
2023-07-14 03:32:18,753 epoch [570/800] time: 5.25s train loss: 0.0643 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:32:19,607 epoch [570/800] time: 0.85s val loss: 0.1401 accuracy: 0.9504 f1: 0.9495
2023-07-14 03:32:24,572 epoch [571/800] time: 4.96s train loss: 0.0645 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:32:25,433 epoch [571/800] time: 0.86s val loss: 0.1393 accuracy: 0.9507 f1: 0.9498
2023-07-14 03:32:30,712 epoch [572/800] time: 5.28s train loss: 0.0645 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:32:31,620 epoch [572/800] time: 0.91s val loss: 0.1389 accuracy: 0.9513 f1: 0.9505
2023-07-14 03:32:36,534 epoch [573/800] time: 4.91s train loss: 0.0624 accuracy: 0.9819 f1: 0.9817
2023-07-14 03:32:37,367 epoch [573/800] time: 0.83s val loss: 0.1389 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:32:42,509 epoch [574/800] time: 5.14s train loss: 0.0638 accuracy: 0.9811 f1: 0.981
2023-07-14 03:32:43,420 epoch [574/800] time: 0.91s val loss: 0.1387 accuracy: 0.9507 f1: 0.95
2023-07-14 03:32:48,412 epoch [575/800] time: 4.99s train loss: 0.0644 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:32:49,338 epoch [575/800] time: 0.93s val loss: 0.1391 accuracy: 0.951 f1: 0.9502
2023-07-14 03:32:54,462 epoch [576/800] time: 5.12s train loss: 0.0642 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:32:55,346 epoch [576/800] time: 0.88s val loss: 0.139 accuracy: 0.951 f1: 0.9502
2023-07-14 03:33:00,655 epoch [577/800] time: 5.31s train loss: 0.0631 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:33:01,537 epoch [577/800] time: 0.88s val loss: 0.1391 accuracy: 0.9502 f1: 0.9493
2023-07-14 03:33:06,631 epoch [578/800] time: 5.09s train loss: 0.0655 accuracy: 0.981 f1: 0.9808
2023-07-14 03:33:07,828 epoch [578/800] time: 1.2s val loss: 0.1395 accuracy: 0.9513 f1: 0.9505
2023-07-14 03:33:13,055 epoch [579/800] time: 5.23s train loss: 0.0638 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:33:13,900 epoch [579/800] time: 0.84s val loss: 0.1389 accuracy: 0.951 f1: 0.9503
2023-07-14 03:33:18,995 epoch [580/800] time: 5.09s train loss: 0.0636 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:33:19,877 epoch [580/800] time: 0.88s val loss: 0.1388 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:33:24,607 epoch [581/800] time: 4.73s train loss: 0.0677 accuracy: 0.9803 f1: 0.9801
2023-07-14 03:33:25,472 epoch [581/800] time: 0.87s val loss: 0.1428 accuracy: 0.9492 f1: 0.9483
2023-07-14 03:33:30,520 epoch [582/800] time: 5.05s train loss: 0.0637 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:33:31,329 epoch [582/800] time: 0.81s val loss: 0.1389 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:33:36,002 epoch [583/800] time: 4.67s train loss: 0.0638 accuracy: 0.9815 f1: 0.9815
2023-07-14 03:33:36,863 epoch [583/800] time: 0.86s val loss: 0.1389 accuracy: 0.951 f1: 0.9502
2023-07-14 03:33:41,614 epoch [584/800] time: 4.75s train loss: 0.0635 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:33:42,485 epoch [584/800] time: 0.87s val loss: 0.1392 accuracy: 0.951 f1: 0.9502
2023-07-14 03:33:47,150 epoch [585/800] time: 4.67s train loss: 0.0634 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:33:47,966 epoch [585/800] time: 0.82s val loss: 0.1396 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:33:52,688 epoch [586/800] time: 4.72s train loss: 0.0654 accuracy: 0.9811 f1: 0.981
2023-07-14 03:33:53,534 epoch [586/800] time: 0.85s val loss: 0.1404 accuracy: 0.9505 f1: 0.9495
2023-07-14 03:33:58,257 epoch [587/800] time: 4.72s train loss: 0.0643 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:33:59,121 epoch [587/800] time: 0.86s val loss: 0.14 accuracy: 0.9503 f1: 0.9495
2023-07-14 03:34:03,949 epoch [588/800] time: 4.83s train loss: 0.0649 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:34:04,754 epoch [588/800] time: 0.8s val loss: 0.1391 accuracy: 0.9509 f1: 0.95
2023-07-14 03:34:09,489 epoch [589/800] time: 4.73s train loss: 0.0635 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:34:10,362 epoch [589/800] time: 0.87s val loss: 0.1389 accuracy: 0.9502 f1: 0.9493
2023-07-14 03:34:15,371 epoch [590/800] time: 5.01s train loss: 0.064 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:34:16,238 epoch [590/800] time: 0.87s val loss: 0.1396 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:34:21,087 epoch [591/800] time: 4.85s train loss: 0.0636 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:34:21,902 epoch [591/800] time: 0.81s val loss: 0.1391 accuracy: 0.9508 f1: 0.95
2023-07-14 03:34:26,880 epoch [592/800] time: 4.98s train loss: 0.0642 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:34:27,771 epoch [592/800] time: 0.89s val loss: 0.1397 accuracy: 0.9508 f1: 0.95
2023-07-14 03:34:32,644 epoch [593/800] time: 4.87s train loss: 0.0652 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:34:33,508 epoch [593/800] time: 0.86s val loss: 0.1396 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:34:38,386 epoch [594/800] time: 4.88s train loss: 0.0646 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:34:39,209 epoch [594/800] time: 0.82s val loss: 0.1389 accuracy: 0.9509 f1: 0.9502
2023-07-14 03:34:44,300 epoch [595/800] time: 5.09s train loss: 0.0653 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:34:45,211 epoch [595/800] time: 0.91s val loss: 0.1391 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:34:50,391 epoch [596/800] time: 5.18s train loss: 0.0647 accuracy: 0.9812 f1: 0.9809
2023-07-14 03:34:51,303 epoch [596/800] time: 0.91s val loss: 0.1394 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:34:56,448 epoch [597/800] time: 5.14s train loss: 0.064 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:34:57,338 epoch [597/800] time: 0.89s val loss: 0.1391 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:35:02,658 epoch [598/800] time: 5.32s train loss: 0.0643 accuracy: 0.981 f1: 0.981
2023-07-14 03:35:03,588 epoch [598/800] time: 0.93s val loss: 0.139 accuracy: 0.9509 f1: 0.9502
2023-07-14 03:35:08,830 epoch [599/800] time: 5.24s train loss: 0.0651 accuracy: 0.9814 f1: 0.9812
2023-07-14 03:35:09,740 epoch [599/800] time: 0.91s val loss: 0.1387 accuracy: 0.9508 f1: 0.95
2023-07-14 03:35:14,946 epoch [600/800] time: 5.2s train loss: 0.0639 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:35:15,820 epoch [600/800] time: 0.87s val loss: 0.1407 accuracy: 0.95 f1: 0.9492
2023-07-14 03:35:20,874 epoch [601/800] time: 5.05s train loss: 0.0644 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:35:21,739 epoch [601/800] time: 0.86s val loss: 0.1394 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:35:26,590 epoch [602/800] time: 4.85s train loss: 0.0644 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:35:27,480 epoch [602/800] time: 0.89s val loss: 0.1393 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:35:32,278 epoch [603/800] time: 4.8s train loss: 0.0639 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:35:33,079 epoch [603/800] time: 0.8s val loss: 0.1384 accuracy: 0.9514 f1: 0.9506
2023-07-14 03:35:37,922 epoch [604/800] time: 4.84s train loss: 0.0644 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:35:38,773 epoch [604/800] time: 0.85s val loss: 0.1403 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:35:43,553 epoch [605/800] time: 4.78s train loss: 0.0644 accuracy: 0.9811 f1: 0.9811
2023-07-14 03:35:44,396 epoch [605/800] time: 0.84s val loss: 0.1408 accuracy: 0.9503 f1: 0.9494
2023-07-14 03:35:49,202 epoch [606/800] time: 4.81s train loss: 0.0644 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:35:50,001 epoch [606/800] time: 0.8s val loss: 0.1396 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:35:54,782 epoch [607/800] time: 4.78s train loss: 0.0636 accuracy: 0.982 f1: 0.9819
2023-07-14 03:35:55,657 epoch [607/800] time: 0.87s val loss: 0.1393 accuracy: 0.9508 f1: 0.9499
2023-07-14 03:36:00,395 epoch [608/800] time: 4.74s train loss: 0.0638 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:36:01,254 epoch [608/800] time: 0.86s val loss: 0.139 accuracy: 0.9503 f1: 0.9494
2023-07-14 03:36:05,834 epoch [609/800] time: 4.58s train loss: 0.0645 accuracy: 0.9812 f1: 0.9809
2023-07-14 03:36:06,642 epoch [609/800] time: 0.81s val loss: 0.1389 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:36:11,237 epoch [610/800] time: 4.6s train loss: 0.0646 accuracy: 0.9818 f1: 0.9816
2023-07-14 03:36:12,087 epoch [610/800] time: 0.85s val loss: 0.1391 accuracy: 0.9505 f1: 0.9496
2023-07-14 03:36:16,587 epoch [611/800] time: 4.5s train loss: 0.0646 accuracy: 0.9818 f1: 0.9818
2023-07-14 03:36:17,432 epoch [611/800] time: 0.84s val loss: 0.1403 accuracy: 0.9503 f1: 0.9494
2023-07-14 03:36:22,162 epoch [612/800] time: 4.73s train loss: 0.0634 accuracy: 0.9817 f1: 0.9815
2023-07-14 03:36:22,985 epoch [612/800] time: 0.82s val loss: 0.1398 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:36:27,722 epoch [613/800] time: 4.74s train loss: 0.0649 accuracy: 0.9811 f1: 0.9809
2023-07-14 03:36:28,575 epoch [613/800] time: 0.85s val loss: 0.1398 accuracy: 0.9506 f1: 0.9497
2023-07-14 03:36:33,368 epoch [614/800] time: 4.79s train loss: 0.0636 accuracy: 0.9819 f1: 0.9817
2023-07-14 03:36:34,214 epoch [614/800] time: 0.85s val loss: 0.1397 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:36:39,215 epoch [615/800] time: 5.0s train loss: 0.0662 accuracy: 0.9812 f1: 0.981
2023-07-14 03:36:40,070 epoch [615/800] time: 0.85s val loss: 0.1402 accuracy: 0.9503 f1: 0.9495
2023-07-14 03:36:45,188 epoch [616/800] time: 5.12s train loss: 0.0642 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:36:46,060 epoch [616/800] time: 0.87s val loss: 0.1389 accuracy: 0.9515 f1: 0.9507
2023-07-14 03:36:51,261 epoch [617/800] time: 5.2s train loss: 0.0647 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:36:52,209 epoch [617/800] time: 0.95s val loss: 0.1393 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:36:57,343 epoch [618/800] time: 5.13s train loss: 0.0636 accuracy: 0.9817 f1: 0.9815
2023-07-14 03:36:58,177 epoch [618/800] time: 0.83s val loss: 0.1399 accuracy: 0.9511 f1: 0.9503
2023-07-14 03:37:03,252 epoch [619/800] time: 5.07s train loss: 0.0646 accuracy: 0.9817 f1: 0.9815
2023-07-14 03:37:04,189 epoch [619/800] time: 0.94s val loss: 0.1394 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:37:08,971 epoch [620/800] time: 4.78s train loss: 0.0652 accuracy: 0.9811 f1: 0.9809
2023-07-14 03:37:09,829 epoch [620/800] time: 0.86s val loss: 0.1406 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:37:14,456 epoch [621/800] time: 4.63s train loss: 0.0642 accuracy: 0.9814 f1: 0.9814
2023-07-14 03:37:15,262 epoch [621/800] time: 0.81s val loss: 0.139 accuracy: 0.9509 f1: 0.95
2023-07-14 03:37:20,042 epoch [622/800] time: 4.78s train loss: 0.0636 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:37:20,923 epoch [622/800] time: 0.88s val loss: 0.1396 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:37:25,712 epoch [623/800] time: 4.79s train loss: 0.064 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:37:26,566 epoch [623/800] time: 0.85s val loss: 0.1395 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:37:31,255 epoch [624/800] time: 4.69s train loss: 0.063 accuracy: 0.9819 f1: 0.9818
2023-07-14 03:37:32,063 epoch [624/800] time: 0.81s val loss: 0.139 accuracy: 0.9511 f1: 0.9504
2023-07-14 03:37:36,829 epoch [625/800] time: 4.77s train loss: 0.0637 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:37:37,678 epoch [625/800] time: 0.85s val loss: 0.1385 accuracy: 0.9511 f1: 0.9503
2023-07-14 03:37:42,491 epoch [626/800] time: 4.81s train loss: 0.0641 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:37:43,363 epoch [626/800] time: 0.87s val loss: 0.1392 accuracy: 0.9506 f1: 0.9497
2023-07-14 03:37:48,218 epoch [627/800] time: 4.85s train loss: 0.064 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:37:49,023 epoch [627/800] time: 0.81s val loss: 0.1391 accuracy: 0.9505 f1: 0.9496
2023-07-14 03:37:53,845 epoch [628/800] time: 4.82s train loss: 0.0643 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:37:54,740 epoch [628/800] time: 0.89s val loss: 0.1391 accuracy: 0.9508 f1: 0.95
2023-07-14 03:37:59,652 epoch [629/800] time: 4.91s train loss: 0.0639 accuracy: 0.9819 f1: 0.9817
2023-07-14 03:38:00,510 epoch [629/800] time: 0.86s val loss: 0.1398 accuracy: 0.9498 f1: 0.9489
2023-07-14 03:38:05,264 epoch [630/800] time: 4.75s train loss: 0.0634 accuracy: 0.9822 f1: 0.9819
2023-07-14 03:38:06,076 epoch [630/800] time: 0.81s val loss: 0.1394 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:38:10,981 epoch [631/800] time: 4.9s train loss: 0.0661 accuracy: 0.9811 f1: 0.9809
2023-07-14 03:38:11,859 epoch [631/800] time: 0.88s val loss: 0.1405 accuracy: 0.9496 f1: 0.9487
2023-07-14 03:38:16,532 epoch [632/800] time: 4.67s train loss: 0.0647 accuracy: 0.981 f1: 0.981
2023-07-14 03:38:17,384 epoch [632/800] time: 0.85s val loss: 0.1391 accuracy: 0.9503 f1: 0.9494
2023-07-14 03:38:22,168 epoch [633/800] time: 4.78s train loss: 0.0655 accuracy: 0.9808 f1: 0.9806
2023-07-14 03:38:22,970 epoch [633/800] time: 0.8s val loss: 0.1386 accuracy: 0.9511 f1: 0.9504
2023-07-14 03:38:27,602 epoch [634/800] time: 4.63s train loss: 0.0627 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:38:28,445 epoch [634/800] time: 0.84s val loss: 0.1388 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:38:33,176 epoch [635/800] time: 4.73s train loss: 0.0646 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:38:34,047 epoch [635/800] time: 0.87s val loss: 0.14 accuracy: 0.9504 f1: 0.9496
2023-07-14 03:38:38,754 epoch [636/800] time: 4.71s train loss: 0.0654 accuracy: 0.981 f1: 0.9809
2023-07-14 03:38:39,561 epoch [636/800] time: 0.81s val loss: 0.1399 accuracy: 0.9512 f1: 0.9505
2023-07-14 03:38:44,344 epoch [637/800] time: 4.78s train loss: 0.0649 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:38:45,188 epoch [637/800] time: 0.84s val loss: 0.1391 accuracy: 0.9502 f1: 0.9494
2023-07-14 03:38:49,907 epoch [638/800] time: 4.72s train loss: 0.0634 accuracy: 0.9819 f1: 0.9818
2023-07-14 03:38:50,761 epoch [638/800] time: 0.85s val loss: 0.1387 accuracy: 0.9503 f1: 0.9495
2023-07-14 03:38:55,509 epoch [639/800] time: 4.75s train loss: 0.0643 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:38:56,310 epoch [639/800] time: 0.8s val loss: 0.1391 accuracy: 0.9505 f1: 0.9496
2023-07-14 03:39:01,276 epoch [640/800] time: 4.97s train loss: 0.0642 accuracy: 0.982 f1: 0.982
2023-07-14 03:39:02,178 epoch [640/800] time: 0.9s val loss: 0.1395 accuracy: 0.9512 f1: 0.9503
2023-07-14 03:39:07,206 epoch [641/800] time: 5.03s train loss: 0.0641 accuracy: 0.9817 f1: 0.9815
2023-07-14 03:39:08,114 epoch [641/800] time: 0.91s val loss: 0.1396 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:39:13,094 epoch [642/800] time: 4.98s train loss: 0.0632 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:39:13,992 epoch [642/800] time: 0.9s val loss: 0.1393 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:39:19,222 epoch [643/800] time: 5.23s train loss: 0.0645 accuracy: 0.9811 f1: 0.981
2023-07-14 03:39:20,158 epoch [643/800] time: 0.94s val loss: 0.1397 accuracy: 0.9503 f1: 0.9494
2023-07-14 03:39:25,186 epoch [644/800] time: 5.03s train loss: 0.0636 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:39:26,071 epoch [644/800] time: 0.88s val loss: 0.1385 accuracy: 0.9511 f1: 0.9504
2023-07-14 03:39:31,345 epoch [645/800] time: 5.27s train loss: 0.0646 accuracy: 0.982 f1: 0.9819
2023-07-14 03:39:32,236 epoch [645/800] time: 0.89s val loss: 0.1395 accuracy: 0.9503 f1: 0.9494
2023-07-14 03:39:37,451 epoch [646/800] time: 5.21s train loss: 0.0632 accuracy: 0.9819 f1: 0.9818
2023-07-14 03:39:38,332 epoch [646/800] time: 0.88s val loss: 0.1393 accuracy: 0.9507 f1: 0.95
2023-07-14 03:39:43,363 epoch [647/800] time: 5.03s train loss: 0.0643 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:39:44,275 epoch [647/800] time: 0.91s val loss: 0.1396 accuracy: 0.9511 f1: 0.9504
2023-07-14 03:39:49,532 epoch [648/800] time: 5.26s train loss: 0.0629 accuracy: 0.9819 f1: 0.9817
2023-07-14 03:39:50,376 epoch [648/800] time: 0.84s val loss: 0.1386 accuracy: 0.9514 f1: 0.9506
2023-07-14 03:39:55,410 epoch [649/800] time: 5.03s train loss: 0.0634 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:39:56,354 epoch [649/800] time: 0.94s val loss: 0.1393 accuracy: 0.9515 f1: 0.9507
2023-07-14 03:40:02,012 epoch [650/800] time: 5.66s train loss: 0.0638 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:40:02,890 epoch [650/800] time: 0.88s val loss: 0.1395 accuracy: 0.9506 f1: 0.9497
2023-07-14 03:40:07,952 epoch [651/800] time: 5.06s train loss: 0.0647 accuracy: 0.9809 f1: 0.9808
2023-07-14 03:40:08,783 epoch [651/800] time: 0.83s val loss: 0.14 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:40:14,000 epoch [652/800] time: 5.22s train loss: 0.0644 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:40:14,905 epoch [652/800] time: 0.9s val loss: 0.1388 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:40:19,919 epoch [653/800] time: 5.01s train loss: 0.0635 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:40:20,802 epoch [653/800] time: 0.88s val loss: 0.1391 accuracy: 0.9512 f1: 0.9505
2023-07-14 03:40:25,910 epoch [654/800] time: 5.11s train loss: 0.0644 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:40:26,745 epoch [654/800] time: 0.84s val loss: 0.1391 accuracy: 0.951 f1: 0.9501
2023-07-14 03:40:31,722 epoch [655/800] time: 4.98s train loss: 0.067 accuracy: 0.9809 f1: 0.9808
2023-07-14 03:40:32,614 epoch [655/800] time: 0.89s val loss: 0.1399 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:40:37,500 epoch [656/800] time: 4.89s train loss: 0.0654 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:40:38,398 epoch [656/800] time: 0.9s val loss: 0.1398 accuracy: 0.9511 f1: 0.9502
2023-07-14 03:40:43,428 epoch [657/800] time: 5.03s train loss: 0.0648 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:40:44,247 epoch [657/800] time: 0.82s val loss: 0.1399 accuracy: 0.9508 f1: 0.9499
2023-07-14 03:40:49,258 epoch [658/800] time: 5.01s train loss: 0.0629 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:40:50,120 epoch [658/800] time: 0.86s val loss: 0.1388 accuracy: 0.9512 f1: 0.9504
2023-07-14 03:40:54,839 epoch [659/800] time: 4.72s train loss: 0.0639 accuracy: 0.982 f1: 0.9819
2023-07-14 03:40:55,691 epoch [659/800] time: 0.85s val loss: 0.1391 accuracy: 0.951 f1: 0.9502
2023-07-14 03:41:00,455 epoch [660/800] time: 4.76s train loss: 0.0643 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:41:01,254 epoch [660/800] time: 0.8s val loss: 0.1402 accuracy: 0.9502 f1: 0.9494
2023-07-14 03:41:06,101 epoch [661/800] time: 4.85s train loss: 0.0638 accuracy: 0.9819 f1: 0.9818
2023-07-14 03:41:06,956 epoch [661/800] time: 0.85s val loss: 0.1386 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:41:11,638 epoch [662/800] time: 4.68s train loss: 0.064 accuracy: 0.9817 f1: 0.9815
2023-07-14 03:41:12,488 epoch [662/800] time: 0.85s val loss: 0.1388 accuracy: 0.9512 f1: 0.9502
2023-07-14 03:41:17,365 epoch [663/800] time: 4.88s train loss: 0.0649 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:41:18,183 epoch [663/800] time: 0.82s val loss: 0.139 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:41:23,063 epoch [664/800] time: 4.88s train loss: 0.0645 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:41:23,914 epoch [664/800] time: 0.85s val loss: 0.1399 accuracy: 0.9507 f1: 0.9498
2023-07-14 03:41:28,619 epoch [665/800] time: 4.7s train loss: 0.0641 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:41:29,484 epoch [665/800] time: 0.86s val loss: 0.1393 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:41:34,437 epoch [666/800] time: 4.95s train loss: 0.0634 accuracy: 0.9819 f1: 0.9818
2023-07-14 03:41:35,241 epoch [666/800] time: 0.8s val loss: 0.1392 accuracy: 0.9506 f1: 0.9499
2023-07-14 03:41:39,937 epoch [667/800] time: 4.7s train loss: 0.0632 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:41:40,789 epoch [667/800] time: 0.85s val loss: 0.1389 accuracy: 0.951 f1: 0.9503
2023-07-14 03:41:45,672 epoch [668/800] time: 4.88s train loss: 0.0648 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:41:46,540 epoch [668/800] time: 0.87s val loss: 0.1398 accuracy: 0.951 f1: 0.9502
2023-07-14 03:41:51,349 epoch [669/800] time: 4.81s train loss: 0.0638 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:41:52,162 epoch [669/800] time: 0.81s val loss: 0.1391 accuracy: 0.9502 f1: 0.9493
2023-07-14 03:41:56,926 epoch [670/800] time: 4.76s train loss: 0.0641 accuracy: 0.9812 f1: 0.981
2023-07-14 03:41:57,765 epoch [670/800] time: 0.84s val loss: 0.1389 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:42:02,446 epoch [671/800] time: 4.68s train loss: 0.065 accuracy: 0.982 f1: 0.9818
2023-07-14 03:42:03,286 epoch [671/800] time: 0.84s val loss: 0.1388 accuracy: 0.951 f1: 0.9503
2023-07-14 03:42:08,009 epoch [672/800] time: 4.72s train loss: 0.0653 accuracy: 0.9812 f1: 0.981
2023-07-14 03:42:08,804 epoch [672/800] time: 0.8s val loss: 0.1392 accuracy: 0.9506 f1: 0.9499
2023-07-14 03:42:13,550 epoch [673/800] time: 4.75s train loss: 0.0643 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:42:14,389 epoch [673/800] time: 0.84s val loss: 0.1389 accuracy: 0.9512 f1: 0.9505
2023-07-14 03:42:19,402 epoch [674/800] time: 5.01s train loss: 0.0638 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:42:20,297 epoch [674/800] time: 0.89s val loss: 0.1389 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:42:25,320 epoch [675/800] time: 5.02s train loss: 0.0659 accuracy: 0.9808 f1: 0.9807
2023-07-14 03:42:26,189 epoch [675/800] time: 0.87s val loss: 0.1402 accuracy: 0.9499 f1: 0.9491
2023-07-14 03:42:31,719 epoch [676/800] time: 5.53s train loss: 0.0647 accuracy: 0.981 f1: 0.9809
2023-07-14 03:42:32,722 epoch [676/800] time: 1.0s val loss: 0.1397 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:42:37,741 epoch [677/800] time: 5.02s train loss: 0.0659 accuracy: 0.981 f1: 0.9808
2023-07-14 03:42:38,598 epoch [677/800] time: 0.86s val loss: 0.141 accuracy: 0.9502 f1: 0.9493
2023-07-14 03:42:43,419 epoch [678/800] time: 4.82s train loss: 0.0645 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:42:44,238 epoch [678/800] time: 0.82s val loss: 0.1399 accuracy: 0.9504 f1: 0.9496
2023-07-14 03:42:49,063 epoch [679/800] time: 4.82s train loss: 0.0639 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:42:49,919 epoch [679/800] time: 0.86s val loss: 0.1393 accuracy: 0.9508 f1: 0.9499
2023-07-14 03:42:54,620 epoch [680/800] time: 4.7s train loss: 0.0635 accuracy: 0.9819 f1: 0.9818
2023-07-14 03:42:55,476 epoch [680/800] time: 0.86s val loss: 0.1398 accuracy: 0.9503 f1: 0.9494
2023-07-14 03:43:00,367 epoch [681/800] time: 4.89s train loss: 0.0639 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:43:01,196 epoch [681/800] time: 0.83s val loss: 0.1396 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:43:05,880 epoch [682/800] time: 4.68s train loss: 0.0635 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:43:06,738 epoch [682/800] time: 0.86s val loss: 0.1386 accuracy: 0.9508 f1: 0.95
2023-07-14 03:43:11,406 epoch [683/800] time: 4.67s train loss: 0.0656 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:43:12,258 epoch [683/800] time: 0.85s val loss: 0.1396 accuracy: 0.9512 f1: 0.9504
2023-07-14 03:43:17,297 epoch [684/800] time: 5.04s train loss: 0.0649 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:43:18,136 epoch [684/800] time: 0.84s val loss: 0.1401 accuracy: 0.9498 f1: 0.9491
2023-07-14 03:43:23,056 epoch [685/800] time: 4.92s train loss: 0.0642 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:43:23,992 epoch [685/800] time: 0.94s val loss: 0.1388 accuracy: 0.951 f1: 0.9503
2023-07-14 03:43:28,840 epoch [686/800] time: 4.85s train loss: 0.0648 accuracy: 0.981 f1: 0.9809
2023-07-14 03:43:29,716 epoch [686/800] time: 0.87s val loss: 0.1392 accuracy: 0.9511 f1: 0.9504
2023-07-14 03:43:34,803 epoch [687/800] time: 5.09s train loss: 0.0637 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:43:35,617 epoch [687/800] time: 0.81s val loss: 0.1388 accuracy: 0.951 f1: 0.9502
2023-07-14 03:43:40,303 epoch [688/800] time: 4.69s train loss: 0.0647 accuracy: 0.9809 f1: 0.9807
2023-07-14 03:43:41,151 epoch [688/800] time: 0.85s val loss: 0.1389 accuracy: 0.951 f1: 0.9502
2023-07-14 03:43:45,794 epoch [689/800] time: 4.64s train loss: 0.0636 accuracy: 0.982 f1: 0.9818
2023-07-14 03:43:46,643 epoch [689/800] time: 0.85s val loss: 0.1398 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:43:51,668 epoch [690/800] time: 5.02s train loss: 0.064 accuracy: 0.9819 f1: 0.9818
2023-07-14 03:43:52,506 epoch [690/800] time: 0.84s val loss: 0.1401 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:43:57,671 epoch [691/800] time: 5.16s train loss: 0.0655 accuracy: 0.981 f1: 0.9809
2023-07-14 03:43:58,579 epoch [691/800] time: 0.91s val loss: 0.1403 accuracy: 0.9504 f1: 0.9495
2023-07-14 03:44:03,764 epoch [692/800] time: 5.18s train loss: 0.0642 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:44:04,648 epoch [692/800] time: 0.88s val loss: 0.1394 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:44:09,664 epoch [693/800] time: 5.02s train loss: 0.0644 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:44:10,496 epoch [693/800] time: 0.83s val loss: 0.1387 accuracy: 0.9509 f1: 0.9503
2023-07-14 03:44:15,493 epoch [694/800] time: 5.0s train loss: 0.0638 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:44:16,398 epoch [694/800] time: 0.9s val loss: 0.1391 accuracy: 0.9508 f1: 0.9499
2023-07-14 03:44:21,891 epoch [695/800] time: 5.49s train loss: 0.0637 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:44:22,838 epoch [695/800] time: 0.95s val loss: 0.1395 accuracy: 0.9501 f1: 0.9493
2023-07-14 03:44:27,952 epoch [696/800] time: 5.11s train loss: 0.0646 accuracy: 0.9806 f1: 0.9805
2023-07-14 03:44:28,805 epoch [696/800] time: 0.85s val loss: 0.1387 accuracy: 0.9508 f1: 0.95
2023-07-14 03:44:33,721 epoch [697/800] time: 4.91s train loss: 0.064 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:44:34,619 epoch [697/800] time: 0.9s val loss: 0.1387 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:44:39,241 epoch [698/800] time: 4.62s train loss: 0.0643 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:44:40,097 epoch [698/800] time: 0.86s val loss: 0.1393 accuracy: 0.9511 f1: 0.9503
2023-07-14 03:44:45,104 epoch [699/800] time: 5.01s train loss: 0.0653 accuracy: 0.9806 f1: 0.9805
2023-07-14 03:44:45,918 epoch [699/800] time: 0.81s val loss: 0.139 accuracy: 0.9505 f1: 0.9498
2023-07-14 03:44:50,623 epoch [700/800] time: 4.7s train loss: 0.0646 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:44:51,478 epoch [700/800] time: 0.85s val loss: 0.1386 accuracy: 0.9511 f1: 0.9504
2023-07-14 03:44:56,156 epoch [701/800] time: 4.68s train loss: 0.0639 accuracy: 0.9819 f1: 0.9817
2023-07-14 03:44:57,013 epoch [701/800] time: 0.86s val loss: 0.1396 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:45:01,602 epoch [702/800] time: 4.59s train loss: 0.0652 accuracy: 0.9812 f1: 0.9812
2023-07-14 03:45:02,410 epoch [702/800] time: 0.81s val loss: 0.1396 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:45:07,047 epoch [703/800] time: 4.64s train loss: 0.0637 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:45:07,893 epoch [703/800] time: 0.85s val loss: 0.1394 accuracy: 0.9504 f1: 0.9496
2023-07-14 03:45:12,511 epoch [704/800] time: 4.62s train loss: 0.0642 accuracy: 0.9809 f1: 0.9807
2023-07-14 03:45:13,356 epoch [704/800] time: 0.84s val loss: 0.1395 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:45:18,149 epoch [705/800] time: 4.79s train loss: 0.0635 accuracy: 0.9819 f1: 0.9817
2023-07-14 03:45:18,953 epoch [705/800] time: 0.8s val loss: 0.1395 accuracy: 0.9509 f1: 0.9503
2023-07-14 03:45:23,709 epoch [706/800] time: 4.76s train loss: 0.0646 accuracy: 0.9811 f1: 0.981
2023-07-14 03:45:24,562 epoch [706/800] time: 0.85s val loss: 0.1389 accuracy: 0.9507 f1: 0.9498
2023-07-14 03:45:29,219 epoch [707/800] time: 4.66s train loss: 0.0645 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:45:30,064 epoch [707/800] time: 0.84s val loss: 0.139 accuracy: 0.9509 f1: 0.9502
2023-07-14 03:45:34,765 epoch [708/800] time: 4.7s train loss: 0.0648 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:45:35,570 epoch [708/800] time: 0.8s val loss: 0.1392 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:45:40,354 epoch [709/800] time: 4.78s train loss: 0.0642 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:45:41,201 epoch [709/800] time: 0.85s val loss: 0.1387 accuracy: 0.9511 f1: 0.9504
2023-07-14 03:45:45,925 epoch [710/800] time: 4.72s train loss: 0.0641 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:45:46,771 epoch [710/800] time: 0.85s val loss: 0.1407 accuracy: 0.9499 f1: 0.9491
2023-07-14 03:45:51,508 epoch [711/800] time: 4.74s train loss: 0.064 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:45:52,323 epoch [711/800] time: 0.81s val loss: 0.1387 accuracy: 0.951 f1: 0.9502
2023-07-14 03:45:57,046 epoch [712/800] time: 4.72s train loss: 0.0639 accuracy: 0.9818 f1: 0.9816
2023-07-14 03:45:57,891 epoch [712/800] time: 0.84s val loss: 0.1399 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:46:02,621 epoch [713/800] time: 4.73s train loss: 0.0641 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:46:03,472 epoch [713/800] time: 0.85s val loss: 0.1393 accuracy: 0.9513 f1: 0.9504
2023-07-14 03:46:08,254 epoch [714/800] time: 4.78s train loss: 0.064 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:46:09,059 epoch [714/800] time: 0.81s val loss: 0.1394 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:46:13,821 epoch [715/800] time: 4.76s train loss: 0.0641 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:46:14,667 epoch [715/800] time: 0.85s val loss: 0.1395 accuracy: 0.9503 f1: 0.9494
2023-07-14 03:46:19,334 epoch [716/800] time: 4.67s train loss: 0.0631 accuracy: 0.9821 f1: 0.9819
2023-07-14 03:46:20,182 epoch [716/800] time: 0.85s val loss: 0.139 accuracy: 0.951 f1: 0.9503
2023-07-14 03:46:24,963 epoch [717/800] time: 4.78s train loss: 0.0661 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:46:25,761 epoch [717/800] time: 0.8s val loss: 0.1405 accuracy: 0.9504 f1: 0.9495
2023-07-14 03:46:30,552 epoch [718/800] time: 4.79s train loss: 0.0644 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:46:31,402 epoch [718/800] time: 0.85s val loss: 0.1387 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:46:35,986 epoch [719/800] time: 4.58s train loss: 0.0632 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:46:36,829 epoch [719/800] time: 0.84s val loss: 0.1388 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:46:41,688 epoch [720/800] time: 4.86s train loss: 0.064 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:46:42,520 epoch [720/800] time: 0.83s val loss: 0.1404 accuracy: 0.9503 f1: 0.9494
2023-07-14 03:46:47,474 epoch [721/800] time: 4.95s train loss: 0.0642 accuracy: 0.982 f1: 0.9819
2023-07-14 03:46:48,336 epoch [721/800] time: 0.86s val loss: 0.1389 accuracy: 0.9508 f1: 0.95
2023-07-14 03:46:52,960 epoch [722/800] time: 4.62s train loss: 0.0638 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:46:53,848 epoch [722/800] time: 0.89s val loss: 0.1396 accuracy: 0.951 f1: 0.9502
2023-07-14 03:46:59,024 epoch [723/800] time: 5.17s train loss: 0.0637 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:46:59,866 epoch [723/800] time: 0.84s val loss: 0.1395 accuracy: 0.9506 f1: 0.9497
2023-07-14 03:47:04,543 epoch [724/800] time: 4.68s train loss: 0.0648 accuracy: 0.9811 f1: 0.981
2023-07-14 03:47:05,410 epoch [724/800] time: 0.87s val loss: 0.1391 accuracy: 0.95 f1: 0.9493
2023-07-14 03:47:10,039 epoch [725/800] time: 4.63s train loss: 0.0647 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:47:10,887 epoch [725/800] time: 0.85s val loss: 0.1394 accuracy: 0.9506 f1: 0.9499
2023-07-14 03:47:15,519 epoch [726/800] time: 4.63s train loss: 0.0641 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:47:16,346 epoch [726/800] time: 0.83s val loss: 0.139 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:47:21,029 epoch [727/800] time: 4.68s train loss: 0.0644 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:47:21,881 epoch [727/800] time: 0.85s val loss: 0.1405 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:47:26,411 epoch [728/800] time: 4.53s train loss: 0.0656 accuracy: 0.9809 f1: 0.9807
2023-07-14 03:47:27,262 epoch [728/800] time: 0.85s val loss: 0.1411 accuracy: 0.9506 f1: 0.9499
2023-07-14 03:47:31,797 epoch [729/800] time: 4.53s train loss: 0.0639 accuracy: 0.9812 f1: 0.981
2023-07-14 03:47:32,647 epoch [729/800] time: 0.85s val loss: 0.1388 accuracy: 0.9508 f1: 0.95
2023-07-14 03:47:37,178 epoch [730/800] time: 4.53s train loss: 0.0631 accuracy: 0.9823 f1: 0.9822
2023-07-14 03:47:38,019 epoch [730/800] time: 0.84s val loss: 0.1392 accuracy: 0.9509 f1: 0.95
2023-07-14 03:47:42,645 epoch [731/800] time: 4.63s train loss: 0.0643 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:47:43,500 epoch [731/800] time: 0.85s val loss: 0.1388 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:47:48,195 epoch [732/800] time: 4.7s train loss: 0.0643 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:47:49,000 epoch [732/800] time: 0.8s val loss: 0.1397 accuracy: 0.9502 f1: 0.9494
2023-07-14 03:47:53,577 epoch [733/800] time: 4.58s train loss: 0.0644 accuracy: 0.9813 f1: 0.981
2023-07-14 03:47:54,432 epoch [733/800] time: 0.85s val loss: 0.1398 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:47:59,194 epoch [734/800] time: 4.76s train loss: 0.0641 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:48:00,059 epoch [734/800] time: 0.86s val loss: 0.1385 accuracy: 0.951 f1: 0.9502
2023-07-14 03:48:04,844 epoch [735/800] time: 4.78s train loss: 0.0643 accuracy: 0.9818 f1: 0.9818
2023-07-14 03:48:05,649 epoch [735/800] time: 0.8s val loss: 0.1408 accuracy: 0.9498 f1: 0.9491
2023-07-14 03:48:10,455 epoch [736/800] time: 4.81s train loss: 0.0649 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:48:11,299 epoch [736/800] time: 0.84s val loss: 0.1402 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:48:15,791 epoch [737/800] time: 4.49s train loss: 0.0645 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:48:16,633 epoch [737/800] time: 0.84s val loss: 0.1391 accuracy: 0.9508 f1: 0.95
2023-07-14 03:48:21,333 epoch [738/800] time: 4.7s train loss: 0.0637 accuracy: 0.9821 f1: 0.982
2023-07-14 03:48:22,138 epoch [738/800] time: 0.8s val loss: 0.1402 accuracy: 0.9501 f1: 0.9491
2023-07-14 03:48:26,711 epoch [739/800] time: 4.57s train loss: 0.0634 accuracy: 0.9822 f1: 0.9821
2023-07-14 03:48:27,560 epoch [739/800] time: 0.85s val loss: 0.1388 accuracy: 0.9507 f1: 0.9498
2023-07-14 03:48:32,320 epoch [740/800] time: 4.76s train loss: 0.0644 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:48:33,192 epoch [740/800] time: 0.87s val loss: 0.1397 accuracy: 0.9509 f1: 0.95
2023-07-14 03:48:38,073 epoch [741/800] time: 4.88s train loss: 0.0637 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:48:38,899 epoch [741/800] time: 0.83s val loss: 0.1395 accuracy: 0.9504 f1: 0.9496
2023-07-14 03:48:43,862 epoch [742/800] time: 4.96s train loss: 0.0644 accuracy: 0.9811 f1: 0.9809
2023-07-14 03:48:44,724 epoch [742/800] time: 0.86s val loss: 0.1402 accuracy: 0.9508 f1: 0.95
2023-07-14 03:48:49,618 epoch [743/800] time: 4.89s train loss: 0.0655 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:48:50,464 epoch [743/800] time: 0.85s val loss: 0.1403 accuracy: 0.9502 f1: 0.9493
2023-07-14 03:48:55,241 epoch [744/800] time: 4.78s train loss: 0.0653 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:48:56,040 epoch [744/800] time: 0.8s val loss: 0.1404 accuracy: 0.9498 f1: 0.9489
2023-07-14 03:49:00,754 epoch [745/800] time: 4.71s train loss: 0.0653 accuracy: 0.9813 f1: 0.9813
2023-07-14 03:49:01,596 epoch [745/800] time: 0.84s val loss: 0.1388 accuracy: 0.951 f1: 0.9503
2023-07-14 03:49:06,218 epoch [746/800] time: 4.62s train loss: 0.0654 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:49:07,062 epoch [746/800] time: 0.84s val loss: 0.1416 accuracy: 0.95 f1: 0.9493
2023-07-14 03:49:11,791 epoch [747/800] time: 4.73s train loss: 0.0656 accuracy: 0.9812 f1: 0.9812
2023-07-14 03:49:12,592 epoch [747/800] time: 0.8s val loss: 0.1402 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:49:17,294 epoch [748/800] time: 4.7s train loss: 0.0643 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:49:18,142 epoch [748/800] time: 0.85s val loss: 0.14 accuracy: 0.9508 f1: 0.95
2023-07-14 03:49:22,770 epoch [749/800] time: 4.63s train loss: 0.064 accuracy: 0.9818 f1: 0.9815
2023-07-14 03:49:23,615 epoch [749/800] time: 0.84s val loss: 0.1391 accuracy: 0.951 f1: 0.9503
2023-07-14 03:49:28,359 epoch [750/800] time: 4.74s train loss: 0.0639 accuracy: 0.9815 f1: 0.9814
2023-07-14 03:49:29,163 epoch [750/800] time: 0.8s val loss: 0.1389 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:49:33,885 epoch [751/800] time: 4.72s train loss: 0.0646 accuracy: 0.9812 f1: 0.981
2023-07-14 03:49:34,731 epoch [751/800] time: 0.85s val loss: 0.1389 accuracy: 0.9508 f1: 0.95
2023-07-14 03:49:39,388 epoch [752/800] time: 4.66s train loss: 0.0642 accuracy: 0.9814 f1: 0.9812
2023-07-14 03:49:40,232 epoch [752/800] time: 0.84s val loss: 0.1399 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:49:44,996 epoch [753/800] time: 4.76s train loss: 0.0633 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:49:45,810 epoch [753/800] time: 0.81s val loss: 0.1387 accuracy: 0.9508 f1: 0.95
2023-07-14 03:49:51,005 epoch [754/800] time: 5.19s train loss: 0.0641 accuracy: 0.9809 f1: 0.9807
2023-07-14 03:49:51,922 epoch [754/800] time: 0.92s val loss: 0.1389 accuracy: 0.9512 f1: 0.9503
2023-07-14 03:49:56,837 epoch [755/800] time: 4.91s train loss: 0.0663 accuracy: 0.9811 f1: 0.981
2023-07-14 03:49:57,695 epoch [755/800] time: 0.86s val loss: 0.1392 accuracy: 0.9502 f1: 0.9494
2023-07-14 03:50:02,707 epoch [756/800] time: 5.01s train loss: 0.0641 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:50:03,603 epoch [756/800] time: 0.9s val loss: 0.1391 accuracy: 0.9513 f1: 0.9505
2023-07-14 03:50:08,823 epoch [757/800] time: 5.22s train loss: 0.064 accuracy: 0.9819 f1: 0.9818
2023-07-14 03:50:09,697 epoch [757/800] time: 0.87s val loss: 0.1392 accuracy: 0.9508 f1: 0.9499
2023-07-14 03:50:14,392 epoch [758/800] time: 4.69s train loss: 0.0634 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:50:15,275 epoch [758/800] time: 0.88s val loss: 0.1405 accuracy: 0.9506 f1: 0.9499
2023-07-14 03:50:20,613 epoch [759/800] time: 5.34s train loss: 0.0631 accuracy: 0.9819 f1: 0.9818
2023-07-14 03:50:21,476 epoch [759/800] time: 0.86s val loss: 0.1391 accuracy: 0.9508 f1: 0.9499
2023-07-14 03:50:26,516 epoch [760/800] time: 5.04s train loss: 0.0667 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:50:27,394 epoch [760/800] time: 0.88s val loss: 0.1404 accuracy: 0.95 f1: 0.949
2023-07-14 03:50:32,439 epoch [761/800] time: 5.04s train loss: 0.0648 accuracy: 0.9808 f1: 0.9806
2023-07-14 03:50:33,397 epoch [761/800] time: 0.96s val loss: 0.1397 accuracy: 0.9506 f1: 0.9497
2023-07-14 03:50:38,555 epoch [762/800] time: 5.16s train loss: 0.0643 accuracy: 0.9817 f1: 0.9815
2023-07-14 03:50:39,384 epoch [762/800] time: 0.83s val loss: 0.1392 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:50:44,372 epoch [763/800] time: 4.99s train loss: 0.0654 accuracy: 0.9803 f1: 0.9801
2023-07-14 03:50:45,338 epoch [763/800] time: 0.97s val loss: 0.1393 accuracy: 0.9505 f1: 0.9498
2023-07-14 03:50:50,517 epoch [764/800] time: 5.18s train loss: 0.0656 accuracy: 0.9809 f1: 0.9807
2023-07-14 03:50:51,453 epoch [764/800] time: 0.94s val loss: 0.139 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:50:56,262 epoch [765/800] time: 4.81s train loss: 0.0633 accuracy: 0.9818 f1: 0.9816
2023-07-14 03:50:57,084 epoch [765/800] time: 0.82s val loss: 0.139 accuracy: 0.9506 f1: 0.9497
2023-07-14 03:51:02,283 epoch [766/800] time: 5.2s train loss: 0.0647 accuracy: 0.9813 f1: 0.9812
2023-07-14 03:51:03,189 epoch [766/800] time: 0.91s val loss: 0.1398 accuracy: 0.951 f1: 0.9501
2023-07-14 03:51:08,215 epoch [767/800] time: 5.03s train loss: 0.0637 accuracy: 0.9822 f1: 0.9821
2023-07-14 03:51:09,094 epoch [767/800] time: 0.88s val loss: 0.1387 accuracy: 0.951 f1: 0.9502
2023-07-14 03:51:14,023 epoch [768/800] time: 4.93s train loss: 0.0649 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:51:14,838 epoch [768/800] time: 0.81s val loss: 0.1396 accuracy: 0.9501 f1: 0.9493
2023-07-14 03:51:19,769 epoch [769/800] time: 4.93s train loss: 0.0638 accuracy: 0.9819 f1: 0.9817
2023-07-14 03:51:20,664 epoch [769/800] time: 0.89s val loss: 0.1392 accuracy: 0.9511 f1: 0.9504
2023-07-14 03:51:25,373 epoch [770/800] time: 4.71s train loss: 0.0629 accuracy: 0.9823 f1: 0.9821
2023-07-14 03:51:26,227 epoch [770/800] time: 0.85s val loss: 0.1393 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:51:31,045 epoch [771/800] time: 4.82s train loss: 0.0646 accuracy: 0.9811 f1: 0.9809
2023-07-14 03:51:31,878 epoch [771/800] time: 0.83s val loss: 0.1396 accuracy: 0.9507 f1: 0.9499
2023-07-14 03:51:36,774 epoch [772/800] time: 4.9s train loss: 0.0646 accuracy: 0.9815 f1: 0.9815
2023-07-14 03:51:37,630 epoch [772/800] time: 0.86s val loss: 0.1397 accuracy: 0.95 f1: 0.9492
2023-07-14 03:51:42,218 epoch [773/800] time: 4.59s train loss: 0.0638 accuracy: 0.9817 f1: 0.9815
2023-07-14 03:51:43,089 epoch [773/800] time: 0.87s val loss: 0.1387 accuracy: 0.9508 f1: 0.9501
2023-07-14 03:51:47,962 epoch [774/800] time: 4.87s train loss: 0.0643 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:51:48,770 epoch [774/800] time: 0.81s val loss: 0.1397 accuracy: 0.951 f1: 0.9502
2023-07-14 03:51:53,460 epoch [775/800] time: 4.69s train loss: 0.0638 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:51:54,311 epoch [775/800] time: 0.85s val loss: 0.1393 accuracy: 0.9507 f1: 0.9498
2023-07-14 03:51:59,012 epoch [776/800] time: 4.7s train loss: 0.0645 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:51:59,891 epoch [776/800] time: 0.88s val loss: 0.1392 accuracy: 0.951 f1: 0.9502
2023-07-14 03:52:04,774 epoch [777/800] time: 4.88s train loss: 0.0642 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:52:05,598 epoch [777/800] time: 0.82s val loss: 0.1393 accuracy: 0.9505 f1: 0.9497
2023-07-14 03:52:10,549 epoch [778/800] time: 4.95s train loss: 0.064 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:52:11,408 epoch [778/800] time: 0.86s val loss: 0.1387 accuracy: 0.9513 f1: 0.9505
2023-07-14 03:52:16,165 epoch [779/800] time: 4.76s train loss: 0.0642 accuracy: 0.9819 f1: 0.9818
2023-07-14 03:52:17,035 epoch [779/800] time: 0.87s val loss: 0.1388 accuracy: 0.951 f1: 0.9503
2023-07-14 03:52:22,011 epoch [780/800] time: 4.98s train loss: 0.065 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:52:22,822 epoch [780/800] time: 0.81s val loss: 0.1391 accuracy: 0.9512 f1: 0.9503
2023-07-14 03:52:27,567 epoch [781/800] time: 4.74s train loss: 0.0636 accuracy: 0.9817 f1: 0.9816
2023-07-14 03:52:28,421 epoch [781/800] time: 0.85s val loss: 0.1393 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:52:33,331 epoch [782/800] time: 4.91s train loss: 0.064 accuracy: 0.9817 f1: 0.9815
2023-07-14 03:52:34,201 epoch [782/800] time: 0.87s val loss: 0.1387 accuracy: 0.9509 f1: 0.9501
2023-07-14 03:52:38,962 epoch [783/800] time: 4.76s train loss: 0.0638 accuracy: 0.982 f1: 0.9819
2023-07-14 03:52:39,781 epoch [783/800] time: 0.82s val loss: 0.1397 accuracy: 0.9506 f1: 0.9498
2023-07-14 03:52:44,616 epoch [784/800] time: 4.83s train loss: 0.0637 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:52:45,458 epoch [784/800] time: 0.84s val loss: 0.1389 accuracy: 0.9512 f1: 0.9503
2023-07-14 03:52:50,185 epoch [785/800] time: 4.73s train loss: 0.0646 accuracy: 0.9818 f1: 0.9818
2023-07-14 03:52:51,081 epoch [785/800] time: 0.9s val loss: 0.1395 accuracy: 0.951 f1: 0.9503
2023-07-14 03:52:56,152 epoch [786/800] time: 5.07s train loss: 0.0639 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:52:57,029 epoch [786/800] time: 0.88s val loss: 0.1392 accuracy: 0.9505 f1: 0.9498
2023-07-14 03:53:02,161 epoch [787/800] time: 5.13s train loss: 0.0641 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:53:03,070 epoch [787/800] time: 0.91s val loss: 0.1385 accuracy: 0.9517 f1: 0.951
2023-07-14 03:53:08,307 epoch [788/800] time: 5.24s train loss: 0.064 accuracy: 0.9821 f1: 0.982
2023-07-14 03:53:09,272 epoch [788/800] time: 0.96s val loss: 0.1398 accuracy: 0.9506 f1: 0.9497
2023-07-14 03:53:14,596 epoch [789/800] time: 5.32s train loss: 0.0642 accuracy: 0.9813 f1: 0.9811
2023-07-14 03:53:15,417 epoch [789/800] time: 0.82s val loss: 0.14 accuracy: 0.9508 f1: 0.9499
2023-07-14 03:53:20,430 epoch [790/800] time: 5.01s train loss: 0.0646 accuracy: 0.9816 f1: 0.9814
2023-07-14 03:53:21,321 epoch [790/800] time: 0.89s val loss: 0.1388 accuracy: 0.951 f1: 0.9502
2023-07-14 03:53:26,468 epoch [791/800] time: 5.15s train loss: 0.0647 accuracy: 0.9812 f1: 0.9811
2023-07-14 03:53:27,373 epoch [791/800] time: 0.9s val loss: 0.1403 accuracy: 0.9496 f1: 0.9487
2023-07-14 03:53:32,171 epoch [792/800] time: 4.8s train loss: 0.065 accuracy: 0.9814 f1: 0.9813
2023-07-14 03:53:32,981 epoch [792/800] time: 0.81s val loss: 0.1403 accuracy: 0.9507 f1: 0.9498
2023-07-14 03:53:37,814 epoch [793/800] time: 4.83s train loss: 0.0648 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:53:38,698 epoch [793/800] time: 0.88s val loss: 0.1412 accuracy: 0.9503 f1: 0.9495
2023-07-14 03:53:43,454 epoch [794/800] time: 4.75s train loss: 0.0642 accuracy: 0.9812 f1: 0.981
2023-07-14 03:53:44,308 epoch [794/800] time: 0.85s val loss: 0.1396 accuracy: 0.9503 f1: 0.9495
2023-07-14 03:53:49,055 epoch [795/800] time: 4.75s train loss: 0.065 accuracy: 0.9811 f1: 0.981
2023-07-14 03:53:49,867 epoch [795/800] time: 0.81s val loss: 0.1396 accuracy: 0.9506 f1: 0.9497
2023-07-14 03:53:54,610 epoch [796/800] time: 4.74s train loss: 0.0639 accuracy: 0.9815 f1: 0.9813
2023-07-14 03:53:55,459 epoch [796/800] time: 0.85s val loss: 0.1404 accuracy: 0.9503 f1: 0.9495
2023-07-14 03:54:00,262 epoch [797/800] time: 4.8s train loss: 0.0645 accuracy: 0.9816 f1: 0.9815
2023-07-14 03:54:01,136 epoch [797/800] time: 0.87s val loss: 0.1406 accuracy: 0.9502 f1: 0.9493
2023-07-14 03:54:05,998 epoch [798/800] time: 4.86s train loss: 0.065 accuracy: 0.9805 f1: 0.9803
2023-07-14 03:54:06,818 epoch [798/800] time: 0.82s val loss: 0.1401 accuracy: 0.9503 f1: 0.9494
2023-07-14 03:54:11,401 epoch [799/800] time: 4.58s train loss: 0.0647 accuracy: 0.9814 f1: 0.9812
2023-07-14 03:54:12,268 epoch [799/800] time: 0.87s val loss: 0.1402 accuracy: 0.9501 f1: 0.9493
2023-07-14 03:54:17,025 epoch [800/800] time: 4.76s train loss: 0.0648 accuracy: 0.9818 f1: 0.9817
2023-07-14 03:54:17,872 epoch [800/800] time: 0.85s val loss: 0.1402 accuracy: 0.9506 f1: 0.9499
2023-07-14 03:54:17,887 The model with best acc is saved: epoch 386, acc 0.98261875
2023-07-14 03:54:17,901 The model with best f1 is saved: epoch 386, f1 0.9825604766339088
2023-07-14 03:54:17,980 =======================================================
2023-07-14 03:54:17,980 Best acc classification report:
               precision    recall  f1-score   support

cluster_00205    0.81641   0.95434   0.88000       219
cluster_00222    0.88356   0.78182   0.82958       165
cluster_00232    0.97297   0.59504   0.73846       242
cluster_00246    0.72289   0.71429   0.71856       168
cluster_00259    0.82353   0.85083   0.83696       181
cluster_00261    0.97561   0.81633   0.88889       147
cluster_00262    0.75177   0.86179   0.80303       246
cluster_00267    0.91772   0.83573   0.87481       347
cluster_00275    0.88197   0.85942   0.87055       313
cluster_00276    0.92593   0.83893   0.88028       149
cluster_00278    0.86232   0.72561   0.78808       164
cluster_00287    0.75000   0.95455   0.84000       176
cluster_00291    0.67176   0.95652   0.78924       184
cluster_00293    0.75510   0.92116   0.82991       241
cluster_00294    0.97087   0.82645   0.89286       121
cluster_00296    0.98113   0.81675   0.89143       191
cluster_00298    0.76522   0.84076   0.80121       314
cluster_00299    0.92135   0.62121   0.74208       132
cluster_00300    0.79435   0.94712   0.86404       208
cluster_00303    0.93056   0.79290   0.85623       169
cluster_00304    0.93717   0.89500   0.91560       200
cluster_00319    0.83486   0.85047   0.84259       214
cluster_00322    0.79683   0.91941   0.85374       273
cluster_00333    0.80000   0.93151   0.86076       146
cluster_00338    0.72021   0.83234   0.77222       167
cluster_00340    0.80556   0.81921   0.81232       177
cluster_00344    0.70946   0.85366   0.77491       123
cluster_00346    0.82022   0.92797   0.87078       236
cluster_00350    0.93750   0.74144   0.82803       263
cluster_00352    0.71622   0.86885   0.78519       122
cluster_00359    0.86145   0.67136   0.75462       213
cluster_00360    0.87931   0.77665   0.82480       197
cluster_00361    0.89109   0.57325   0.69767       157
cluster_00365    0.93301   0.84416   0.88636       231
cluster_00368    0.80913   0.91121   0.85714       214
cluster_00373    0.73967   0.90404   0.81364       198
cluster_00374    0.79424   0.86161   0.82655       224
cluster_00375    0.78571   0.88168   0.83094       262
cluster_00377    0.75077   0.96063   0.84283       254
cluster_00380    0.91954   0.89888   0.90909       178
cluster_00385    0.95631   0.76953   0.85281       256
cluster_00388    0.96939   0.61489   0.75248       309
cluster_00389    0.76757   0.68932   0.72634       206
cluster_00390    0.90270   0.85641   0.87895       195
cluster_00394    0.90000   0.77778   0.83444       162
cluster_00400    0.80672   0.86486   0.83478       111
cluster_00401    0.79487   0.95679   0.86835       162
cluster_00405    0.80645   0.85034   0.82781       147
cluster_00407    0.92462   0.72727   0.81416       253
cluster_00408    0.71963   0.72986   0.72471       211
cluster_00409    0.70588   0.68571   0.69565       245
cluster_00412    0.96364   0.84127   0.89831       252
cluster_00445    0.98824   0.61765   0.76018       136
cluster_00473    0.65455   0.90000   0.75789       120
cluster_00585    0.72532   0.80095   0.76126       211
cluster_00589    0.74265   0.72662   0.73455       139
cluster_00591    0.90909   0.78212   0.84084       179
cluster_00593    0.88333   0.72603   0.79699       146
cluster_00596    0.84615   0.70642   0.77000       109
cluster_00603    0.87333   0.83439   0.85342       157
cluster_00604    0.97468   0.96250   0.96855       160
cluster_00607    0.82969   0.89623   0.86168       212
cluster_00612    0.95699   0.86829   0.91049       205
cluster_00616    0.89674   0.73661   0.80882       224
cluster_00619    0.74449   0.97688   0.84500       173
cluster_00629    0.85135   0.84375   0.84753       224
cluster_00630    0.79724   0.88718   0.83981       195
cluster_00635    0.81043   0.87692   0.84236       195
cluster_00637    0.67181   0.87879   0.76149       198
cluster_00639    0.81362   0.92276   0.86476       246
cluster_00642    0.93056   0.88546   0.90745       227
cluster_00645    0.93985   0.69444   0.79872       180
cluster_00647    0.80822   0.58416   0.67816       202
cluster_00652    0.80786   0.81140   0.80963       228
cluster_00653    0.84921   0.75887   0.80150       141
cluster_00656    0.95858   0.88525   0.92045       183
cluster_00657    0.60595   0.72444   0.65992       225
cluster_00661    0.72609   0.97093   0.83085       172
cluster_00662    0.88412   0.83401   0.85833       247
cluster_00667    0.82266   0.79904   0.81068       209
cluster_00762    0.92486   0.88889   0.90652       180
cluster_00201    1.00000   0.99519   0.99759       208
cluster_00217    0.92517   0.72727   0.81437       187
cluster_00239    0.93182   0.88362   0.90708       232
cluster_00320    0.79048   0.97647   0.87368       170
cluster_00391    0.83544   0.91986   0.87562       287
cluster_00398    0.81470   0.94444   0.87479       270
cluster_00415    0.89617   0.91620   0.90608       179
cluster_00477    0.92667   0.76374   0.83735       182
cluster_00478    0.77689   0.96059   0.85903       203
cluster_00479    0.80412   0.98734   0.88636       158
cluster_00078    0.89199   0.91756   0.90459       279
cluster_00079    0.72294   0.97093   0.82878       172
cluster_00083    0.89850   0.80201   0.84752       298
cluster_00090    0.83186   0.88679   0.85845       106
cluster_00094    0.77863   0.83607   0.80632       122
cluster_00096    0.87288   0.86555   0.86920       119
cluster_00101    0.95041   0.77181   0.85185       149
cluster_00086    0.89049   0.97785   0.93213       316
cluster_00095    0.85714   0.83938   0.84817       193
cluster_00097    0.95455   0.84000   0.89362       125
cluster_00106    0.91716   0.99359   0.95385       312
cluster_00553    0.94054   0.83654   0.88550       208
cluster_00554    0.83582   0.96220   0.89457       291
cluster_00569    0.93642   0.79024   0.85714       205
cluster_00015    0.86408   0.87255   0.86829       102
cluster_00017    0.77941   0.93972   0.85209       282
cluster_00018    0.89474   0.73381   0.80632       139
cluster_00023    0.65714   0.90000   0.75963       230
cluster_00025    0.75355   0.88333   0.81330       180
cluster_00030    0.88060   0.63784   0.73981       185
cluster_00035    0.90977   0.76582   0.83162       158
cluster_00039    0.74752   0.78238   0.76456       193
cluster_00042    0.86096   0.81313   0.83636       198
cluster_00046    0.76817   0.94872   0.84895       234
cluster_00055    0.91329   0.81443   0.86104       194
cluster_00059    0.76170   0.84434   0.80089       212
cluster_00061    0.95808   0.84211   0.89636       190
cluster_00274    0.85973   0.96939   0.91127       196
cluster_00308    0.82741   0.88587   0.85564       184
cluster_00337    0.92121   0.84916   0.88372       179
cluster_00362    0.91371   0.88670   0.90000       203
cluster_00369    0.87500   0.97902   0.92409       143
cluster_00392    0.93750   0.95122   0.94431       205
cluster_00414    0.94958   0.93388   0.94167       121
cluster_00419    0.92857   0.80176   0.86052       227
cluster_00420    0.80303   0.86885   0.83465       183
cluster_00421    0.81429   0.91200   0.86038       125
cluster_00422    0.84874   0.78599   0.81616       257
cluster_00427    0.79503   0.85333   0.82315       150
cluster_00430    0.91304   0.56000   0.69421       225
cluster_00431    0.75875   0.81590   0.78629       239
cluster_00436    0.89451   0.98148   0.93598       216
cluster_00439    0.84524   0.91613   0.87926       310
cluster_00444    0.94286   0.98020   0.96117       202
cluster_00447    0.87156   0.65068   0.74510       146
cluster_00448    0.84500   0.86224   0.85354       196
cluster_00450    0.88362   0.77652   0.82661       264
cluster_00456    0.93860   0.79851   0.86290       134
cluster_00458    0.87747   0.77352   0.82222       287
cluster_00460    0.91257   0.86979   0.89067       192
cluster_00463    0.79618   0.84459   0.81967       148
cluster_00467    0.94074   0.76506   0.84385       166
cluster_00483    0.81818   0.90826   0.86087       109
cluster_00484    0.91729   0.85915   0.88727       142
cluster_00007    0.90132   0.83030   0.86435       165
cluster_00036    0.83226   0.92143   0.87458       280
cluster_00054    0.89865   0.93662   0.91724       142
cluster_00062    0.73878   0.84977   0.79039       213
cluster_00064    0.97126   0.82039   0.88947       206
cluster_00065    0.96774   0.90909   0.93750       198
cluster_00067    0.75497   0.86364   0.80565       132
cluster_00071    0.82014   0.86364   0.84133       132
cluster_00075    0.91411   0.64502   0.75635       231
cluster_00084    0.89804   0.89804   0.89804       255
cluster_00093    0.88517   0.79741   0.83900       232
cluster_00001    0.75248   0.93061   0.83212       245
cluster_00002    0.82443   0.71523   0.76596       151
cluster_00003    0.93750   0.55147   0.69444       272
cluster_00006    0.98065   0.81283   0.88889       187
cluster_00008    0.86268   0.86572   0.86420       283
cluster_00010    0.92308   0.74286   0.82322       210
cluster_00012    0.77301   0.85714   0.81290       147
cluster_00019    0.95968   0.79866   0.87179       149
cluster_00022    0.74057   0.88701   0.80720       177
cluster_00026    0.88591   0.72527   0.79758       182
cluster_00029    0.73171   0.92105   0.81553       228
cluster_00031    0.82909   0.90476   0.86528       252
cluster_00043    0.88339   0.90580   0.89445       276
cluster_00051    0.73733   0.88398   0.80402       181
cluster_00052    0.79118   0.97429   0.87324       350
cluster_00073    0.83712   0.91322   0.87352       242
cluster_00076    0.83051   0.89091   0.85965       220
cluster_00082    0.97788   0.79783   0.87873       277
cluster_00107    0.94634   0.89815   0.92162       216
cluster_00432    0.89091   0.89416   0.89253       274
cluster_00440    0.95327   0.80000   0.86994       255
cluster_00455    0.96914   0.85792   0.91014       183
cluster_00714    0.91163   0.85590   0.88288       229
cluster_00791    0.85567   0.94318   0.89730       176
cluster_00119    0.84783   0.93301   0.88838       209
cluster_00121    0.99379   0.91954   0.95522       174
cluster_00155    0.80844   0.96512   0.87986       258
cluster_00556    0.92481   0.99194   0.95720       248
cluster_00557    0.94346   0.93684   0.94014       285
cluster_00689    0.98661   0.94850   0.96718       233
cluster_00692    0.95154   0.92704   0.93913       233
cluster_00718    0.90517   0.93333   0.91904       225
cluster_00725    0.82222   0.88623   0.85303       167
cluster_00727    0.96350   0.89189   0.92632       148
cluster_00729    0.91228   0.92527   0.91873       281
cluster_00733    0.99242   0.94245   0.96679       139
cluster_00738    0.98026   0.88166   0.92835       169
cluster_00740    0.98675   0.90854   0.94603       164
cluster_00744    0.84800   0.89451   0.87064       237
cluster_00753    0.89381   0.92237   0.90787       219
cluster_00777    0.90090   0.95238   0.92593       210
cluster_00795    0.95425   0.82022   0.88218       178

     accuracy                        0.85113     40000
    macro avg    0.86013   0.84852   0.84871     40000
 weighted avg    0.86077   0.85113   0.85031     40000

2023-07-14 03:54:17,980 =======================================================
2023-07-14 03:54:17,980 

2023-07-14 03:54:18,176 =======================================================
2023-07-14 03:54:18,177 Best f1 classification report:
               precision    recall  f1-score   support

cluster_00205    0.81641   0.95434   0.88000       219
cluster_00222    0.88356   0.78182   0.82958       165
cluster_00232    0.97297   0.59504   0.73846       242
cluster_00246    0.72289   0.71429   0.71856       168
cluster_00259    0.82353   0.85083   0.83696       181
cluster_00261    0.97561   0.81633   0.88889       147
cluster_00262    0.75177   0.86179   0.80303       246
cluster_00267    0.91772   0.83573   0.87481       347
cluster_00275    0.88197   0.85942   0.87055       313
cluster_00276    0.92593   0.83893   0.88028       149
cluster_00278    0.86232   0.72561   0.78808       164
cluster_00287    0.75000   0.95455   0.84000       176
cluster_00291    0.67176   0.95652   0.78924       184
cluster_00293    0.75510   0.92116   0.82991       241
cluster_00294    0.97087   0.82645   0.89286       121
cluster_00296    0.98113   0.81675   0.89143       191
cluster_00298    0.76522   0.84076   0.80121       314
cluster_00299    0.92135   0.62121   0.74208       132
cluster_00300    0.79435   0.94712   0.86404       208
cluster_00303    0.93056   0.79290   0.85623       169
cluster_00304    0.93717   0.89500   0.91560       200
cluster_00319    0.83486   0.85047   0.84259       214
cluster_00322    0.79683   0.91941   0.85374       273
cluster_00333    0.80000   0.93151   0.86076       146
cluster_00338    0.72021   0.83234   0.77222       167
cluster_00340    0.80556   0.81921   0.81232       177
cluster_00344    0.70946   0.85366   0.77491       123
cluster_00346    0.82022   0.92797   0.87078       236
cluster_00350    0.93750   0.74144   0.82803       263
cluster_00352    0.71622   0.86885   0.78519       122
cluster_00359    0.86145   0.67136   0.75462       213
cluster_00360    0.87931   0.77665   0.82480       197
cluster_00361    0.89109   0.57325   0.69767       157
cluster_00365    0.93301   0.84416   0.88636       231
cluster_00368    0.80913   0.91121   0.85714       214
cluster_00373    0.73967   0.90404   0.81364       198
cluster_00374    0.79424   0.86161   0.82655       224
cluster_00375    0.78571   0.88168   0.83094       262
cluster_00377    0.75077   0.96063   0.84283       254
cluster_00380    0.91954   0.89888   0.90909       178
cluster_00385    0.95631   0.76953   0.85281       256
cluster_00388    0.96939   0.61489   0.75248       309
cluster_00389    0.76757   0.68932   0.72634       206
cluster_00390    0.90270   0.85641   0.87895       195
cluster_00394    0.90000   0.77778   0.83444       162
cluster_00400    0.80672   0.86486   0.83478       111
cluster_00401    0.79487   0.95679   0.86835       162
cluster_00405    0.80645   0.85034   0.82781       147
cluster_00407    0.92462   0.72727   0.81416       253
cluster_00408    0.71963   0.72986   0.72471       211
cluster_00409    0.70588   0.68571   0.69565       245
cluster_00412    0.96364   0.84127   0.89831       252
cluster_00445    0.98824   0.61765   0.76018       136
cluster_00473    0.65455   0.90000   0.75789       120
cluster_00585    0.72532   0.80095   0.76126       211
cluster_00589    0.74265   0.72662   0.73455       139
cluster_00591    0.90909   0.78212   0.84084       179
cluster_00593    0.88333   0.72603   0.79699       146
cluster_00596    0.84615   0.70642   0.77000       109
cluster_00603    0.87333   0.83439   0.85342       157
cluster_00604    0.97468   0.96250   0.96855       160
cluster_00607    0.82969   0.89623   0.86168       212
cluster_00612    0.95699   0.86829   0.91049       205
cluster_00616    0.89674   0.73661   0.80882       224
cluster_00619    0.74449   0.97688   0.84500       173
cluster_00629    0.85135   0.84375   0.84753       224
cluster_00630    0.79724   0.88718   0.83981       195
cluster_00635    0.81043   0.87692   0.84236       195
cluster_00637    0.67181   0.87879   0.76149       198
cluster_00639    0.81362   0.92276   0.86476       246
cluster_00642    0.93056   0.88546   0.90745       227
cluster_00645    0.93985   0.69444   0.79872       180
cluster_00647    0.80822   0.58416   0.67816       202
cluster_00652    0.80786   0.81140   0.80963       228
cluster_00653    0.84921   0.75887   0.80150       141
cluster_00656    0.95858   0.88525   0.92045       183
cluster_00657    0.60595   0.72444   0.65992       225
cluster_00661    0.72609   0.97093   0.83085       172
cluster_00662    0.88412   0.83401   0.85833       247
cluster_00667    0.82266   0.79904   0.81068       209
cluster_00762    0.92486   0.88889   0.90652       180
cluster_00201    1.00000   0.99519   0.99759       208
cluster_00217    0.92517   0.72727   0.81437       187
cluster_00239    0.93182   0.88362   0.90708       232
cluster_00320    0.79048   0.97647   0.87368       170
cluster_00391    0.83544   0.91986   0.87562       287
cluster_00398    0.81470   0.94444   0.87479       270
cluster_00415    0.89617   0.91620   0.90608       179
cluster_00477    0.92667   0.76374   0.83735       182
cluster_00478    0.77689   0.96059   0.85903       203
cluster_00479    0.80412   0.98734   0.88636       158
cluster_00078    0.89199   0.91756   0.90459       279
cluster_00079    0.72294   0.97093   0.82878       172
cluster_00083    0.89850   0.80201   0.84752       298
cluster_00090    0.83186   0.88679   0.85845       106
cluster_00094    0.77863   0.83607   0.80632       122
cluster_00096    0.87288   0.86555   0.86920       119
cluster_00101    0.95041   0.77181   0.85185       149
cluster_00086    0.89049   0.97785   0.93213       316
cluster_00095    0.85714   0.83938   0.84817       193
cluster_00097    0.95455   0.84000   0.89362       125
cluster_00106    0.91716   0.99359   0.95385       312
cluster_00553    0.94054   0.83654   0.88550       208
cluster_00554    0.83582   0.96220   0.89457       291
cluster_00569    0.93642   0.79024   0.85714       205
cluster_00015    0.86408   0.87255   0.86829       102
cluster_00017    0.77941   0.93972   0.85209       282
cluster_00018    0.89474   0.73381   0.80632       139
cluster_00023    0.65714   0.90000   0.75963       230
cluster_00025    0.75355   0.88333   0.81330       180
cluster_00030    0.88060   0.63784   0.73981       185
cluster_00035    0.90977   0.76582   0.83162       158
cluster_00039    0.74752   0.78238   0.76456       193
cluster_00042    0.86096   0.81313   0.83636       198
cluster_00046    0.76817   0.94872   0.84895       234
cluster_00055    0.91329   0.81443   0.86104       194
cluster_00059    0.76170   0.84434   0.80089       212
cluster_00061    0.95808   0.84211   0.89636       190
cluster_00274    0.85973   0.96939   0.91127       196
cluster_00308    0.82741   0.88587   0.85564       184
cluster_00337    0.92121   0.84916   0.88372       179
cluster_00362    0.91371   0.88670   0.90000       203
cluster_00369    0.87500   0.97902   0.92409       143
cluster_00392    0.93750   0.95122   0.94431       205
cluster_00414    0.94958   0.93388   0.94167       121
cluster_00419    0.92857   0.80176   0.86052       227
cluster_00420    0.80303   0.86885   0.83465       183
cluster_00421    0.81429   0.91200   0.86038       125
cluster_00422    0.84874   0.78599   0.81616       257
cluster_00427    0.79503   0.85333   0.82315       150
cluster_00430    0.91304   0.56000   0.69421       225
cluster_00431    0.75875   0.81590   0.78629       239
cluster_00436    0.89451   0.98148   0.93598       216
cluster_00439    0.84524   0.91613   0.87926       310
cluster_00444    0.94286   0.98020   0.96117       202
cluster_00447    0.87156   0.65068   0.74510       146
cluster_00448    0.84500   0.86224   0.85354       196
cluster_00450    0.88362   0.77652   0.82661       264
cluster_00456    0.93860   0.79851   0.86290       134
cluster_00458    0.87747   0.77352   0.82222       287
cluster_00460    0.91257   0.86979   0.89067       192
cluster_00463    0.79618   0.84459   0.81967       148
cluster_00467    0.94074   0.76506   0.84385       166
cluster_00483    0.81818   0.90826   0.86087       109
cluster_00484    0.91729   0.85915   0.88727       142
cluster_00007    0.90132   0.83030   0.86435       165
cluster_00036    0.83226   0.92143   0.87458       280
cluster_00054    0.89865   0.93662   0.91724       142
cluster_00062    0.73878   0.84977   0.79039       213
cluster_00064    0.97126   0.82039   0.88947       206
cluster_00065    0.96774   0.90909   0.93750       198
cluster_00067    0.75497   0.86364   0.80565       132
cluster_00071    0.82014   0.86364   0.84133       132
cluster_00075    0.91411   0.64502   0.75635       231
cluster_00084    0.89804   0.89804   0.89804       255
cluster_00093    0.88517   0.79741   0.83900       232
cluster_00001    0.75248   0.93061   0.83212       245
cluster_00002    0.82443   0.71523   0.76596       151
cluster_00003    0.93750   0.55147   0.69444       272
cluster_00006    0.98065   0.81283   0.88889       187
cluster_00008    0.86268   0.86572   0.86420       283
cluster_00010    0.92308   0.74286   0.82322       210
cluster_00012    0.77301   0.85714   0.81290       147
cluster_00019    0.95968   0.79866   0.87179       149
cluster_00022    0.74057   0.88701   0.80720       177
cluster_00026    0.88591   0.72527   0.79758       182
cluster_00029    0.73171   0.92105   0.81553       228
cluster_00031    0.82909   0.90476   0.86528       252
cluster_00043    0.88339   0.90580   0.89445       276
cluster_00051    0.73733   0.88398   0.80402       181
cluster_00052    0.79118   0.97429   0.87324       350
cluster_00073    0.83712   0.91322   0.87352       242
cluster_00076    0.83051   0.89091   0.85965       220
cluster_00082    0.97788   0.79783   0.87873       277
cluster_00107    0.94634   0.89815   0.92162       216
cluster_00432    0.89091   0.89416   0.89253       274
cluster_00440    0.95327   0.80000   0.86994       255
cluster_00455    0.96914   0.85792   0.91014       183
cluster_00714    0.91163   0.85590   0.88288       229
cluster_00791    0.85567   0.94318   0.89730       176
cluster_00119    0.84783   0.93301   0.88838       209
cluster_00121    0.99379   0.91954   0.95522       174
cluster_00155    0.80844   0.96512   0.87986       258
cluster_00556    0.92481   0.99194   0.95720       248
cluster_00557    0.94346   0.93684   0.94014       285
cluster_00689    0.98661   0.94850   0.96718       233
cluster_00692    0.95154   0.92704   0.93913       233
cluster_00718    0.90517   0.93333   0.91904       225
cluster_00725    0.82222   0.88623   0.85303       167
cluster_00727    0.96350   0.89189   0.92632       148
cluster_00729    0.91228   0.92527   0.91873       281
cluster_00733    0.99242   0.94245   0.96679       139
cluster_00738    0.98026   0.88166   0.92835       169
cluster_00740    0.98675   0.90854   0.94603       164
cluster_00744    0.84800   0.89451   0.87064       237
cluster_00753    0.89381   0.92237   0.90787       219
cluster_00777    0.90090   0.95238   0.92593       210
cluster_00795    0.95425   0.82022   0.88218       178

     accuracy                        0.85113     40000
    macro avg    0.86013   0.84852   0.84871     40000
 weighted avg    0.86077   0.85113   0.85031     40000

2023-07-14 03:54:18,177 =======================================================
2023-07-14 03:54:18,177 

2023-07-14 03:54:18,892 =======================================================
2023-07-14 03:54:18,892 Best acc classification report:
               precision    recall  f1-score   support

cluster_00205    0.98058   0.98483   0.98270       923
cluster_00222    0.97876   0.98024   0.97950       658
cluster_00232    0.96670   0.96872   0.96771       959
cluster_00246    0.96644   0.97297   0.96970       740
cluster_00259    0.98367   0.97047   0.97703       745
cluster_00261    0.99117   0.98942   0.99029       567
cluster_00262    0.97868   0.97430   0.97648       895
cluster_00267    0.98689   0.98617   0.98653      1374
cluster_00275    0.97832   0.98172   0.98002      1149
cluster_00276    0.98104   0.97950   0.98027       634
cluster_00278    0.96133   0.98166   0.97139       709
cluster_00287    0.97914   0.98501   0.98206       667
cluster_00291    0.98240   0.97953   0.98097       684
cluster_00293    0.98213   0.98389   0.98301      1117
cluster_00294    0.99031   0.97847   0.98436       418
cluster_00296    0.98709   0.98286   0.98497       700
cluster_00298    0.97523   0.97372   0.97448      1294
cluster_00299    0.98291   0.96842   0.97561       475
cluster_00300    0.96742   0.97069   0.96905       887
cluster_00303    0.98103   0.98772   0.98436       733
cluster_00304    0.99285   0.98860   0.99072       702
cluster_00319    0.98016   0.98476   0.98246       853
cluster_00322    0.98568   0.98568   0.98568      1187
cluster_00333    0.95376   0.96680   0.96023       512
cluster_00338    0.97108   0.96229   0.96667       663
cluster_00340    0.98219   0.98974   0.98595       780
cluster_00344    0.95961   0.96900   0.96429       613
cluster_00346    0.98607   0.98186   0.98396       937
cluster_00350    0.97959   0.97786   0.97872      1129
cluster_00352    0.98167   0.98003   0.98085       601
cluster_00359    0.95937   0.96825   0.96379       756
cluster_00360    0.98148   0.97906   0.98027       812
cluster_00361    0.96073   0.96510   0.96291       659
cluster_00365    0.97982   0.98855   0.98417       786
cluster_00368    0.97343   0.97816   0.97579       824
cluster_00373    0.97290   0.97158   0.97224       739
cluster_00374    0.97805   0.97590   0.97697       913
cluster_00375    0.97537   0.96680   0.97106      1024
cluster_00377    0.96988   0.97281   0.97134       993
cluster_00380    0.98481   0.98890   0.98685       721
cluster_00385    0.99008   0.98714   0.98861      1011
cluster_00388    0.97494   0.97409   0.97451      1158
cluster_00389    0.97722   0.97229   0.97475       794
cluster_00390    0.99007   0.99336   0.99171       903
cluster_00394    0.97314   0.96855   0.97084       636
cluster_00400    0.98420   0.97978   0.98198       445
cluster_00401    0.98085   0.96662   0.97368       689
cluster_00405    0.97876   0.97432   0.97653       662
cluster_00407    0.98848   0.98659   0.98754      1044
cluster_00408    0.96973   0.96078   0.96524       867
cluster_00409    0.96781   0.96885   0.96833       931
cluster_00412    0.98919   0.98493   0.98706       929
cluster_00445    0.97490   0.97679   0.97585       517
cluster_00473    0.97095   0.97704   0.97399       479
cluster_00585    0.96163   0.96952   0.96556       853
cluster_00589    0.97627   0.98126   0.97876       587
cluster_00591    0.98132   0.98747   0.98438       798
cluster_00593    0.98325   0.97347   0.97833       603
cluster_00596    0.97715   0.96696   0.97203       575
cluster_00603    0.98118   0.97724   0.97921       747
cluster_00604    0.99653   0.99653   0.99653       576
cluster_00607    0.98338   0.97589   0.97962       788
cluster_00612    0.98908   0.99512   0.99209       819
cluster_00616    0.97619   0.97518   0.97569       967
cluster_00619    0.97447   0.97171   0.97309       707
cluster_00629    0.98619   0.98847   0.98733       867
cluster_00630    0.98811   0.98929   0.98870       840
cluster_00635    0.97570   0.98198   0.97883       777
cluster_00637    0.96875   0.96124   0.96498       774
cluster_00639    0.98051   0.97851   0.97951       977
cluster_00642    0.98978   0.98531   0.98754       885
cluster_00645    0.97698   0.97139   0.97418       699
cluster_00647    0.96749   0.95876   0.96311       776
cluster_00652    0.97503   0.97062   0.97282       885
cluster_00653    0.99376   0.99376   0.99376       641
cluster_00656    0.99003   0.99286   0.99144       700
cluster_00657    0.96785   0.96269   0.96526       938
cluster_00661    0.98489   0.98897   0.98692       725
cluster_00662    0.98312   0.99000   0.98655      1000
cluster_00667    0.98084   0.98675   0.98378       830
cluster_00762    0.98686   0.99470   0.99077       755
cluster_00201    1.00000   1.00000   1.00000       839
cluster_00217    0.98182   0.99293   0.98734       707
cluster_00239    0.98635   0.98635   0.98635       879
cluster_00320    0.98468   0.98605   0.98537       717
cluster_00391    0.98422   0.97786   0.98103      1084
cluster_00398    0.98362   0.98362   0.98362       977
cluster_00415    0.98493   0.98493   0.98493       730
cluster_00477    0.98451   0.98451   0.98451       710
cluster_00478    0.98645   0.99048   0.98846       735
cluster_00479    0.98624   0.99078   0.98851       651
cluster_00078    0.96139   0.97003   0.96569      1001
cluster_00079    0.96016   0.95492   0.95753       732
cluster_00083    0.96546   0.96290   0.96418      1132
cluster_00090    0.97092   0.96875   0.96983       448
cluster_00094    0.96275   0.95525   0.95898       514
cluster_00096    0.98117   0.98117   0.98117       478
cluster_00101    0.98651   0.99225   0.98937       516
cluster_00086    0.99463   0.99641   0.99552      1115
cluster_00095    0.98805   0.98805   0.98805       837
cluster_00097    0.99172   0.99584   0.99378       481
cluster_00106    0.99578   0.99411   0.99495      1188
cluster_00553    0.99280   0.99280   0.99280       833
cluster_00554    0.99063   0.99232   0.99147      1172
cluster_00569    0.99275   0.98798   0.99036       832
cluster_00015    0.98691   0.98950   0.98820       381
cluster_00017    0.97998   0.96890   0.97441      1061
cluster_00018    0.98254   0.97788   0.98021       633
cluster_00023    0.97439   0.97439   0.97439       937
cluster_00025    0.98220   0.97588   0.97903       622
cluster_00030    0.97059   0.97935   0.97495       775
cluster_00035    0.98566   0.97518   0.98039       564
cluster_00039    0.97900   0.98677   0.98287       756
cluster_00042    0.97211   0.96271   0.96738       724
cluster_00046    0.97611   0.98467   0.98037       913
cluster_00055    0.98118   0.98118   0.98118       744
cluster_00059    0.97146   0.97727   0.97436       836
cluster_00061    0.98983   0.98608   0.98795       790
cluster_00274    0.98949   0.98819   0.98884       762
cluster_00308    0.97931   0.97931   0.97931       725
cluster_00337    0.99590   0.99048   0.99318       735
cluster_00362    0.98675   0.98285   0.98480       758
cluster_00369    0.98589   0.99189   0.98888       493
cluster_00392    0.99057   0.99644   0.99349       843
cluster_00414    0.98589   0.98788   0.98688       495
cluster_00419    0.98305   0.98639   0.98472       882
cluster_00420    0.99192   0.98398   0.98794       749
cluster_00421    0.99140   0.99140   0.99140       465
cluster_00422    0.97951   0.97856   0.97903      1026
cluster_00427    0.95625   0.97452   0.96530       628
cluster_00430    0.97436   0.96575   0.97003       905
cluster_00431    0.96802   0.97654   0.97226      1023
cluster_00436    0.98677   0.99334   0.99005       751
cluster_00439    0.98667   0.99079   0.98873      1195
cluster_00444    0.99748   0.99497   0.99623       796
cluster_00447    0.96780   0.97607   0.97191       585
cluster_00448    0.98778   0.99020   0.98898       816
cluster_00450    0.96552   0.96838   0.96695      1012
cluster_00456    0.99634   0.98911   0.99271       551
cluster_00458    0.98299   0.97861   0.98079      1122
cluster_00460    0.98265   0.97901   0.98083       810
cluster_00463    0.98170   0.98827   0.98497       597
cluster_00467    0.98833   0.98833   0.98833       600
cluster_00483    0.98246   0.97110   0.97674       519
cluster_00484    0.98750   0.98399   0.98574       562
cluster_00007    0.98944   0.99545   0.99244       659
cluster_00036    0.97600   0.97796   0.97698       998
cluster_00054    0.99406   0.99209   0.99308       506
cluster_00062    0.96926   0.94600   0.95749      1000
cluster_00064    0.97756   0.98599   0.98176       928
cluster_00065    0.98920   0.98920   0.98920       741
cluster_00067    0.97377   0.97858   0.97617       607
cluster_00071    0.96534   0.97378   0.96954       572
cluster_00075    0.96708   0.96599   0.96653       882
cluster_00084    0.98136   0.97953   0.98045      1075
cluster_00093    0.96875   0.97213   0.97043       861
cluster_00001    0.98754   0.98659   0.98706      1044
cluster_00002    0.97151   0.99128   0.98129       688
cluster_00003    0.96913   0.98175   0.97540      1151
cluster_00006    0.99874   0.99622   0.99747       793
cluster_00008    0.98948   0.98003   0.98474      1152
cluster_00010    0.98565   0.98329   0.98447       838
cluster_00012    0.98841   0.97290   0.98059       701
cluster_00019    0.99060   1.00000   0.99528       527
cluster_00022    0.97589   0.97713   0.97651       787
cluster_00026    0.98643   0.97978   0.98310       742
cluster_00029    0.97250   0.97357   0.97303       908
cluster_00031    0.98065   0.97979   0.98022      1138
cluster_00043    0.99549   0.99819   0.99684      1106
cluster_00051    0.99248   0.98630   0.98938       803
cluster_00052    0.97731   0.97802   0.97766      1365
cluster_00073    0.98714   0.98397   0.98555       936
cluster_00076    0.98536   0.97984   0.98259       893
cluster_00082    0.98424   0.98944   0.98683      1136
cluster_00107    0.99554   0.99332   0.99443       898
cluster_00432    0.99799   0.99499   0.99649       999
cluster_00440    0.99289   0.99188   0.99238       985
cluster_00455    0.99125   0.99707   0.99415       682
cluster_00714    0.99886   1.00000   0.99943       879
cluster_00791    0.99149   0.99573   0.99360       702
cluster_00119    0.99778   0.99668   0.99723       903
cluster_00121    0.99866   0.99866   0.99866       747
cluster_00155    0.99534   0.99720   0.99627      1072
cluster_00556    0.99662   0.99887   0.99774       885
cluster_00557    0.99822   0.99556   0.99689      1127
cluster_00689    1.00000   0.99680   0.99840       938
cluster_00692    0.99679   0.99786   0.99733       935
cluster_00718    1.00000   0.99176   0.99586       849
cluster_00725    0.99306   0.99860   0.99582       716
cluster_00727    0.99323   1.00000   0.99660       587
cluster_00729    0.99647   0.99735   0.99691      1133
cluster_00733    1.00000   1.00000   1.00000       603
cluster_00738    0.99540   1.00000   0.99769       649
cluster_00740    0.99512   0.99674   0.99593       614
cluster_00744    0.99785   0.99464   0.99624       933
cluster_00753    0.99773   0.99660   0.99716       882
cluster_00777    1.00000   0.99528   0.99763       847
cluster_00795    0.99607   0.99738   0.99673       763

     accuracy                        0.98262    160000
    macro avg    0.98255   0.98259   0.98256    160000
 weighted avg    0.98263   0.98262   0.98262    160000

2023-07-14 03:54:18,892 =======================================================
2023-07-14 03:54:18,892 

2023-07-14 03:54:20,259 =======================================================
2023-07-14 03:54:20,259 Best f1 classification report:
               precision    recall  f1-score   support

cluster_00205    0.98058   0.98483   0.98270       923
cluster_00222    0.97876   0.98024   0.97950       658
cluster_00232    0.96670   0.96872   0.96771       959
cluster_00246    0.96644   0.97297   0.96970       740
cluster_00259    0.98367   0.97047   0.97703       745
cluster_00261    0.99117   0.98942   0.99029       567
cluster_00262    0.97868   0.97430   0.97648       895
cluster_00267    0.98689   0.98617   0.98653      1374
cluster_00275    0.97832   0.98172   0.98002      1149
cluster_00276    0.98104   0.97950   0.98027       634
cluster_00278    0.96133   0.98166   0.97139       709
cluster_00287    0.97914   0.98501   0.98206       667
cluster_00291    0.98240   0.97953   0.98097       684
cluster_00293    0.98213   0.98389   0.98301      1117
cluster_00294    0.99031   0.97847   0.98436       418
cluster_00296    0.98709   0.98286   0.98497       700
cluster_00298    0.97523   0.97372   0.97448      1294
cluster_00299    0.98291   0.96842   0.97561       475
cluster_00300    0.96742   0.97069   0.96905       887
cluster_00303    0.98103   0.98772   0.98436       733
cluster_00304    0.99285   0.98860   0.99072       702
cluster_00319    0.98016   0.98476   0.98246       853
cluster_00322    0.98568   0.98568   0.98568      1187
cluster_00333    0.95376   0.96680   0.96023       512
cluster_00338    0.97108   0.96229   0.96667       663
cluster_00340    0.98219   0.98974   0.98595       780
cluster_00344    0.95961   0.96900   0.96429       613
cluster_00346    0.98607   0.98186   0.98396       937
cluster_00350    0.97959   0.97786   0.97872      1129
cluster_00352    0.98167   0.98003   0.98085       601
cluster_00359    0.95937   0.96825   0.96379       756
cluster_00360    0.98148   0.97906   0.98027       812
cluster_00361    0.96073   0.96510   0.96291       659
cluster_00365    0.97982   0.98855   0.98417       786
cluster_00368    0.97343   0.97816   0.97579       824
cluster_00373    0.97290   0.97158   0.97224       739
cluster_00374    0.97805   0.97590   0.97697       913
cluster_00375    0.97537   0.96680   0.97106      1024
cluster_00377    0.96988   0.97281   0.97134       993
cluster_00380    0.98481   0.98890   0.98685       721
cluster_00385    0.99008   0.98714   0.98861      1011
cluster_00388    0.97494   0.97409   0.97451      1158
cluster_00389    0.97722   0.97229   0.97475       794
cluster_00390    0.99007   0.99336   0.99171       903
cluster_00394    0.97314   0.96855   0.97084       636
cluster_00400    0.98420   0.97978   0.98198       445
cluster_00401    0.98085   0.96662   0.97368       689
cluster_00405    0.97876   0.97432   0.97653       662
cluster_00407    0.98848   0.98659   0.98754      1044
cluster_00408    0.96973   0.96078   0.96524       867
cluster_00409    0.96781   0.96885   0.96833       931
cluster_00412    0.98919   0.98493   0.98706       929
cluster_00445    0.97490   0.97679   0.97585       517
cluster_00473    0.97095   0.97704   0.97399       479
cluster_00585    0.96163   0.96952   0.96556       853
cluster_00589    0.97627   0.98126   0.97876       587
cluster_00591    0.98132   0.98747   0.98438       798
cluster_00593    0.98325   0.97347   0.97833       603
cluster_00596    0.97715   0.96696   0.97203       575
cluster_00603    0.98118   0.97724   0.97921       747
cluster_00604    0.99653   0.99653   0.99653       576
cluster_00607    0.98338   0.97589   0.97962       788
cluster_00612    0.98908   0.99512   0.99209       819
cluster_00616    0.97619   0.97518   0.97569       967
cluster_00619    0.97447   0.97171   0.97309       707
cluster_00629    0.98619   0.98847   0.98733       867
cluster_00630    0.98811   0.98929   0.98870       840
cluster_00635    0.97570   0.98198   0.97883       777
cluster_00637    0.96875   0.96124   0.96498       774
cluster_00639    0.98051   0.97851   0.97951       977
cluster_00642    0.98978   0.98531   0.98754       885
cluster_00645    0.97698   0.97139   0.97418       699
cluster_00647    0.96749   0.95876   0.96311       776
cluster_00652    0.97503   0.97062   0.97282       885
cluster_00653    0.99376   0.99376   0.99376       641
cluster_00656    0.99003   0.99286   0.99144       700
cluster_00657    0.96785   0.96269   0.96526       938
cluster_00661    0.98489   0.98897   0.98692       725
cluster_00662    0.98312   0.99000   0.98655      1000
cluster_00667    0.98084   0.98675   0.98378       830
cluster_00762    0.98686   0.99470   0.99077       755
cluster_00201    1.00000   1.00000   1.00000       839
cluster_00217    0.98182   0.99293   0.98734       707
cluster_00239    0.98635   0.98635   0.98635       879
cluster_00320    0.98468   0.98605   0.98537       717
cluster_00391    0.98422   0.97786   0.98103      1084
cluster_00398    0.98362   0.98362   0.98362       977
cluster_00415    0.98493   0.98493   0.98493       730
cluster_00477    0.98451   0.98451   0.98451       710
cluster_00478    0.98645   0.99048   0.98846       735
cluster_00479    0.98624   0.99078   0.98851       651
cluster_00078    0.96139   0.97003   0.96569      1001
cluster_00079    0.96016   0.95492   0.95753       732
cluster_00083    0.96546   0.96290   0.96418      1132
cluster_00090    0.97092   0.96875   0.96983       448
cluster_00094    0.96275   0.95525   0.95898       514
cluster_00096    0.98117   0.98117   0.98117       478
cluster_00101    0.98651   0.99225   0.98937       516
cluster_00086    0.99463   0.99641   0.99552      1115
cluster_00095    0.98805   0.98805   0.98805       837
cluster_00097    0.99172   0.99584   0.99378       481
cluster_00106    0.99578   0.99411   0.99495      1188
cluster_00553    0.99280   0.99280   0.99280       833
cluster_00554    0.99063   0.99232   0.99147      1172
cluster_00569    0.99275   0.98798   0.99036       832
cluster_00015    0.98691   0.98950   0.98820       381
cluster_00017    0.97998   0.96890   0.97441      1061
cluster_00018    0.98254   0.97788   0.98021       633
cluster_00023    0.97439   0.97439   0.97439       937
cluster_00025    0.98220   0.97588   0.97903       622
cluster_00030    0.97059   0.97935   0.97495       775
cluster_00035    0.98566   0.97518   0.98039       564
cluster_00039    0.97900   0.98677   0.98287       756
cluster_00042    0.97211   0.96271   0.96738       724
cluster_00046    0.97611   0.98467   0.98037       913
cluster_00055    0.98118   0.98118   0.98118       744
cluster_00059    0.97146   0.97727   0.97436       836
cluster_00061    0.98983   0.98608   0.98795       790
cluster_00274    0.98949   0.98819   0.98884       762
cluster_00308    0.97931   0.97931   0.97931       725
cluster_00337    0.99590   0.99048   0.99318       735
cluster_00362    0.98675   0.98285   0.98480       758
cluster_00369    0.98589   0.99189   0.98888       493
cluster_00392    0.99057   0.99644   0.99349       843
cluster_00414    0.98589   0.98788   0.98688       495
cluster_00419    0.98305   0.98639   0.98472       882
cluster_00420    0.99192   0.98398   0.98794       749
cluster_00421    0.99140   0.99140   0.99140       465
cluster_00422    0.97951   0.97856   0.97903      1026
cluster_00427    0.95625   0.97452   0.96530       628
cluster_00430    0.97436   0.96575   0.97003       905
cluster_00431    0.96802   0.97654   0.97226      1023
cluster_00436    0.98677   0.99334   0.99005       751
cluster_00439    0.98667   0.99079   0.98873      1195
cluster_00444    0.99748   0.99497   0.99623       796
cluster_00447    0.96780   0.97607   0.97191       585
cluster_00448    0.98778   0.99020   0.98898       816
cluster_00450    0.96552   0.96838   0.96695      1012
cluster_00456    0.99634   0.98911   0.99271       551
cluster_00458    0.98299   0.97861   0.98079      1122
cluster_00460    0.98265   0.97901   0.98083       810
cluster_00463    0.98170   0.98827   0.98497       597
cluster_00467    0.98833   0.98833   0.98833       600
cluster_00483    0.98246   0.97110   0.97674       519
cluster_00484    0.98750   0.98399   0.98574       562
cluster_00007    0.98944   0.99545   0.99244       659
cluster_00036    0.97600   0.97796   0.97698       998
cluster_00054    0.99406   0.99209   0.99308       506
cluster_00062    0.96926   0.94600   0.95749      1000
cluster_00064    0.97756   0.98599   0.98176       928
cluster_00065    0.98920   0.98920   0.98920       741
cluster_00067    0.97377   0.97858   0.97617       607
cluster_00071    0.96534   0.97378   0.96954       572
cluster_00075    0.96708   0.96599   0.96653       882
cluster_00084    0.98136   0.97953   0.98045      1075
cluster_00093    0.96875   0.97213   0.97043       861
cluster_00001    0.98754   0.98659   0.98706      1044
cluster_00002    0.97151   0.99128   0.98129       688
cluster_00003    0.96913   0.98175   0.97540      1151
cluster_00006    0.99874   0.99622   0.99747       793
cluster_00008    0.98948   0.98003   0.98474      1152
cluster_00010    0.98565   0.98329   0.98447       838
cluster_00012    0.98841   0.97290   0.98059       701
cluster_00019    0.99060   1.00000   0.99528       527
cluster_00022    0.97589   0.97713   0.97651       787
cluster_00026    0.98643   0.97978   0.98310       742
cluster_00029    0.97250   0.97357   0.97303       908
cluster_00031    0.98065   0.97979   0.98022      1138
cluster_00043    0.99549   0.99819   0.99684      1106
cluster_00051    0.99248   0.98630   0.98938       803
cluster_00052    0.97731   0.97802   0.97766      1365
cluster_00073    0.98714   0.98397   0.98555       936
cluster_00076    0.98536   0.97984   0.98259       893
cluster_00082    0.98424   0.98944   0.98683      1136
cluster_00107    0.99554   0.99332   0.99443       898
cluster_00432    0.99799   0.99499   0.99649       999
cluster_00440    0.99289   0.99188   0.99238       985
cluster_00455    0.99125   0.99707   0.99415       682
cluster_00714    0.99886   1.00000   0.99943       879
cluster_00791    0.99149   0.99573   0.99360       702
cluster_00119    0.99778   0.99668   0.99723       903
cluster_00121    0.99866   0.99866   0.99866       747
cluster_00155    0.99534   0.99720   0.99627      1072
cluster_00556    0.99662   0.99887   0.99774       885
cluster_00557    0.99822   0.99556   0.99689      1127
cluster_00689    1.00000   0.99680   0.99840       938
cluster_00692    0.99679   0.99786   0.99733       935
cluster_00718    1.00000   0.99176   0.99586       849
cluster_00725    0.99306   0.99860   0.99582       716
cluster_00727    0.99323   1.00000   0.99660       587
cluster_00729    0.99647   0.99735   0.99691      1133
cluster_00733    1.00000   1.00000   1.00000       603
cluster_00738    0.99540   1.00000   0.99769       649
cluster_00740    0.99512   0.99674   0.99593       614
cluster_00744    0.99785   0.99464   0.99624       933
cluster_00753    0.99773   0.99660   0.99716       882
cluster_00777    1.00000   0.99528   0.99763       847
cluster_00795    0.99607   0.99738   0.99673       763

     accuracy                        0.98262    160000
    macro avg    0.98255   0.98259   0.98256    160000
 weighted avg    0.98263   0.98262   0.98262    160000

2023-07-14 03:54:20,259 =======================================================
2023-07-14 03:54:20,259 

2023-07-14 03:54:21,010 Total processing time is 4596.09s
2023-07-14 03:54:21,012 =======================================================
2023-07-14 03:54:21,012 Namespace(T_0=10, T_mult=2, best_metric='f1', decay_factor=0.5, epoch=800, eval_fold_zero=False, input_path='***', k_fold=5, lr=0.001, manualSeed=0, momentum=0, num_workers=4, opt='Adam', out_path='***', out_path_base='***', redistribute_class=True, scheduler='step', step_size=20, train_batch_size=2048, val_batch_size=1024, weight_decay=0.0)
2023-07-14 03:54:21,012 =======================================================
2023-07-14 03:54:21,012 Implement 5 fold experiment
2023-07-14 03:54:21,338 use [1, 2, 3, 4] fold as train data
2023-07-14 03:54:21,338 The size of feature for train is (160000, 15, 3)
2023-07-14 03:54:21,396 use 5 fold as validation data
2023-07-14 03:54:21,396 The size of feature for val is (40000, 15, 3)
2023-07-14 03:54:21,413 The training data size is:160000
2023-07-14 03:54:21,413 The validation data size is:40000
2023-07-14 03:54:21,413 The number of classes is:198
2023-07-14 03:54:21,414 The label names are: [b'cluster_00205', b'cluster_00222', b'cluster_00232', b'cluster_00246', b'cluster_00259', b'cluster_00261', b'cluster_00262', b'cluster_00267', b'cluster_00275', b'cluster_00276', b'cluster_00278', b'cluster_00287', b'cluster_00291', b'cluster_00293', b'cluster_00294', b'cluster_00296', b'cluster_00298', b'cluster_00299', b'cluster_00300', b'cluster_00303', b'cluster_00304', b'cluster_00319', b'cluster_00322', b'cluster_00333', b'cluster_00338', b'cluster_00340', b'cluster_00344', b'cluster_00346', b'cluster_00350', b'cluster_00352', b'cluster_00359', b'cluster_00360', b'cluster_00361', b'cluster_00365', b'cluster_00368', b'cluster_00373', b'cluster_00374', b'cluster_00375', b'cluster_00377', b'cluster_00380', b'cluster_00385', b'cluster_00388', b'cluster_00389', b'cluster_00390', b'cluster_00394', b'cluster_00400', b'cluster_00401', b'cluster_00405', b'cluster_00407', b'cluster_00408', b'cluster_00409', b'cluster_00412', b'cluster_00445', b'cluster_00473', b'cluster_00585', b'cluster_00589', b'cluster_00591', b'cluster_00593', b'cluster_00596', b'cluster_00603', b'cluster_00604', b'cluster_00607', b'cluster_00612', b'cluster_00616', b'cluster_00619', b'cluster_00629', b'cluster_00630', b'cluster_00635', b'cluster_00637', b'cluster_00639', b'cluster_00642', b'cluster_00645', b'cluster_00647', b'cluster_00652', b'cluster_00653', b'cluster_00656', b'cluster_00657', b'cluster_00661', b'cluster_00662', b'cluster_00667', b'cluster_00762', b'cluster_00201', b'cluster_00217', b'cluster_00239', b'cluster_00320', b'cluster_00391', b'cluster_00398', b'cluster_00415', b'cluster_00477', b'cluster_00478', b'cluster_00479', b'cluster_00078', b'cluster_00079', b'cluster_00083', b'cluster_00090', b'cluster_00094', b'cluster_00096', b'cluster_00101', b'cluster_00086', b'cluster_00095', b'cluster_00097', b'cluster_00106', b'cluster_00553', b'cluster_00554', b'cluster_00569', b'cluster_00015', b'cluster_00017', b'cluster_00018', b'cluster_00023', b'cluster_00025', b'cluster_00030', b'cluster_00035', b'cluster_00039', b'cluster_00042', b'cluster_00046', b'cluster_00055', b'cluster_00059', b'cluster_00061', b'cluster_00274', b'cluster_00308', b'cluster_00337', b'cluster_00362', b'cluster_00369', b'cluster_00392', b'cluster_00414', b'cluster_00419', b'cluster_00420', b'cluster_00421', b'cluster_00422', b'cluster_00427', b'cluster_00430', b'cluster_00431', b'cluster_00436', b'cluster_00439', b'cluster_00444', b'cluster_00447', b'cluster_00448', b'cluster_00450', b'cluster_00456', b'cluster_00458', b'cluster_00460', b'cluster_00463', b'cluster_00467', b'cluster_00483', b'cluster_00484', b'cluster_00007', b'cluster_00036', b'cluster_00054', b'cluster_00062', b'cluster_00064', b'cluster_00065', b'cluster_00067', b'cluster_00071', b'cluster_00075', b'cluster_00084', b'cluster_00093', b'cluster_00001', b'cluster_00002', b'cluster_00003', b'cluster_00006', b'cluster_00008', b'cluster_00010', b'cluster_00012', b'cluster_00019', b'cluster_00022', b'cluster_00026', b'cluster_00029', b'cluster_00031', b'cluster_00043', b'cluster_00051', b'cluster_00052', b'cluster_00073', b'cluster_00076', b'cluster_00082', b'cluster_00107', b'cluster_00432', b'cluster_00440', b'cluster_00455', b'cluster_00714', b'cluster_00791', b'cluster_00119', b'cluster_00121', b'cluster_00155', b'cluster_00556', b'cluster_00557', b'cluster_00689', b'cluster_00692', b'cluster_00718', b'cluster_00725', b'cluster_00727', b'cluster_00729', b'cluster_00733', b'cluster_00738', b'cluster_00740', b'cluster_00744', b'cluster_00753', b'cluster_00777', b'cluster_00795']
2023-07-14 03:54:26,094 epoch [1/800] time: 4.66s train loss: 2.4053 accuracy: 0.4829 f1: 0.4563
2023-07-14 03:54:26,904 epoch [1/800] time: 0.8s val loss: 1.3203 accuracy: 0.6917 f1: 0.6741
2023-07-14 03:54:31,959 epoch [2/800] time: 5.05s train loss: 0.8459 accuracy: 0.7624 f1: 0.756
2023-07-14 03:54:32,871 epoch [2/800] time: 0.91s val loss: 0.7334 accuracy: 0.7669 f1: 0.7634
2023-07-14 03:54:38,058 epoch [3/800] time: 5.18s train loss: 0.6114 accuracy: 0.8005 f1: 0.7971
2023-07-14 03:54:39,004 epoch [3/800] time: 0.94s val loss: 0.6058 accuracy: 0.7912 f1: 0.7879
2023-07-14 03:54:44,325 epoch [4/800] time: 5.32s train loss: 0.5235 accuracy: 0.8188 f1: 0.8159
2023-07-14 03:54:45,278 epoch [4/800] time: 0.95s val loss: 0.5436 accuracy: 0.8057 f1: 0.8019
2023-07-14 03:54:50,339 epoch [5/800] time: 5.06s train loss: 0.485 accuracy: 0.8264 f1: 0.8238
2023-07-14 03:54:51,264 epoch [5/800] time: 0.92s val loss: 0.5448 accuracy: 0.7954 f1: 0.7918
2023-07-14 03:54:56,432 epoch [6/800] time: 5.17s train loss: 0.441 accuracy: 0.8411 f1: 0.8392
2023-07-14 03:54:57,349 epoch [6/800] time: 0.91s val loss: 0.4958 accuracy: 0.8123 f1: 0.8087
2023-07-14 03:55:02,182 epoch [7/800] time: 4.83s train loss: 0.4244 accuracy: 0.8449 f1: 0.8427
2023-07-14 03:55:03,046 epoch [7/800] time: 0.86s val loss: 0.4131 accuracy: 0.8437 f1: 0.8413
2023-07-14 03:55:07,786 epoch [8/800] time: 4.74s train loss: 0.4071 accuracy: 0.8501 f1: 0.8482
2023-07-14 03:55:08,676 epoch [8/800] time: 0.88s val loss: 0.4432 accuracy: 0.8314 f1: 0.8303
2023-07-14 03:55:13,800 epoch [9/800] time: 5.12s train loss: 0.3864 accuracy: 0.8571 f1: 0.8553
2023-07-14 03:55:14,667 epoch [9/800] time: 0.86s val loss: 0.4182 accuracy: 0.8405 f1: 0.8377
2023-07-14 03:55:19,405 epoch [10/800] time: 4.74s train loss: 0.3719 accuracy: 0.8603 f1: 0.8585
2023-07-14 03:55:20,277 epoch [10/800] time: 0.87s val loss: 0.4688 accuracy: 0.8221 f1: 0.8198
2023-07-14 03:55:24,803 epoch [11/800] time: 4.53s train loss: 0.3536 accuracy: 0.8676 f1: 0.8659
2023-07-14 03:55:25,652 epoch [11/800] time: 0.84s val loss: 0.4049 accuracy: 0.8424 f1: 0.8402
2023-07-14 03:55:30,191 epoch [12/800] time: 4.54s train loss: 0.3513 accuracy: 0.8681 f1: 0.8664
2023-07-14 03:55:31,002 epoch [12/800] time: 0.8s val loss: 0.461 accuracy: 0.8273 f1: 0.8236
2023-07-14 03:55:35,523 epoch [13/800] time: 4.52s train loss: 0.3383 accuracy: 0.872 f1: 0.8706
2023-07-14 03:55:36,374 epoch [13/800] time: 0.84s val loss: 0.4105 accuracy: 0.8427 f1: 0.8421
2023-07-14 03:55:41,067 epoch [14/800] time: 4.69s train loss: 0.3282 accuracy: 0.8756 f1: 0.874
2023-07-14 03:55:41,927 epoch [14/800] time: 0.85s val loss: 0.4065 accuracy: 0.8428 f1: 0.8405
2023-07-14 03:55:46,729 epoch [15/800] time: 4.8s train loss: 0.3316 accuracy: 0.8741 f1: 0.8725
2023-07-14 03:55:47,529 epoch [15/800] time: 0.8s val loss: 0.3531 accuracy: 0.8645 f1: 0.8599
2023-07-14 03:55:52,269 epoch [16/800] time: 4.74s train loss: 0.3159 accuracy: 0.8815 f1: 0.8801
2023-07-14 03:55:53,115 epoch [16/800] time: 0.84s val loss: 0.3858 accuracy: 0.854 f1: 0.8527
2023-07-14 03:55:57,828 epoch [17/800] time: 4.71s train loss: 0.3041 accuracy: 0.8844 f1: 0.8831
2023-07-14 03:55:58,674 epoch [17/800] time: 0.84s val loss: 0.3553 accuracy: 0.8636 f1: 0.8615
2023-07-14 03:56:03,419 epoch [18/800] time: 4.74s train loss: 0.3093 accuracy: 0.8816 f1: 0.88
2023-07-14 03:56:04,219 epoch [18/800] time: 0.8s val loss: 0.4894 accuracy: 0.8199 f1: 0.8184
2023-07-14 03:56:08,969 epoch [19/800] time: 4.75s train loss: 0.3028 accuracy: 0.8833 f1: 0.882
2023-07-14 03:56:09,812 epoch [19/800] time: 0.84s val loss: 0.347 accuracy: 0.8662 f1: 0.8641
2023-07-14 03:56:14,531 epoch [20/800] time: 4.72s train loss: 0.2909 accuracy: 0.8894 f1: 0.8881
2023-07-14 03:56:15,376 epoch [20/800] time: 0.84s val loss: 0.4092 accuracy: 0.8467 f1: 0.8442
2023-07-14 03:56:20,089 epoch [21/800] time: 4.71s train loss: 0.2516 accuracy: 0.9056 f1: 0.9044
2023-07-14 03:56:20,893 epoch [21/800] time: 0.8s val loss: 0.2413 accuracy: 0.9076 f1: 0.9064
2023-07-14 03:56:25,641 epoch [22/800] time: 4.74s train loss: 0.234 accuracy: 0.9113 f1: 0.9102
2023-07-14 03:56:26,487 epoch [22/800] time: 0.84s val loss: 0.2489 accuracy: 0.9024 f1: 0.9003
2023-07-14 03:56:31,200 epoch [23/800] time: 4.71s train loss: 0.2299 accuracy: 0.9138 f1: 0.9127
2023-07-14 03:56:32,047 epoch [23/800] time: 0.84s val loss: 0.2431 accuracy: 0.9035 f1: 0.9014
2023-07-14 03:56:36,821 epoch [24/800] time: 4.77s train loss: 0.223 accuracy: 0.9163 f1: 0.9153
2023-07-14 03:56:37,627 epoch [24/800] time: 0.8s val loss: 0.2457 accuracy: 0.9047 f1: 0.9034
2023-07-14 03:56:42,389 epoch [25/800] time: 4.76s train loss: 0.2231 accuracy: 0.916 f1: 0.9152
2023-07-14 03:56:43,230 epoch [25/800] time: 0.84s val loss: 0.2749 accuracy: 0.8952 f1: 0.8941
2023-07-14 03:56:48,353 epoch [26/800] time: 5.12s train loss: 0.2275 accuracy: 0.9128 f1: 0.9119
2023-07-14 03:56:49,206 epoch [26/800] time: 0.85s val loss: 0.2872 accuracy: 0.8896 f1: 0.8875
2023-07-14 03:56:53,960 epoch [27/800] time: 4.75s train loss: 0.2264 accuracy: 0.9142 f1: 0.9133
2023-07-14 03:56:54,764 epoch [27/800] time: 0.8s val loss: 0.2583 accuracy: 0.8974 f1: 0.8959
2023-07-14 03:56:59,404 epoch [28/800] time: 4.64s train loss: 0.2167 accuracy: 0.918 f1: 0.9171
2023-07-14 03:57:00,266 epoch [28/800] time: 0.86s val loss: 0.2464 accuracy: 0.9032 f1: 0.9022
2023-07-14 03:57:04,968 epoch [29/800] time: 4.7s train loss: 0.2153 accuracy: 0.918 f1: 0.9173
2023-07-14 03:57:05,844 epoch [29/800] time: 0.87s val loss: 0.2562 accuracy: 0.9011 f1: 0.8988
2023-07-14 03:57:10,789 epoch [30/800] time: 4.94s train loss: 0.2196 accuracy: 0.9165 f1: 0.9156
2023-07-14 03:57:11,642 epoch [30/800] time: 0.85s val loss: 0.2354 accuracy: 0.9095 f1: 0.908
2023-07-14 03:57:16,508 epoch [31/800] time: 4.87s train loss: 0.2104 accuracy: 0.9212 f1: 0.9204
2023-07-14 03:57:17,380 epoch [31/800] time: 0.87s val loss: 0.2773 accuracy: 0.8925 f1: 0.8903
2023-07-14 03:57:22,386 epoch [32/800] time: 5.0s train loss: 0.2134 accuracy: 0.9192 f1: 0.9184
2023-07-14 03:57:23,358 epoch [32/800] time: 0.97s val loss: 0.2322 accuracy: 0.9105 f1: 0.9094
2023-07-14 03:57:28,511 epoch [33/800] time: 5.15s train loss: 0.2066 accuracy: 0.9225 f1: 0.9216
2023-07-14 03:57:29,340 epoch [33/800] time: 0.82s val loss: 0.2326 accuracy: 0.9095 f1: 0.9077
2023-07-14 03:57:34,324 epoch [34/800] time: 4.98s train loss: 0.2006 accuracy: 0.9235 f1: 0.9227
2023-07-14 03:57:35,257 epoch [34/800] time: 0.93s val loss: 0.2328 accuracy: 0.9081 f1: 0.9068
2023-07-14 03:57:40,502 epoch [35/800] time: 5.24s train loss: 0.2009 accuracy: 0.9238 f1: 0.9229
2023-07-14 03:57:41,404 epoch [35/800] time: 0.9s val loss: 0.2201 accuracy: 0.9159 f1: 0.914
2023-07-14 03:57:46,299 epoch [36/800] time: 4.89s train loss: 0.203 accuracy: 0.9234 f1: 0.9225
2023-07-14 03:57:47,201 epoch [36/800] time: 0.9s val loss: 0.2667 accuracy: 0.8969 f1: 0.8942
2023-07-14 03:57:52,436 epoch [37/800] time: 5.23s train loss: 0.2061 accuracy: 0.9209 f1: 0.9202
2023-07-14 03:57:53,358 epoch [37/800] time: 0.92s val loss: 0.2263 accuracy: 0.9126 f1: 0.9107
2023-07-14 03:57:58,353 epoch [38/800] time: 5.0s train loss: 0.1969 accuracy: 0.9257 f1: 0.9248
2023-07-14 03:57:59,241 epoch [38/800] time: 0.88s val loss: 0.2419 accuracy: 0.9075 f1: 0.9065
2023-07-14 03:58:04,429 epoch [39/800] time: 5.19s train loss: 0.1971 accuracy: 0.925 f1: 0.9242
2023-07-14 03:58:05,246 epoch [39/800] time: 0.82s val loss: 0.2397 accuracy: 0.9062 f1: 0.9047
2023-07-14 03:58:10,132 epoch [40/800] time: 4.89s train loss: 0.1921 accuracy: 0.9261 f1: 0.9256
2023-07-14 03:58:10,990 epoch [40/800] time: 0.85s val loss: 0.2344 accuracy: 0.9082 f1: 0.9059
2023-07-14 03:58:15,884 epoch [41/800] time: 4.89s train loss: 0.1618 accuracy: 0.9411 f1: 0.9404
2023-07-14 03:58:16,768 epoch [41/800] time: 0.88s val loss: 0.1895 accuracy: 0.9263 f1: 0.9246
2023-07-14 03:58:21,816 epoch [42/800] time: 5.05s train loss: 0.1526 accuracy: 0.9441 f1: 0.9436
2023-07-14 03:58:22,638 epoch [42/800] time: 0.82s val loss: 0.191 accuracy: 0.9264 f1: 0.9249
2023-07-14 03:58:27,498 epoch [43/800] time: 4.86s train loss: 0.1561 accuracy: 0.9433 f1: 0.9428
2023-07-14 03:58:28,404 epoch [43/800] time: 0.91s val loss: 0.1863 accuracy: 0.9293 f1: 0.9284
2023-07-14 03:58:33,474 epoch [44/800] time: 5.07s train loss: 0.151 accuracy: 0.9463 f1: 0.9455
2023-07-14 03:58:34,357 epoch [44/800] time: 0.88s val loss: 0.2025 accuracy: 0.9216 f1: 0.92
2023-07-14 03:58:39,257 epoch [45/800] time: 4.9s train loss: 0.1582 accuracy: 0.9415 f1: 0.9409
2023-07-14 03:58:40,070 epoch [45/800] time: 0.81s val loss: 0.1857 accuracy: 0.9269 f1: 0.9254
2023-07-14 03:58:45,108 epoch [46/800] time: 5.04s train loss: 0.1471 accuracy: 0.946 f1: 0.9452
2023-07-14 03:58:46,028 epoch [46/800] time: 0.92s val loss: 0.185 accuracy: 0.9285 f1: 0.9271
2023-07-14 03:58:51,006 epoch [47/800] time: 4.98s train loss: 0.1485 accuracy: 0.9449 f1: 0.9444
2023-07-14 03:58:51,880 epoch [47/800] time: 0.87s val loss: 0.1803 accuracy: 0.9306 f1: 0.9292
2023-07-14 03:58:56,774 epoch [48/800] time: 4.89s train loss: 0.1475 accuracy: 0.9457 f1: 0.9453
2023-07-14 03:58:57,599 epoch [48/800] time: 0.82s val loss: 0.207 accuracy: 0.9202 f1: 0.9184
2023-07-14 03:59:02,645 epoch [49/800] time: 5.05s train loss: 0.148 accuracy: 0.9452 f1: 0.9445
2023-07-14 03:59:03,517 epoch [49/800] time: 0.87s val loss: 0.1857 accuracy: 0.9283 f1: 0.9268
2023-07-14 03:59:08,271 epoch [50/800] time: 4.75s train loss: 0.1481 accuracy: 0.945 f1: 0.9446
2023-07-14 03:59:09,126 epoch [50/800] time: 0.85s val loss: 0.1757 accuracy: 0.9328 f1: 0.9316
2023-07-14 03:59:13,860 epoch [51/800] time: 4.73s train loss: 0.1428 accuracy: 0.9478 f1: 0.9473
2023-07-14 03:59:14,718 epoch [51/800] time: 0.85s val loss: 0.1971 accuracy: 0.9246 f1: 0.9234
2023-07-14 03:59:19,474 epoch [52/800] time: 4.76s train loss: 0.1431 accuracy: 0.9472 f1: 0.9468
2023-07-14 03:59:20,319 epoch [52/800] time: 0.84s val loss: 0.1935 accuracy: 0.9253 f1: 0.9242
2023-07-14 03:59:25,035 epoch [53/800] time: 4.72s train loss: 0.1406 accuracy: 0.9486 f1: 0.9481
2023-07-14 03:59:25,895 epoch [53/800] time: 0.85s val loss: 0.1872 accuracy: 0.9275 f1: 0.9259
2023-07-14 03:59:30,759 epoch [54/800] time: 4.86s train loss: 0.1369 accuracy: 0.9502 f1: 0.9498
2023-07-14 03:59:31,572 epoch [54/800] time: 0.81s val loss: 0.1872 accuracy: 0.9273 f1: 0.9256
2023-07-14 03:59:36,189 epoch [55/800] time: 4.62s train loss: 0.1369 accuracy: 0.9488 f1: 0.9481
2023-07-14 03:59:37,047 epoch [55/800] time: 0.86s val loss: 0.1934 accuracy: 0.925 f1: 0.9238
2023-07-14 03:59:41,838 epoch [56/800] time: 4.79s train loss: 0.1383 accuracy: 0.9492 f1: 0.9488
2023-07-14 03:59:42,710 epoch [56/800] time: 0.87s val loss: 0.2046 accuracy: 0.9204 f1: 0.9192
2023-07-14 03:59:47,593 epoch [57/800] time: 4.88s train loss: 0.1337 accuracy: 0.9512 f1: 0.9507
2023-07-14 03:59:48,405 epoch [57/800] time: 0.8s val loss: 0.1767 accuracy: 0.9324 f1: 0.9313
2023-07-14 03:59:53,090 epoch [58/800] time: 4.69s train loss: 0.1353 accuracy: 0.9506 f1: 0.9501
2023-07-14 03:59:53,981 epoch [58/800] time: 0.89s val loss: 0.1876 accuracy: 0.9293 f1: 0.9278
2023-07-14 03:59:58,867 epoch [59/800] time: 4.88s train loss: 0.1359 accuracy: 0.9502 f1: 0.9497
2023-07-14 03:59:59,728 epoch [59/800] time: 0.86s val loss: 0.1922 accuracy: 0.9261 f1: 0.9245
2023-07-14 04:00:04,486 epoch [60/800] time: 4.76s train loss: 0.1339 accuracy: 0.9507 f1: 0.9503
2023-07-14 04:00:05,292 epoch [60/800] time: 0.81s val loss: 0.1874 accuracy: 0.9287 f1: 0.9277
2023-07-14 04:00:10,248 epoch [61/800] time: 4.96s train loss: 0.1156 accuracy: 0.9593 f1: 0.9589
2023-07-14 04:00:11,137 epoch [61/800] time: 0.88s val loss: 0.1598 accuracy: 0.9401 f1: 0.9391
2023-07-14 04:00:15,721 epoch [62/800] time: 4.58s train loss: 0.1122 accuracy: 0.9609 f1: 0.9606
2023-07-14 04:00:16,582 epoch [62/800] time: 0.86s val loss: 0.1775 accuracy: 0.9331 f1: 0.9318
2023-07-14 04:00:21,393 epoch [63/800] time: 4.81s train loss: 0.1119 accuracy: 0.9606 f1: 0.9601
2023-07-14 04:00:22,291 epoch [63/800] time: 0.9s val loss: 0.1578 accuracy: 0.9401 f1: 0.9388
2023-07-14 04:00:27,689 epoch [64/800] time: 5.4s train loss: 0.1104 accuracy: 0.9619 f1: 0.9615
2023-07-14 04:00:28,594 epoch [64/800] time: 0.9s val loss: 0.1593 accuracy: 0.9401 f1: 0.9389
2023-07-14 04:00:33,999 epoch [65/800] time: 5.4s train loss: 0.1099 accuracy: 0.9617 f1: 0.9614
2023-07-14 04:00:34,947 epoch [65/800] time: 0.95s val loss: 0.1603 accuracy: 0.94 f1: 0.9392
2023-07-14 04:00:40,227 epoch [66/800] time: 5.28s train loss: 0.1069 accuracy: 0.963 f1: 0.9626
2023-07-14 04:00:41,067 epoch [66/800] time: 0.83s val loss: 0.1516 accuracy: 0.9428 f1: 0.9416
2023-07-14 04:00:46,257 epoch [67/800] time: 5.19s train loss: 0.1098 accuracy: 0.9615 f1: 0.9612
2023-07-14 04:00:47,220 epoch [67/800] time: 0.96s val loss: 0.1587 accuracy: 0.94 f1: 0.9388
2023-07-14 04:00:52,373 epoch [68/800] time: 5.15s train loss: 0.1052 accuracy: 0.9638 f1: 0.9634
2023-07-14 04:00:53,237 epoch [68/800] time: 0.86s val loss: 0.1568 accuracy: 0.9407 f1: 0.9394
2023-07-14 04:00:58,172 epoch [69/800] time: 4.93s train loss: 0.1071 accuracy: 0.9633 f1: 0.9631
2023-07-14 04:00:58,999 epoch [69/800] time: 0.83s val loss: 0.1555 accuracy: 0.9419 f1: 0.9409
2023-07-14 04:01:04,129 epoch [70/800] time: 5.13s train loss: 0.1081 accuracy: 0.9626 f1: 0.9623
2023-07-14 04:01:05,043 epoch [70/800] time: 0.91s val loss: 0.1613 accuracy: 0.9395 f1: 0.9379
2023-07-14 04:01:10,193 epoch [71/800] time: 5.15s train loss: 0.1075 accuracy: 0.9625 f1: 0.9619
2023-07-14 04:01:11,125 epoch [71/800] time: 0.93s val loss: 0.1621 accuracy: 0.9384 f1: 0.9372
2023-07-14 04:01:16,514 epoch [72/800] time: 5.39s train loss: 0.1053 accuracy: 0.9628 f1: 0.9626
2023-07-14 04:01:17,377 epoch [72/800] time: 0.86s val loss: 0.158 accuracy: 0.9392 f1: 0.938
2023-07-14 04:01:22,550 epoch [73/800] time: 5.17s train loss: 0.1032 accuracy: 0.9642 f1: 0.9639
2023-07-14 04:01:23,446 epoch [73/800] time: 0.89s val loss: 0.1535 accuracy: 0.9414 f1: 0.9403
2023-07-14 04:01:28,663 epoch [74/800] time: 5.22s train loss: 0.1027 accuracy: 0.9647 f1: 0.9644
2023-07-14 04:01:29,580 epoch [74/800] time: 0.91s val loss: 0.1514 accuracy: 0.9433 f1: 0.9422
2023-07-14 04:01:34,618 epoch [75/800] time: 5.04s train loss: 0.1052 accuracy: 0.9637 f1: 0.9634
2023-07-14 04:01:35,431 epoch [75/800] time: 0.81s val loss: 0.1535 accuracy: 0.9427 f1: 0.9415
2023-07-14 04:01:40,342 epoch [76/800] time: 4.91s train loss: 0.1043 accuracy: 0.9629 f1: 0.9625
2023-07-14 04:01:41,270 epoch [76/800] time: 0.93s val loss: 0.1568 accuracy: 0.9415 f1: 0.9405
2023-07-14 04:01:46,077 epoch [77/800] time: 4.81s train loss: 0.1005 accuracy: 0.9648 f1: 0.9644
2023-07-14 04:01:46,950 epoch [77/800] time: 0.87s val loss: 0.1515 accuracy: 0.9434 f1: 0.9426
2023-07-14 04:01:51,578 epoch [78/800] time: 4.63s train loss: 0.0961 accuracy: 0.9668 f1: 0.9666
2023-07-14 04:01:52,438 epoch [78/800] time: 0.85s val loss: 0.1525 accuracy: 0.9436 f1: 0.9426
2023-07-14 04:01:57,283 epoch [79/800] time: 4.84s train loss: 0.0994 accuracy: 0.9655 f1: 0.9652
2023-07-14 04:01:58,155 epoch [79/800] time: 0.87s val loss: 0.1574 accuracy: 0.9403 f1: 0.9392
2023-07-14 04:02:02,761 epoch [80/800] time: 4.61s train loss: 0.1014 accuracy: 0.9656 f1: 0.9652
2023-07-14 04:02:03,615 epoch [80/800] time: 0.85s val loss: 0.1688 accuracy: 0.9366 f1: 0.936
2023-07-14 04:02:08,317 epoch [81/800] time: 4.7s train loss: 0.0926 accuracy: 0.9689 f1: 0.9687
2023-07-14 04:02:09,127 epoch [81/800] time: 0.8s val loss: 0.1391 accuracy: 0.9493 f1: 0.9481
2023-07-14 04:02:13,836 epoch [82/800] time: 4.71s train loss: 0.0891 accuracy: 0.9705 f1: 0.9701
2023-07-14 04:02:14,722 epoch [82/800] time: 0.88s val loss: 0.151 accuracy: 0.9431 f1: 0.942
2023-07-14 04:02:19,546 epoch [83/800] time: 4.82s train loss: 0.0875 accuracy: 0.9713 f1: 0.971
2023-07-14 04:02:20,401 epoch [83/800] time: 0.85s val loss: 0.1429 accuracy: 0.9469 f1: 0.9456
2023-07-14 04:02:25,176 epoch [84/800] time: 4.77s train loss: 0.0882 accuracy: 0.9709 f1: 0.9706
2023-07-14 04:02:25,987 epoch [84/800] time: 0.81s val loss: 0.1399 accuracy: 0.9484 f1: 0.9472
2023-07-14 04:02:30,787 epoch [85/800] time: 4.8s train loss: 0.0876 accuracy: 0.971 f1: 0.9708
2023-07-14 04:02:31,645 epoch [85/800] time: 0.86s val loss: 0.14 accuracy: 0.9484 f1: 0.9473
2023-07-14 04:02:36,170 epoch [86/800] time: 4.52s train loss: 0.085 accuracy: 0.9725 f1: 0.9722
2023-07-14 04:02:37,024 epoch [86/800] time: 0.85s val loss: 0.1418 accuracy: 0.9485 f1: 0.9475
2023-07-14 04:02:41,622 epoch [87/800] time: 4.6s train loss: 0.0855 accuracy: 0.972 f1: 0.9718
2023-07-14 04:02:42,422 epoch [87/800] time: 0.8s val loss: 0.1413 accuracy: 0.9478 f1: 0.9465
2023-07-14 04:02:46,968 epoch [88/800] time: 4.55s train loss: 0.0838 accuracy: 0.9728 f1: 0.9725
2023-07-14 04:02:47,812 epoch [88/800] time: 0.84s val loss: 0.1404 accuracy: 0.9487 f1: 0.9477
2023-07-14 04:02:52,341 epoch [89/800] time: 4.53s train loss: 0.0835 accuracy: 0.9725 f1: 0.9723
2023-07-14 04:02:53,188 epoch [89/800] time: 0.85s val loss: 0.1388 accuracy: 0.9496 f1: 0.9484
2023-07-14 04:02:57,737 epoch [90/800] time: 4.55s train loss: 0.0845 accuracy: 0.9719 f1: 0.9717
2023-07-14 04:02:58,541 epoch [90/800] time: 0.8s val loss: 0.1398 accuracy: 0.9491 f1: 0.9478
2023-07-14 04:03:03,284 epoch [91/800] time: 4.74s train loss: 0.0835 accuracy: 0.9724 f1: 0.9722
2023-07-14 04:03:04,156 epoch [91/800] time: 0.87s val loss: 0.1377 accuracy: 0.9497 f1: 0.9486
2023-07-14 04:03:08,947 epoch [92/800] time: 4.79s train loss: 0.0824 accuracy: 0.9732 f1: 0.9729
2023-07-14 04:03:09,802 epoch [92/800] time: 0.85s val loss: 0.1416 accuracy: 0.9474 f1: 0.9464
2023-07-14 04:03:14,541 epoch [93/800] time: 4.74s train loss: 0.0833 accuracy: 0.9727 f1: 0.9725
2023-07-14 04:03:15,404 epoch [93/800] time: 0.86s val loss: 0.1403 accuracy: 0.9486 f1: 0.9475
2023-07-14 04:03:20,151 epoch [94/800] time: 4.75s train loss: 0.0843 accuracy: 0.9727 f1: 0.9725
2023-07-14 04:03:21,007 epoch [94/800] time: 0.86s val loss: 0.141 accuracy: 0.9488 f1: 0.9476
2023-07-14 04:03:25,526 epoch [95/800] time: 4.52s train loss: 0.085 accuracy: 0.9722 f1: 0.972
2023-07-14 04:03:26,376 epoch [95/800] time: 0.85s val loss: 0.1455 accuracy: 0.9477 f1: 0.9465
2023-07-14 04:03:30,943 epoch [96/800] time: 4.57s train loss: 0.0829 accuracy: 0.9731 f1: 0.9729
2023-07-14 04:03:31,744 epoch [96/800] time: 0.8s val loss: 0.1364 accuracy: 0.9496 f1: 0.9484
2023-07-14 04:03:36,337 epoch [97/800] time: 4.59s train loss: 0.0819 accuracy: 0.9738 f1: 0.9736
2023-07-14 04:03:37,181 epoch [97/800] time: 0.84s val loss: 0.1418 accuracy: 0.9485 f1: 0.9475
2023-07-14 04:03:41,801 epoch [98/800] time: 4.62s train loss: 0.0818 accuracy: 0.973 f1: 0.9728
2023-07-14 04:03:42,642 epoch [98/800] time: 0.84s val loss: 0.1401 accuracy: 0.949 f1: 0.948
2023-07-14 04:03:47,340 epoch [99/800] time: 4.7s train loss: 0.0815 accuracy: 0.9737 f1: 0.9737
2023-07-14 04:03:48,143 epoch [99/800] time: 0.8s val loss: 0.1391 accuracy: 0.9486 f1: 0.9476
2023-07-14 04:03:53,059 epoch [100/800] time: 4.92s train loss: 0.0811 accuracy: 0.973 f1: 0.9728
2023-07-14 04:03:53,940 epoch [100/800] time: 0.88s val loss: 0.139 accuracy: 0.9499 f1: 0.949
2023-07-14 04:03:58,767 epoch [101/800] time: 4.83s train loss: 0.0767 accuracy: 0.9761 f1: 0.9758
2023-07-14 04:03:59,631 epoch [101/800] time: 0.86s val loss: 0.1343 accuracy: 0.9505 f1: 0.9493
2023-07-14 04:04:04,514 epoch [102/800] time: 4.88s train loss: 0.0739 accuracy: 0.9771 f1: 0.977
2023-07-14 04:04:05,399 epoch [102/800] time: 0.88s val loss: 0.1351 accuracy: 0.9511 f1: 0.95
2023-07-14 04:04:10,490 epoch [103/800] time: 5.09s train loss: 0.0756 accuracy: 0.9768 f1: 0.9765
2023-07-14 04:04:11,355 epoch [103/800] time: 0.87s val loss: 0.1346 accuracy: 0.9512 f1: 0.9503
2023-07-14 04:04:16,151 epoch [104/800] time: 4.8s train loss: 0.0738 accuracy: 0.9766 f1: 0.9764
2023-07-14 04:04:17,008 epoch [104/800] time: 0.86s val loss: 0.1337 accuracy: 0.9516 f1: 0.9507
2023-07-14 04:04:21,885 epoch [105/800] time: 4.88s train loss: 0.0741 accuracy: 0.9768 f1: 0.9766
2023-07-14 04:04:22,694 epoch [105/800] time: 0.81s val loss: 0.1336 accuracy: 0.9512 f1: 0.9502
2023-07-14 04:04:27,515 epoch [106/800] time: 4.82s train loss: 0.0736 accuracy: 0.977 f1: 0.9768
2023-07-14 04:04:28,364 epoch [106/800] time: 0.85s val loss: 0.1338 accuracy: 0.9513 f1: 0.9503
2023-07-14 04:04:33,106 epoch [107/800] time: 4.74s train loss: 0.0755 accuracy: 0.9761 f1: 0.9759
2023-07-14 04:04:33,954 epoch [107/800] time: 0.85s val loss: 0.1358 accuracy: 0.9514 f1: 0.9505
2023-07-14 04:04:39,023 epoch [108/800] time: 5.07s train loss: 0.0731 accuracy: 0.9767 f1: 0.9763
2023-07-14 04:04:39,845 epoch [108/800] time: 0.82s val loss: 0.1342 accuracy: 0.9512 f1: 0.9504
2023-07-14 04:04:44,695 epoch [109/800] time: 4.85s train loss: 0.0746 accuracy: 0.9765 f1: 0.9763
2023-07-14 04:04:45,546 epoch [109/800] time: 0.85s val loss: 0.1348 accuracy: 0.9512 f1: 0.9503
2023-07-14 04:04:50,474 epoch [110/800] time: 4.93s train loss: 0.0744 accuracy: 0.9767 f1: 0.9765
2023-07-14 04:04:51,350 epoch [110/800] time: 0.88s val loss: 0.1329 accuracy: 0.9521 f1: 0.9511
2023-07-14 04:04:56,145 epoch [111/800] time: 4.79s train loss: 0.0745 accuracy: 0.9779 f1: 0.9777
2023-07-14 04:04:56,951 epoch [111/800] time: 0.8s val loss: 0.1344 accuracy: 0.9511 f1: 0.9499
2023-07-14 04:05:01,721 epoch [112/800] time: 4.77s train loss: 0.075 accuracy: 0.9763 f1: 0.976
2023-07-14 04:05:02,574 epoch [112/800] time: 0.85s val loss: 0.1328 accuracy: 0.9518 f1: 0.9508
2023-07-14 04:05:07,274 epoch [113/800] time: 4.7s train loss: 0.073 accuracy: 0.9774 f1: 0.9772
2023-07-14 04:05:08,113 epoch [113/800] time: 0.84s val loss: 0.134 accuracy: 0.9516 f1: 0.9506
2023-07-14 04:05:12,798 epoch [114/800] time: 4.69s train loss: 0.0726 accuracy: 0.9774 f1: 0.9772
2023-07-14 04:05:13,599 epoch [114/800] time: 0.8s val loss: 0.132 accuracy: 0.9527 f1: 0.9519
2023-07-14 04:05:18,338 epoch [115/800] time: 4.74s train loss: 0.0717 accuracy: 0.9778 f1: 0.9776
2023-07-14 04:05:19,177 epoch [115/800] time: 0.84s val loss: 0.134 accuracy: 0.952 f1: 0.951
2023-07-14 04:05:23,914 epoch [116/800] time: 4.74s train loss: 0.0723 accuracy: 0.9772 f1: 0.9768
2023-07-14 04:05:24,757 epoch [116/800] time: 0.84s val loss: 0.1327 accuracy: 0.9525 f1: 0.9514
2023-07-14 04:05:29,606 epoch [117/800] time: 4.85s train loss: 0.0721 accuracy: 0.9778 f1: 0.9776
2023-07-14 04:05:30,413 epoch [117/800] time: 0.81s val loss: 0.1353 accuracy: 0.9518 f1: 0.9511
2023-07-14 04:05:35,199 epoch [118/800] time: 4.79s train loss: 0.0703 accuracy: 0.9788 f1: 0.9786
2023-07-14 04:05:36,050 epoch [118/800] time: 0.84s val loss: 0.1339 accuracy: 0.9527 f1: 0.9517
2023-07-14 04:05:40,881 epoch [119/800] time: 4.83s train loss: 0.0715 accuracy: 0.9777 f1: 0.9775
2023-07-14 04:05:41,749 epoch [119/800] time: 0.87s val loss: 0.1324 accuracy: 0.9525 f1: 0.9513
2023-07-14 04:05:46,592 epoch [120/800] time: 4.84s train loss: 0.071 accuracy: 0.9777 f1: 0.9774
2023-07-14 04:05:47,393 epoch [120/800] time: 0.8s val loss: 0.1329 accuracy: 0.9525 f1: 0.9514
2023-07-14 04:05:52,112 epoch [121/800] time: 4.72s train loss: 0.0693 accuracy: 0.9791 f1: 0.9788
2023-07-14 04:05:52,967 epoch [121/800] time: 0.85s val loss: 0.1305 accuracy: 0.9532 f1: 0.9523
2023-07-14 04:05:57,680 epoch [122/800] time: 4.71s train loss: 0.069 accuracy: 0.979 f1: 0.9789
2023-07-14 04:05:58,522 epoch [122/800] time: 0.84s val loss: 0.1326 accuracy: 0.9513 f1: 0.9502
2023-07-14 04:06:03,298 epoch [123/800] time: 4.78s train loss: 0.0682 accuracy: 0.9794 f1: 0.9792
2023-07-14 04:06:04,121 epoch [123/800] time: 0.82s val loss: 0.1312 accuracy: 0.9527 f1: 0.9519
2023-07-14 04:06:09,005 epoch [124/800] time: 4.88s train loss: 0.0676 accuracy: 0.9792 f1: 0.979
2023-07-14 04:06:09,861 epoch [124/800] time: 0.86s val loss: 0.1309 accuracy: 0.9533 f1: 0.9522
2023-07-14 04:06:14,407 epoch [125/800] time: 4.55s train loss: 0.0672 accuracy: 0.9796 f1: 0.9794
2023-07-14 04:06:15,275 epoch [125/800] time: 0.86s val loss: 0.1316 accuracy: 0.953 f1: 0.9522
2023-07-14 04:06:19,999 epoch [126/800] time: 4.72s train loss: 0.0679 accuracy: 0.9796 f1: 0.9794
2023-07-14 04:06:20,806 epoch [126/800] time: 0.81s val loss: 0.1305 accuracy: 0.9537 f1: 0.9527
2023-07-14 04:06:25,562 epoch [127/800] time: 4.76s train loss: 0.0684 accuracy: 0.9791 f1: 0.9789
2023-07-14 04:06:26,409 epoch [127/800] time: 0.85s val loss: 0.131 accuracy: 0.9529 f1: 0.9519
2023-07-14 04:06:31,123 epoch [128/800] time: 4.71s train loss: 0.0659 accuracy: 0.9802 f1: 0.98
2023-07-14 04:06:31,978 epoch [128/800] time: 0.85s val loss: 0.1306 accuracy: 0.953 f1: 0.952
2023-07-14 04:06:36,717 epoch [129/800] time: 4.74s train loss: 0.0663 accuracy: 0.9801 f1: 0.9799
2023-07-14 04:06:37,516 epoch [129/800] time: 0.8s val loss: 0.1293 accuracy: 0.9545 f1: 0.9534
2023-07-14 04:06:42,280 epoch [130/800] time: 4.76s train loss: 0.0675 accuracy: 0.9795 f1: 0.9791
2023-07-14 04:06:43,124 epoch [130/800] time: 0.84s val loss: 0.1299 accuracy: 0.9535 f1: 0.9525
2023-07-14 04:06:47,618 epoch [131/800] time: 4.49s train loss: 0.0689 accuracy: 0.9794 f1: 0.9791
2023-07-14 04:06:48,462 epoch [131/800] time: 0.84s val loss: 0.1309 accuracy: 0.9534 f1: 0.9524
2023-07-14 04:06:53,232 epoch [132/800] time: 4.77s train loss: 0.0689 accuracy: 0.979 f1: 0.9788
2023-07-14 04:06:54,037 epoch [132/800] time: 0.8s val loss: 0.13 accuracy: 0.9535 f1: 0.9525
2023-07-14 04:06:59,179 epoch [133/800] time: 5.14s train loss: 0.0684 accuracy: 0.9795 f1: 0.9794
2023-07-14 04:07:00,099 epoch [133/800] time: 0.92s val loss: 0.1315 accuracy: 0.9527 f1: 0.9517
2023-07-14 04:07:05,187 epoch [134/800] time: 5.09s train loss: 0.0665 accuracy: 0.9798 f1: 0.9795
2023-07-14 04:07:06,098 epoch [134/800] time: 0.91s val loss: 0.1316 accuracy: 0.9535 f1: 0.9526
2023-07-14 04:07:11,302 epoch [135/800] time: 5.2s train loss: 0.0656 accuracy: 0.9804 f1: 0.9801
2023-07-14 04:07:12,219 epoch [135/800] time: 0.91s val loss: 0.1303 accuracy: 0.9535 f1: 0.9524
2023-07-14 04:07:17,456 epoch [136/800] time: 5.24s train loss: 0.0658 accuracy: 0.9804 f1: 0.9803
2023-07-14 04:07:18,388 epoch [136/800] time: 0.93s val loss: 0.1294 accuracy: 0.954 f1: 0.9531
2023-07-14 04:07:23,521 epoch [137/800] time: 5.13s train loss: 0.0661 accuracy: 0.9802 f1: 0.9801
2023-07-14 04:07:24,513 epoch [137/800] time: 0.99s val loss: 0.1306 accuracy: 0.9537 f1: 0.9529
2023-07-14 04:07:29,802 epoch [138/800] time: 5.29s train loss: 0.0662 accuracy: 0.9801 f1: 0.98
2023-07-14 04:07:30,636 epoch [138/800] time: 0.83s val loss: 0.1301 accuracy: 0.9536 f1: 0.9527
2023-07-14 04:07:35,831 epoch [139/800] time: 5.19s train loss: 0.0651 accuracy: 0.9807 f1: 0.9805
2023-07-14 04:07:36,745 epoch [139/800] time: 0.91s val loss: 0.1307 accuracy: 0.9532 f1: 0.9521
2023-07-14 04:07:41,947 epoch [140/800] time: 5.2s train loss: 0.0655 accuracy: 0.9808 f1: 0.9806
2023-07-14 04:07:42,838 epoch [140/800] time: 0.88s val loss: 0.1303 accuracy: 0.953 f1: 0.952
2023-07-14 04:07:47,894 epoch [141/800] time: 5.06s train loss: 0.0649 accuracy: 0.9806 f1: 0.9804
2023-07-14 04:07:48,738 epoch [141/800] time: 0.84s val loss: 0.1307 accuracy: 0.9526 f1: 0.9516
2023-07-14 04:07:53,709 epoch [142/800] time: 4.97s train loss: 0.065 accuracy: 0.9806 f1: 0.9805
2023-07-14 04:07:54,569 epoch [142/800] time: 0.86s val loss: 0.1302 accuracy: 0.9536 f1: 0.9526
2023-07-14 04:07:59,528 epoch [143/800] time: 4.96s train loss: 0.0645 accuracy: 0.981 f1: 0.9808
2023-07-14 04:08:00,416 epoch [143/800] time: 0.88s val loss: 0.1294 accuracy: 0.9533 f1: 0.9523
2023-07-14 04:08:05,540 epoch [144/800] time: 5.12s train loss: 0.0642 accuracy: 0.981 f1: 0.9809
2023-07-14 04:08:06,366 epoch [144/800] time: 0.82s val loss: 0.1289 accuracy: 0.9538 f1: 0.9527
2023-07-14 04:08:11,337 epoch [145/800] time: 4.97s train loss: 0.0644 accuracy: 0.9809 f1: 0.9806
2023-07-14 04:08:12,222 epoch [145/800] time: 0.88s val loss: 0.1294 accuracy: 0.9543 f1: 0.9535
2023-07-14 04:08:17,201 epoch [146/800] time: 4.98s train loss: 0.0637 accuracy: 0.9814 f1: 0.9812
2023-07-14 04:08:18,078 epoch [146/800] time: 0.87s val loss: 0.1291 accuracy: 0.9536 f1: 0.9527
2023-07-14 04:08:22,795 epoch [147/800] time: 4.72s train loss: 0.0646 accuracy: 0.9806 f1: 0.9805
2023-07-14 04:08:23,662 epoch [147/800] time: 0.87s val loss: 0.129 accuracy: 0.9543 f1: 0.9534
2023-07-14 04:08:28,618 epoch [148/800] time: 4.96s train loss: 0.0632 accuracy: 0.9812 f1: 0.9811
2023-07-14 04:08:29,501 epoch [148/800] time: 0.88s val loss: 0.1288 accuracy: 0.9537 f1: 0.9525
2023-07-14 04:08:34,041 epoch [149/800] time: 4.54s train loss: 0.0625 accuracy: 0.9821 f1: 0.982
2023-07-14 04:08:34,891 epoch [149/800] time: 0.84s val loss: 0.1293 accuracy: 0.9536 f1: 0.9528
2023-07-14 04:08:39,835 epoch [150/800] time: 4.94s train loss: 0.0639 accuracy: 0.9813 f1: 0.9813
2023-07-14 04:08:40,681 epoch [150/800] time: 0.85s val loss: 0.1286 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:08:45,594 epoch [151/800] time: 4.91s train loss: 0.0663 accuracy: 0.9801 f1: 0.98
2023-07-14 04:08:46,453 epoch [151/800] time: 0.86s val loss: 0.1306 accuracy: 0.9534 f1: 0.9524
2023-07-14 04:08:51,180 epoch [152/800] time: 4.73s train loss: 0.0642 accuracy: 0.9808 f1: 0.9806
2023-07-14 04:08:52,034 epoch [152/800] time: 0.85s val loss: 0.1289 accuracy: 0.954 f1: 0.9531
2023-07-14 04:08:57,030 epoch [153/800] time: 5.0s train loss: 0.0623 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:08:57,842 epoch [153/800] time: 0.81s val loss: 0.1298 accuracy: 0.9536 f1: 0.9525
2023-07-14 04:09:02,655 epoch [154/800] time: 4.81s train loss: 0.0631 accuracy: 0.9822 f1: 0.982
2023-07-14 04:09:03,504 epoch [154/800] time: 0.85s val loss: 0.13 accuracy: 0.9536 f1: 0.9526
2023-07-14 04:09:08,283 epoch [155/800] time: 4.78s train loss: 0.0641 accuracy: 0.981 f1: 0.9809
2023-07-14 04:09:09,150 epoch [155/800] time: 0.87s val loss: 0.1296 accuracy: 0.9536 f1: 0.9524
2023-07-14 04:09:13,934 epoch [156/800] time: 4.78s train loss: 0.065 accuracy: 0.981 f1: 0.9809
2023-07-14 04:09:14,736 epoch [156/800] time: 0.8s val loss: 0.1292 accuracy: 0.9543 f1: 0.9534
2023-07-14 04:09:19,468 epoch [157/800] time: 4.73s train loss: 0.0639 accuracy: 0.981 f1: 0.9809
2023-07-14 04:09:20,336 epoch [157/800] time: 0.87s val loss: 0.1294 accuracy: 0.9539 f1: 0.953
2023-07-14 04:09:25,260 epoch [158/800] time: 4.92s train loss: 0.064 accuracy: 0.9811 f1: 0.9808
2023-07-14 04:09:26,116 epoch [158/800] time: 0.86s val loss: 0.1297 accuracy: 0.9536 f1: 0.9527
2023-07-14 04:09:30,670 epoch [159/800] time: 4.55s train loss: 0.0641 accuracy: 0.9809 f1: 0.9808
2023-07-14 04:09:31,475 epoch [159/800] time: 0.81s val loss: 0.1294 accuracy: 0.9536 f1: 0.9526
2023-07-14 04:09:36,068 epoch [160/800] time: 4.59s train loss: 0.0631 accuracy: 0.9816 f1: 0.9814
2023-07-14 04:09:36,913 epoch [160/800] time: 0.85s val loss: 0.1295 accuracy: 0.9539 f1: 0.9529
2023-07-14 04:09:41,489 epoch [161/800] time: 4.58s train loss: 0.0635 accuracy: 0.9817 f1: 0.9815
2023-07-14 04:09:42,328 epoch [161/800] time: 0.84s val loss: 0.1302 accuracy: 0.9529 f1: 0.9519
2023-07-14 04:09:47,022 epoch [162/800] time: 4.69s train loss: 0.0625 accuracy: 0.9817 f1: 0.9816
2023-07-14 04:09:47,818 epoch [162/800] time: 0.8s val loss: 0.1294 accuracy: 0.9534 f1: 0.9524
2023-07-14 04:09:52,533 epoch [163/800] time: 4.71s train loss: 0.0624 accuracy: 0.9819 f1: 0.9817
2023-07-14 04:09:53,371 epoch [163/800] time: 0.84s val loss: 0.1287 accuracy: 0.9543 f1: 0.9533
2023-07-14 04:09:58,102 epoch [164/800] time: 4.73s train loss: 0.0628 accuracy: 0.9818 f1: 0.9817
2023-07-14 04:09:58,943 epoch [164/800] time: 0.84s val loss: 0.1281 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:10:03,662 epoch [165/800] time: 4.72s train loss: 0.0633 accuracy: 0.9812 f1: 0.9809
2023-07-14 04:10:04,463 epoch [165/800] time: 0.8s val loss: 0.1287 accuracy: 0.9538 f1: 0.9527
2023-07-14 04:10:08,983 epoch [166/800] time: 4.52s train loss: 0.0618 accuracy: 0.9821 f1: 0.982
2023-07-14 04:10:09,835 epoch [166/800] time: 0.85s val loss: 0.1282 accuracy: 0.9543 f1: 0.9533
2023-07-14 04:10:14,320 epoch [167/800] time: 4.48s train loss: 0.0632 accuracy: 0.9812 f1: 0.9811
2023-07-14 04:10:15,162 epoch [167/800] time: 0.84s val loss: 0.1299 accuracy: 0.9532 f1: 0.952
2023-07-14 04:10:20,033 epoch [168/800] time: 4.87s train loss: 0.0628 accuracy: 0.9815 f1: 0.9813
2023-07-14 04:10:20,884 epoch [168/800] time: 0.85s val loss: 0.1287 accuracy: 0.9542 f1: 0.9531
2023-07-14 04:10:26,037 epoch [169/800] time: 5.15s train loss: 0.0631 accuracy: 0.9813 f1: 0.9812
2023-07-14 04:10:26,969 epoch [169/800] time: 0.93s val loss: 0.1286 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:10:32,119 epoch [170/800] time: 5.15s train loss: 0.0633 accuracy: 0.9815 f1: 0.9813
2023-07-14 04:10:33,271 epoch [170/800] time: 1.15s val loss: 0.1288 accuracy: 0.9541 f1: 0.9531
2023-07-14 04:10:38,726 epoch [171/800] time: 5.45s train loss: 0.0626 accuracy: 0.982 f1: 0.9819
2023-07-14 04:10:39,555 epoch [171/800] time: 0.83s val loss: 0.1292 accuracy: 0.954 f1: 0.9529
2023-07-14 04:10:44,649 epoch [172/800] time: 5.09s train loss: 0.0623 accuracy: 0.9817 f1: 0.9815
2023-07-14 04:10:45,531 epoch [172/800] time: 0.88s val loss: 0.1288 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:10:50,609 epoch [173/800] time: 5.08s train loss: 0.062 accuracy: 0.982 f1: 0.9818
2023-07-14 04:10:51,565 epoch [173/800] time: 0.96s val loss: 0.1291 accuracy: 0.9535 f1: 0.9525
2023-07-14 04:10:56,709 epoch [174/800] time: 5.14s train loss: 0.0621 accuracy: 0.9818 f1: 0.9816
2023-07-14 04:10:57,544 epoch [174/800] time: 0.83s val loss: 0.1288 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:11:02,723 epoch [175/800] time: 5.18s train loss: 0.0628 accuracy: 0.9818 f1: 0.9816
2023-07-14 04:11:03,614 epoch [175/800] time: 0.89s val loss: 0.1293 accuracy: 0.9543 f1: 0.9534
2023-07-14 04:11:08,521 epoch [176/800] time: 4.91s train loss: 0.0622 accuracy: 0.982 f1: 0.9819
2023-07-14 04:11:09,385 epoch [176/800] time: 0.86s val loss: 0.1281 accuracy: 0.9549 f1: 0.954
2023-07-14 04:11:14,465 epoch [177/800] time: 5.08s train loss: 0.0622 accuracy: 0.9821 f1: 0.9819
2023-07-14 04:11:15,288 epoch [177/800] time: 0.82s val loss: 0.1289 accuracy: 0.955 f1: 0.954
2023-07-14 04:11:20,099 epoch [178/800] time: 4.81s train loss: 0.0628 accuracy: 0.9814 f1: 0.9813
2023-07-14 04:11:20,956 epoch [178/800] time: 0.86s val loss: 0.1289 accuracy: 0.9544 f1: 0.9535
2023-07-14 04:11:25,840 epoch [179/800] time: 4.88s train loss: 0.0631 accuracy: 0.9813 f1: 0.9811
2023-07-14 04:11:26,684 epoch [179/800] time: 0.84s val loss: 0.1284 accuracy: 0.9536 f1: 0.9525
2023-07-14 04:11:31,434 epoch [180/800] time: 4.75s train loss: 0.0632 accuracy: 0.9812 f1: 0.9811
2023-07-14 04:11:32,256 epoch [180/800] time: 0.82s val loss: 0.128 accuracy: 0.9545 f1: 0.9536
2023-07-14 04:11:37,126 epoch [181/800] time: 4.87s train loss: 0.0629 accuracy: 0.9821 f1: 0.9818
2023-07-14 04:11:37,990 epoch [181/800] time: 0.86s val loss: 0.1287 accuracy: 0.9543 f1: 0.9533
2023-07-14 04:11:42,770 epoch [182/800] time: 4.78s train loss: 0.0615 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:11:43,667 epoch [182/800] time: 0.89s val loss: 0.129 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:11:48,426 epoch [183/800] time: 4.76s train loss: 0.0618 accuracy: 0.9819 f1: 0.9816
2023-07-14 04:11:49,232 epoch [183/800] time: 0.81s val loss: 0.1284 accuracy: 0.9544 f1: 0.9534
2023-07-14 04:11:53,788 epoch [184/800] time: 4.56s train loss: 0.0624 accuracy: 0.9822 f1: 0.9821
2023-07-14 04:11:54,637 epoch [184/800] time: 0.85s val loss: 0.1284 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:11:59,178 epoch [185/800] time: 4.54s train loss: 0.0614 accuracy: 0.9819 f1: 0.9818
2023-07-14 04:12:00,020 epoch [185/800] time: 0.84s val loss: 0.1283 accuracy: 0.9544 f1: 0.9534
2023-07-14 04:12:04,729 epoch [186/800] time: 4.71s train loss: 0.062 accuracy: 0.9822 f1: 0.982
2023-07-14 04:12:05,530 epoch [186/800] time: 0.8s val loss: 0.1289 accuracy: 0.954 f1: 0.9531
2023-07-14 04:12:10,099 epoch [187/800] time: 4.57s train loss: 0.0629 accuracy: 0.9819 f1: 0.9816
2023-07-14 04:12:10,939 epoch [187/800] time: 0.84s val loss: 0.129 accuracy: 0.9548 f1: 0.954
2023-07-14 04:12:15,440 epoch [188/800] time: 4.5s train loss: 0.0629 accuracy: 0.9816 f1: 0.9814
2023-07-14 04:12:16,290 epoch [188/800] time: 0.85s val loss: 0.128 accuracy: 0.9546 f1: 0.9536
2023-07-14 04:12:20,791 epoch [189/800] time: 4.5s train loss: 0.0628 accuracy: 0.9819 f1: 0.9817
2023-07-14 04:12:21,588 epoch [189/800] time: 0.8s val loss: 0.1295 accuracy: 0.9533 f1: 0.9522
2023-07-14 04:12:26,100 epoch [190/800] time: 4.51s train loss: 0.061 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:12:26,936 epoch [190/800] time: 0.84s val loss: 0.1283 accuracy: 0.954 f1: 0.953
2023-07-14 04:12:31,741 epoch [191/800] time: 4.8s train loss: 0.0627 accuracy: 0.9821 f1: 0.9819
2023-07-14 04:12:32,673 epoch [191/800] time: 0.93s val loss: 0.1297 accuracy: 0.9538 f1: 0.9528
2023-07-14 04:12:37,885 epoch [192/800] time: 5.21s train loss: 0.0608 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:12:38,771 epoch [192/800] time: 0.88s val loss: 0.1283 accuracy: 0.9543 f1: 0.9533
2023-07-14 04:12:44,056 epoch [193/800] time: 5.29s train loss: 0.0606 accuracy: 0.9828 f1: 0.9825
2023-07-14 04:12:45,011 epoch [193/800] time: 0.95s val loss: 0.1298 accuracy: 0.9534 f1: 0.9524
2023-07-14 04:12:50,225 epoch [194/800] time: 5.21s train loss: 0.0624 accuracy: 0.9813 f1: 0.9811
2023-07-14 04:12:51,155 epoch [194/800] time: 0.93s val loss: 0.1288 accuracy: 0.9537 f1: 0.9527
2023-07-14 04:12:56,294 epoch [195/800] time: 5.14s train loss: 0.062 accuracy: 0.9821 f1: 0.982
2023-07-14 04:12:57,128 epoch [195/800] time: 0.83s val loss: 0.1292 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:13:02,246 epoch [196/800] time: 5.12s train loss: 0.0623 accuracy: 0.982 f1: 0.9818
2023-07-14 04:13:03,129 epoch [196/800] time: 0.88s val loss: 0.1298 accuracy: 0.9532 f1: 0.9521
2023-07-14 04:13:08,018 epoch [197/800] time: 4.89s train loss: 0.0616 accuracy: 0.9824 f1: 0.9821
2023-07-14 04:13:08,907 epoch [197/800] time: 0.89s val loss: 0.1292 accuracy: 0.9539 f1: 0.9529
2023-07-14 04:13:13,801 epoch [198/800] time: 4.89s train loss: 0.0627 accuracy: 0.9817 f1: 0.9815
2023-07-14 04:13:14,608 epoch [198/800] time: 0.81s val loss: 0.1291 accuracy: 0.9542 f1: 0.9533
2023-07-14 04:13:19,399 epoch [199/800] time: 4.79s train loss: 0.0611 accuracy: 0.9818 f1: 0.9816
2023-07-14 04:13:20,271 epoch [199/800] time: 0.87s val loss: 0.1288 accuracy: 0.9542 f1: 0.9531
2023-07-14 04:13:24,990 epoch [200/800] time: 4.72s train loss: 0.0637 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:13:25,840 epoch [200/800] time: 0.85s val loss: 0.1296 accuracy: 0.9537 f1: 0.9528
2023-07-14 04:13:30,610 epoch [201/800] time: 4.77s train loss: 0.0613 accuracy: 0.9822 f1: 0.9819
2023-07-14 04:13:31,415 epoch [201/800] time: 0.8s val loss: 0.1294 accuracy: 0.9539 f1: 0.953
2023-07-14 04:13:36,294 epoch [202/800] time: 4.88s train loss: 0.0598 accuracy: 0.9832 f1: 0.9831
2023-07-14 04:13:37,189 epoch [202/800] time: 0.89s val loss: 0.1284 accuracy: 0.9536 f1: 0.9526
2023-07-14 04:13:42,020 epoch [203/800] time: 4.83s train loss: 0.0618 accuracy: 0.9821 f1: 0.9819
2023-07-14 04:13:42,901 epoch [203/800] time: 0.88s val loss: 0.1292 accuracy: 0.9532 f1: 0.9522
2023-07-14 04:13:47,795 epoch [204/800] time: 4.89s train loss: 0.0613 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:13:48,626 epoch [204/800] time: 0.83s val loss: 0.1279 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:13:53,493 epoch [205/800] time: 4.87s train loss: 0.0616 accuracy: 0.9821 f1: 0.9817
2023-07-14 04:13:54,379 epoch [205/800] time: 0.89s val loss: 0.1287 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:13:59,206 epoch [206/800] time: 4.83s train loss: 0.0623 accuracy: 0.9817 f1: 0.9815
2023-07-14 04:14:00,086 epoch [206/800] time: 0.88s val loss: 0.13 accuracy: 0.9534 f1: 0.9523
2023-07-14 04:14:04,984 epoch [207/800] time: 4.9s train loss: 0.0618 accuracy: 0.9816 f1: 0.9814
2023-07-14 04:14:05,803 epoch [207/800] time: 0.82s val loss: 0.1286 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:14:10,773 epoch [208/800] time: 4.97s train loss: 0.063 accuracy: 0.9818 f1: 0.9816
2023-07-14 04:14:11,708 epoch [208/800] time: 0.93s val loss: 0.1288 accuracy: 0.9546 f1: 0.9535
2023-07-14 04:14:16,579 epoch [209/800] time: 4.87s train loss: 0.0633 accuracy: 0.9816 f1: 0.9815
2023-07-14 04:14:17,461 epoch [209/800] time: 0.88s val loss: 0.1287 accuracy: 0.9544 f1: 0.9534
2023-07-14 04:14:22,328 epoch [210/800] time: 4.87s train loss: 0.0619 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:14:23,140 epoch [210/800] time: 0.81s val loss: 0.1304 accuracy: 0.9531 f1: 0.9521
2023-07-14 04:14:27,931 epoch [211/800] time: 4.79s train loss: 0.0637 accuracy: 0.9822 f1: 0.982
2023-07-14 04:14:28,777 epoch [211/800] time: 0.85s val loss: 0.1314 accuracy: 0.9527 f1: 0.9516
2023-07-14 04:14:33,458 epoch [212/800] time: 4.68s train loss: 0.0603 accuracy: 0.9828 f1: 0.9827
2023-07-14 04:14:34,311 epoch [212/800] time: 0.85s val loss: 0.1284 accuracy: 0.954 f1: 0.953
2023-07-14 04:14:38,976 epoch [213/800] time: 4.67s train loss: 0.0605 accuracy: 0.9827 f1: 0.9826
2023-07-14 04:14:39,774 epoch [213/800] time: 0.8s val loss: 0.1284 accuracy: 0.9546 f1: 0.9538
2023-07-14 04:14:44,547 epoch [214/800] time: 4.77s train loss: 0.0605 accuracy: 0.9825 f1: 0.9822
2023-07-14 04:14:45,392 epoch [214/800] time: 0.85s val loss: 0.1282 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:14:50,099 epoch [215/800] time: 4.71s train loss: 0.0617 accuracy: 0.9822 f1: 0.982
2023-07-14 04:14:50,942 epoch [215/800] time: 0.84s val loss: 0.1283 accuracy: 0.9548 f1: 0.9539
2023-07-14 04:14:55,651 epoch [216/800] time: 4.71s train loss: 0.0617 accuracy: 0.9822 f1: 0.982
2023-07-14 04:14:56,450 epoch [216/800] time: 0.8s val loss: 0.1289 accuracy: 0.9549 f1: 0.9539
2023-07-14 04:15:01,144 epoch [217/800] time: 4.69s train loss: 0.0614 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:15:01,996 epoch [217/800] time: 0.85s val loss: 0.128 accuracy: 0.9547 f1: 0.9539
2023-07-14 04:15:06,605 epoch [218/800] time: 4.61s train loss: 0.0612 accuracy: 0.9824 f1: 0.9822
2023-07-14 04:15:07,445 epoch [218/800] time: 0.84s val loss: 0.1285 accuracy: 0.954 f1: 0.953
2023-07-14 04:15:12,205 epoch [219/800] time: 4.76s train loss: 0.0623 accuracy: 0.9823 f1: 0.9821
2023-07-14 04:15:13,003 epoch [219/800] time: 0.8s val loss: 0.1293 accuracy: 0.9537 f1: 0.9526
2023-07-14 04:15:17,722 epoch [220/800] time: 4.72s train loss: 0.0612 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:15:18,562 epoch [220/800] time: 0.84s val loss: 0.1283 accuracy: 0.9543 f1: 0.9535
2023-07-14 04:15:23,223 epoch [221/800] time: 4.66s train loss: 0.0615 accuracy: 0.9822 f1: 0.9821
2023-07-14 04:15:24,063 epoch [221/800] time: 0.84s val loss: 0.1293 accuracy: 0.9537 f1: 0.9526
2023-07-14 04:15:28,730 epoch [222/800] time: 4.67s train loss: 0.0609 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:15:29,532 epoch [222/800] time: 0.8s val loss: 0.128 accuracy: 0.9545 f1: 0.9534
2023-07-14 04:15:34,579 epoch [223/800] time: 5.05s train loss: 0.0604 accuracy: 0.983 f1: 0.9829
2023-07-14 04:15:35,469 epoch [223/800] time: 0.89s val loss: 0.1284 accuracy: 0.9542 f1: 0.9531
2023-07-14 04:15:40,458 epoch [224/800] time: 4.99s train loss: 0.0612 accuracy: 0.9824 f1: 0.9823
2023-07-14 04:15:41,315 epoch [224/800] time: 0.86s val loss: 0.1282 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:15:46,228 epoch [225/800] time: 4.91s train loss: 0.0623 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:15:47,108 epoch [225/800] time: 0.88s val loss: 0.129 accuracy: 0.9539 f1: 0.9529
2023-07-14 04:15:52,128 epoch [226/800] time: 5.02s train loss: 0.061 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:15:52,992 epoch [226/800] time: 0.86s val loss: 0.1283 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:15:57,907 epoch [227/800] time: 4.91s train loss: 0.0603 accuracy: 0.9828 f1: 0.9827
2023-07-14 04:15:58,834 epoch [227/800] time: 0.93s val loss: 0.1287 accuracy: 0.9542 f1: 0.9534
2023-07-14 04:16:04,056 epoch [228/800] time: 5.22s train loss: 0.0613 accuracy: 0.9825 f1: 0.9825
2023-07-14 04:16:04,887 epoch [228/800] time: 0.83s val loss: 0.1289 accuracy: 0.9541 f1: 0.953
2023-07-14 04:16:09,640 epoch [229/800] time: 4.75s train loss: 0.0606 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:16:10,538 epoch [229/800] time: 0.9s val loss: 0.1283 accuracy: 0.9543 f1: 0.9533
2023-07-14 04:16:15,657 epoch [230/800] time: 5.12s train loss: 0.0601 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:16:16,562 epoch [230/800] time: 0.9s val loss: 0.1284 accuracy: 0.9547 f1: 0.9539
2023-07-14 04:16:21,358 epoch [231/800] time: 4.8s train loss: 0.062 accuracy: 0.9816 f1: 0.9815
2023-07-14 04:16:22,172 epoch [231/800] time: 0.81s val loss: 0.1284 accuracy: 0.9546 f1: 0.9538
2023-07-14 04:16:27,191 epoch [232/800] time: 5.02s train loss: 0.061 accuracy: 0.9827 f1: 0.9824
2023-07-14 04:16:28,059 epoch [232/800] time: 0.87s val loss: 0.1286 accuracy: 0.9546 f1: 0.9536
2023-07-14 04:16:32,654 epoch [233/800] time: 4.59s train loss: 0.0602 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:16:33,515 epoch [233/800] time: 0.86s val loss: 0.1287 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:16:38,339 epoch [234/800] time: 4.82s train loss: 0.0615 accuracy: 0.9824 f1: 0.9824
2023-07-14 04:16:39,141 epoch [234/800] time: 0.8s val loss: 0.1295 accuracy: 0.954 f1: 0.9531
2023-07-14 04:16:43,741 epoch [235/800] time: 4.6s train loss: 0.0614 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:16:44,625 epoch [235/800] time: 0.88s val loss: 0.129 accuracy: 0.9543 f1: 0.9533
2023-07-14 04:16:49,489 epoch [236/800] time: 4.86s train loss: 0.0608 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:16:50,356 epoch [236/800] time: 0.87s val loss: 0.1285 accuracy: 0.9548 f1: 0.954
2023-07-14 04:16:55,062 epoch [237/800] time: 4.71s train loss: 0.0621 accuracy: 0.9822 f1: 0.9821
2023-07-14 04:16:55,882 epoch [237/800] time: 0.82s val loss: 0.1283 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:17:00,926 epoch [238/800] time: 5.04s train loss: 0.0609 accuracy: 0.9823 f1: 0.9821
2023-07-14 04:17:01,810 epoch [238/800] time: 0.88s val loss: 0.1285 accuracy: 0.9547 f1: 0.9537
2023-07-14 04:17:06,591 epoch [239/800] time: 4.78s train loss: 0.0611 accuracy: 0.9821 f1: 0.9819
2023-07-14 04:17:07,448 epoch [239/800] time: 0.86s val loss: 0.1289 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:17:12,315 epoch [240/800] time: 4.87s train loss: 0.06 accuracy: 0.9833 f1: 0.983
2023-07-14 04:17:13,156 epoch [240/800] time: 0.84s val loss: 0.1287 accuracy: 0.9537 f1: 0.9528
2023-07-14 04:17:18,180 epoch [241/800] time: 5.02s train loss: 0.0615 accuracy: 0.9822 f1: 0.982
2023-07-14 04:17:19,045 epoch [241/800] time: 0.86s val loss: 0.1288 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:17:23,656 epoch [242/800] time: 4.61s train loss: 0.0626 accuracy: 0.9821 f1: 0.9819
2023-07-14 04:17:24,543 epoch [242/800] time: 0.89s val loss: 0.1298 accuracy: 0.953 f1: 0.952
2023-07-14 04:17:29,559 epoch [243/800] time: 5.02s train loss: 0.061 accuracy: 0.9822 f1: 0.982
2023-07-14 04:17:30,388 epoch [243/800] time: 0.83s val loss: 0.1288 accuracy: 0.9539 f1: 0.953
2023-07-14 04:17:35,182 epoch [244/800] time: 4.79s train loss: 0.0625 accuracy: 0.9821 f1: 0.9819
2023-07-14 04:17:36,041 epoch [244/800] time: 0.86s val loss: 0.1288 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:17:41,124 epoch [245/800] time: 5.08s train loss: 0.0606 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:17:42,028 epoch [245/800] time: 0.9s val loss: 0.1294 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:17:47,118 epoch [246/800] time: 5.09s train loss: 0.0614 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:17:47,964 epoch [246/800] time: 0.85s val loss: 0.1282 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:17:52,918 epoch [247/800] time: 4.95s train loss: 0.0614 accuracy: 0.9824 f1: 0.9822
2023-07-14 04:17:53,809 epoch [247/800] time: 0.89s val loss: 0.129 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:17:58,543 epoch [248/800] time: 4.73s train loss: 0.0609 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:17:59,435 epoch [248/800] time: 0.89s val loss: 0.1289 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:18:04,544 epoch [249/800] time: 5.11s train loss: 0.0606 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:18:05,362 epoch [249/800] time: 0.82s val loss: 0.1292 accuracy: 0.9539 f1: 0.9531
2023-07-14 04:18:10,149 epoch [250/800] time: 4.79s train loss: 0.0616 accuracy: 0.9824 f1: 0.9822
2023-07-14 04:18:11,007 epoch [250/800] time: 0.86s val loss: 0.1283 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:18:15,858 epoch [251/800] time: 4.85s train loss: 0.0613 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:18:16,734 epoch [251/800] time: 0.87s val loss: 0.1292 accuracy: 0.9546 f1: 0.9535
2023-07-14 04:18:21,528 epoch [252/800] time: 4.79s train loss: 0.0601 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:18:22,335 epoch [252/800] time: 0.81s val loss: 0.129 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:18:27,140 epoch [253/800] time: 4.8s train loss: 0.0615 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:18:27,992 epoch [253/800] time: 0.85s val loss: 0.1284 accuracy: 0.9546 f1: 0.9536
2023-07-14 04:18:32,723 epoch [254/800] time: 4.73s train loss: 0.0604 accuracy: 0.9829 f1: 0.9827
2023-07-14 04:18:33,572 epoch [254/800] time: 0.85s val loss: 0.1284 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:18:38,313 epoch [255/800] time: 4.74s train loss: 0.0606 accuracy: 0.9828 f1: 0.9827
2023-07-14 04:18:39,118 epoch [255/800] time: 0.8s val loss: 0.128 accuracy: 0.9544 f1: 0.9534
2023-07-14 04:18:43,816 epoch [256/800] time: 4.7s train loss: 0.0623 accuracy: 0.9819 f1: 0.9817
2023-07-14 04:18:44,662 epoch [256/800] time: 0.85s val loss: 0.129 accuracy: 0.9541 f1: 0.9531
2023-07-14 04:18:49,341 epoch [257/800] time: 4.68s train loss: 0.0615 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:18:50,190 epoch [257/800] time: 0.85s val loss: 0.1284 accuracy: 0.9546 f1: 0.9536
2023-07-14 04:18:54,985 epoch [258/800] time: 4.79s train loss: 0.062 accuracy: 0.9827 f1: 0.9826
2023-07-14 04:18:55,840 epoch [258/800] time: 0.86s val loss: 0.1291 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:19:00,929 epoch [259/800] time: 5.09s train loss: 0.0616 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:19:01,900 epoch [259/800] time: 0.97s val loss: 0.1299 accuracy: 0.9536 f1: 0.9528
2023-07-14 04:19:06,817 epoch [260/800] time: 4.92s train loss: 0.0622 accuracy: 0.9824 f1: 0.9823
2023-07-14 04:19:07,674 epoch [260/800] time: 0.86s val loss: 0.1285 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:19:12,596 epoch [261/800] time: 4.92s train loss: 0.0602 accuracy: 0.9829 f1: 0.9828
2023-07-14 04:19:13,451 epoch [261/800] time: 0.85s val loss: 0.1279 accuracy: 0.9551 f1: 0.9542
2023-07-14 04:19:18,449 epoch [262/800] time: 5.0s train loss: 0.0611 accuracy: 0.9827 f1: 0.9826
2023-07-14 04:19:19,369 epoch [262/800] time: 0.92s val loss: 0.1285 accuracy: 0.9545 f1: 0.9536
2023-07-14 04:19:24,556 epoch [263/800] time: 5.19s train loss: 0.0617 accuracy: 0.983 f1: 0.9829
2023-07-14 04:19:25,468 epoch [263/800] time: 0.91s val loss: 0.1286 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:19:30,475 epoch [264/800] time: 5.01s train loss: 0.0618 accuracy: 0.982 f1: 0.9817
2023-07-14 04:19:31,296 epoch [264/800] time: 0.82s val loss: 0.1283 accuracy: 0.9545 f1: 0.9536
2023-07-14 04:19:36,450 epoch [265/800] time: 5.15s train loss: 0.0613 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:19:37,398 epoch [265/800] time: 0.95s val loss: 0.1288 accuracy: 0.954 f1: 0.9531
2023-07-14 04:19:42,387 epoch [266/800] time: 4.99s train loss: 0.0613 accuracy: 0.9824 f1: 0.9822
2023-07-14 04:19:43,266 epoch [266/800] time: 0.88s val loss: 0.1289 accuracy: 0.9538 f1: 0.9528
2023-07-14 04:19:48,186 epoch [267/800] time: 4.92s train loss: 0.0611 accuracy: 0.9823 f1: 0.9819
2023-07-14 04:19:49,006 epoch [267/800] time: 0.82s val loss: 0.129 accuracy: 0.9546 f1: 0.9538
2023-07-14 04:19:53,868 epoch [268/800] time: 4.86s train loss: 0.0615 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:19:54,728 epoch [268/800] time: 0.86s val loss: 0.1294 accuracy: 0.9539 f1: 0.9529
2023-07-14 04:19:59,457 epoch [269/800] time: 4.73s train loss: 0.0604 accuracy: 0.9829 f1: 0.9827
2023-07-14 04:20:00,317 epoch [269/800] time: 0.86s val loss: 0.1286 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:20:05,029 epoch [270/800] time: 4.71s train loss: 0.0606 accuracy: 0.9822 f1: 0.9821
2023-07-14 04:20:05,851 epoch [270/800] time: 0.82s val loss: 0.1284 accuracy: 0.9549 f1: 0.954
2023-07-14 04:20:10,856 epoch [271/800] time: 5.0s train loss: 0.062 accuracy: 0.982 f1: 0.9818
2023-07-14 04:20:11,715 epoch [271/800] time: 0.86s val loss: 0.1287 accuracy: 0.9548 f1: 0.9539
2023-07-14 04:20:16,254 epoch [272/800] time: 4.54s train loss: 0.06 accuracy: 0.9831 f1: 0.983
2023-07-14 04:20:17,108 epoch [272/800] time: 0.85s val loss: 0.1283 accuracy: 0.9545 f1: 0.9536
2023-07-14 04:20:21,782 epoch [273/800] time: 4.67s train loss: 0.0614 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:20:22,606 epoch [273/800] time: 0.82s val loss: 0.1296 accuracy: 0.9536 f1: 0.9527
2023-07-14 04:20:27,349 epoch [274/800] time: 4.74s train loss: 0.0616 accuracy: 0.9822 f1: 0.9822
2023-07-14 04:20:28,206 epoch [274/800] time: 0.86s val loss: 0.1285 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:20:32,774 epoch [275/800] time: 4.57s train loss: 0.0617 accuracy: 0.9823 f1: 0.9821
2023-07-14 04:20:33,633 epoch [275/800] time: 0.86s val loss: 0.1288 accuracy: 0.9547 f1: 0.9537
2023-07-14 04:20:38,578 epoch [276/800] time: 4.95s train loss: 0.0611 accuracy: 0.9831 f1: 0.9829
2023-07-14 04:20:39,390 epoch [276/800] time: 0.81s val loss: 0.1294 accuracy: 0.9541 f1: 0.9531
2023-07-14 04:20:44,052 epoch [277/800] time: 4.66s train loss: 0.0617 accuracy: 0.9827 f1: 0.9824
2023-07-14 04:20:44,908 epoch [277/800] time: 0.86s val loss: 0.1284 accuracy: 0.9542 f1: 0.9533
2023-07-14 04:20:49,686 epoch [278/800] time: 4.78s train loss: 0.0614 accuracy: 0.9819 f1: 0.9817
2023-07-14 04:20:50,578 epoch [278/800] time: 0.89s val loss: 0.1288 accuracy: 0.9539 f1: 0.9528
2023-07-14 04:20:55,513 epoch [279/800] time: 4.94s train loss: 0.062 accuracy: 0.9826 f1: 0.9823
2023-07-14 04:20:56,322 epoch [279/800] time: 0.81s val loss: 0.1284 accuracy: 0.9544 f1: 0.9534
2023-07-14 04:21:01,272 epoch [280/800] time: 4.95s train loss: 0.0614 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:21:02,156 epoch [280/800] time: 0.88s val loss: 0.1286 accuracy: 0.9552 f1: 0.9544
2023-07-14 04:21:07,249 epoch [281/800] time: 5.09s train loss: 0.0604 accuracy: 0.9833 f1: 0.9831
2023-07-14 04:21:08,153 epoch [281/800] time: 0.9s val loss: 0.1285 accuracy: 0.9543 f1: 0.9534
2023-07-14 04:21:13,560 epoch [282/800] time: 5.41s train loss: 0.0605 accuracy: 0.9829 f1: 0.9826
2023-07-14 04:21:14,388 epoch [282/800] time: 0.83s val loss: 0.1286 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:21:19,517 epoch [283/800] time: 5.13s train loss: 0.0616 accuracy: 0.9822 f1: 0.9822
2023-07-14 04:21:20,466 epoch [283/800] time: 0.95s val loss: 0.1283 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:21:25,407 epoch [284/800] time: 4.94s train loss: 0.0598 accuracy: 0.9832 f1: 0.983
2023-07-14 04:21:26,298 epoch [284/800] time: 0.89s val loss: 0.1284 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:21:31,392 epoch [285/800] time: 5.09s train loss: 0.0618 accuracy: 0.9821 f1: 0.9819
2023-07-14 04:21:32,201 epoch [285/800] time: 0.81s val loss: 0.1285 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:21:36,961 epoch [286/800] time: 4.76s train loss: 0.0611 accuracy: 0.9827 f1: 0.9826
2023-07-14 04:21:37,859 epoch [286/800] time: 0.9s val loss: 0.1288 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:21:42,865 epoch [287/800] time: 5.01s train loss: 0.062 accuracy: 0.9821 f1: 0.9819
2023-07-14 04:21:43,782 epoch [287/800] time: 0.92s val loss: 0.1299 accuracy: 0.9542 f1: 0.9533
2023-07-14 04:21:49,081 epoch [288/800] time: 5.3s train loss: 0.0619 accuracy: 0.9822 f1: 0.982
2023-07-14 04:21:49,909 epoch [288/800] time: 0.83s val loss: 0.1288 accuracy: 0.9541 f1: 0.9531
2023-07-14 04:21:55,130 epoch [289/800] time: 5.22s train loss: 0.0608 accuracy: 0.9822 f1: 0.982
2023-07-14 04:21:56,053 epoch [289/800] time: 0.92s val loss: 0.1288 accuracy: 0.9544 f1: 0.9535
2023-07-14 04:22:00,854 epoch [290/800] time: 4.8s train loss: 0.061 accuracy: 0.9822 f1: 0.982
2023-07-14 04:22:01,733 epoch [290/800] time: 0.88s val loss: 0.1287 accuracy: 0.9538 f1: 0.9528
2023-07-14 04:22:06,763 epoch [291/800] time: 5.03s train loss: 0.0629 accuracy: 0.9824 f1: 0.9823
2023-07-14 04:22:07,606 epoch [291/800] time: 0.84s val loss: 0.1291 accuracy: 0.9546 f1: 0.9536
2023-07-14 04:22:12,506 epoch [292/800] time: 4.9s train loss: 0.0607 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:22:13,365 epoch [292/800] time: 0.86s val loss: 0.1293 accuracy: 0.9538 f1: 0.9529
2023-07-14 04:22:18,005 epoch [293/800] time: 4.64s train loss: 0.061 accuracy: 0.9826 f1: 0.9825
2023-07-14 04:22:18,862 epoch [293/800] time: 0.86s val loss: 0.1293 accuracy: 0.955 f1: 0.954
2023-07-14 04:22:23,530 epoch [294/800] time: 4.67s train loss: 0.0599 accuracy: 0.9831 f1: 0.9829
2023-07-14 04:22:24,340 epoch [294/800] time: 0.81s val loss: 0.1284 accuracy: 0.9545 f1: 0.9536
2023-07-14 04:22:29,040 epoch [295/800] time: 4.7s train loss: 0.0601 accuracy: 0.9832 f1: 0.983
2023-07-14 04:22:29,891 epoch [295/800] time: 0.85s val loss: 0.1289 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:22:34,571 epoch [296/800] time: 4.68s train loss: 0.0614 accuracy: 0.9823 f1: 0.9821
2023-07-14 04:22:35,419 epoch [296/800] time: 0.85s val loss: 0.1293 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:22:40,167 epoch [297/800] time: 4.75s train loss: 0.0612 accuracy: 0.982 f1: 0.9819
2023-07-14 04:22:40,967 epoch [297/800] time: 0.8s val loss: 0.1283 accuracy: 0.9543 f1: 0.9533
2023-07-14 04:22:45,485 epoch [298/800] time: 4.52s train loss: 0.0625 accuracy: 0.982 f1: 0.9819
2023-07-14 04:22:46,326 epoch [298/800] time: 0.84s val loss: 0.1286 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:22:50,909 epoch [299/800] time: 4.58s train loss: 0.0612 accuracy: 0.982 f1: 0.9817
2023-07-14 04:22:51,751 epoch [299/800] time: 0.84s val loss: 0.1298 accuracy: 0.9535 f1: 0.9524
2023-07-14 04:22:56,350 epoch [300/800] time: 4.6s train loss: 0.0618 accuracy: 0.9821 f1: 0.9819
2023-07-14 04:22:57,153 epoch [300/800] time: 0.8s val loss: 0.1298 accuracy: 0.9537 f1: 0.9526
2023-07-14 04:23:01,877 epoch [301/800] time: 4.72s train loss: 0.0609 accuracy: 0.9821 f1: 0.982
2023-07-14 04:23:02,720 epoch [301/800] time: 0.84s val loss: 0.128 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:23:07,207 epoch [302/800] time: 4.49s train loss: 0.0638 accuracy: 0.9822 f1: 0.982
2023-07-14 04:23:08,047 epoch [302/800] time: 0.84s val loss: 0.1296 accuracy: 0.9532 f1: 0.9521
2023-07-14 04:23:12,575 epoch [303/800] time: 4.53s train loss: 0.0613 accuracy: 0.9821 f1: 0.9819
2023-07-14 04:23:13,373 epoch [303/800] time: 0.8s val loss: 0.1289 accuracy: 0.9539 f1: 0.9531
2023-07-14 04:23:18,145 epoch [304/800] time: 4.77s train loss: 0.0611 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:23:18,987 epoch [304/800] time: 0.84s val loss: 0.1279 accuracy: 0.9551 f1: 0.9542
2023-07-14 04:23:23,529 epoch [305/800] time: 4.54s train loss: 0.0615 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:23:24,378 epoch [305/800] time: 0.85s val loss: 0.1292 accuracy: 0.9537 f1: 0.9529
2023-07-14 04:23:29,024 epoch [306/800] time: 4.65s train loss: 0.0608 accuracy: 0.9829 f1: 0.9827
2023-07-14 04:23:29,863 epoch [306/800] time: 0.84s val loss: 0.1284 accuracy: 0.9539 f1: 0.9528
2023-07-14 04:23:34,657 epoch [307/800] time: 4.79s train loss: 0.0615 accuracy: 0.982 f1: 0.982
2023-07-14 04:23:35,511 epoch [307/800] time: 0.85s val loss: 0.128 accuracy: 0.9552 f1: 0.9543
2023-07-14 04:23:40,040 epoch [308/800] time: 4.53s train loss: 0.061 accuracy: 0.9822 f1: 0.982
2023-07-14 04:23:40,892 epoch [308/800] time: 0.85s val loss: 0.1284 accuracy: 0.9544 f1: 0.9534
2023-07-14 04:23:45,494 epoch [309/800] time: 4.6s train loss: 0.0617 accuracy: 0.9828 f1: 0.9825
2023-07-14 04:23:46,297 epoch [309/800] time: 0.8s val loss: 0.1293 accuracy: 0.9546 f1: 0.9536
2023-07-14 04:23:51,155 epoch [310/800] time: 4.86s train loss: 0.0614 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:23:52,063 epoch [310/800] time: 0.91s val loss: 0.1295 accuracy: 0.9547 f1: 0.9537
2023-07-14 04:23:56,849 epoch [311/800] time: 4.79s train loss: 0.0596 accuracy: 0.9833 f1: 0.9831
2023-07-14 04:23:57,709 epoch [311/800] time: 0.86s val loss: 0.1294 accuracy: 0.9539 f1: 0.9528
2023-07-14 04:24:02,505 epoch [312/800] time: 4.8s train loss: 0.0611 accuracy: 0.9829 f1: 0.9828
2023-07-14 04:24:03,341 epoch [312/800] time: 0.84s val loss: 0.1286 accuracy: 0.9546 f1: 0.9536
2023-07-14 04:24:08,383 epoch [313/800] time: 5.04s train loss: 0.0615 accuracy: 0.9826 f1: 0.9825
2023-07-14 04:24:09,284 epoch [313/800] time: 0.9s val loss: 0.129 accuracy: 0.9541 f1: 0.9531
2023-07-14 04:24:14,071 epoch [314/800] time: 4.79s train loss: 0.06 accuracy: 0.9827 f1: 0.9826
2023-07-14 04:24:14,936 epoch [314/800] time: 0.86s val loss: 0.1288 accuracy: 0.9543 f1: 0.9533
2023-07-14 04:24:19,728 epoch [315/800] time: 4.79s train loss: 0.0619 accuracy: 0.9819 f1: 0.9818
2023-07-14 04:24:20,578 epoch [315/800] time: 0.85s val loss: 0.1295 accuracy: 0.9541 f1: 0.9532
2023-07-14 04:24:25,432 epoch [316/800] time: 4.85s train loss: 0.0607 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:24:26,286 epoch [316/800] time: 0.85s val loss: 0.1284 accuracy: 0.9543 f1: 0.9534
2023-07-14 04:24:31,259 epoch [317/800] time: 4.97s train loss: 0.0628 accuracy: 0.9821 f1: 0.9818
2023-07-14 04:24:32,131 epoch [317/800] time: 0.87s val loss: 0.1291 accuracy: 0.9542 f1: 0.9534
2023-07-14 04:24:36,942 epoch [318/800] time: 4.81s train loss: 0.0604 accuracy: 0.9827 f1: 0.9826
2023-07-14 04:24:37,749 epoch [318/800] time: 0.81s val loss: 0.1289 accuracy: 0.9538 f1: 0.9528
2023-07-14 04:24:42,471 epoch [319/800] time: 4.72s train loss: 0.0621 accuracy: 0.9821 f1: 0.9819
2023-07-14 04:24:43,318 epoch [319/800] time: 0.85s val loss: 0.1285 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:24:48,091 epoch [320/800] time: 4.77s train loss: 0.0602 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:24:48,963 epoch [320/800] time: 0.87s val loss: 0.129 accuracy: 0.9539 f1: 0.953
2023-07-14 04:24:53,789 epoch [321/800] time: 4.83s train loss: 0.0611 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:24:54,600 epoch [321/800] time: 0.81s val loss: 0.1297 accuracy: 0.9537 f1: 0.9528
2023-07-14 04:24:59,318 epoch [322/800] time: 4.72s train loss: 0.0596 accuracy: 0.983 f1: 0.9829
2023-07-14 04:25:00,221 epoch [322/800] time: 0.9s val loss: 0.1286 accuracy: 0.9544 f1: 0.9535
2023-07-14 04:25:05,146 epoch [323/800] time: 4.92s train loss: 0.0622 accuracy: 0.9819 f1: 0.9819
2023-07-14 04:25:06,008 epoch [323/800] time: 0.86s val loss: 0.1297 accuracy: 0.9541 f1: 0.9532
2023-07-14 04:25:10,786 epoch [324/800] time: 4.78s train loss: 0.0633 accuracy: 0.9812 f1: 0.9811
2023-07-14 04:25:11,598 epoch [324/800] time: 0.81s val loss: 0.1293 accuracy: 0.9538 f1: 0.9529
2023-07-14 04:25:16,395 epoch [325/800] time: 4.8s train loss: 0.0623 accuracy: 0.9822 f1: 0.9821
2023-07-14 04:25:17,237 epoch [325/800] time: 0.84s val loss: 0.1294 accuracy: 0.9539 f1: 0.9531
2023-07-14 04:25:21,815 epoch [326/800] time: 4.58s train loss: 0.0605 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:25:22,657 epoch [326/800] time: 0.84s val loss: 0.129 accuracy: 0.9534 f1: 0.9523
2023-07-14 04:25:27,363 epoch [327/800] time: 4.71s train loss: 0.0616 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:25:28,164 epoch [327/800] time: 0.8s val loss: 0.1296 accuracy: 0.9534 f1: 0.9523
2023-07-14 04:25:32,826 epoch [328/800] time: 4.66s train loss: 0.0616 accuracy: 0.9823 f1: 0.9821
2023-07-14 04:25:33,693 epoch [328/800] time: 0.87s val loss: 0.1293 accuracy: 0.9539 f1: 0.9528
2023-07-14 04:25:38,219 epoch [329/800] time: 4.53s train loss: 0.0607 accuracy: 0.9828 f1: 0.9825
2023-07-14 04:25:39,079 epoch [329/800] time: 0.86s val loss: 0.1291 accuracy: 0.9546 f1: 0.9538
2023-07-14 04:25:43,664 epoch [330/800] time: 4.58s train loss: 0.062 accuracy: 0.9818 f1: 0.9818
2023-07-14 04:25:44,487 epoch [330/800] time: 0.82s val loss: 0.1287 accuracy: 0.9543 f1: 0.9533
2023-07-14 04:25:49,043 epoch [331/800] time: 4.56s train loss: 0.062 accuracy: 0.9829 f1: 0.9828
2023-07-14 04:25:49,896 epoch [331/800] time: 0.85s val loss: 0.1284 accuracy: 0.9544 f1: 0.9533
2023-07-14 04:25:54,428 epoch [332/800] time: 4.53s train loss: 0.0618 accuracy: 0.9821 f1: 0.982
2023-07-14 04:25:55,278 epoch [332/800] time: 0.85s val loss: 0.1283 accuracy: 0.9542 f1: 0.9533
2023-07-14 04:25:59,840 epoch [333/800] time: 4.56s train loss: 0.0613 accuracy: 0.9821 f1: 0.9818
2023-07-14 04:26:00,647 epoch [333/800] time: 0.81s val loss: 0.128 accuracy: 0.9543 f1: 0.9532
2023-07-14 04:26:05,219 epoch [334/800] time: 4.57s train loss: 0.0613 accuracy: 0.9824 f1: 0.9823
2023-07-14 04:26:06,069 epoch [334/800] time: 0.85s val loss: 0.1289 accuracy: 0.9541 f1: 0.9532
2023-07-14 04:26:10,598 epoch [335/800] time: 4.53s train loss: 0.0607 accuracy: 0.9824 f1: 0.9823
2023-07-14 04:26:11,448 epoch [335/800] time: 0.85s val loss: 0.1286 accuracy: 0.955 f1: 0.9541
2023-07-14 04:26:16,009 epoch [336/800] time: 4.56s train loss: 0.0618 accuracy: 0.9822 f1: 0.982
2023-07-14 04:26:16,828 epoch [336/800] time: 0.82s val loss: 0.1288 accuracy: 0.9549 f1: 0.954
2023-07-14 04:26:21,388 epoch [337/800] time: 4.56s train loss: 0.0612 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:26:22,243 epoch [337/800] time: 0.85s val loss: 0.1287 accuracy: 0.9546 f1: 0.9538
2023-07-14 04:26:26,770 epoch [338/800] time: 4.53s train loss: 0.0609 accuracy: 0.9822 f1: 0.9821
2023-07-14 04:26:27,618 epoch [338/800] time: 0.85s val loss: 0.1291 accuracy: 0.9535 f1: 0.9524
2023-07-14 04:26:32,169 epoch [339/800] time: 4.55s train loss: 0.0607 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:26:32,977 epoch [339/800] time: 0.81s val loss: 0.128 accuracy: 0.9542 f1: 0.9533
2023-07-14 04:26:37,541 epoch [340/800] time: 4.56s train loss: 0.0604 accuracy: 0.9829 f1: 0.9829
2023-07-14 04:26:38,392 epoch [340/800] time: 0.85s val loss: 0.1282 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:26:42,924 epoch [341/800] time: 4.53s train loss: 0.0605 accuracy: 0.9824 f1: 0.9823
2023-07-14 04:26:43,768 epoch [341/800] time: 0.84s val loss: 0.1283 accuracy: 0.9546 f1: 0.9536
2023-07-14 04:26:48,296 epoch [342/800] time: 4.53s train loss: 0.0611 accuracy: 0.9826 f1: 0.9826
2023-07-14 04:26:49,096 epoch [342/800] time: 0.8s val loss: 0.1282 accuracy: 0.9548 f1: 0.9539
2023-07-14 04:26:53,642 epoch [343/800] time: 4.55s train loss: 0.0611 accuracy: 0.9824 f1: 0.982
2023-07-14 04:26:54,487 epoch [343/800] time: 0.84s val loss: 0.1291 accuracy: 0.9537 f1: 0.9526
2023-07-14 04:26:58,989 epoch [344/800] time: 4.5s train loss: 0.0596 accuracy: 0.9828 f1: 0.9825
2023-07-14 04:26:59,831 epoch [344/800] time: 0.84s val loss: 0.1283 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:27:04,357 epoch [345/800] time: 4.53s train loss: 0.0603 accuracy: 0.9826 f1: 0.9823
2023-07-14 04:27:05,157 epoch [345/800] time: 0.8s val loss: 0.1288 accuracy: 0.9541 f1: 0.9531
2023-07-14 04:27:09,702 epoch [346/800] time: 4.55s train loss: 0.0625 accuracy: 0.9818 f1: 0.9815
2023-07-14 04:27:10,544 epoch [346/800] time: 0.84s val loss: 0.1288 accuracy: 0.9536 f1: 0.9527
2023-07-14 04:27:15,082 epoch [347/800] time: 4.54s train loss: 0.0609 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:27:15,925 epoch [347/800] time: 0.84s val loss: 0.1278 accuracy: 0.9545 f1: 0.9536
2023-07-14 04:27:20,539 epoch [348/800] time: 4.61s train loss: 0.0605 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:27:21,338 epoch [348/800] time: 0.8s val loss: 0.1292 accuracy: 0.954 f1: 0.9532
2023-07-14 04:27:25,913 epoch [349/800] time: 4.57s train loss: 0.0602 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:27:26,755 epoch [349/800] time: 0.84s val loss: 0.1287 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:27:31,308 epoch [350/800] time: 4.55s train loss: 0.0604 accuracy: 0.9824 f1: 0.9821
2023-07-14 04:27:32,151 epoch [350/800] time: 0.84s val loss: 0.1291 accuracy: 0.9537 f1: 0.9527
2023-07-14 04:27:36,750 epoch [351/800] time: 4.6s train loss: 0.061 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:27:37,551 epoch [351/800] time: 0.8s val loss: 0.1289 accuracy: 0.9543 f1: 0.9534
2023-07-14 04:27:42,164 epoch [352/800] time: 4.61s train loss: 0.0625 accuracy: 0.9818 f1: 0.9817
2023-07-14 04:27:43,005 epoch [352/800] time: 0.84s val loss: 0.1279 accuracy: 0.955 f1: 0.9542
2023-07-14 04:27:47,595 epoch [353/800] time: 4.59s train loss: 0.0634 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:27:48,437 epoch [353/800] time: 0.84s val loss: 0.1301 accuracy: 0.9542 f1: 0.9534
2023-07-14 04:27:53,062 epoch [354/800] time: 4.63s train loss: 0.0613 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:27:53,862 epoch [354/800] time: 0.8s val loss: 0.1282 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:27:58,384 epoch [355/800] time: 4.52s train loss: 0.0613 accuracy: 0.9822 f1: 0.9821
2023-07-14 04:27:59,233 epoch [355/800] time: 0.85s val loss: 0.1283 accuracy: 0.9541 f1: 0.953
2023-07-14 04:28:03,717 epoch [356/800] time: 4.48s train loss: 0.0625 accuracy: 0.9819 f1: 0.9818
2023-07-14 04:28:04,559 epoch [356/800] time: 0.84s val loss: 0.1283 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:28:09,081 epoch [357/800] time: 4.52s train loss: 0.0609 accuracy: 0.9821 f1: 0.9819
2023-07-14 04:28:09,882 epoch [357/800] time: 0.8s val loss: 0.1284 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:28:14,421 epoch [358/800] time: 4.54s train loss: 0.0616 accuracy: 0.9822 f1: 0.982
2023-07-14 04:28:15,263 epoch [358/800] time: 0.84s val loss: 0.1281 accuracy: 0.9546 f1: 0.9536
2023-07-14 04:28:19,804 epoch [359/800] time: 4.54s train loss: 0.0601 accuracy: 0.983 f1: 0.9828
2023-07-14 04:28:20,646 epoch [359/800] time: 0.84s val loss: 0.1284 accuracy: 0.9542 f1: 0.9533
2023-07-14 04:28:25,225 epoch [360/800] time: 4.58s train loss: 0.0622 accuracy: 0.9824 f1: 0.9822
2023-07-14 04:28:26,026 epoch [360/800] time: 0.8s val loss: 0.1292 accuracy: 0.9542 f1: 0.9531
2023-07-14 04:28:30,643 epoch [361/800] time: 4.62s train loss: 0.0614 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:28:31,485 epoch [361/800] time: 0.84s val loss: 0.1284 accuracy: 0.9548 f1: 0.954
2023-07-14 04:28:36,095 epoch [362/800] time: 4.61s train loss: 0.0599 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:28:36,936 epoch [362/800] time: 0.84s val loss: 0.1282 accuracy: 0.9546 f1: 0.9536
2023-07-14 04:28:41,779 epoch [363/800] time: 4.84s train loss: 0.0608 accuracy: 0.9828 f1: 0.9827
2023-07-14 04:28:42,633 epoch [363/800] time: 0.85s val loss: 0.1281 accuracy: 0.9549 f1: 0.954
2023-07-14 04:28:47,631 epoch [364/800] time: 5.0s train loss: 0.0607 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:28:48,488 epoch [364/800] time: 0.86s val loss: 0.1285 accuracy: 0.9549 f1: 0.954
2023-07-14 04:28:53,317 epoch [365/800] time: 4.83s train loss: 0.0601 accuracy: 0.9827 f1: 0.9826
2023-07-14 04:28:54,278 epoch [365/800] time: 0.96s val loss: 0.1285 accuracy: 0.9544 f1: 0.9536
2023-07-14 04:28:59,278 epoch [366/800] time: 5.0s train loss: 0.0609 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:29:00,095 epoch [366/800] time: 0.82s val loss: 0.1288 accuracy: 0.9541 f1: 0.9532
2023-07-14 04:29:04,754 epoch [367/800] time: 4.66s train loss: 0.0606 accuracy: 0.9823 f1: 0.982
2023-07-14 04:29:05,637 epoch [367/800] time: 0.88s val loss: 0.1287 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:29:10,862 epoch [368/800] time: 5.22s train loss: 0.0603 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:29:11,779 epoch [368/800] time: 0.92s val loss: 0.1288 accuracy: 0.954 f1: 0.953
2023-07-14 04:29:16,595 epoch [369/800] time: 4.82s train loss: 0.0603 accuracy: 0.9827 f1: 0.9826
2023-07-14 04:29:17,405 epoch [369/800] time: 0.81s val loss: 0.129 accuracy: 0.9545 f1: 0.9536
2023-07-14 04:29:22,620 epoch [370/800] time: 5.21s train loss: 0.0612 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:29:23,575 epoch [370/800] time: 0.95s val loss: 0.129 accuracy: 0.9542 f1: 0.9533
2023-07-14 04:29:28,738 epoch [371/800] time: 5.16s train loss: 0.0607 accuracy: 0.9829 f1: 0.9827
2023-07-14 04:29:29,611 epoch [371/800] time: 0.87s val loss: 0.128 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:29:34,732 epoch [372/800] time: 5.12s train loss: 0.0607 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:29:35,590 epoch [372/800] time: 0.86s val loss: 0.1287 accuracy: 0.9537 f1: 0.9527
2023-07-14 04:29:40,387 epoch [373/800] time: 4.8s train loss: 0.0624 accuracy: 0.9822 f1: 0.982
2023-07-14 04:29:41,305 epoch [373/800] time: 0.92s val loss: 0.1291 accuracy: 0.9535 f1: 0.9524
2023-07-14 04:29:46,196 epoch [374/800] time: 4.89s train loss: 0.0603 accuracy: 0.9827 f1: 0.9824
2023-07-14 04:29:47,109 epoch [374/800] time: 0.91s val loss: 0.1284 accuracy: 0.9543 f1: 0.9533
2023-07-14 04:29:51,879 epoch [375/800] time: 4.77s train loss: 0.0615 accuracy: 0.9822 f1: 0.9821
2023-07-14 04:29:52,691 epoch [375/800] time: 0.81s val loss: 0.1292 accuracy: 0.9537 f1: 0.9528
2023-07-14 04:29:57,748 epoch [376/800] time: 5.06s train loss: 0.0624 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:29:58,613 epoch [376/800] time: 0.86s val loss: 0.1295 accuracy: 0.9543 f1: 0.9534
2023-07-14 04:30:03,467 epoch [377/800] time: 4.85s train loss: 0.0635 accuracy: 0.9821 f1: 0.982
2023-07-14 04:30:04,330 epoch [377/800] time: 0.86s val loss: 0.1295 accuracy: 0.9539 f1: 0.953
2023-07-14 04:30:09,292 epoch [378/800] time: 4.96s train loss: 0.0605 accuracy: 0.9828 f1: 0.9827
2023-07-14 04:30:10,116 epoch [378/800] time: 0.82s val loss: 0.1293 accuracy: 0.954 f1: 0.9531
2023-07-14 04:30:15,045 epoch [379/800] time: 4.93s train loss: 0.0622 accuracy: 0.9829 f1: 0.9826
2023-07-14 04:30:15,897 epoch [379/800] time: 0.85s val loss: 0.129 accuracy: 0.9539 f1: 0.9529
2023-07-14 04:30:20,617 epoch [380/800] time: 4.72s train loss: 0.0608 accuracy: 0.9828 f1: 0.9825
2023-07-14 04:30:21,513 epoch [380/800] time: 0.9s val loss: 0.1293 accuracy: 0.9535 f1: 0.9525
2023-07-14 04:30:26,460 epoch [381/800] time: 4.95s train loss: 0.0609 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:30:27,270 epoch [381/800] time: 0.81s val loss: 0.1302 accuracy: 0.9536 f1: 0.9526
2023-07-14 04:30:32,196 epoch [382/800] time: 4.93s train loss: 0.06 accuracy: 0.9832 f1: 0.9831
2023-07-14 04:30:33,055 epoch [382/800] time: 0.86s val loss: 0.129 accuracy: 0.9541 f1: 0.9532
2023-07-14 04:30:37,842 epoch [383/800] time: 4.79s train loss: 0.0615 accuracy: 0.982 f1: 0.9818
2023-07-14 04:30:38,692 epoch [383/800] time: 0.85s val loss: 0.1282 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:30:43,538 epoch [384/800] time: 4.85s train loss: 0.0607 accuracy: 0.9822 f1: 0.982
2023-07-14 04:30:44,363 epoch [384/800] time: 0.82s val loss: 0.1292 accuracy: 0.9541 f1: 0.9532
2023-07-14 04:30:49,226 epoch [385/800] time: 4.86s train loss: 0.061 accuracy: 0.9829 f1: 0.9828
2023-07-14 04:30:50,075 epoch [385/800] time: 0.85s val loss: 0.1283 accuracy: 0.9544 f1: 0.9534
2023-07-14 04:30:54,873 epoch [386/800] time: 4.8s train loss: 0.0604 accuracy: 0.983 f1: 0.9828
2023-07-14 04:30:55,762 epoch [386/800] time: 0.89s val loss: 0.1284 accuracy: 0.9543 f1: 0.9532
2023-07-14 04:31:00,839 epoch [387/800] time: 5.08s train loss: 0.0606 accuracy: 0.9826 f1: 0.9823
2023-07-14 04:31:01,647 epoch [387/800] time: 0.81s val loss: 0.1288 accuracy: 0.954 f1: 0.953
2023-07-14 04:31:06,436 epoch [388/800] time: 4.79s train loss: 0.0619 accuracy: 0.9821 f1: 0.982
2023-07-14 04:31:07,290 epoch [388/800] time: 0.85s val loss: 0.1286 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:31:12,324 epoch [389/800] time: 5.03s train loss: 0.0613 accuracy: 0.9821 f1: 0.9819
2023-07-14 04:31:13,215 epoch [389/800] time: 0.89s val loss: 0.1282 accuracy: 0.9543 f1: 0.9534
2023-07-14 04:31:18,049 epoch [390/800] time: 4.83s train loss: 0.0611 accuracy: 0.9819 f1: 0.9817
2023-07-14 04:31:18,857 epoch [390/800] time: 0.81s val loss: 0.128 accuracy: 0.9548 f1: 0.9539
2023-07-14 04:31:23,727 epoch [391/800] time: 4.87s train loss: 0.0601 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:31:24,614 epoch [391/800] time: 0.89s val loss: 0.1287 accuracy: 0.9548 f1: 0.9539
2023-07-14 04:31:29,466 epoch [392/800] time: 4.85s train loss: 0.061 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:31:30,321 epoch [392/800] time: 0.85s val loss: 0.1284 accuracy: 0.9545 f1: 0.9536
2023-07-14 04:31:35,109 epoch [393/800] time: 4.79s train loss: 0.0622 accuracy: 0.9824 f1: 0.9823
2023-07-14 04:31:35,919 epoch [393/800] time: 0.81s val loss: 0.1294 accuracy: 0.9535 f1: 0.9525
2023-07-14 04:31:40,918 epoch [394/800] time: 5.0s train loss: 0.0601 accuracy: 0.9832 f1: 0.983
2023-07-14 04:31:41,783 epoch [394/800] time: 0.86s val loss: 0.129 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:31:46,553 epoch [395/800] time: 4.77s train loss: 0.0617 accuracy: 0.9823 f1: 0.982
2023-07-14 04:31:47,407 epoch [395/800] time: 0.85s val loss: 0.1293 accuracy: 0.9535 f1: 0.9525
2023-07-14 04:31:52,531 epoch [396/800] time: 5.12s train loss: 0.0612 accuracy: 0.9823 f1: 0.9821
2023-07-14 04:31:53,418 epoch [396/800] time: 0.89s val loss: 0.1286 accuracy: 0.954 f1: 0.953
2023-07-14 04:31:58,598 epoch [397/800] time: 5.18s train loss: 0.0635 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:31:59,539 epoch [397/800] time: 0.94s val loss: 0.1302 accuracy: 0.9534 f1: 0.9524
2023-07-14 04:32:04,853 epoch [398/800] time: 5.31s train loss: 0.062 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:32:05,804 epoch [398/800] time: 0.95s val loss: 0.1296 accuracy: 0.954 f1: 0.953
2023-07-14 04:32:10,881 epoch [399/800] time: 5.08s train loss: 0.0597 accuracy: 0.9831 f1: 0.9829
2023-07-14 04:32:11,733 epoch [399/800] time: 0.85s val loss: 0.1284 accuracy: 0.9537 f1: 0.9527
2023-07-14 04:32:16,874 epoch [400/800] time: 5.14s train loss: 0.0603 accuracy: 0.9827 f1: 0.9826
2023-07-14 04:32:17,779 epoch [400/800] time: 0.91s val loss: 0.1284 accuracy: 0.9546 f1: 0.9535
2023-07-14 04:32:22,615 epoch [401/800] time: 4.84s train loss: 0.06 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:32:23,571 epoch [401/800] time: 0.96s val loss: 0.1288 accuracy: 0.9536 f1: 0.9526
2023-07-14 04:32:28,538 epoch [402/800] time: 4.97s train loss: 0.0606 accuracy: 0.983 f1: 0.9828
2023-07-14 04:32:29,353 epoch [402/800] time: 0.81s val loss: 0.128 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:32:34,043 epoch [403/800] time: 4.69s train loss: 0.0619 accuracy: 0.9821 f1: 0.982
2023-07-14 04:32:34,912 epoch [403/800] time: 0.87s val loss: 0.1287 accuracy: 0.9549 f1: 0.9539
2023-07-14 04:32:39,893 epoch [404/800] time: 4.98s train loss: 0.0605 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:32:40,777 epoch [404/800] time: 0.88s val loss: 0.1287 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:32:45,651 epoch [405/800] time: 4.87s train loss: 0.0628 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:32:46,461 epoch [405/800] time: 0.81s val loss: 0.1299 accuracy: 0.9532 f1: 0.9522
2023-07-14 04:32:51,319 epoch [406/800] time: 4.86s train loss: 0.0603 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:32:52,175 epoch [406/800] time: 0.86s val loss: 0.1294 accuracy: 0.9538 f1: 0.9529
2023-07-14 04:32:56,885 epoch [407/800] time: 4.71s train loss: 0.0606 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:32:57,728 epoch [407/800] time: 0.84s val loss: 0.1294 accuracy: 0.9544 f1: 0.9534
2023-07-14 04:33:02,427 epoch [408/800] time: 4.7s train loss: 0.0605 accuracy: 0.983 f1: 0.9829
2023-07-14 04:33:03,230 epoch [408/800] time: 0.8s val loss: 0.1288 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:33:07,913 epoch [409/800] time: 4.68s train loss: 0.063 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:33:08,757 epoch [409/800] time: 0.84s val loss: 0.1302 accuracy: 0.9533 f1: 0.9524
2023-07-14 04:33:13,486 epoch [410/800] time: 4.73s train loss: 0.0632 accuracy: 0.982 f1: 0.9818
2023-07-14 04:33:14,326 epoch [410/800] time: 0.84s val loss: 0.1303 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:33:19,074 epoch [411/800] time: 4.75s train loss: 0.0614 accuracy: 0.9829 f1: 0.9826
2023-07-14 04:33:19,873 epoch [411/800] time: 0.8s val loss: 0.1285 accuracy: 0.9546 f1: 0.9535
2023-07-14 04:33:24,596 epoch [412/800] time: 4.72s train loss: 0.0603 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:33:25,437 epoch [412/800] time: 0.84s val loss: 0.1282 accuracy: 0.9548 f1: 0.9539
2023-07-14 04:33:30,162 epoch [413/800] time: 4.72s train loss: 0.0615 accuracy: 0.9816 f1: 0.9815
2023-07-14 04:33:31,019 epoch [413/800] time: 0.86s val loss: 0.1286 accuracy: 0.954 f1: 0.953
2023-07-14 04:33:36,101 epoch [414/800] time: 5.08s train loss: 0.0605 accuracy: 0.9827 f1: 0.9824
2023-07-14 04:33:36,990 epoch [414/800] time: 0.89s val loss: 0.13 accuracy: 0.9533 f1: 0.9522
2023-07-14 04:33:42,405 epoch [415/800] time: 5.41s train loss: 0.0607 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:33:43,369 epoch [415/800] time: 0.96s val loss: 0.129 accuracy: 0.9545 f1: 0.9536
2023-07-14 04:33:48,629 epoch [416/800] time: 5.26s train loss: 0.0604 accuracy: 0.9828 f1: 0.9827
2023-07-14 04:33:49,544 epoch [416/800] time: 0.91s val loss: 0.1277 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:33:54,694 epoch [417/800] time: 5.15s train loss: 0.0612 accuracy: 0.9824 f1: 0.9823
2023-07-14 04:33:55,551 epoch [417/800] time: 0.86s val loss: 0.1283 accuracy: 0.9547 f1: 0.9537
2023-07-14 04:34:00,742 epoch [418/800] time: 5.19s train loss: 0.0604 accuracy: 0.9824 f1: 0.9822
2023-07-14 04:34:01,714 epoch [418/800] time: 0.97s val loss: 0.128 accuracy: 0.9549 f1: 0.954
2023-07-14 04:34:07,153 epoch [419/800] time: 5.44s train loss: 0.061 accuracy: 0.9822 f1: 0.9821
2023-07-14 04:34:08,053 epoch [419/800] time: 0.9s val loss: 0.1286 accuracy: 0.9543 f1: 0.9534
2023-07-14 04:34:13,428 epoch [420/800] time: 5.37s train loss: 0.0598 accuracy: 0.983 f1: 0.9829
2023-07-14 04:34:14,256 epoch [420/800] time: 0.83s val loss: 0.1279 accuracy: 0.9543 f1: 0.9535
2023-07-14 04:34:19,243 epoch [421/800] time: 4.99s train loss: 0.0614 accuracy: 0.9824 f1: 0.9824
2023-07-14 04:34:20,129 epoch [421/800] time: 0.89s val loss: 0.128 accuracy: 0.9547 f1: 0.9537
2023-07-14 04:34:24,990 epoch [422/800] time: 4.86s train loss: 0.0602 accuracy: 0.9829 f1: 0.9827
2023-07-14 04:34:25,861 epoch [422/800] time: 0.87s val loss: 0.1291 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:34:30,683 epoch [423/800] time: 4.82s train loss: 0.06 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:34:31,499 epoch [423/800] time: 0.82s val loss: 0.1292 accuracy: 0.9543 f1: 0.9532
2023-07-14 04:34:36,178 epoch [424/800] time: 4.68s train loss: 0.0616 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:34:37,055 epoch [424/800] time: 0.88s val loss: 0.129 accuracy: 0.9537 f1: 0.9527
2023-07-14 04:34:41,846 epoch [425/800] time: 4.79s train loss: 0.0617 accuracy: 0.9829 f1: 0.9827
2023-07-14 04:34:42,716 epoch [425/800] time: 0.87s val loss: 0.129 accuracy: 0.9538 f1: 0.9527
2023-07-14 04:34:47,714 epoch [426/800] time: 5.0s train loss: 0.0617 accuracy: 0.9821 f1: 0.9821
2023-07-14 04:34:48,523 epoch [426/800] time: 0.81s val loss: 0.1289 accuracy: 0.9543 f1: 0.9534
2023-07-14 04:34:53,324 epoch [427/800] time: 4.8s train loss: 0.0603 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:34:54,178 epoch [427/800] time: 0.85s val loss: 0.1286 accuracy: 0.9543 f1: 0.9534
2023-07-14 04:34:58,734 epoch [428/800] time: 4.56s train loss: 0.0622 accuracy: 0.982 f1: 0.9819
2023-07-14 04:34:59,580 epoch [428/800] time: 0.85s val loss: 0.1285 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:35:04,231 epoch [429/800] time: 4.65s train loss: 0.0603 accuracy: 0.9828 f1: 0.9827
2023-07-14 04:35:05,037 epoch [429/800] time: 0.8s val loss: 0.1285 accuracy: 0.9542 f1: 0.9533
2023-07-14 04:35:09,672 epoch [430/800] time: 4.63s train loss: 0.0601 accuracy: 0.9831 f1: 0.9829
2023-07-14 04:35:10,519 epoch [430/800] time: 0.85s val loss: 0.1289 accuracy: 0.9541 f1: 0.9533
2023-07-14 04:35:15,148 epoch [431/800] time: 4.63s train loss: 0.0599 accuracy: 0.983 f1: 0.9828
2023-07-14 04:35:15,995 epoch [431/800] time: 0.85s val loss: 0.1284 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:35:20,624 epoch [432/800] time: 4.63s train loss: 0.0606 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:35:21,428 epoch [432/800] time: 0.8s val loss: 0.1288 accuracy: 0.9539 f1: 0.9529
2023-07-14 04:35:26,022 epoch [433/800] time: 4.59s train loss: 0.0608 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:35:26,873 epoch [433/800] time: 0.85s val loss: 0.1295 accuracy: 0.9536 f1: 0.9525
2023-07-14 04:35:31,498 epoch [434/800] time: 4.62s train loss: 0.0609 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:35:32,343 epoch [434/800] time: 0.84s val loss: 0.1285 accuracy: 0.9544 f1: 0.9534
2023-07-14 04:35:37,005 epoch [435/800] time: 4.66s train loss: 0.0608 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:35:37,808 epoch [435/800] time: 0.8s val loss: 0.1286 accuracy: 0.9548 f1: 0.954
2023-07-14 04:35:42,453 epoch [436/800] time: 4.65s train loss: 0.0612 accuracy: 0.9824 f1: 0.9822
2023-07-14 04:35:43,301 epoch [436/800] time: 0.85s val loss: 0.1288 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:35:47,924 epoch [437/800] time: 4.62s train loss: 0.0605 accuracy: 0.9829 f1: 0.9828
2023-07-14 04:35:48,772 epoch [437/800] time: 0.85s val loss: 0.1298 accuracy: 0.9535 f1: 0.9525
2023-07-14 04:35:53,398 epoch [438/800] time: 4.63s train loss: 0.0632 accuracy: 0.9821 f1: 0.9819
2023-07-14 04:35:54,203 epoch [438/800] time: 0.8s val loss: 0.1312 accuracy: 0.9538 f1: 0.9528
2023-07-14 04:35:58,839 epoch [439/800] time: 4.64s train loss: 0.0602 accuracy: 0.9827 f1: 0.9826
2023-07-14 04:35:59,685 epoch [439/800] time: 0.85s val loss: 0.1281 accuracy: 0.9547 f1: 0.9537
2023-07-14 04:36:04,310 epoch [440/800] time: 4.62s train loss: 0.0627 accuracy: 0.9817 f1: 0.9816
2023-07-14 04:36:05,158 epoch [440/800] time: 0.85s val loss: 0.1291 accuracy: 0.9544 f1: 0.9534
2023-07-14 04:36:09,827 epoch [441/800] time: 4.67s train loss: 0.0612 accuracy: 0.9824 f1: 0.9823
2023-07-14 04:36:10,631 epoch [441/800] time: 0.8s val loss: 0.128 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:36:15,351 epoch [442/800] time: 4.72s train loss: 0.0602 accuracy: 0.9835 f1: 0.9833
2023-07-14 04:36:16,194 epoch [442/800] time: 0.84s val loss: 0.1285 accuracy: 0.9551 f1: 0.9542
2023-07-14 04:36:20,679 epoch [443/800] time: 4.48s train loss: 0.0609 accuracy: 0.9822 f1: 0.982
2023-07-14 04:36:21,524 epoch [443/800] time: 0.85s val loss: 0.128 accuracy: 0.9547 f1: 0.9539
2023-07-14 04:36:26,046 epoch [444/800] time: 4.52s train loss: 0.0627 accuracy: 0.9824 f1: 0.9822
2023-07-14 04:36:26,848 epoch [444/800] time: 0.8s val loss: 0.1288 accuracy: 0.9539 f1: 0.953
2023-07-14 04:36:31,733 epoch [445/800] time: 4.88s train loss: 0.0612 accuracy: 0.982 f1: 0.9819
2023-07-14 04:36:32,608 epoch [445/800] time: 0.87s val loss: 0.128 accuracy: 0.955 f1: 0.954
2023-07-14 04:36:37,612 epoch [446/800] time: 5.0s train loss: 0.0613 accuracy: 0.9823 f1: 0.982
2023-07-14 04:36:38,491 epoch [446/800] time: 0.88s val loss: 0.1285 accuracy: 0.955 f1: 0.9542
2023-07-14 04:36:43,186 epoch [447/800] time: 4.7s train loss: 0.0611 accuracy: 0.9829 f1: 0.9827
2023-07-14 04:36:44,010 epoch [447/800] time: 0.82s val loss: 0.1282 accuracy: 0.9546 f1: 0.9536
2023-07-14 04:36:49,264 epoch [448/800] time: 5.25s train loss: 0.0611 accuracy: 0.9827 f1: 0.9826
2023-07-14 04:36:50,191 epoch [448/800] time: 0.93s val loss: 0.1289 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:36:54,965 epoch [449/800] time: 4.77s train loss: 0.0615 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:36:55,830 epoch [449/800] time: 0.86s val loss: 0.1285 accuracy: 0.9539 f1: 0.9529
2023-07-14 04:37:00,802 epoch [450/800] time: 4.97s train loss: 0.0608 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:37:01,712 epoch [450/800] time: 0.91s val loss: 0.1285 accuracy: 0.9551 f1: 0.9542
2023-07-14 04:37:06,770 epoch [451/800] time: 5.06s train loss: 0.0618 accuracy: 0.9823 f1: 0.9821
2023-07-14 04:37:07,642 epoch [451/800] time: 0.87s val loss: 0.1281 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:37:12,392 epoch [452/800] time: 4.75s train loss: 0.0618 accuracy: 0.982 f1: 0.9819
2023-07-14 04:37:13,326 epoch [452/800] time: 0.93s val loss: 0.128 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:37:18,589 epoch [453/800] time: 5.26s train loss: 0.0611 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:37:19,437 epoch [453/800] time: 0.85s val loss: 0.128 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:37:24,238 epoch [454/800] time: 4.8s train loss: 0.0612 accuracy: 0.9826 f1: 0.9825
2023-07-14 04:37:25,110 epoch [454/800] time: 0.87s val loss: 0.1283 accuracy: 0.9547 f1: 0.9537
2023-07-14 04:37:29,706 epoch [455/800] time: 4.6s train loss: 0.0623 accuracy: 0.9819 f1: 0.9817
2023-07-14 04:37:30,561 epoch [455/800] time: 0.85s val loss: 0.1284 accuracy: 0.9541 f1: 0.9531
2023-07-14 04:37:35,098 epoch [456/800] time: 4.54s train loss: 0.0609 accuracy: 0.9829 f1: 0.9827
2023-07-14 04:37:35,904 epoch [456/800] time: 0.81s val loss: 0.1296 accuracy: 0.9543 f1: 0.9534
2023-07-14 04:37:40,690 epoch [457/800] time: 4.79s train loss: 0.0614 accuracy: 0.9824 f1: 0.9821
2023-07-14 04:37:41,534 epoch [457/800] time: 0.84s val loss: 0.1286 accuracy: 0.955 f1: 0.9541
2023-07-14 04:37:46,143 epoch [458/800] time: 4.61s train loss: 0.0617 accuracy: 0.9823 f1: 0.9821
2023-07-14 04:37:47,015 epoch [458/800] time: 0.87s val loss: 0.1293 accuracy: 0.9536 f1: 0.9525
2023-07-14 04:37:51,657 epoch [459/800] time: 4.64s train loss: 0.0616 accuracy: 0.9819 f1: 0.9817
2023-07-14 04:37:52,462 epoch [459/800] time: 0.8s val loss: 0.1289 accuracy: 0.9547 f1: 0.9537
2023-07-14 04:37:57,186 epoch [460/800] time: 4.72s train loss: 0.0613 accuracy: 0.9828 f1: 0.9827
2023-07-14 04:37:58,082 epoch [460/800] time: 0.9s val loss: 0.1287 accuracy: 0.9544 f1: 0.9535
2023-07-14 04:38:02,860 epoch [461/800] time: 4.78s train loss: 0.0611 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:38:03,733 epoch [461/800] time: 0.87s val loss: 0.1299 accuracy: 0.9535 f1: 0.9523
2023-07-14 04:38:08,508 epoch [462/800] time: 4.77s train loss: 0.0608 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:38:09,314 epoch [462/800] time: 0.81s val loss: 0.1286 accuracy: 0.9543 f1: 0.9534
2023-07-14 04:38:14,357 epoch [463/800] time: 5.04s train loss: 0.0607 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:38:15,307 epoch [463/800] time: 0.95s val loss: 0.1284 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:38:20,458 epoch [464/800] time: 5.15s train loss: 0.0612 accuracy: 0.982 f1: 0.9819
2023-07-14 04:38:21,391 epoch [464/800] time: 0.93s val loss: 0.1283 accuracy: 0.9545 f1: 0.9536
2023-07-14 04:38:26,546 epoch [465/800] time: 5.16s train loss: 0.0601 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:38:27,386 epoch [465/800] time: 0.84s val loss: 0.1282 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:38:32,543 epoch [466/800] time: 5.16s train loss: 0.0615 accuracy: 0.9822 f1: 0.982
2023-07-14 04:38:33,447 epoch [466/800] time: 0.9s val loss: 0.1286 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:38:38,571 epoch [467/800] time: 5.12s train loss: 0.0607 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:38:39,491 epoch [467/800] time: 0.92s val loss: 0.1284 accuracy: 0.9544 f1: 0.9535
2023-07-14 04:38:44,592 epoch [468/800] time: 5.1s train loss: 0.0611 accuracy: 0.9823 f1: 0.9821
2023-07-14 04:38:45,412 epoch [468/800] time: 0.82s val loss: 0.1289 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:38:50,271 epoch [469/800] time: 4.86s train loss: 0.06 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:38:51,123 epoch [469/800] time: 0.85s val loss: 0.1288 accuracy: 0.9538 f1: 0.9528
2023-07-14 04:38:55,886 epoch [470/800] time: 4.76s train loss: 0.0625 accuracy: 0.9821 f1: 0.9818
2023-07-14 04:38:56,763 epoch [470/800] time: 0.88s val loss: 0.1283 accuracy: 0.9549 f1: 0.9539
2023-07-14 04:39:01,381 epoch [471/800] time: 4.62s train loss: 0.0611 accuracy: 0.9829 f1: 0.9827
2023-07-14 04:39:02,187 epoch [471/800] time: 0.81s val loss: 0.1294 accuracy: 0.9541 f1: 0.9532
2023-07-14 04:39:06,799 epoch [472/800] time: 4.61s train loss: 0.0602 accuracy: 0.983 f1: 0.9827
2023-07-14 04:39:07,652 epoch [472/800] time: 0.85s val loss: 0.128 accuracy: 0.9546 f1: 0.9536
2023-07-14 04:39:12,162 epoch [473/800] time: 4.51s train loss: 0.0617 accuracy: 0.9827 f1: 0.9826
2023-07-14 04:39:13,009 epoch [473/800] time: 0.85s val loss: 0.1291 accuracy: 0.9539 f1: 0.9529
2023-07-14 04:39:17,738 epoch [474/800] time: 4.73s train loss: 0.0629 accuracy: 0.9817 f1: 0.9815
2023-07-14 04:39:18,556 epoch [474/800] time: 0.82s val loss: 0.1286 accuracy: 0.9541 f1: 0.9532
2023-07-14 04:39:23,195 epoch [475/800] time: 4.64s train loss: 0.0633 accuracy: 0.9822 f1: 0.9821
2023-07-14 04:39:24,047 epoch [475/800] time: 0.85s val loss: 0.129 accuracy: 0.9543 f1: 0.9533
2023-07-14 04:39:28,570 epoch [476/800] time: 4.52s train loss: 0.0593 accuracy: 0.9834 f1: 0.9833
2023-07-14 04:39:29,444 epoch [476/800] time: 0.87s val loss: 0.1279 accuracy: 0.9548 f1: 0.9538
2023-07-14 04:39:34,255 epoch [477/800] time: 4.81s train loss: 0.0619 accuracy: 0.9823 f1: 0.9821
2023-07-14 04:39:35,063 epoch [477/800] time: 0.81s val loss: 0.1288 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:39:39,641 epoch [478/800] time: 4.58s train loss: 0.0624 accuracy: 0.9821 f1: 0.9819
2023-07-14 04:39:40,504 epoch [478/800] time: 0.86s val loss: 0.13 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:39:45,273 epoch [479/800] time: 4.77s train loss: 0.0612 accuracy: 0.9822 f1: 0.982
2023-07-14 04:39:46,140 epoch [479/800] time: 0.87s val loss: 0.1286 accuracy: 0.9543 f1: 0.9534
2023-07-14 04:39:51,010 epoch [480/800] time: 4.87s train loss: 0.0617 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:39:51,815 epoch [480/800] time: 0.8s val loss: 0.129 accuracy: 0.9542 f1: 0.9534
2023-07-14 04:39:56,382 epoch [481/800] time: 4.57s train loss: 0.0606 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:39:57,260 epoch [481/800] time: 0.88s val loss: 0.1286 accuracy: 0.9552 f1: 0.9542
2023-07-14 04:40:02,127 epoch [482/800] time: 4.87s train loss: 0.0613 accuracy: 0.9826 f1: 0.9823
2023-07-14 04:40:02,984 epoch [482/800] time: 0.86s val loss: 0.1288 accuracy: 0.9543 f1: 0.9534
2023-07-14 04:40:07,709 epoch [483/800] time: 4.72s train loss: 0.0613 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:40:08,514 epoch [483/800] time: 0.8s val loss: 0.1286 accuracy: 0.9548 f1: 0.954
2023-07-14 04:40:13,224 epoch [484/800] time: 4.71s train loss: 0.0602 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:40:14,064 epoch [484/800] time: 0.84s val loss: 0.1288 accuracy: 0.9542 f1: 0.9531
2023-07-14 04:40:18,694 epoch [485/800] time: 4.63s train loss: 0.0623 accuracy: 0.9822 f1: 0.982
2023-07-14 04:40:19,534 epoch [485/800] time: 0.84s val loss: 0.1289 accuracy: 0.9541 f1: 0.9532
2023-07-14 04:40:24,374 epoch [486/800] time: 4.84s train loss: 0.0615 accuracy: 0.9818 f1: 0.9816
2023-07-14 04:40:25,192 epoch [486/800] time: 0.82s val loss: 0.129 accuracy: 0.9538 f1: 0.9528
2023-07-14 04:40:30,097 epoch [487/800] time: 4.9s train loss: 0.0617 accuracy: 0.9822 f1: 0.9821
2023-07-14 04:40:30,950 epoch [487/800] time: 0.85s val loss: 0.1294 accuracy: 0.9537 f1: 0.9526
2023-07-14 04:40:35,576 epoch [488/800] time: 4.63s train loss: 0.062 accuracy: 0.9824 f1: 0.9823
2023-07-14 04:40:36,504 epoch [488/800] time: 0.93s val loss: 0.1287 accuracy: 0.9546 f1: 0.9536
2023-07-14 04:40:41,350 epoch [489/800] time: 4.85s train loss: 0.061 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:40:42,166 epoch [489/800] time: 0.82s val loss: 0.1277 accuracy: 0.9548 f1: 0.9539
2023-07-14 04:40:46,999 epoch [490/800] time: 4.83s train loss: 0.061 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:40:47,864 epoch [490/800] time: 0.86s val loss: 0.1295 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:40:52,814 epoch [491/800] time: 4.95s train loss: 0.0601 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:40:53,678 epoch [491/800] time: 0.86s val loss: 0.1285 accuracy: 0.9543 f1: 0.9532
2023-07-14 04:40:58,372 epoch [492/800] time: 4.69s train loss: 0.0606 accuracy: 0.9824 f1: 0.9824
2023-07-14 04:40:59,177 epoch [492/800] time: 0.8s val loss: 0.1283 accuracy: 0.9543 f1: 0.9533
2023-07-14 04:41:03,987 epoch [493/800] time: 4.81s train loss: 0.0607 accuracy: 0.9823 f1: 0.982
2023-07-14 04:41:04,862 epoch [493/800] time: 0.87s val loss: 0.1288 accuracy: 0.9545 f1: 0.9537
2023-07-14 04:41:09,576 epoch [494/800] time: 4.71s train loss: 0.0611 accuracy: 0.9829 f1: 0.9829
2023-07-14 04:41:10,482 epoch [494/800] time: 0.9s val loss: 0.129 accuracy: 0.9538 f1: 0.9528
2023-07-14 04:41:15,597 epoch [495/800] time: 5.12s train loss: 0.0601 accuracy: 0.9831 f1: 0.9829
2023-07-14 04:41:16,495 epoch [495/800] time: 0.9s val loss: 0.1283 accuracy: 0.9552 f1: 0.9541
2023-07-14 04:41:21,752 epoch [496/800] time: 5.26s train loss: 0.0599 accuracy: 0.9827 f1: 0.9824
2023-07-14 04:41:22,661 epoch [496/800] time: 0.91s val loss: 0.1293 accuracy: 0.9542 f1: 0.9533
2023-07-14 04:41:28,473 epoch [497/800] time: 5.81s train loss: 0.0613 accuracy: 0.9819 f1: 0.9818
2023-07-14 04:41:29,392 epoch [497/800] time: 0.92s val loss: 0.128 accuracy: 0.9554 f1: 0.9545
2023-07-14 04:41:34,823 epoch [498/800] time: 5.43s train loss: 0.0606 accuracy: 0.9828 f1: 0.9827
2023-07-14 04:41:35,700 epoch [498/800] time: 0.88s val loss: 0.1298 accuracy: 0.9532 f1: 0.9523
2023-07-14 04:41:40,766 epoch [499/800] time: 5.07s train loss: 0.0614 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:41:41,636 epoch [499/800] time: 0.87s val loss: 0.1285 accuracy: 0.9543 f1: 0.9533
2023-07-14 04:41:46,460 epoch [500/800] time: 4.82s train loss: 0.061 accuracy: 0.9821 f1: 0.982
2023-07-14 04:41:47,339 epoch [500/800] time: 0.88s val loss: 0.1282 accuracy: 0.9551 f1: 0.9541
2023-07-14 04:41:52,177 epoch [501/800] time: 4.84s train loss: 0.0597 accuracy: 0.9831 f1: 0.983
2023-07-14 04:41:52,995 epoch [501/800] time: 0.82s val loss: 0.1281 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:41:57,880 epoch [502/800] time: 4.88s train loss: 0.0604 accuracy: 0.9824 f1: 0.9823
2023-07-14 04:41:58,768 epoch [502/800] time: 0.89s val loss: 0.1286 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:42:03,602 epoch [503/800] time: 4.83s train loss: 0.0598 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:42:04,465 epoch [503/800] time: 0.86s val loss: 0.1283 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:42:09,455 epoch [504/800] time: 4.99s train loss: 0.0614 accuracy: 0.9821 f1: 0.9821
2023-07-14 04:42:10,265 epoch [504/800] time: 0.81s val loss: 0.1297 accuracy: 0.9535 f1: 0.9525
2023-07-14 04:42:15,065 epoch [505/800] time: 4.8s train loss: 0.0603 accuracy: 0.983 f1: 0.9828
2023-07-14 04:42:15,921 epoch [505/800] time: 0.86s val loss: 0.1283 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:42:20,653 epoch [506/800] time: 4.73s train loss: 0.0614 accuracy: 0.9824 f1: 0.9822
2023-07-14 04:42:21,495 epoch [506/800] time: 0.84s val loss: 0.1283 accuracy: 0.9548 f1: 0.9538
2023-07-14 04:42:26,316 epoch [507/800] time: 4.82s train loss: 0.061 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:42:27,143 epoch [507/800] time: 0.83s val loss: 0.1287 accuracy: 0.9541 f1: 0.9533
2023-07-14 04:42:32,007 epoch [508/800] time: 4.86s train loss: 0.0601 accuracy: 0.9829 f1: 0.9828
2023-07-14 04:42:32,862 epoch [508/800] time: 0.86s val loss: 0.1285 accuracy: 0.9541 f1: 0.953
2023-07-14 04:42:37,402 epoch [509/800] time: 4.54s train loss: 0.0616 accuracy: 0.9824 f1: 0.9823
2023-07-14 04:42:38,257 epoch [509/800] time: 0.85s val loss: 0.129 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:42:43,070 epoch [510/800] time: 4.81s train loss: 0.0614 accuracy: 0.9823 f1: 0.9821
2023-07-14 04:42:43,884 epoch [510/800] time: 0.81s val loss: 0.1284 accuracy: 0.9545 f1: 0.9534
2023-07-14 04:42:48,479 epoch [511/800] time: 4.59s train loss: 0.0612 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:42:49,332 epoch [511/800] time: 0.85s val loss: 0.1295 accuracy: 0.9538 f1: 0.9529
2023-07-14 04:42:53,918 epoch [512/800] time: 4.59s train loss: 0.0614 accuracy: 0.9822 f1: 0.9819
2023-07-14 04:42:54,761 epoch [512/800] time: 0.84s val loss: 0.1282 accuracy: 0.9547 f1: 0.9537
2023-07-14 04:42:59,600 epoch [513/800] time: 4.84s train loss: 0.0618 accuracy: 0.982 f1: 0.9819
2023-07-14 04:43:00,480 epoch [513/800] time: 0.88s val loss: 0.1288 accuracy: 0.9548 f1: 0.954
2023-07-14 04:43:05,435 epoch [514/800] time: 4.95s train loss: 0.0615 accuracy: 0.9824 f1: 0.9823
2023-07-14 04:43:06,321 epoch [514/800] time: 0.89s val loss: 0.1283 accuracy: 0.9547 f1: 0.9537
2023-07-14 04:43:11,130 epoch [515/800] time: 4.81s train loss: 0.0612 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:43:12,036 epoch [515/800] time: 0.91s val loss: 0.1288 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:43:17,156 epoch [516/800] time: 5.12s train loss: 0.0618 accuracy: 0.982 f1: 0.9819
2023-07-14 04:43:17,988 epoch [516/800] time: 0.83s val loss: 0.1292 accuracy: 0.9546 f1: 0.9536
2023-07-14 04:43:22,930 epoch [517/800] time: 4.94s train loss: 0.0622 accuracy: 0.9822 f1: 0.982
2023-07-14 04:43:23,808 epoch [517/800] time: 0.88s val loss: 0.1296 accuracy: 0.9539 f1: 0.9527
2023-07-14 04:43:28,645 epoch [518/800] time: 4.84s train loss: 0.0605 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:43:29,500 epoch [518/800] time: 0.85s val loss: 0.1286 accuracy: 0.9549 f1: 0.954
2023-07-14 04:43:34,371 epoch [519/800] time: 4.87s train loss: 0.0613 accuracy: 0.9823 f1: 0.9821
2023-07-14 04:43:35,176 epoch [519/800] time: 0.8s val loss: 0.1298 accuracy: 0.9532 f1: 0.9523
2023-07-14 04:43:39,874 epoch [520/800] time: 4.7s train loss: 0.061 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:43:40,742 epoch [520/800] time: 0.87s val loss: 0.1297 accuracy: 0.9542 f1: 0.9534
2023-07-14 04:43:45,277 epoch [521/800] time: 4.53s train loss: 0.0607 accuracy: 0.9827 f1: 0.9826
2023-07-14 04:43:46,158 epoch [521/800] time: 0.88s val loss: 0.1291 accuracy: 0.9536 f1: 0.9527
2023-07-14 04:43:50,850 epoch [522/800] time: 4.69s train loss: 0.0612 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:43:51,655 epoch [522/800] time: 0.8s val loss: 0.129 accuracy: 0.9545 f1: 0.9536
2023-07-14 04:43:56,348 epoch [523/800] time: 4.69s train loss: 0.0606 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:43:57,196 epoch [523/800] time: 0.85s val loss: 0.1279 accuracy: 0.9554 f1: 0.9544
2023-07-14 04:44:01,807 epoch [524/800] time: 4.61s train loss: 0.0607 accuracy: 0.9823 f1: 0.9821
2023-07-14 04:44:02,654 epoch [524/800] time: 0.85s val loss: 0.1282 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:44:07,310 epoch [525/800] time: 4.66s train loss: 0.0612 accuracy: 0.9827 f1: 0.9826
2023-07-14 04:44:08,112 epoch [525/800] time: 0.8s val loss: 0.129 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:44:12,773 epoch [526/800] time: 4.66s train loss: 0.0612 accuracy: 0.9822 f1: 0.9821
2023-07-14 04:44:13,641 epoch [526/800] time: 0.87s val loss: 0.1279 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:44:18,281 epoch [527/800] time: 4.64s train loss: 0.062 accuracy: 0.9817 f1: 0.9815
2023-07-14 04:44:19,144 epoch [527/800] time: 0.86s val loss: 0.1293 accuracy: 0.9541 f1: 0.9531
2023-07-14 04:44:24,342 epoch [528/800] time: 5.2s train loss: 0.0614 accuracy: 0.982 f1: 0.9819
2023-07-14 04:44:25,401 epoch [528/800] time: 1.06s val loss: 0.1288 accuracy: 0.9544 f1: 0.9533
2023-07-14 04:44:30,775 epoch [529/800] time: 5.37s train loss: 0.0611 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:44:31,766 epoch [529/800] time: 0.99s val loss: 0.1292 accuracy: 0.954 f1: 0.9531
2023-07-14 04:44:36,755 epoch [530/800] time: 4.99s train loss: 0.061 accuracy: 0.9824 f1: 0.9822
2023-07-14 04:44:37,676 epoch [530/800] time: 0.92s val loss: 0.1286 accuracy: 0.9543 f1: 0.9532
2023-07-14 04:44:42,806 epoch [531/800] time: 5.13s train loss: 0.0594 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:44:43,637 epoch [531/800] time: 0.83s val loss: 0.1281 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:44:48,442 epoch [532/800] time: 4.8s train loss: 0.0613 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:44:49,297 epoch [532/800] time: 0.85s val loss: 0.1286 accuracy: 0.9544 f1: 0.9534
2023-07-14 04:44:54,062 epoch [533/800] time: 4.76s train loss: 0.0598 accuracy: 0.983 f1: 0.9828
2023-07-14 04:44:54,921 epoch [533/800] time: 0.86s val loss: 0.1278 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:44:59,827 epoch [534/800] time: 4.91s train loss: 0.0613 accuracy: 0.9822 f1: 0.9821
2023-07-14 04:45:00,649 epoch [534/800] time: 0.82s val loss: 0.1284 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:45:05,627 epoch [535/800] time: 4.98s train loss: 0.062 accuracy: 0.9822 f1: 0.9821
2023-07-14 04:45:06,549 epoch [535/800] time: 0.92s val loss: 0.1282 accuracy: 0.9547 f1: 0.9537
2023-07-14 04:45:11,584 epoch [536/800] time: 5.03s train loss: 0.0608 accuracy: 0.9825 f1: 0.9822
2023-07-14 04:45:12,538 epoch [536/800] time: 0.95s val loss: 0.1283 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:45:17,342 epoch [537/800] time: 4.8s train loss: 0.0615 accuracy: 0.9818 f1: 0.9817
2023-07-14 04:45:18,152 epoch [537/800] time: 0.81s val loss: 0.1285 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:45:22,855 epoch [538/800] time: 4.7s train loss: 0.0618 accuracy: 0.982 f1: 0.9818
2023-07-14 04:45:23,711 epoch [538/800] time: 0.86s val loss: 0.1293 accuracy: 0.9538 f1: 0.9528
2023-07-14 04:45:28,325 epoch [539/800] time: 4.61s train loss: 0.0609 accuracy: 0.9826 f1: 0.9825
2023-07-14 04:45:29,167 epoch [539/800] time: 0.84s val loss: 0.1286 accuracy: 0.9544 f1: 0.9534
2023-07-14 04:45:33,946 epoch [540/800] time: 4.78s train loss: 0.0605 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:45:34,747 epoch [540/800] time: 0.8s val loss: 0.1285 accuracy: 0.9549 f1: 0.954
2023-07-14 04:45:39,500 epoch [541/800] time: 4.75s train loss: 0.0616 accuracy: 0.9829 f1: 0.9827
2023-07-14 04:45:40,343 epoch [541/800] time: 0.84s val loss: 0.1295 accuracy: 0.9539 f1: 0.9529
2023-07-14 04:45:45,055 epoch [542/800] time: 4.71s train loss: 0.0625 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:45:45,900 epoch [542/800] time: 0.84s val loss: 0.1289 accuracy: 0.9536 f1: 0.9525
2023-07-14 04:45:50,682 epoch [543/800] time: 4.78s train loss: 0.0608 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:45:51,481 epoch [543/800] time: 0.8s val loss: 0.1292 accuracy: 0.9548 f1: 0.9539
2023-07-14 04:45:56,016 epoch [544/800] time: 4.53s train loss: 0.0612 accuracy: 0.9822 f1: 0.9821
2023-07-14 04:45:56,857 epoch [544/800] time: 0.84s val loss: 0.1286 accuracy: 0.954 f1: 0.953
2023-07-14 04:46:01,614 epoch [545/800] time: 4.76s train loss: 0.0613 accuracy: 0.9821 f1: 0.982
2023-07-14 04:46:02,660 epoch [545/800] time: 1.05s val loss: 0.1286 accuracy: 0.9542 f1: 0.9533
2023-07-14 04:46:08,137 epoch [546/800] time: 5.48s train loss: 0.0606 accuracy: 0.983 f1: 0.9828
2023-07-14 04:46:08,971 epoch [546/800] time: 0.83s val loss: 0.1286 accuracy: 0.9544 f1: 0.9536
2023-07-14 04:46:14,025 epoch [547/800] time: 5.05s train loss: 0.0611 accuracy: 0.9823 f1: 0.982
2023-07-14 04:46:14,944 epoch [547/800] time: 0.92s val loss: 0.1286 accuracy: 0.9539 f1: 0.9529
2023-07-14 04:46:20,642 epoch [548/800] time: 5.7s train loss: 0.0611 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:46:21,585 epoch [548/800] time: 0.94s val loss: 0.129 accuracy: 0.9545 f1: 0.9536
2023-07-14 04:46:26,569 epoch [549/800] time: 4.98s train loss: 0.0601 accuracy: 0.9829 f1: 0.9828
2023-07-14 04:46:27,404 epoch [549/800] time: 0.83s val loss: 0.1281 accuracy: 0.9549 f1: 0.9541
2023-07-14 04:46:32,600 epoch [550/800] time: 5.2s train loss: 0.061 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:46:33,574 epoch [550/800] time: 0.97s val loss: 0.1285 accuracy: 0.9544 f1: 0.9533
2023-07-14 04:46:38,796 epoch [551/800] time: 5.22s train loss: 0.0606 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:46:39,665 epoch [551/800] time: 0.87s val loss: 0.129 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:46:44,558 epoch [552/800] time: 4.89s train loss: 0.0606 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:46:45,358 epoch [552/800] time: 0.8s val loss: 0.129 accuracy: 0.9541 f1: 0.9531
2023-07-14 04:46:50,142 epoch [553/800] time: 4.78s train loss: 0.0613 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:46:51,007 epoch [553/800] time: 0.86s val loss: 0.1283 accuracy: 0.9546 f1: 0.9538
2023-07-14 04:46:55,799 epoch [554/800] time: 4.79s train loss: 0.0618 accuracy: 0.9822 f1: 0.982
2023-07-14 04:46:56,666 epoch [554/800] time: 0.87s val loss: 0.1298 accuracy: 0.9535 f1: 0.9524
2023-07-14 04:47:01,452 epoch [555/800] time: 4.79s train loss: 0.0609 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:47:02,258 epoch [555/800] time: 0.81s val loss: 0.129 accuracy: 0.9539 f1: 0.9529
2023-07-14 04:47:07,138 epoch [556/800] time: 4.88s train loss: 0.0599 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:47:08,061 epoch [556/800] time: 0.92s val loss: 0.1286 accuracy: 0.954 f1: 0.953
2023-07-14 04:47:12,911 epoch [557/800] time: 4.85s train loss: 0.0611 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:47:13,795 epoch [557/800] time: 0.88s val loss: 0.1283 accuracy: 0.9548 f1: 0.9539
2023-07-14 04:47:18,751 epoch [558/800] time: 4.96s train loss: 0.0609 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:47:19,638 epoch [558/800] time: 0.89s val loss: 0.1285 accuracy: 0.9547 f1: 0.9537
2023-07-14 04:47:24,695 epoch [559/800] time: 5.06s train loss: 0.0603 accuracy: 0.9831 f1: 0.9829
2023-07-14 04:47:25,577 epoch [559/800] time: 0.88s val loss: 0.1288 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:47:30,529 epoch [560/800] time: 4.95s train loss: 0.0608 accuracy: 0.9832 f1: 0.9831
2023-07-14 04:47:31,410 epoch [560/800] time: 0.88s val loss: 0.1284 accuracy: 0.9549 f1: 0.954
2023-07-14 04:47:36,446 epoch [561/800] time: 5.04s train loss: 0.0603 accuracy: 0.9831 f1: 0.9829
2023-07-14 04:47:37,504 epoch [561/800] time: 1.06s val loss: 0.1289 accuracy: 0.9542 f1: 0.9533
2023-07-14 04:47:43,378 epoch [562/800] time: 5.87s train loss: 0.0605 accuracy: 0.9825 f1: 0.9822
2023-07-14 04:47:44,279 epoch [562/800] time: 0.9s val loss: 0.1301 accuracy: 0.9535 f1: 0.9527
2023-07-14 04:47:49,198 epoch [563/800] time: 4.92s train loss: 0.0621 accuracy: 0.982 f1: 0.9818
2023-07-14 04:47:50,108 epoch [563/800] time: 0.91s val loss: 0.1287 accuracy: 0.9538 f1: 0.9529
2023-07-14 04:47:55,683 epoch [564/800] time: 5.57s train loss: 0.0605 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:47:56,538 epoch [564/800] time: 0.85s val loss: 0.1289 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:48:02,133 epoch [565/800] time: 5.59s train loss: 0.0609 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:48:03,288 epoch [565/800] time: 1.15s val loss: 0.1288 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:48:08,563 epoch [566/800] time: 5.27s train loss: 0.0626 accuracy: 0.982 f1: 0.9818
2023-07-14 04:48:09,545 epoch [566/800] time: 0.98s val loss: 0.1287 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:48:14,812 epoch [567/800] time: 5.27s train loss: 0.0615 accuracy: 0.9823 f1: 0.982
2023-07-14 04:48:15,647 epoch [567/800] time: 0.84s val loss: 0.1284 accuracy: 0.9543 f1: 0.9534
2023-07-14 04:48:20,695 epoch [568/800] time: 5.05s train loss: 0.0608 accuracy: 0.9822 f1: 0.982
2023-07-14 04:48:21,603 epoch [568/800] time: 0.91s val loss: 0.13 accuracy: 0.9536 f1: 0.9527
2023-07-14 04:48:26,419 epoch [569/800] time: 4.82s train loss: 0.0603 accuracy: 0.9826 f1: 0.9825
2023-07-14 04:48:27,299 epoch [569/800] time: 0.88s val loss: 0.1288 accuracy: 0.9535 f1: 0.9524
2023-07-14 04:48:32,206 epoch [570/800] time: 4.91s train loss: 0.061 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:48:33,036 epoch [570/800] time: 0.83s val loss: 0.1284 accuracy: 0.9542 f1: 0.9533
2023-07-14 04:48:37,969 epoch [571/800] time: 4.93s train loss: 0.062 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:48:38,824 epoch [571/800] time: 0.85s val loss: 0.1298 accuracy: 0.9536 f1: 0.9526
2023-07-14 04:48:43,794 epoch [572/800] time: 4.97s train loss: 0.0604 accuracy: 0.9832 f1: 0.983
2023-07-14 04:48:44,648 epoch [572/800] time: 0.85s val loss: 0.1282 accuracy: 0.9542 f1: 0.9533
2023-07-14 04:48:50,607 epoch [573/800] time: 5.96s train loss: 0.0609 accuracy: 0.9835 f1: 0.9833
2023-07-14 04:48:51,741 epoch [573/800] time: 1.13s val loss: 0.1293 accuracy: 0.9547 f1: 0.9537
2023-07-14 04:48:56,703 epoch [574/800] time: 4.96s train loss: 0.0628 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:48:57,555 epoch [574/800] time: 0.85s val loss: 0.1301 accuracy: 0.9531 f1: 0.9521
2023-07-14 04:49:02,290 epoch [575/800] time: 4.73s train loss: 0.061 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:49:03,135 epoch [575/800] time: 0.85s val loss: 0.1285 accuracy: 0.9549 f1: 0.954
2023-07-14 04:49:07,710 epoch [576/800] time: 4.58s train loss: 0.0621 accuracy: 0.9824 f1: 0.9822
2023-07-14 04:49:08,511 epoch [576/800] time: 0.8s val loss: 0.1291 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:49:13,065 epoch [577/800] time: 4.55s train loss: 0.0611 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:49:13,913 epoch [577/800] time: 0.85s val loss: 0.1291 accuracy: 0.9543 f1: 0.9533
2023-07-14 04:49:18,425 epoch [578/800] time: 4.51s train loss: 0.0607 accuracy: 0.9825 f1: 0.9825
2023-07-14 04:49:19,272 epoch [578/800] time: 0.85s val loss: 0.1285 accuracy: 0.9547 f1: 0.9537
2023-07-14 04:49:24,088 epoch [579/800] time: 4.82s train loss: 0.0611 accuracy: 0.9828 f1: 0.9827
2023-07-14 04:49:24,897 epoch [579/800] time: 0.81s val loss: 0.1281 accuracy: 0.9547 f1: 0.9537
2023-07-14 04:49:29,704 epoch [580/800] time: 4.81s train loss: 0.0616 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:49:30,567 epoch [580/800] time: 0.86s val loss: 0.1281 accuracy: 0.9549 f1: 0.954
2023-07-14 04:49:35,406 epoch [581/800] time: 4.84s train loss: 0.0621 accuracy: 0.9827 f1: 0.9824
2023-07-14 04:49:36,265 epoch [581/800] time: 0.86s val loss: 0.1294 accuracy: 0.9536 f1: 0.9526
2023-07-14 04:49:41,067 epoch [582/800] time: 4.8s train loss: 0.0606 accuracy: 0.9826 f1: 0.9826
2023-07-14 04:49:41,883 epoch [582/800] time: 0.82s val loss: 0.1283 accuracy: 0.9547 f1: 0.9537
2023-07-14 04:49:46,797 epoch [583/800] time: 4.91s train loss: 0.0613 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:49:47,693 epoch [583/800] time: 0.9s val loss: 0.1284 accuracy: 0.9538 f1: 0.9528
2023-07-14 04:49:52,539 epoch [584/800] time: 4.85s train loss: 0.06 accuracy: 0.983 f1: 0.983
2023-07-14 04:49:53,390 epoch [584/800] time: 0.85s val loss: 0.1287 accuracy: 0.9541 f1: 0.9531
2023-07-14 04:49:59,326 epoch [585/800] time: 5.94s train loss: 0.0614 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:50:00,130 epoch [585/800] time: 0.8s val loss: 0.1282 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:50:04,912 epoch [586/800] time: 4.78s train loss: 0.0612 accuracy: 0.9826 f1: 0.9823
2023-07-14 04:50:05,758 epoch [586/800] time: 0.85s val loss: 0.1284 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:50:10,454 epoch [587/800] time: 4.7s train loss: 0.0604 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:50:11,325 epoch [587/800] time: 0.87s val loss: 0.1282 accuracy: 0.9544 f1: 0.9535
2023-07-14 04:50:16,240 epoch [588/800] time: 4.91s train loss: 0.0609 accuracy: 0.9824 f1: 0.9823
2023-07-14 04:50:17,087 epoch [588/800] time: 0.85s val loss: 0.1285 accuracy: 0.9544 f1: 0.9534
2023-07-14 04:50:21,980 epoch [589/800] time: 4.89s train loss: 0.0591 accuracy: 0.983 f1: 0.9829
2023-07-14 04:50:22,854 epoch [589/800] time: 0.87s val loss: 0.129 accuracy: 0.9542 f1: 0.9534
2023-07-14 04:50:27,626 epoch [590/800] time: 4.77s train loss: 0.0622 accuracy: 0.9814 f1: 0.9813
2023-07-14 04:50:28,482 epoch [590/800] time: 0.86s val loss: 0.1291 accuracy: 0.9541 f1: 0.9532
2023-07-14 04:50:33,312 epoch [591/800] time: 4.83s train loss: 0.0618 accuracy: 0.9826 f1: 0.9825
2023-07-14 04:50:34,119 epoch [591/800] time: 0.81s val loss: 0.129 accuracy: 0.9539 f1: 0.953
2023-07-14 04:50:38,914 epoch [592/800] time: 4.79s train loss: 0.0597 accuracy: 0.9832 f1: 0.9831
2023-07-14 04:50:39,774 epoch [592/800] time: 0.86s val loss: 0.1279 accuracy: 0.9549 f1: 0.9539
2023-07-14 04:50:44,299 epoch [593/800] time: 4.52s train loss: 0.0605 accuracy: 0.9831 f1: 0.9829
2023-07-14 04:50:45,157 epoch [593/800] time: 0.86s val loss: 0.1297 accuracy: 0.9542 f1: 0.9533
2023-07-14 04:50:49,732 epoch [594/800] time: 4.58s train loss: 0.0613 accuracy: 0.9822 f1: 0.9821
2023-07-14 04:50:50,537 epoch [594/800] time: 0.8s val loss: 0.1282 accuracy: 0.9541 f1: 0.9531
2023-07-14 04:50:55,341 epoch [595/800] time: 4.8s train loss: 0.0618 accuracy: 0.9822 f1: 0.9819
2023-07-14 04:50:56,187 epoch [595/800] time: 0.85s val loss: 0.1288 accuracy: 0.9544 f1: 0.9535
2023-07-14 04:51:00,933 epoch [596/800] time: 4.75s train loss: 0.0611 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:51:01,779 epoch [596/800] time: 0.85s val loss: 0.1288 accuracy: 0.9538 f1: 0.9529
2023-07-14 04:51:06,559 epoch [597/800] time: 4.78s train loss: 0.0624 accuracy: 0.9821 f1: 0.9819
2023-07-14 04:51:07,375 epoch [597/800] time: 0.82s val loss: 0.1282 accuracy: 0.9544 f1: 0.9535
2023-07-14 04:51:12,264 epoch [598/800] time: 4.89s train loss: 0.0608 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:51:13,111 epoch [598/800] time: 0.85s val loss: 0.1279 accuracy: 0.9545 f1: 0.9536
2023-07-14 04:51:17,932 epoch [599/800] time: 4.82s train loss: 0.061 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:51:18,787 epoch [599/800] time: 0.85s val loss: 0.1284 accuracy: 0.954 f1: 0.953
2023-07-14 04:51:23,645 epoch [600/800] time: 4.86s train loss: 0.0604 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:51:24,472 epoch [600/800] time: 0.83s val loss: 0.1284 accuracy: 0.9547 f1: 0.9536
2023-07-14 04:51:29,296 epoch [601/800] time: 4.82s train loss: 0.0602 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:51:30,171 epoch [601/800] time: 0.87s val loss: 0.1284 accuracy: 0.954 f1: 0.9531
2023-07-14 04:51:35,000 epoch [602/800] time: 4.83s train loss: 0.0604 accuracy: 0.983 f1: 0.9828
2023-07-14 04:51:35,852 epoch [602/800] time: 0.85s val loss: 0.1289 accuracy: 0.9548 f1: 0.954
2023-07-14 04:51:40,556 epoch [603/800] time: 4.7s train loss: 0.0614 accuracy: 0.9822 f1: 0.9819
2023-07-14 04:51:41,361 epoch [603/800] time: 0.8s val loss: 0.1291 accuracy: 0.9539 f1: 0.9529
2023-07-14 04:51:46,080 epoch [604/800] time: 4.72s train loss: 0.0612 accuracy: 0.9829 f1: 0.9828
2023-07-14 04:51:46,927 epoch [604/800] time: 0.85s val loss: 0.1287 accuracy: 0.9544 f1: 0.9534
2023-07-14 04:51:51,644 epoch [605/800] time: 4.72s train loss: 0.06 accuracy: 0.9828 f1: 0.9825
2023-07-14 04:51:52,490 epoch [605/800] time: 0.85s val loss: 0.1282 accuracy: 0.9543 f1: 0.9534
2023-07-14 04:51:57,262 epoch [606/800] time: 4.77s train loss: 0.0607 accuracy: 0.9829 f1: 0.9827
2023-07-14 04:51:58,062 epoch [606/800] time: 0.8s val loss: 0.1286 accuracy: 0.9536 f1: 0.9527
2023-07-14 04:52:02,899 epoch [607/800] time: 4.84s train loss: 0.0609 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:52:03,751 epoch [607/800] time: 0.85s val loss: 0.1282 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:52:08,556 epoch [608/800] time: 4.8s train loss: 0.0612 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:52:09,469 epoch [608/800] time: 0.91s val loss: 0.1286 accuracy: 0.9544 f1: 0.9534
2023-07-14 04:52:14,260 epoch [609/800] time: 4.79s train loss: 0.0615 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:52:15,071 epoch [609/800] time: 0.81s val loss: 0.1296 accuracy: 0.9544 f1: 0.9536
2023-07-14 04:52:19,755 epoch [610/800] time: 4.68s train loss: 0.0609 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:52:20,677 epoch [610/800] time: 0.92s val loss: 0.1286 accuracy: 0.954 f1: 0.953
2023-07-14 04:52:26,652 epoch [611/800] time: 5.97s train loss: 0.0603 accuracy: 0.9828 f1: 0.9827
2023-07-14 04:52:27,798 epoch [611/800] time: 1.15s val loss: 0.1298 accuracy: 0.9532 f1: 0.9521
2023-07-14 04:52:32,721 epoch [612/800] time: 4.92s train loss: 0.06 accuracy: 0.983 f1: 0.9828
2023-07-14 04:52:33,529 epoch [612/800] time: 0.81s val loss: 0.1289 accuracy: 0.954 f1: 0.953
2023-07-14 04:52:38,234 epoch [613/800] time: 4.7s train loss: 0.0615 accuracy: 0.9826 f1: 0.9823
2023-07-14 04:52:39,091 epoch [613/800] time: 0.86s val loss: 0.1284 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:52:43,963 epoch [614/800] time: 4.87s train loss: 0.0598 accuracy: 0.9831 f1: 0.9829
2023-07-14 04:52:44,841 epoch [614/800] time: 0.88s val loss: 0.1285 accuracy: 0.9544 f1: 0.9534
2023-07-14 04:52:50,224 epoch [615/800] time: 5.38s train loss: 0.0601 accuracy: 0.9832 f1: 0.983
2023-07-14 04:52:51,036 epoch [615/800] time: 0.81s val loss: 0.1296 accuracy: 0.9543 f1: 0.9534
2023-07-14 04:52:55,812 epoch [616/800] time: 4.78s train loss: 0.0606 accuracy: 0.9829 f1: 0.9828
2023-07-14 04:52:56,692 epoch [616/800] time: 0.88s val loss: 0.129 accuracy: 0.9545 f1: 0.9536
2023-07-14 04:53:01,327 epoch [617/800] time: 4.63s train loss: 0.0612 accuracy: 0.9821 f1: 0.982
2023-07-14 04:53:02,187 epoch [617/800] time: 0.86s val loss: 0.1281 accuracy: 0.9549 f1: 0.954
2023-07-14 04:53:07,029 epoch [618/800] time: 4.84s train loss: 0.0631 accuracy: 0.9816 f1: 0.9814
2023-07-14 04:53:07,879 epoch [618/800] time: 0.85s val loss: 0.129 accuracy: 0.9538 f1: 0.9529
2023-07-14 04:53:12,755 epoch [619/800] time: 4.88s train loss: 0.0617 accuracy: 0.9818 f1: 0.9815
2023-07-14 04:53:13,617 epoch [619/800] time: 0.86s val loss: 0.1283 accuracy: 0.954 f1: 0.9531
2023-07-14 04:53:18,548 epoch [620/800] time: 4.93s train loss: 0.0609 accuracy: 0.9826 f1: 0.9825
2023-07-14 04:53:19,420 epoch [620/800] time: 0.87s val loss: 0.1281 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:53:24,335 epoch [621/800] time: 4.91s train loss: 0.061 accuracy: 0.982 f1: 0.9818
2023-07-14 04:53:25,165 epoch [621/800] time: 0.83s val loss: 0.1284 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:53:30,155 epoch [622/800] time: 4.99s train loss: 0.0601 accuracy: 0.983 f1: 0.9829
2023-07-14 04:53:31,018 epoch [622/800] time: 0.86s val loss: 0.1293 accuracy: 0.9539 f1: 0.9528
2023-07-14 04:53:35,810 epoch [623/800] time: 4.79s train loss: 0.0607 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:53:36,669 epoch [623/800] time: 0.86s val loss: 0.1289 accuracy: 0.9543 f1: 0.9532
2023-07-14 04:53:41,575 epoch [624/800] time: 4.91s train loss: 0.0605 accuracy: 0.9827 f1: 0.9826
2023-07-14 04:53:42,384 epoch [624/800] time: 0.81s val loss: 0.1284 accuracy: 0.954 f1: 0.9531
2023-07-14 04:53:47,139 epoch [625/800] time: 4.75s train loss: 0.062 accuracy: 0.9824 f1: 0.9823
2023-07-14 04:53:48,038 epoch [625/800] time: 0.9s val loss: 0.1289 accuracy: 0.9538 f1: 0.9528
2023-07-14 04:53:52,672 epoch [626/800] time: 4.63s train loss: 0.0609 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:53:53,548 epoch [626/800] time: 0.88s val loss: 0.1296 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:53:58,342 epoch [627/800] time: 4.79s train loss: 0.0609 accuracy: 0.9831 f1: 0.9828
2023-07-14 04:53:59,440 epoch [627/800] time: 1.1s val loss: 0.1297 accuracy: 0.9543 f1: 0.9533
2023-07-14 04:54:04,318 epoch [628/800] time: 4.88s train loss: 0.0606 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:54:05,199 epoch [628/800] time: 0.88s val loss: 0.1285 accuracy: 0.9543 f1: 0.9533
2023-07-14 04:54:10,139 epoch [629/800] time: 4.94s train loss: 0.0648 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:54:11,019 epoch [629/800] time: 0.88s val loss: 0.1307 accuracy: 0.9537 f1: 0.9528
2023-07-14 04:54:15,891 epoch [630/800] time: 4.87s train loss: 0.0607 accuracy: 0.9828 f1: 0.9827
2023-07-14 04:54:16,709 epoch [630/800] time: 0.82s val loss: 0.1287 accuracy: 0.9538 f1: 0.9529
2023-07-14 04:54:21,599 epoch [631/800] time: 4.89s train loss: 0.0617 accuracy: 0.9822 f1: 0.9821
2023-07-14 04:54:22,461 epoch [631/800] time: 0.86s val loss: 0.1286 accuracy: 0.9539 f1: 0.9529
2023-07-14 04:54:27,244 epoch [632/800] time: 4.78s train loss: 0.0618 accuracy: 0.9823 f1: 0.9821
2023-07-14 04:54:28,177 epoch [632/800] time: 0.93s val loss: 0.1284 accuracy: 0.9545 f1: 0.9534
2023-07-14 04:54:33,124 epoch [633/800] time: 4.95s train loss: 0.0627 accuracy: 0.9817 f1: 0.9815
2023-07-14 04:54:34,041 epoch [633/800] time: 0.92s val loss: 0.1281 accuracy: 0.955 f1: 0.954
2023-07-14 04:54:39,298 epoch [634/800] time: 5.26s train loss: 0.061 accuracy: 0.9829 f1: 0.9828
2023-07-14 04:54:40,181 epoch [634/800] time: 0.88s val loss: 0.1289 accuracy: 0.9548 f1: 0.9539
2023-07-14 04:54:44,879 epoch [635/800] time: 4.7s train loss: 0.0616 accuracy: 0.9824 f1: 0.9823
2023-07-14 04:54:45,747 epoch [635/800] time: 0.87s val loss: 0.1288 accuracy: 0.9536 f1: 0.9526
2023-07-14 04:54:50,495 epoch [636/800] time: 4.75s train loss: 0.0608 accuracy: 0.9827 f1: 0.9824
2023-07-14 04:54:51,302 epoch [636/800] time: 0.81s val loss: 0.1282 accuracy: 0.9549 f1: 0.9539
2023-07-14 04:54:56,013 epoch [637/800] time: 4.71s train loss: 0.0615 accuracy: 0.9821 f1: 0.9819
2023-07-14 04:54:56,860 epoch [637/800] time: 0.85s val loss: 0.1293 accuracy: 0.9543 f1: 0.9533
2023-07-14 04:55:01,513 epoch [638/800] time: 4.65s train loss: 0.0599 accuracy: 0.9829 f1: 0.9827
2023-07-14 04:55:02,364 epoch [638/800] time: 0.85s val loss: 0.1285 accuracy: 0.9552 f1: 0.9542
2023-07-14 04:55:07,069 epoch [639/800] time: 4.7s train loss: 0.0617 accuracy: 0.9823 f1: 0.9821
2023-07-14 04:55:07,872 epoch [639/800] time: 0.8s val loss: 0.1297 accuracy: 0.9543 f1: 0.9533
2023-07-14 04:55:12,653 epoch [640/800] time: 4.78s train loss: 0.0618 accuracy: 0.9823 f1: 0.9821
2023-07-14 04:55:13,514 epoch [640/800] time: 0.86s val loss: 0.1291 accuracy: 0.9537 f1: 0.9526
2023-07-14 04:55:18,196 epoch [641/800] time: 4.68s train loss: 0.0625 accuracy: 0.9821 f1: 0.9819
2023-07-14 04:55:19,043 epoch [641/800] time: 0.85s val loss: 0.1284 accuracy: 0.9549 f1: 0.9539
2023-07-14 04:55:23,589 epoch [642/800] time: 4.55s train loss: 0.0617 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:55:24,391 epoch [642/800] time: 0.8s val loss: 0.1292 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:55:29,044 epoch [643/800] time: 4.65s train loss: 0.0608 accuracy: 0.9822 f1: 0.9821
2023-07-14 04:55:29,896 epoch [643/800] time: 0.85s val loss: 0.1285 accuracy: 0.954 f1: 0.953
2023-07-14 04:55:34,476 epoch [644/800] time: 4.58s train loss: 0.061 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:55:35,325 epoch [644/800] time: 0.85s val loss: 0.1283 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:55:39,887 epoch [645/800] time: 4.56s train loss: 0.0605 accuracy: 0.9832 f1: 0.9832
2023-07-14 04:55:40,689 epoch [645/800] time: 0.8s val loss: 0.129 accuracy: 0.9543 f1: 0.9535
2023-07-14 04:55:45,375 epoch [646/800] time: 4.69s train loss: 0.0601 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:55:46,220 epoch [646/800] time: 0.84s val loss: 0.1289 accuracy: 0.9537 f1: 0.9527
2023-07-14 04:55:50,717 epoch [647/800] time: 4.5s train loss: 0.06 accuracy: 0.9825 f1: 0.9824
2023-07-14 04:55:51,570 epoch [647/800] time: 0.85s val loss: 0.1279 accuracy: 0.9548 f1: 0.9539
2023-07-14 04:55:56,103 epoch [648/800] time: 4.53s train loss: 0.0609 accuracy: 0.983 f1: 0.9829
2023-07-14 04:55:56,902 epoch [648/800] time: 0.8s val loss: 0.1284 accuracy: 0.9545 f1: 0.9537
2023-07-14 04:56:01,612 epoch [649/800] time: 4.71s train loss: 0.0618 accuracy: 0.9822 f1: 0.9821
2023-07-14 04:56:02,456 epoch [649/800] time: 0.84s val loss: 0.1287 accuracy: 0.9544 f1: 0.9535
2023-07-14 04:56:06,951 epoch [650/800] time: 4.49s train loss: 0.0616 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:56:07,793 epoch [650/800] time: 0.84s val loss: 0.1285 accuracy: 0.9545 f1: 0.9536
2023-07-14 04:56:12,337 epoch [651/800] time: 4.54s train loss: 0.0612 accuracy: 0.983 f1: 0.9829
2023-07-14 04:56:13,137 epoch [651/800] time: 0.8s val loss: 0.1287 accuracy: 0.9541 f1: 0.9531
2023-07-14 04:56:17,737 epoch [652/800] time: 4.6s train loss: 0.061 accuracy: 0.9826 f1: 0.9825
2023-07-14 04:56:18,581 epoch [652/800] time: 0.84s val loss: 0.1276 accuracy: 0.9552 f1: 0.9543
2023-07-14 04:56:23,188 epoch [653/800] time: 4.61s train loss: 0.0618 accuracy: 0.9821 f1: 0.9819
2023-07-14 04:56:24,030 epoch [653/800] time: 0.84s val loss: 0.1288 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:56:28,702 epoch [654/800] time: 4.67s train loss: 0.0599 accuracy: 0.9829 f1: 0.9827
2023-07-14 04:56:29,503 epoch [654/800] time: 0.8s val loss: 0.1279 accuracy: 0.955 f1: 0.954
2023-07-14 04:56:34,204 epoch [655/800] time: 4.7s train loss: 0.0616 accuracy: 0.9823 f1: 0.9821
2023-07-14 04:56:35,047 epoch [655/800] time: 0.84s val loss: 0.1308 accuracy: 0.9527 f1: 0.9517
2023-07-14 04:56:39,711 epoch [656/800] time: 4.66s train loss: 0.061 accuracy: 0.9823 f1: 0.9821
2023-07-14 04:56:40,556 epoch [656/800] time: 0.84s val loss: 0.1287 accuracy: 0.9544 f1: 0.9535
2023-07-14 04:56:45,336 epoch [657/800] time: 4.78s train loss: 0.0602 accuracy: 0.9829 f1: 0.9826
2023-07-14 04:56:46,140 epoch [657/800] time: 0.8s val loss: 0.1284 accuracy: 0.9541 f1: 0.9532
2023-07-14 04:56:50,675 epoch [658/800] time: 4.53s train loss: 0.0625 accuracy: 0.9816 f1: 0.9814
2023-07-14 04:56:51,520 epoch [658/800] time: 0.84s val loss: 0.1286 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:56:56,081 epoch [659/800] time: 4.56s train loss: 0.0617 accuracy: 0.9823 f1: 0.9823
2023-07-14 04:56:56,927 epoch [659/800] time: 0.85s val loss: 0.1299 accuracy: 0.953 f1: 0.9519
2023-07-14 04:57:01,643 epoch [660/800] time: 4.72s train loss: 0.0621 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:57:02,446 epoch [660/800] time: 0.8s val loss: 0.1287 accuracy: 0.9539 f1: 0.9529
2023-07-14 04:57:07,134 epoch [661/800] time: 4.69s train loss: 0.0635 accuracy: 0.9818 f1: 0.9817
2023-07-14 04:57:07,982 epoch [661/800] time: 0.85s val loss: 0.1297 accuracy: 0.9538 f1: 0.9528
2023-07-14 04:57:12,796 epoch [662/800] time: 4.81s train loss: 0.0605 accuracy: 0.9831 f1: 0.9829
2023-07-14 04:57:13,842 epoch [662/800] time: 1.05s val loss: 0.129 accuracy: 0.9541 f1: 0.9531
2023-07-14 04:57:19,109 epoch [663/800] time: 5.27s train loss: 0.0613 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:57:19,990 epoch [663/800] time: 0.88s val loss: 0.1285 accuracy: 0.9543 f1: 0.9534
2023-07-14 04:57:25,308 epoch [664/800] time: 5.32s train loss: 0.0611 accuracy: 0.9823 f1: 0.9822
2023-07-14 04:57:26,246 epoch [664/800] time: 0.94s val loss: 0.1287 accuracy: 0.9549 f1: 0.954
2023-07-14 04:57:31,219 epoch [665/800] time: 4.97s train loss: 0.0617 accuracy: 0.9824 f1: 0.9823
2023-07-14 04:57:32,152 epoch [665/800] time: 0.93s val loss: 0.1287 accuracy: 0.9541 f1: 0.9531
2023-07-14 04:57:37,052 epoch [666/800] time: 4.9s train loss: 0.0607 accuracy: 0.9827 f1: 0.9823
2023-07-14 04:57:37,877 epoch [666/800] time: 0.82s val loss: 0.1283 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:57:42,829 epoch [667/800] time: 4.95s train loss: 0.0603 accuracy: 0.9827 f1: 0.9826
2023-07-14 04:57:43,733 epoch [667/800] time: 0.9s val loss: 0.1284 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:57:48,552 epoch [668/800] time: 4.82s train loss: 0.0609 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:57:49,440 epoch [668/800] time: 0.89s val loss: 0.1296 accuracy: 0.9535 f1: 0.9525
2023-07-14 04:57:54,339 epoch [669/800] time: 4.9s train loss: 0.0618 accuracy: 0.9822 f1: 0.9821
2023-07-14 04:57:55,166 epoch [669/800] time: 0.83s val loss: 0.1283 accuracy: 0.954 f1: 0.953
2023-07-14 04:58:00,123 epoch [670/800] time: 4.96s train loss: 0.061 accuracy: 0.9825 f1: 0.9822
2023-07-14 04:58:01,007 epoch [670/800] time: 0.88s val loss: 0.1286 accuracy: 0.9547 f1: 0.9538
2023-07-14 04:58:06,188 epoch [671/800] time: 5.18s train loss: 0.0626 accuracy: 0.9819 f1: 0.9818
2023-07-14 04:58:07,106 epoch [671/800] time: 0.92s val loss: 0.1291 accuracy: 0.9542 f1: 0.9533
2023-07-14 04:58:12,047 epoch [672/800] time: 4.94s train loss: 0.0623 accuracy: 0.9823 f1: 0.9821
2023-07-14 04:58:12,871 epoch [672/800] time: 0.82s val loss: 0.1288 accuracy: 0.9538 f1: 0.9528
2023-07-14 04:58:17,866 epoch [673/800] time: 4.99s train loss: 0.06 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:58:18,737 epoch [673/800] time: 0.87s val loss: 0.1283 accuracy: 0.9538 f1: 0.9529
2023-07-14 04:58:23,473 epoch [674/800] time: 4.74s train loss: 0.061 accuracy: 0.9825 f1: 0.9825
2023-07-14 04:58:24,344 epoch [674/800] time: 0.87s val loss: 0.1297 accuracy: 0.9538 f1: 0.9528
2023-07-14 04:58:29,164 epoch [675/800] time: 4.82s train loss: 0.0606 accuracy: 0.9824 f1: 0.9823
2023-07-14 04:58:29,978 epoch [675/800] time: 0.81s val loss: 0.1285 accuracy: 0.9546 f1: 0.9537
2023-07-14 04:58:34,845 epoch [676/800] time: 4.87s train loss: 0.0608 accuracy: 0.982 f1: 0.9818
2023-07-14 04:58:35,715 epoch [676/800] time: 0.87s val loss: 0.1283 accuracy: 0.9551 f1: 0.9541
2023-07-14 04:58:40,599 epoch [677/800] time: 4.88s train loss: 0.0602 accuracy: 0.9828 f1: 0.9826
2023-07-14 04:58:41,444 epoch [677/800] time: 0.84s val loss: 0.1286 accuracy: 0.9544 f1: 0.9535
2023-07-14 04:58:46,111 epoch [678/800] time: 4.67s train loss: 0.0608 accuracy: 0.9825 f1: 0.9823
2023-07-14 04:58:46,914 epoch [678/800] time: 0.8s val loss: 0.129 accuracy: 0.954 f1: 0.9531
2023-07-14 04:58:51,958 epoch [679/800] time: 5.04s train loss: 0.0617 accuracy: 0.9828 f1: 0.9825
2023-07-14 04:58:53,169 epoch [679/800] time: 1.21s val loss: 0.1285 accuracy: 0.9541 f1: 0.9533
2023-07-14 04:58:58,219 epoch [680/800] time: 5.05s train loss: 0.061 accuracy: 0.9824 f1: 0.9822
2023-07-14 04:58:59,139 epoch [680/800] time: 0.92s val loss: 0.1282 accuracy: 0.9553 f1: 0.9544
2023-07-14 04:59:04,159 epoch [681/800] time: 5.02s train loss: 0.059 accuracy: 0.983 f1: 0.9829
2023-07-14 04:59:04,999 epoch [681/800] time: 0.84s val loss: 0.1279 accuracy: 0.9542 f1: 0.9532
2023-07-14 04:59:09,849 epoch [682/800] time: 4.85s train loss: 0.0617 accuracy: 0.9822 f1: 0.982
2023-07-14 04:59:10,721 epoch [682/800] time: 0.87s val loss: 0.1289 accuracy: 0.9548 f1: 0.9538
2023-07-14 04:59:15,458 epoch [683/800] time: 4.74s train loss: 0.06 accuracy: 0.9832 f1: 0.983
2023-07-14 04:59:16,320 epoch [683/800] time: 0.86s val loss: 0.1281 accuracy: 0.9541 f1: 0.9531
2023-07-14 04:59:21,245 epoch [684/800] time: 4.92s train loss: 0.0609 accuracy: 0.9826 f1: 0.9824
2023-07-14 04:59:22,070 epoch [684/800] time: 0.82s val loss: 0.1287 accuracy: 0.9545 f1: 0.9535
2023-07-14 04:59:26,877 epoch [685/800] time: 4.81s train loss: 0.0607 accuracy: 0.9826 f1: 0.9825
2023-07-14 04:59:27,738 epoch [685/800] time: 0.86s val loss: 0.1293 accuracy: 0.9536 f1: 0.9526
2023-07-14 04:59:32,633 epoch [686/800] time: 4.89s train loss: 0.0605 accuracy: 0.9827 f1: 0.9824
2023-07-14 04:59:33,536 epoch [686/800] time: 0.9s val loss: 0.1288 accuracy: 0.9546 f1: 0.9536
2023-07-14 04:59:38,392 epoch [687/800] time: 4.86s train loss: 0.0609 accuracy: 0.9824 f1: 0.9823
2023-07-14 04:59:39,207 epoch [687/800] time: 0.82s val loss: 0.1284 accuracy: 0.9544 f1: 0.9535
2023-07-14 04:59:44,048 epoch [688/800] time: 4.84s train loss: 0.061 accuracy: 0.9822 f1: 0.982
2023-07-14 04:59:44,908 epoch [688/800] time: 0.86s val loss: 0.1288 accuracy: 0.9545 f1: 0.9536
2023-07-14 04:59:49,663 epoch [689/800] time: 4.75s train loss: 0.0627 accuracy: 0.982 f1: 0.9819
2023-07-14 04:59:50,534 epoch [689/800] time: 0.87s val loss: 0.1293 accuracy: 0.9537 f1: 0.9527
2023-07-14 04:59:55,357 epoch [690/800] time: 4.82s train loss: 0.0612 accuracy: 0.9827 f1: 0.9825
2023-07-14 04:59:56,169 epoch [690/800] time: 0.81s val loss: 0.1284 accuracy: 0.9542 f1: 0.9534
2023-07-14 05:00:01,149 epoch [691/800] time: 4.98s train loss: 0.0616 accuracy: 0.9819 f1: 0.9817
2023-07-14 05:00:02,009 epoch [691/800] time: 0.86s val loss: 0.1282 accuracy: 0.9548 f1: 0.9539
2023-07-14 05:00:06,750 epoch [692/800] time: 4.74s train loss: 0.0605 accuracy: 0.9824 f1: 0.9822
2023-07-14 05:00:07,622 epoch [692/800] time: 0.87s val loss: 0.1283 accuracy: 0.9542 f1: 0.9531
2023-07-14 05:00:12,434 epoch [693/800] time: 4.81s train loss: 0.0612 accuracy: 0.9821 f1: 0.982
2023-07-14 05:00:13,240 epoch [693/800] time: 0.81s val loss: 0.1289 accuracy: 0.9546 f1: 0.9538
2023-07-14 05:00:18,032 epoch [694/800] time: 4.79s train loss: 0.0596 accuracy: 0.9832 f1: 0.9829
2023-07-14 05:00:18,897 epoch [694/800] time: 0.86s val loss: 0.1289 accuracy: 0.9547 f1: 0.9538
2023-07-14 05:00:24,011 epoch [695/800] time: 5.11s train loss: 0.0612 accuracy: 0.9819 f1: 0.9818
2023-07-14 05:00:25,002 epoch [695/800] time: 0.99s val loss: 0.1285 accuracy: 0.9543 f1: 0.9533
2023-07-14 05:00:30,405 epoch [696/800] time: 5.4s train loss: 0.061 accuracy: 0.9827 f1: 0.9825
2023-07-14 05:00:31,242 epoch [696/800] time: 0.84s val loss: 0.1295 accuracy: 0.9546 f1: 0.9537
2023-07-14 05:00:36,331 epoch [697/800] time: 5.09s train loss: 0.0607 accuracy: 0.9828 f1: 0.9826
2023-07-14 05:00:37,271 epoch [697/800] time: 0.94s val loss: 0.128 accuracy: 0.9547 f1: 0.9537
2023-07-14 05:00:42,560 epoch [698/800] time: 5.29s train loss: 0.0643 accuracy: 0.9816 f1: 0.9815
2023-07-14 05:00:43,444 epoch [698/800] time: 0.88s val loss: 0.129 accuracy: 0.9544 f1: 0.9535
2023-07-14 05:00:48,128 epoch [699/800] time: 4.68s train loss: 0.0607 accuracy: 0.9828 f1: 0.9826
2023-07-14 05:00:48,966 epoch [699/800] time: 0.84s val loss: 0.1278 accuracy: 0.9548 f1: 0.9538
2023-07-14 05:00:53,931 epoch [700/800] time: 4.96s train loss: 0.06 accuracy: 0.983 f1: 0.9828
2023-07-14 05:00:54,855 epoch [700/800] time: 0.92s val loss: 0.1285 accuracy: 0.9548 f1: 0.9539
2023-07-14 05:00:59,859 epoch [701/800] time: 5.0s train loss: 0.062 accuracy: 0.9821 f1: 0.9819
2023-07-14 05:01:00,774 epoch [701/800] time: 0.92s val loss: 0.1284 accuracy: 0.9544 f1: 0.9536
2023-07-14 05:01:06,357 epoch [702/800] time: 5.58s train loss: 0.0613 accuracy: 0.9824 f1: 0.9822
2023-07-14 05:01:07,195 epoch [702/800] time: 0.84s val loss: 0.1299 accuracy: 0.9541 f1: 0.9532
2023-07-14 05:01:12,768 epoch [703/800] time: 5.57s train loss: 0.0623 accuracy: 0.9819 f1: 0.9818
2023-07-14 05:01:13,667 epoch [703/800] time: 0.9s val loss: 0.1295 accuracy: 0.954 f1: 0.953
2023-07-14 05:01:18,510 epoch [704/800] time: 4.84s train loss: 0.0606 accuracy: 0.9827 f1: 0.9826
2023-07-14 05:01:19,420 epoch [704/800] time: 0.91s val loss: 0.1283 accuracy: 0.9542 f1: 0.9533
2023-07-14 05:01:24,495 epoch [705/800] time: 5.08s train loss: 0.0604 accuracy: 0.983 f1: 0.9828
2023-07-14 05:01:25,445 epoch [705/800] time: 0.95s val loss: 0.1282 accuracy: 0.9548 f1: 0.9539
2023-07-14 05:01:31,268 epoch [706/800] time: 5.82s train loss: 0.0618 accuracy: 0.982 f1: 0.9818
2023-07-14 05:01:32,253 epoch [706/800] time: 0.98s val loss: 0.1292 accuracy: 0.9535 f1: 0.9525
2023-07-14 05:01:37,226 epoch [707/800] time: 4.97s train loss: 0.0607 accuracy: 0.9827 f1: 0.9825
2023-07-14 05:01:38,135 epoch [707/800] time: 0.91s val loss: 0.1285 accuracy: 0.9542 f1: 0.9531
2023-07-14 05:01:43,194 epoch [708/800] time: 5.06s train loss: 0.0608 accuracy: 0.9827 f1: 0.9825
2023-07-14 05:01:44,020 epoch [708/800] time: 0.83s val loss: 0.1291 accuracy: 0.9539 f1: 0.9529
2023-07-14 05:01:49,024 epoch [709/800] time: 5.0s train loss: 0.0609 accuracy: 0.9825 f1: 0.9823
2023-07-14 05:01:49,926 epoch [709/800] time: 0.9s val loss: 0.1286 accuracy: 0.9543 f1: 0.9534
2023-07-14 05:01:54,851 epoch [710/800] time: 4.92s train loss: 0.0612 accuracy: 0.9829 f1: 0.9827
2023-07-14 05:01:55,863 epoch [710/800] time: 1.01s val loss: 0.1289 accuracy: 0.9545 f1: 0.9536
2023-07-14 05:02:01,149 epoch [711/800] time: 5.29s train loss: 0.0606 accuracy: 0.9825 f1: 0.9824
2023-07-14 05:02:01,982 epoch [711/800] time: 0.83s val loss: 0.128 accuracy: 0.9549 f1: 0.9541
2023-07-14 05:02:06,995 epoch [712/800] time: 5.01s train loss: 0.0611 accuracy: 0.9829 f1: 0.9829
2023-07-14 05:02:07,943 epoch [712/800] time: 0.95s val loss: 0.1297 accuracy: 0.9545 f1: 0.9534
2023-07-14 05:02:13,305 epoch [713/800] time: 5.36s train loss: 0.0615 accuracy: 0.9825 f1: 0.9823
2023-07-14 05:02:14,210 epoch [713/800] time: 0.9s val loss: 0.129 accuracy: 0.9546 f1: 0.9537
2023-07-14 05:02:19,250 epoch [714/800] time: 5.04s train loss: 0.0604 accuracy: 0.9829 f1: 0.9828
2023-07-14 05:02:20,125 epoch [714/800] time: 0.87s val loss: 0.1285 accuracy: 0.9542 f1: 0.9531
2023-07-14 05:02:25,344 epoch [715/800] time: 5.22s train loss: 0.0616 accuracy: 0.9819 f1: 0.9817
2023-07-14 05:02:26,235 epoch [715/800] time: 0.89s val loss: 0.1286 accuracy: 0.9545 f1: 0.9536
2023-07-14 05:02:31,011 epoch [716/800] time: 4.78s train loss: 0.0613 accuracy: 0.9824 f1: 0.9822
2023-07-14 05:02:31,895 epoch [716/800] time: 0.88s val loss: 0.1286 accuracy: 0.9549 f1: 0.9539
2023-07-14 05:02:36,865 epoch [717/800] time: 4.97s train loss: 0.0609 accuracy: 0.983 f1: 0.9828
2023-07-14 05:02:37,684 epoch [717/800] time: 0.82s val loss: 0.1285 accuracy: 0.9546 f1: 0.9536
2023-07-14 05:02:42,565 epoch [718/800] time: 4.88s train loss: 0.0617 accuracy: 0.9819 f1: 0.9816
2023-07-14 05:02:43,487 epoch [718/800] time: 0.92s val loss: 0.1292 accuracy: 0.9538 f1: 0.953
2023-07-14 05:02:48,355 epoch [719/800] time: 4.87s train loss: 0.0607 accuracy: 0.9826 f1: 0.9824
2023-07-14 05:02:49,237 epoch [719/800] time: 0.88s val loss: 0.1289 accuracy: 0.9537 f1: 0.9527
2023-07-14 05:02:54,058 epoch [720/800] time: 4.82s train loss: 0.0607 accuracy: 0.9828 f1: 0.9826
2023-07-14 05:02:54,878 epoch [720/800] time: 0.82s val loss: 0.1289 accuracy: 0.9547 f1: 0.9538
2023-07-14 05:02:59,854 epoch [721/800] time: 4.98s train loss: 0.0611 accuracy: 0.9824 f1: 0.9822
2023-07-14 05:03:00,712 epoch [721/800] time: 0.86s val loss: 0.1284 accuracy: 0.9546 f1: 0.9536
2023-07-14 05:03:05,340 epoch [722/800] time: 4.63s train loss: 0.0599 accuracy: 0.9829 f1: 0.9826
2023-07-14 05:03:06,202 epoch [722/800] time: 0.86s val loss: 0.128 accuracy: 0.9549 f1: 0.9539
2023-07-14 05:03:10,975 epoch [723/800] time: 4.77s train loss: 0.0614 accuracy: 0.9822 f1: 0.982
2023-07-14 05:03:11,840 epoch [723/800] time: 0.86s val loss: 0.1285 accuracy: 0.9544 f1: 0.9535
2023-07-14 05:03:17,058 epoch [724/800] time: 5.22s train loss: 0.0604 accuracy: 0.9828 f1: 0.9825
2023-07-14 05:03:17,989 epoch [724/800] time: 0.93s val loss: 0.1284 accuracy: 0.9542 f1: 0.9532
2023-07-14 05:03:22,886 epoch [725/800] time: 4.9s train loss: 0.0601 accuracy: 0.9823 f1: 0.9822
2023-07-14 05:03:23,754 epoch [725/800] time: 0.87s val loss: 0.129 accuracy: 0.9544 f1: 0.9535
2023-07-14 05:03:28,734 epoch [726/800] time: 4.98s train loss: 0.0608 accuracy: 0.9827 f1: 0.9826
2023-07-14 05:03:29,613 epoch [726/800] time: 0.88s val loss: 0.1284 accuracy: 0.9541 f1: 0.9532
2023-07-14 05:03:34,728 epoch [727/800] time: 5.11s train loss: 0.061 accuracy: 0.9822 f1: 0.9819
2023-07-14 05:03:35,626 epoch [727/800] time: 0.9s val loss: 0.1284 accuracy: 0.9542 f1: 0.9533
2023-07-14 05:03:40,698 epoch [728/800] time: 5.07s train loss: 0.061 accuracy: 0.9825 f1: 0.9823
2023-07-14 05:03:41,604 epoch [728/800] time: 0.91s val loss: 0.1287 accuracy: 0.9542 f1: 0.9532
2023-07-14 05:03:46,433 epoch [729/800] time: 4.83s train loss: 0.0616 accuracy: 0.9826 f1: 0.9824
2023-07-14 05:03:47,245 epoch [729/800] time: 0.81s val loss: 0.1286 accuracy: 0.9547 f1: 0.9537
2023-07-14 05:03:51,927 epoch [730/800] time: 4.68s train loss: 0.0599 accuracy: 0.983 f1: 0.983
2023-07-14 05:03:52,800 epoch [730/800] time: 0.87s val loss: 0.1277 accuracy: 0.9549 f1: 0.954
2023-07-14 05:03:57,447 epoch [731/800] time: 4.65s train loss: 0.0626 accuracy: 0.9825 f1: 0.9823
2023-07-14 05:03:58,315 epoch [731/800] time: 0.87s val loss: 0.1296 accuracy: 0.9536 f1: 0.9525
2023-07-14 05:04:02,993 epoch [732/800] time: 4.68s train loss: 0.0603 accuracy: 0.983 f1: 0.9829
2023-07-14 05:04:03,876 epoch [732/800] time: 0.88s val loss: 0.1285 accuracy: 0.954 f1: 0.9531
2023-07-14 05:04:08,635 epoch [733/800] time: 4.76s train loss: 0.06 accuracy: 0.9829 f1: 0.9827
2023-07-14 05:04:09,483 epoch [733/800] time: 0.85s val loss: 0.1282 accuracy: 0.9545 f1: 0.9537
2023-07-14 05:04:14,246 epoch [734/800] time: 4.76s train loss: 0.0607 accuracy: 0.9825 f1: 0.9824
2023-07-14 05:04:15,095 epoch [734/800] time: 0.85s val loss: 0.1296 accuracy: 0.9537 f1: 0.9527
2023-07-14 05:04:19,933 epoch [735/800] time: 4.84s train loss: 0.0609 accuracy: 0.9828 f1: 0.9826
2023-07-14 05:04:20,740 epoch [735/800] time: 0.81s val loss: 0.1293 accuracy: 0.9542 f1: 0.9531
2023-07-14 05:04:25,501 epoch [736/800] time: 4.76s train loss: 0.0611 accuracy: 0.9822 f1: 0.982
2023-07-14 05:04:26,338 epoch [736/800] time: 0.84s val loss: 0.1292 accuracy: 0.9543 f1: 0.9534
2023-07-14 05:04:31,059 epoch [737/800] time: 4.72s train loss: 0.062 accuracy: 0.9824 f1: 0.9823
2023-07-14 05:04:31,901 epoch [737/800] time: 0.84s val loss: 0.129 accuracy: 0.9547 f1: 0.9538
2023-07-14 05:04:36,616 epoch [738/800] time: 4.71s train loss: 0.0628 accuracy: 0.9818 f1: 0.9816
2023-07-14 05:04:37,414 epoch [738/800] time: 0.8s val loss: 0.1292 accuracy: 0.9541 f1: 0.9531
2023-07-14 05:04:41,927 epoch [739/800] time: 4.51s train loss: 0.0615 accuracy: 0.9827 f1: 0.9825
2023-07-14 05:04:42,767 epoch [739/800] time: 0.84s val loss: 0.1288 accuracy: 0.9542 f1: 0.9533
2023-07-14 05:04:47,316 epoch [740/800] time: 4.55s train loss: 0.0608 accuracy: 0.9825 f1: 0.9824
2023-07-14 05:04:48,156 epoch [740/800] time: 0.84s val loss: 0.1296 accuracy: 0.9542 f1: 0.9532
2023-07-14 05:04:52,769 epoch [741/800] time: 4.61s train loss: 0.0614 accuracy: 0.9824 f1: 0.9822
2023-07-14 05:04:53,587 epoch [741/800] time: 0.82s val loss: 0.1281 accuracy: 0.9546 f1: 0.9536
2023-07-14 05:04:58,571 epoch [742/800] time: 4.98s train loss: 0.0605 accuracy: 0.9828 f1: 0.9826
2023-07-14 05:04:59,589 epoch [742/800] time: 1.02s val loss: 0.1286 accuracy: 0.9542 f1: 0.9531
2023-07-14 05:05:04,661 epoch [743/800] time: 5.07s train loss: 0.0613 accuracy: 0.9823 f1: 0.9821
2023-07-14 05:05:05,583 epoch [743/800] time: 0.92s val loss: 0.1288 accuracy: 0.954 f1: 0.953
2023-07-14 05:05:10,628 epoch [744/800] time: 5.04s train loss: 0.0605 accuracy: 0.983 f1: 0.9828
2023-07-14 05:05:11,461 epoch [744/800] time: 0.83s val loss: 0.129 accuracy: 0.954 f1: 0.953
2023-07-14 05:05:16,522 epoch [745/800] time: 5.06s train loss: 0.0604 accuracy: 0.9831 f1: 0.9829
2023-07-14 05:05:17,461 epoch [745/800] time: 0.94s val loss: 0.1282 accuracy: 0.9547 f1: 0.9539
2023-07-14 05:05:22,537 epoch [746/800] time: 5.08s train loss: 0.0613 accuracy: 0.9826 f1: 0.9823
2023-07-14 05:05:23,431 epoch [746/800] time: 0.89s val loss: 0.1285 accuracy: 0.9548 f1: 0.954
2023-07-14 05:05:28,538 epoch [747/800] time: 5.11s train loss: 0.0637 accuracy: 0.9821 f1: 0.9819
2023-07-14 05:05:29,534 epoch [747/800] time: 0.99s val loss: 0.1308 accuracy: 0.953 f1: 0.952
2023-07-14 05:05:35,044 epoch [748/800] time: 5.51s train loss: 0.0614 accuracy: 0.9826 f1: 0.9825
2023-07-14 05:05:35,958 epoch [748/800] time: 0.91s val loss: 0.1282 accuracy: 0.9542 f1: 0.9533
2023-07-14 05:05:41,347 epoch [749/800] time: 5.39s train loss: 0.0601 accuracy: 0.9831 f1: 0.9829
2023-07-14 05:05:42,338 epoch [749/800] time: 0.99s val loss: 0.1287 accuracy: 0.9544 f1: 0.9535
2023-07-14 05:05:47,770 epoch [750/800] time: 5.43s train loss: 0.0615 accuracy: 0.9823 f1: 0.9822
2023-07-14 05:05:48,610 epoch [750/800] time: 0.84s val loss: 0.1285 accuracy: 0.9546 f1: 0.9537
2023-07-14 05:05:53,958 epoch [751/800] time: 5.35s train loss: 0.0611 accuracy: 0.9827 f1: 0.9825
2023-07-14 05:05:55,124 epoch [751/800] time: 1.17s val loss: 0.1285 accuracy: 0.9548 f1: 0.9539
2023-07-14 05:06:01,253 epoch [752/800] time: 6.13s train loss: 0.0602 accuracy: 0.9827 f1: 0.9825
2023-07-14 05:06:02,426 epoch [752/800] time: 1.17s val loss: 0.1289 accuracy: 0.9549 f1: 0.9538
2023-07-14 05:06:07,474 epoch [753/800] time: 5.05s train loss: 0.0606 accuracy: 0.9824 f1: 0.9823
2023-07-14 05:06:08,321 epoch [753/800] time: 0.85s val loss: 0.1297 accuracy: 0.9535 f1: 0.9524
2023-07-14 05:06:14,127 epoch [754/800] time: 5.8s train loss: 0.0623 accuracy: 0.982 f1: 0.9818
2023-07-14 05:06:15,030 epoch [754/800] time: 0.9s val loss: 0.1281 accuracy: 0.9548 f1: 0.9539
2023-07-14 05:06:19,916 epoch [755/800] time: 4.89s train loss: 0.0607 accuracy: 0.9821 f1: 0.9819
2023-07-14 05:06:20,823 epoch [755/800] time: 0.91s val loss: 0.1283 accuracy: 0.9546 f1: 0.9536
2023-07-14 05:06:26,056 epoch [756/800] time: 5.23s train loss: 0.0626 accuracy: 0.982 f1: 0.9819
2023-07-14 05:06:26,897 epoch [756/800] time: 0.84s val loss: 0.1292 accuracy: 0.9541 f1: 0.9531
2023-07-14 05:06:31,784 epoch [757/800] time: 4.89s train loss: 0.0601 accuracy: 0.9828 f1: 0.9826
2023-07-14 05:06:32,662 epoch [757/800] time: 0.88s val loss: 0.1281 accuracy: 0.9548 f1: 0.9539
2023-07-14 05:06:37,779 epoch [758/800] time: 5.12s train loss: 0.061 accuracy: 0.9824 f1: 0.9823
2023-07-14 05:06:38,649 epoch [758/800] time: 0.87s val loss: 0.1289 accuracy: 0.9545 f1: 0.9536
2023-07-14 05:06:43,483 epoch [759/800] time: 4.83s train loss: 0.0605 accuracy: 0.9827 f1: 0.9825
2023-07-14 05:06:44,298 epoch [759/800] time: 0.81s val loss: 0.1283 accuracy: 0.9549 f1: 0.9539
2023-07-14 05:06:49,322 epoch [760/800] time: 5.02s train loss: 0.0617 accuracy: 0.9821 f1: 0.982
2023-07-14 05:06:50,218 epoch [760/800] time: 0.9s val loss: 0.1285 accuracy: 0.9547 f1: 0.9539
2023-07-14 05:06:55,109 epoch [761/800] time: 4.89s train loss: 0.0617 accuracy: 0.9827 f1: 0.9826
2023-07-14 05:06:55,972 epoch [761/800] time: 0.86s val loss: 0.1292 accuracy: 0.9545 f1: 0.9535
2023-07-14 05:07:00,941 epoch [762/800] time: 4.97s train loss: 0.0596 accuracy: 0.9831 f1: 0.983
2023-07-14 05:07:01,779 epoch [762/800] time: 0.84s val loss: 0.1286 accuracy: 0.9547 f1: 0.9538
2023-07-14 05:07:06,683 epoch [763/800] time: 4.9s train loss: 0.0605 accuracy: 0.9829 f1: 0.9828
2023-07-14 05:07:07,543 epoch [763/800] time: 0.86s val loss: 0.1293 accuracy: 0.9538 f1: 0.9528
2023-07-14 05:07:12,275 epoch [764/800] time: 4.73s train loss: 0.0611 accuracy: 0.9823 f1: 0.982
2023-07-14 05:07:13,146 epoch [764/800] time: 0.87s val loss: 0.1282 accuracy: 0.9544 f1: 0.9534
2023-07-14 05:07:17,910 epoch [765/800] time: 4.76s train loss: 0.0606 accuracy: 0.9826 f1: 0.9823
2023-07-14 05:07:18,713 epoch [765/800] time: 0.8s val loss: 0.1283 accuracy: 0.9547 f1: 0.9538
2023-07-14 05:07:23,494 epoch [766/800] time: 4.78s train loss: 0.0607 accuracy: 0.9823 f1: 0.9822
2023-07-14 05:07:24,340 epoch [766/800] time: 0.85s val loss: 0.1286 accuracy: 0.9547 f1: 0.9537
2023-07-14 05:07:29,200 epoch [767/800] time: 4.86s train loss: 0.0647 accuracy: 0.9819 f1: 0.9817
2023-07-14 05:07:30,060 epoch [767/800] time: 0.86s val loss: 0.131 accuracy: 0.9534 f1: 0.9524
2023-07-14 05:07:34,817 epoch [768/800] time: 4.76s train loss: 0.0618 accuracy: 0.9828 f1: 0.9827
2023-07-14 05:07:35,623 epoch [768/800] time: 0.81s val loss: 0.1292 accuracy: 0.955 f1: 0.9541
2023-07-14 05:07:40,542 epoch [769/800] time: 4.92s train loss: 0.0615 accuracy: 0.9819 f1: 0.9818
2023-07-14 05:07:41,415 epoch [769/800] time: 0.87s val loss: 0.1294 accuracy: 0.9542 f1: 0.9531
2023-07-14 05:07:46,203 epoch [770/800] time: 4.79s train loss: 0.0601 accuracy: 0.9825 f1: 0.9824
2023-07-14 05:07:47,060 epoch [770/800] time: 0.86s val loss: 0.129 accuracy: 0.9539 f1: 0.9528
2023-07-14 05:07:51,780 epoch [771/800] time: 4.72s train loss: 0.0611 accuracy: 0.9826 f1: 0.9824
2023-07-14 05:07:52,596 epoch [771/800] time: 0.82s val loss: 0.1282 accuracy: 0.9551 f1: 0.9542
2023-07-14 05:07:57,590 epoch [772/800] time: 4.99s train loss: 0.0606 accuracy: 0.9826 f1: 0.9825
2023-07-14 05:07:58,450 epoch [772/800] time: 0.86s val loss: 0.1281 accuracy: 0.9546 f1: 0.9538
2023-07-14 05:08:03,225 epoch [773/800] time: 4.77s train loss: 0.0609 accuracy: 0.9826 f1: 0.9824
2023-07-14 05:08:04,077 epoch [773/800] time: 0.85s val loss: 0.1296 accuracy: 0.9543 f1: 0.9535
2023-07-14 05:08:08,873 epoch [774/800] time: 4.8s train loss: 0.0611 accuracy: 0.9825 f1: 0.9822
2023-07-14 05:08:09,689 epoch [774/800] time: 0.82s val loss: 0.1304 accuracy: 0.9534 f1: 0.9525
2023-07-14 05:08:14,807 epoch [775/800] time: 5.12s train loss: 0.0614 accuracy: 0.9827 f1: 0.9825
2023-07-14 05:08:15,721 epoch [775/800] time: 0.91s val loss: 0.1299 accuracy: 0.9534 f1: 0.9523
2023-07-14 05:08:21,019 epoch [776/800] time: 5.3s train loss: 0.0605 accuracy: 0.9835 f1: 0.9833
2023-07-14 05:08:21,966 epoch [776/800] time: 0.94s val loss: 0.1281 accuracy: 0.9547 f1: 0.9537
2023-07-14 05:08:27,051 epoch [777/800] time: 5.08s train loss: 0.0636 accuracy: 0.9824 f1: 0.9822
2023-07-14 05:08:27,903 epoch [777/800] time: 0.85s val loss: 0.1294 accuracy: 0.9539 f1: 0.9529
2023-07-14 05:08:33,214 epoch [778/800] time: 5.31s train loss: 0.0613 accuracy: 0.9823 f1: 0.9822
2023-07-14 05:08:34,147 epoch [778/800] time: 0.93s val loss: 0.1288 accuracy: 0.9543 f1: 0.9533
2023-07-14 05:08:39,449 epoch [779/800] time: 5.3s train loss: 0.0619 accuracy: 0.9822 f1: 0.982
2023-07-14 05:08:40,381 epoch [779/800] time: 0.93s val loss: 0.1283 accuracy: 0.9545 f1: 0.9535
2023-07-14 05:08:45,650 epoch [780/800] time: 5.27s train loss: 0.0606 accuracy: 0.9828 f1: 0.9825
2023-07-14 05:08:46,496 epoch [780/800] time: 0.85s val loss: 0.1281 accuracy: 0.9546 f1: 0.9536
2023-07-14 05:08:51,547 epoch [781/800] time: 5.05s train loss: 0.0618 accuracy: 0.9823 f1: 0.9821
2023-07-14 05:08:52,417 epoch [781/800] time: 0.87s val loss: 0.1287 accuracy: 0.9544 f1: 0.9534
2023-07-14 05:08:57,234 epoch [782/800] time: 4.82s train loss: 0.0614 accuracy: 0.9825 f1: 0.9822
2023-07-14 05:08:58,092 epoch [782/800] time: 0.86s val loss: 0.129 accuracy: 0.9547 f1: 0.9538
2023-07-14 05:09:02,817 epoch [783/800] time: 4.73s train loss: 0.0616 accuracy: 0.9827 f1: 0.9826
2023-07-14 05:09:03,663 epoch [783/800] time: 0.85s val loss: 0.1286 accuracy: 0.9545 f1: 0.9534
2023-07-14 05:09:08,585 epoch [784/800] time: 4.92s train loss: 0.0605 accuracy: 0.9827 f1: 0.9823
2023-07-14 05:09:09,446 epoch [784/800] time: 0.86s val loss: 0.1291 accuracy: 0.9549 f1: 0.9541
2023-07-14 05:09:14,334 epoch [785/800] time: 4.89s train loss: 0.0635 accuracy: 0.9819 f1: 0.9817
2023-07-14 05:09:15,210 epoch [785/800] time: 0.88s val loss: 0.1291 accuracy: 0.954 f1: 0.953
2023-07-14 05:09:20,104 epoch [786/800] time: 4.89s train loss: 0.0616 accuracy: 0.9824 f1: 0.9823
2023-07-14 05:09:20,911 epoch [786/800] time: 0.81s val loss: 0.1289 accuracy: 0.954 f1: 0.953
2023-07-14 05:09:25,726 epoch [787/800] time: 4.81s train loss: 0.0606 accuracy: 0.983 f1: 0.9828
2023-07-14 05:09:26,613 epoch [787/800] time: 0.89s val loss: 0.1294 accuracy: 0.9543 f1: 0.9532
2023-07-14 05:09:31,514 epoch [788/800] time: 4.9s train loss: 0.0604 accuracy: 0.9826 f1: 0.9824
2023-07-14 05:09:32,428 epoch [788/800] time: 0.91s val loss: 0.1283 accuracy: 0.9544 f1: 0.9534
2023-07-14 05:09:37,473 epoch [789/800] time: 5.04s train loss: 0.0606 accuracy: 0.9826 f1: 0.9824
2023-07-14 05:09:38,289 epoch [789/800] time: 0.82s val loss: 0.1284 accuracy: 0.9547 f1: 0.9538
2023-07-14 05:09:43,075 epoch [790/800] time: 4.79s train loss: 0.061 accuracy: 0.9823 f1: 0.9821
2023-07-14 05:09:43,985 epoch [790/800] time: 0.91s val loss: 0.129 accuracy: 0.9541 f1: 0.9532
2023-07-14 05:09:48,979 epoch [791/800] time: 4.99s train loss: 0.0605 accuracy: 0.9827 f1: 0.9826
2023-07-14 05:09:49,862 epoch [791/800] time: 0.88s val loss: 0.1284 accuracy: 0.9549 f1: 0.9541
2023-07-14 05:09:54,774 epoch [792/800] time: 4.91s train loss: 0.0605 accuracy: 0.9827 f1: 0.9825
2023-07-14 05:09:55,589 epoch [792/800] time: 0.81s val loss: 0.1284 accuracy: 0.9548 f1: 0.9538
2023-07-14 05:10:00,287 epoch [793/800] time: 4.7s train loss: 0.0619 accuracy: 0.9823 f1: 0.9821
2023-07-14 05:10:01,155 epoch [793/800] time: 0.87s val loss: 0.1296 accuracy: 0.9541 f1: 0.9531
2023-07-14 05:10:05,762 epoch [794/800] time: 4.61s train loss: 0.0605 accuracy: 0.9824 f1: 0.9823
2023-07-14 05:10:06,610 epoch [794/800] time: 0.85s val loss: 0.1293 accuracy: 0.9544 f1: 0.9534
2023-07-14 05:10:11,149 epoch [795/800] time: 4.54s train loss: 0.0597 accuracy: 0.9834 f1: 0.9832
2023-07-14 05:10:11,964 epoch [795/800] time: 0.81s val loss: 0.1289 accuracy: 0.9537 f1: 0.9527
2023-07-14 05:10:16,689 epoch [796/800] time: 4.72s train loss: 0.0621 accuracy: 0.9826 f1: 0.9824
2023-07-14 05:10:17,545 epoch [796/800] time: 0.86s val loss: 0.1299 accuracy: 0.9537 f1: 0.9526
2023-07-14 05:10:22,084 epoch [797/800] time: 4.54s train loss: 0.0612 accuracy: 0.9822 f1: 0.9821
2023-07-14 05:10:22,932 epoch [797/800] time: 0.85s val loss: 0.1288 accuracy: 0.9541 f1: 0.953
2023-07-14 05:10:27,529 epoch [798/800] time: 4.6s train loss: 0.0619 accuracy: 0.982 f1: 0.9818
2023-07-14 05:10:28,328 epoch [798/800] time: 0.8s val loss: 0.1301 accuracy: 0.9535 f1: 0.9524
2023-07-14 05:10:32,986 epoch [799/800] time: 4.66s train loss: 0.0604 accuracy: 0.9827 f1: 0.9825
2023-07-14 05:10:33,856 epoch [799/800] time: 0.87s val loss: 0.1291 accuracy: 0.9537 f1: 0.9526
2023-07-14 05:10:38,562 epoch [800/800] time: 4.71s train loss: 0.0611 accuracy: 0.9823 f1: 0.9821
2023-07-14 05:10:39,413 epoch [800/800] time: 0.85s val loss: 0.1282 accuracy: 0.9546 f1: 0.9536
2023-07-14 05:10:39,428 The model with best acc is saved: epoch 776, acc 0.98354375
2023-07-14 05:10:39,442 The model with best f1 is saved: epoch 442, f1 0.9833421026630499
2023-07-14 05:10:39,518 =======================================================
2023-07-14 05:10:39,518 Best acc classification report:
               precision    recall  f1-score   support

cluster_00205    0.95436   0.93496   0.94456       246
cluster_00222    0.89241   0.92763   0.90968       152
cluster_00232    0.91270   0.91633   0.91451       251
cluster_00246    0.82301   0.93467   0.87529       199
cluster_00259    0.92929   0.90640   0.91771       203
cluster_00261    0.97183   0.98571   0.97872       140
cluster_00262    0.89333   0.85897   0.87582       234
cluster_00267    0.89544   0.98817   0.93952       338
cluster_00275    0.93506   0.93506   0.93506       308
cluster_00276    0.94667   0.85542   0.89873       166
cluster_00278    0.87701   0.87234   0.87467       188
cluster_00287    0.91358   0.89697   0.90520       165
cluster_00291    0.96078   0.90184   0.93038       163
cluster_00293    0.96429   0.85866   0.90841       283
cluster_00294    0.94444   0.97143   0.95775       105
cluster_00296    0.86188   0.95122   0.90435       164
cluster_00298    0.89941   0.93538   0.91704       325
cluster_00299    0.91367   0.95489   0.93382       133
cluster_00300    0.91188   0.92248   0.91715       258
cluster_00303    0.93011   0.92021   0.92513       188
cluster_00304    0.94152   0.90960   0.92529       177
cluster_00319    0.90868   0.95673   0.93208       208
cluster_00322    0.93197   0.94158   0.93675       291
cluster_00333    0.86000   0.91489   0.88660       141
cluster_00338    0.94375   0.83889   0.88824       180
cluster_00340    0.95349   0.91620   0.93447       179
cluster_00344    0.89552   0.80537   0.84806       149
cluster_00346    0.90800   0.90800   0.90800       250
cluster_00350    0.89078   0.93885   0.91419       278
cluster_00352    0.94915   0.80576   0.87160       139
cluster_00359    0.88889   0.83721   0.86228       172
cluster_00360    0.93085   0.86634   0.89744       202
cluster_00361    0.90909   0.84746   0.87719       177
cluster_00365    0.85714   0.98077   0.91480       208
cluster_00368    0.94175   0.89401   0.91726       217
cluster_00373    0.83556   0.95431   0.89100       197
cluster_00374    0.94175   0.85463   0.89607       227
cluster_00375    0.93307   0.86182   0.89603       275
cluster_00377    0.87597   0.95359   0.91313       237
cluster_00380    0.90608   0.95349   0.92918       172
cluster_00385    0.90625   0.94694   0.92615       245
cluster_00388    0.94834   0.87713   0.91135       293
cluster_00389    0.85714   0.90909   0.88235       198
cluster_00390    0.96244   0.93182   0.94688       220
cluster_00394    0.85393   0.96203   0.90476       158
cluster_00400    0.87302   0.91667   0.89431       120
cluster_00401    0.93182   0.88649   0.90859       185
cluster_00405    0.92763   0.92157   0.92459       153
cluster_00407    0.95918   0.92885   0.94378       253
cluster_00408    0.92268   0.80995   0.86265       221
cluster_00409    0.90625   0.80930   0.85504       215
cluster_00412    0.84556   0.97333   0.90496       225
cluster_00445    0.85496   0.86822   0.86154       129
cluster_00473    0.94643   0.88333   0.91379       120
cluster_00585    0.84585   0.95964   0.89916       223
cluster_00589    0.88148   0.82639   0.85305       144
cluster_00591    0.89163   0.95263   0.92112       190
cluster_00593    0.82468   0.89437   0.85811       142
cluster_00596    0.82550   0.84247   0.83390       146
cluster_00603    0.90230   0.87222   0.88701       180
cluster_00604    0.93893   0.98400   0.96094       125
cluster_00607    0.86275   0.89796   0.88000       196
cluster_00612    0.96875   0.94898   0.95876       196
cluster_00616    0.85903   0.91549   0.88636       213
cluster_00619    0.89024   0.89571   0.89297       163
cluster_00629    0.92760   0.94037   0.93394       218
cluster_00630    0.91102   0.94714   0.92873       227
cluster_00635    0.85185   0.91477   0.88219       176
cluster_00637    0.93452   0.84865   0.88952       185
cluster_00639    0.93727   0.92364   0.93040       275
cluster_00642    0.97727   0.88660   0.92973       194
cluster_00645    0.83908   0.85882   0.84884       170
cluster_00647    0.80788   0.85864   0.83249       191
cluster_00652    0.87243   0.90987   0.89076       233
cluster_00653    0.92486   0.96386   0.94395       166
cluster_00656    0.93976   0.94545   0.94260       165
cluster_00657    0.87983   0.90708   0.89325       226
cluster_00661    0.98204   0.87701   0.92655       187
cluster_00662    0.93802   0.91532   0.92653       248
cluster_00667    0.93839   0.94286   0.94062       210
cluster_00762    0.93548   0.94565   0.94054       184
cluster_00201    0.99099   1.00000   0.99548       220
cluster_00217    0.95205   0.82249   0.88254       169
cluster_00239    0.89252   0.97949   0.93399       195
cluster_00320    0.94220   0.94767   0.94493       172
cluster_00391    0.94937   0.85878   0.90180       262
cluster_00398    0.95669   0.89338   0.92395       272
cluster_00415    0.91379   0.89831   0.90598       177
cluster_00477    0.93902   0.88000   0.90855       175
cluster_00478    0.86634   0.94595   0.90439       185
cluster_00479    0.96226   0.87931   0.91892       174
cluster_00078    0.75152   0.97638   0.84932       254
cluster_00079    0.91515   0.85795   0.88563       176
cluster_00083    0.88000   0.80936   0.84321       299
cluster_00090    0.90833   0.97321   0.93966       112
cluster_00094    0.81944   0.89394   0.85507       132
cluster_00096    0.92000   0.82143   0.86792       112
cluster_00101    0.92248   0.90840   0.91538       131
cluster_00086    0.94040   0.97931   0.95946       290
cluster_00095    0.85714   0.93659   0.89510       205
cluster_00097    0.97115   0.84874   0.90583       119
cluster_00106    0.95364   0.95364   0.95364       302
cluster_00553    0.92718   0.93627   0.93171       204
cluster_00554    0.89273   0.91489   0.90368       282
cluster_00569    0.92432   0.83010   0.87468       206
cluster_00015    0.87368   0.92222   0.89730        90
cluster_00017    0.83562   0.90706   0.86988       269
cluster_00018    0.72340   0.97143   0.82927       140
cluster_00023    0.84000   0.84000   0.84000       250
cluster_00025    0.81871   0.93333   0.87227       150
cluster_00030    0.78774   0.93820   0.85641       178
cluster_00035    0.85333   0.89510   0.87372       143
cluster_00039    0.90556   0.83590   0.86933       195
cluster_00042    0.88202   0.87222   0.87709       180
cluster_00046    0.93434   0.81140   0.86854       228
cluster_00055    0.84000   0.92818   0.88189       181
cluster_00059    0.91705   0.87665   0.89640       227
cluster_00061    0.94764   0.89163   0.91878       203
cluster_00274    0.88325   0.93548   0.90862       186
cluster_00308    0.87283   0.81183   0.84123       186
cluster_00337    0.88068   0.98101   0.92814       158
cluster_00362    0.89231   0.92063   0.90625       189
cluster_00369    0.89147   0.97458   0.93117       118
cluster_00392    0.97044   0.90367   0.93587       218
cluster_00414    0.93496   0.92742   0.93117       124
cluster_00419    0.92462   0.86792   0.89538       212
cluster_00420    0.96914   0.89205   0.92899       176
cluster_00421    0.86957   0.97087   0.91743       103
cluster_00422    0.93590   0.85214   0.89206       257
cluster_00427    0.87786   0.77703   0.82437       148
cluster_00430    0.78077   0.86383   0.82020       235
cluster_00431    0.91266   0.86722   0.88936       241
cluster_00436    0.96532   0.93820   0.95157       178
cluster_00439    0.95172   0.89902   0.92462       307
cluster_00444    0.99492   0.95610   0.97512       205
cluster_00447    0.87654   0.87654   0.87654       162
cluster_00448    0.88235   0.89189   0.88710       185
cluster_00450    0.75987   0.95455   0.84615       242
cluster_00456    0.81884   0.95763   0.88281       118
cluster_00458    0.88693   0.87153   0.87916       288
cluster_00460    0.91061   0.86702   0.88828       188
cluster_00463    0.86076   0.85535   0.85804       159
cluster_00467    0.93548   0.88415   0.90909       164
cluster_00483    0.95604   0.80556   0.87437       108
cluster_00484    0.95489   0.84106   0.89437       151
cluster_00007    0.97015   0.80247   0.87838       162
cluster_00036    0.90038   0.89354   0.89695       263
cluster_00054    0.91971   0.89362   0.90647       141
cluster_00062    0.85124   0.85477   0.85300       241
cluster_00064    0.92917   0.88492   0.90650       252
cluster_00065    0.95706   0.93413   0.94545       167
cluster_00067    0.88333   0.86885   0.87603       122
cluster_00071    0.95714   0.85350   0.90236       157
cluster_00075    0.89418   0.79717   0.84289       212
cluster_00084    0.92279   0.89007   0.90614       282
cluster_00093    0.96891   0.88626   0.92574       211
cluster_00001    0.86897   0.97297   0.91803       259
cluster_00002    0.85455   0.81503   0.83432       173
cluster_00003    0.93676   0.80612   0.86654       294
cluster_00006    0.97701   0.93407   0.95506       182
cluster_00008    0.84807   0.97771   0.90828       314
cluster_00010    0.95977   0.85641   0.90515       195
cluster_00012    0.80952   0.96835   0.88184       158
cluster_00019    0.98291   0.85185   0.91270       135
cluster_00022    0.86161   0.92344   0.89145       209
cluster_00026    0.97887   0.72021   0.82985       193
cluster_00029    0.89362   0.85714   0.87500       245
cluster_00031    0.83388   0.89510   0.86341       286
cluster_00043    0.93226   0.98299   0.95695       294
cluster_00051    0.91216   0.75419   0.82569       179
cluster_00052    0.87293   0.94895   0.90935       333
cluster_00073    0.92825   0.85185   0.88841       243
cluster_00076    0.84739   0.91739   0.88100       230
cluster_00082    0.89404   0.90000   0.89701       300
cluster_00107    0.91703   0.96330   0.93960       218
cluster_00432    0.96109   0.93208   0.94636       265
cluster_00440    0.97881   0.87833   0.92585       263
cluster_00455    0.87845   0.95783   0.91643       166
cluster_00714    0.90171   0.97235   0.93570       217
cluster_00791    0.94872   0.90244   0.92500       164
cluster_00119    0.92095   0.95492   0.93763       244
cluster_00121    0.96429   0.98438   0.97423       192
cluster_00155    0.94800   0.94800   0.94800       250
cluster_00556    0.96460   0.95614   0.96035       228
cluster_00557    0.96691   0.94604   0.95636       278
cluster_00689    0.97403   0.98253   0.97826       229
cluster_00692    0.94954   1.00000   0.97412       207
cluster_00718    0.94643   0.96804   0.95711       219
cluster_00725    0.92308   0.91803   0.92055       183
cluster_00727    0.92638   0.97419   0.94969       155
cluster_00729    0.97578   0.94314   0.95918       299
cluster_00733    1.00000   0.98077   0.99029       156
cluster_00738    0.98113   0.98113   0.98113       159
cluster_00740    0.95973   0.94079   0.95017       152
cluster_00744    1.00000   0.93004   0.96375       243
cluster_00753    0.92544   0.96789   0.94619       218
cluster_00777    0.94470   0.96244   0.95349       213
cluster_00795    0.93750   0.93750   0.93750       192

     accuracy                        0.90758     40000
    macro avg    0.90969   0.90635   0.90642     40000
 weighted avg    0.91056   0.90758   0.90754     40000

2023-07-14 05:10:39,518 =======================================================
2023-07-14 05:10:39,518 

2023-07-14 05:10:39,710 =======================================================
2023-07-14 05:10:39,710 Best f1 classification report:
               precision    recall  f1-score   support

cluster_00205    0.95436   0.93496   0.94456       246
cluster_00222    0.89241   0.92763   0.90968       152
cluster_00232    0.91270   0.91633   0.91451       251
cluster_00246    0.82301   0.93467   0.87529       199
cluster_00259    0.92929   0.90640   0.91771       203
cluster_00261    0.97183   0.98571   0.97872       140
cluster_00262    0.89333   0.85897   0.87582       234
cluster_00267    0.89544   0.98817   0.93952       338
cluster_00275    0.93506   0.93506   0.93506       308
cluster_00276    0.94667   0.85542   0.89873       166
cluster_00278    0.87701   0.87234   0.87467       188
cluster_00287    0.91358   0.89697   0.90520       165
cluster_00291    0.96078   0.90184   0.93038       163
cluster_00293    0.96429   0.85866   0.90841       283
cluster_00294    0.94444   0.97143   0.95775       105
cluster_00296    0.86188   0.95122   0.90435       164
cluster_00298    0.89941   0.93538   0.91704       325
cluster_00299    0.91367   0.95489   0.93382       133
cluster_00300    0.91188   0.92248   0.91715       258
cluster_00303    0.93011   0.92021   0.92513       188
cluster_00304    0.94152   0.90960   0.92529       177
cluster_00319    0.90868   0.95673   0.93208       208
cluster_00322    0.93197   0.94158   0.93675       291
cluster_00333    0.86000   0.91489   0.88660       141
cluster_00338    0.94375   0.83889   0.88824       180
cluster_00340    0.95349   0.91620   0.93447       179
cluster_00344    0.89552   0.80537   0.84806       149
cluster_00346    0.90800   0.90800   0.90800       250
cluster_00350    0.89078   0.93885   0.91419       278
cluster_00352    0.94915   0.80576   0.87160       139
cluster_00359    0.88889   0.83721   0.86228       172
cluster_00360    0.93085   0.86634   0.89744       202
cluster_00361    0.90909   0.84746   0.87719       177
cluster_00365    0.85714   0.98077   0.91480       208
cluster_00368    0.94175   0.89401   0.91726       217
cluster_00373    0.83556   0.95431   0.89100       197
cluster_00374    0.94175   0.85463   0.89607       227
cluster_00375    0.93307   0.86182   0.89603       275
cluster_00377    0.87597   0.95359   0.91313       237
cluster_00380    0.90608   0.95349   0.92918       172
cluster_00385    0.90625   0.94694   0.92615       245
cluster_00388    0.94834   0.87713   0.91135       293
cluster_00389    0.85714   0.90909   0.88235       198
cluster_00390    0.96244   0.93182   0.94688       220
cluster_00394    0.85393   0.96203   0.90476       158
cluster_00400    0.87302   0.91667   0.89431       120
cluster_00401    0.93182   0.88649   0.90859       185
cluster_00405    0.92763   0.92157   0.92459       153
cluster_00407    0.95918   0.92885   0.94378       253
cluster_00408    0.92268   0.80995   0.86265       221
cluster_00409    0.90625   0.80930   0.85504       215
cluster_00412    0.84556   0.97333   0.90496       225
cluster_00445    0.85496   0.86822   0.86154       129
cluster_00473    0.94643   0.88333   0.91379       120
cluster_00585    0.84585   0.95964   0.89916       223
cluster_00589    0.88148   0.82639   0.85305       144
cluster_00591    0.89163   0.95263   0.92112       190
cluster_00593    0.82468   0.89437   0.85811       142
cluster_00596    0.82550   0.84247   0.83390       146
cluster_00603    0.90230   0.87222   0.88701       180
cluster_00604    0.93893   0.98400   0.96094       125
cluster_00607    0.86275   0.89796   0.88000       196
cluster_00612    0.96875   0.94898   0.95876       196
cluster_00616    0.85903   0.91549   0.88636       213
cluster_00619    0.89024   0.89571   0.89297       163
cluster_00629    0.92760   0.94037   0.93394       218
cluster_00630    0.91102   0.94714   0.92873       227
cluster_00635    0.85185   0.91477   0.88219       176
cluster_00637    0.93452   0.84865   0.88952       185
cluster_00639    0.93727   0.92364   0.93040       275
cluster_00642    0.97727   0.88660   0.92973       194
cluster_00645    0.83908   0.85882   0.84884       170
cluster_00647    0.80788   0.85864   0.83249       191
cluster_00652    0.87243   0.90987   0.89076       233
cluster_00653    0.92486   0.96386   0.94395       166
cluster_00656    0.93976   0.94545   0.94260       165
cluster_00657    0.87983   0.90708   0.89325       226
cluster_00661    0.98204   0.87701   0.92655       187
cluster_00662    0.93802   0.91532   0.92653       248
cluster_00667    0.93839   0.94286   0.94062       210
cluster_00762    0.93548   0.94565   0.94054       184
cluster_00201    0.99099   1.00000   0.99548       220
cluster_00217    0.95205   0.82249   0.88254       169
cluster_00239    0.89252   0.97949   0.93399       195
cluster_00320    0.94220   0.94767   0.94493       172
cluster_00391    0.94937   0.85878   0.90180       262
cluster_00398    0.95669   0.89338   0.92395       272
cluster_00415    0.91379   0.89831   0.90598       177
cluster_00477    0.93902   0.88000   0.90855       175
cluster_00478    0.86634   0.94595   0.90439       185
cluster_00479    0.96226   0.87931   0.91892       174
cluster_00078    0.75152   0.97638   0.84932       254
cluster_00079    0.91515   0.85795   0.88563       176
cluster_00083    0.88000   0.80936   0.84321       299
cluster_00090    0.90833   0.97321   0.93966       112
cluster_00094    0.81944   0.89394   0.85507       132
cluster_00096    0.92000   0.82143   0.86792       112
cluster_00101    0.92248   0.90840   0.91538       131
cluster_00086    0.94040   0.97931   0.95946       290
cluster_00095    0.85714   0.93659   0.89510       205
cluster_00097    0.97115   0.84874   0.90583       119
cluster_00106    0.95364   0.95364   0.95364       302
cluster_00553    0.92718   0.93627   0.93171       204
cluster_00554    0.89273   0.91489   0.90368       282
cluster_00569    0.92432   0.83010   0.87468       206
cluster_00015    0.87368   0.92222   0.89730        90
cluster_00017    0.83562   0.90706   0.86988       269
cluster_00018    0.72340   0.97143   0.82927       140
cluster_00023    0.84000   0.84000   0.84000       250
cluster_00025    0.81871   0.93333   0.87227       150
cluster_00030    0.78774   0.93820   0.85641       178
cluster_00035    0.85333   0.89510   0.87372       143
cluster_00039    0.90556   0.83590   0.86933       195
cluster_00042    0.88202   0.87222   0.87709       180
cluster_00046    0.93434   0.81140   0.86854       228
cluster_00055    0.84000   0.92818   0.88189       181
cluster_00059    0.91705   0.87665   0.89640       227
cluster_00061    0.94764   0.89163   0.91878       203
cluster_00274    0.88325   0.93548   0.90862       186
cluster_00308    0.87283   0.81183   0.84123       186
cluster_00337    0.88068   0.98101   0.92814       158
cluster_00362    0.89231   0.92063   0.90625       189
cluster_00369    0.89147   0.97458   0.93117       118
cluster_00392    0.97044   0.90367   0.93587       218
cluster_00414    0.93496   0.92742   0.93117       124
cluster_00419    0.92462   0.86792   0.89538       212
cluster_00420    0.96914   0.89205   0.92899       176
cluster_00421    0.86957   0.97087   0.91743       103
cluster_00422    0.93590   0.85214   0.89206       257
cluster_00427    0.87786   0.77703   0.82437       148
cluster_00430    0.78077   0.86383   0.82020       235
cluster_00431    0.91266   0.86722   0.88936       241
cluster_00436    0.96532   0.93820   0.95157       178
cluster_00439    0.95172   0.89902   0.92462       307
cluster_00444    0.99492   0.95610   0.97512       205
cluster_00447    0.87654   0.87654   0.87654       162
cluster_00448    0.88235   0.89189   0.88710       185
cluster_00450    0.75987   0.95455   0.84615       242
cluster_00456    0.81884   0.95763   0.88281       118
cluster_00458    0.88693   0.87153   0.87916       288
cluster_00460    0.91061   0.86702   0.88828       188
cluster_00463    0.86076   0.85535   0.85804       159
cluster_00467    0.93548   0.88415   0.90909       164
cluster_00483    0.95604   0.80556   0.87437       108
cluster_00484    0.95489   0.84106   0.89437       151
cluster_00007    0.97015   0.80247   0.87838       162
cluster_00036    0.90038   0.89354   0.89695       263
cluster_00054    0.91971   0.89362   0.90647       141
cluster_00062    0.85124   0.85477   0.85300       241
cluster_00064    0.92917   0.88492   0.90650       252
cluster_00065    0.95706   0.93413   0.94545       167
cluster_00067    0.88333   0.86885   0.87603       122
cluster_00071    0.95714   0.85350   0.90236       157
cluster_00075    0.89418   0.79717   0.84289       212
cluster_00084    0.92279   0.89007   0.90614       282
cluster_00093    0.96891   0.88626   0.92574       211
cluster_00001    0.86897   0.97297   0.91803       259
cluster_00002    0.85455   0.81503   0.83432       173
cluster_00003    0.93676   0.80612   0.86654       294
cluster_00006    0.97701   0.93407   0.95506       182
cluster_00008    0.84807   0.97771   0.90828       314
cluster_00010    0.95977   0.85641   0.90515       195
cluster_00012    0.80952   0.96835   0.88184       158
cluster_00019    0.98291   0.85185   0.91270       135
cluster_00022    0.86161   0.92344   0.89145       209
cluster_00026    0.97887   0.72021   0.82985       193
cluster_00029    0.89362   0.85714   0.87500       245
cluster_00031    0.83388   0.89510   0.86341       286
cluster_00043    0.93226   0.98299   0.95695       294
cluster_00051    0.91216   0.75419   0.82569       179
cluster_00052    0.87293   0.94895   0.90935       333
cluster_00073    0.92825   0.85185   0.88841       243
cluster_00076    0.84739   0.91739   0.88100       230
cluster_00082    0.89404   0.90000   0.89701       300
cluster_00107    0.91703   0.96330   0.93960       218
cluster_00432    0.96109   0.93208   0.94636       265
cluster_00440    0.97881   0.87833   0.92585       263
cluster_00455    0.87845   0.95783   0.91643       166
cluster_00714    0.90171   0.97235   0.93570       217
cluster_00791    0.94872   0.90244   0.92500       164
cluster_00119    0.92095   0.95492   0.93763       244
cluster_00121    0.96429   0.98438   0.97423       192
cluster_00155    0.94800   0.94800   0.94800       250
cluster_00556    0.96460   0.95614   0.96035       228
cluster_00557    0.96691   0.94604   0.95636       278
cluster_00689    0.97403   0.98253   0.97826       229
cluster_00692    0.94954   1.00000   0.97412       207
cluster_00718    0.94643   0.96804   0.95711       219
cluster_00725    0.92308   0.91803   0.92055       183
cluster_00727    0.92638   0.97419   0.94969       155
cluster_00729    0.97578   0.94314   0.95918       299
cluster_00733    1.00000   0.98077   0.99029       156
cluster_00738    0.98113   0.98113   0.98113       159
cluster_00740    0.95973   0.94079   0.95017       152
cluster_00744    1.00000   0.93004   0.96375       243
cluster_00753    0.92544   0.96789   0.94619       218
cluster_00777    0.94470   0.96244   0.95349       213
cluster_00795    0.93750   0.93750   0.93750       192

     accuracy                        0.90758     40000
    macro avg    0.90969   0.90635   0.90642     40000
 weighted avg    0.91056   0.90758   0.90754     40000

2023-07-14 05:10:39,711 =======================================================
2023-07-14 05:10:39,711 

2023-07-14 05:10:40,425 =======================================================
2023-07-14 05:10:40,425 Best acc classification report:
               precision    recall  f1-score   support

cluster_00205    0.98333   0.98772   0.98552       896
cluster_00222    0.98663   0.98957   0.98810       671
cluster_00232    0.97576   0.97474   0.97525       950
cluster_00246    0.98003   0.96897   0.97447       709
cluster_00259    0.97354   0.96680   0.97016       723
cluster_00261    0.99475   0.98955   0.99214       574
cluster_00262    0.97790   0.97574   0.97682       907
cluster_00267    0.99055   0.98554   0.98804      1383
cluster_00275    0.97311   0.97227   0.97269      1154
cluster_00276    0.98541   0.98541   0.98541       617
cluster_00278    0.97093   0.97518   0.97305       685
cluster_00287    0.98366   0.97640   0.98001       678
cluster_00291    0.97881   0.98298   0.98089       705
cluster_00293    0.98039   0.97674   0.97856      1075
cluster_00294    0.98165   0.98618   0.98391       434
cluster_00296    0.99311   0.99175   0.99243       727
cluster_00298    0.98131   0.98207   0.98169      1283
cluster_00299    0.97046   0.97046   0.97046       474
cluster_00300    0.97494   0.97611   0.97552       837
cluster_00303    0.98872   0.98179   0.98524       714
cluster_00304    0.99586   0.99448   0.99517       725
cluster_00319    0.97783   0.97555   0.97669       859
cluster_00322    0.97968   0.98973   0.98468      1169
cluster_00333    0.95220   0.96325   0.95769       517
cluster_00338    0.97381   0.97231   0.97306       650
cluster_00340    0.97698   0.98201   0.97949       778
cluster_00344    0.96593   0.96593   0.96593       587
cluster_00346    0.98808   0.98808   0.98808       923
cluster_00350    0.98213   0.98654   0.98433      1114
cluster_00352    0.97104   0.97603   0.97353       584
cluster_00359    0.97719   0.96738   0.97226       797
cluster_00360    0.98515   0.98637   0.98576       807
cluster_00361    0.96573   0.97027   0.96799       639
cluster_00365    0.99377   0.98640   0.99007       809
cluster_00368    0.97909   0.96955   0.97430       821
cluster_00373    0.97564   0.97432   0.97498       740
cluster_00374    0.98138   0.98462   0.98300       910
cluster_00375    0.97230   0.97230   0.97230      1011
cluster_00377    0.97120   0.96832   0.96976      1010
cluster_00380    0.99172   0.98900   0.99036       727
cluster_00385    0.98830   0.99217   0.99023      1022
cluster_00388    0.97787   0.97871   0.97829      1174
cluster_00389    0.97212   0.95636   0.96417       802
cluster_00390    0.99200   0.98861   0.99030       878
cluster_00394    0.97222   0.98438   0.97826       640
cluster_00400    0.98383   0.97706   0.98044       436
cluster_00401    0.96997   0.96997   0.96997       666
cluster_00405    0.96667   0.97256   0.96960       656
cluster_00407    0.98847   0.98563   0.98705      1044
cluster_00408    0.96959   0.96733   0.96846       857
cluster_00409    0.96885   0.97086   0.96985       961
cluster_00412    0.98227   0.98536   0.98381       956
cluster_00445    0.97126   0.96756   0.96941       524
cluster_00473    0.98520   0.97286   0.97899       479
cluster_00585    0.97143   0.97027   0.97085       841
cluster_00589    0.99296   0.96907   0.98087       582
cluster_00591    0.98724   0.98348   0.98536       787
cluster_00593    0.96849   0.96211   0.96529       607
cluster_00596    0.98505   0.97955   0.98229       538
cluster_00603    0.98361   0.99448   0.98901       724
cluster_00604    0.99508   0.99345   0.99427       611
cluster_00607    0.98640   0.99254   0.98946       804
cluster_00612    0.99514   0.98913   0.99213       828
cluster_00616    0.97248   0.97546   0.97397       978
cluster_00619    0.96788   0.96653   0.96720       717
cluster_00629    0.98516   0.98855   0.98685       873
cluster_00630    0.98889   0.99134   0.99011       808
cluster_00635    0.98363   0.98116   0.98239       796
cluster_00637    0.96931   0.96315   0.96622       787
cluster_00639    0.97910   0.98840   0.98373       948
cluster_00642    0.98811   0.99564   0.99186       918
cluster_00645    0.97316   0.97179   0.97248       709
cluster_00647    0.96847   0.97586   0.97215       787
cluster_00652    0.97605   0.97273   0.97439       880
cluster_00653    0.99346   0.98701   0.99023       616
cluster_00656    0.98338   0.98886   0.98611       718
cluster_00657    0.96417   0.97652   0.97031       937
cluster_00661    0.98596   0.98873   0.98734       710
cluster_00662    0.98703   0.98999   0.98851       999
cluster_00667    0.98558   0.98914   0.98736       829
cluster_00762    0.98667   0.98535   0.98601       751
cluster_00201    1.00000   1.00000   1.00000       827
cluster_00217    0.98630   0.99310   0.98969       725
cluster_00239    0.99346   0.99563   0.99455       916
cluster_00320    0.98319   0.98182   0.98251       715
cluster_00391    0.98742   0.99098   0.98920      1109
cluster_00398    0.98664   0.98462   0.98563       975
cluster_00415    0.98090   0.98224   0.98157       732
cluster_00477    0.97775   0.98047   0.97911       717
cluster_00478    0.98289   0.99203   0.98744       753
cluster_00479    0.99048   0.98268   0.98656       635
cluster_00078    0.97176   0.97271   0.97224      1026
cluster_00079    0.95777   0.96566   0.96170       728
cluster_00083    0.96726   0.96640   0.96683      1131
cluster_00090    0.97273   0.96833   0.97052       442
cluster_00094    0.97012   0.96627   0.96819       504
cluster_00096    0.98554   0.98351   0.98452       485
cluster_00101    0.98689   0.98689   0.98689       534
cluster_00086    0.99475   0.99649   0.99562      1141
cluster_00095    0.98670   0.98909   0.98789       825
cluster_00097    0.98776   0.99384   0.99079       487
cluster_00106    0.99333   0.99416   0.99374      1198
cluster_00553    0.99165   0.99283   0.99224       837
cluster_00554    0.99327   0.99915   0.99620      1181
cluster_00569    0.98789   0.98195   0.98491       831
cluster_00015    0.99742   0.98473   0.99104       393
cluster_00017    0.97866   0.98231   0.98048      1074
cluster_00018    0.97165   0.97627   0.97395       632
cluster_00023    0.97256   0.96619   0.96937       917
cluster_00025    0.97557   0.98006   0.97781       652
cluster_00030    0.96071   0.96931   0.96499       782
cluster_00035    0.97762   0.98100   0.97931       579
cluster_00039    0.97487   0.97745   0.97616       754
cluster_00042    0.97594   0.98383   0.97987       742
cluster_00046    0.98691   0.98477   0.98584       919
cluster_00055    0.98163   0.98811   0.98486       757
cluster_00059    0.98051   0.98051   0.98051       821
cluster_00061    0.98708   0.98327   0.98517       777
cluster_00274    0.99221   0.98964   0.99092       772
cluster_00308    0.98061   0.97925   0.97993       723
cluster_00337    0.98677   0.98677   0.98677       756
cluster_00362    0.98575   0.98575   0.98575       772
cluster_00369    0.99417   0.98842   0.99129       518
cluster_00392    0.98331   0.99398   0.98862       830
cluster_00414    0.99391   0.99593   0.99492       492
cluster_00419    0.98989   0.98216   0.98601       897
cluster_00420    0.99204   0.98942   0.99073       756
cluster_00421    0.99180   0.99384   0.99282       487
cluster_00422    0.97841   0.97173   0.97506      1026
cluster_00427    0.97764   0.97143   0.97452       630
cluster_00430    0.96885   0.97318   0.97101       895
cluster_00431    0.97176   0.97747   0.97461      1021
cluster_00436    0.99620   0.99747   0.99683       789
cluster_00439    0.98264   0.99249   0.98754      1198
cluster_00444    0.99874   0.99748   0.99811       793
cluster_00447    0.98063   0.97891   0.97977       569
cluster_00448    0.99027   0.98428   0.98727       827
cluster_00450    0.98439   0.97582   0.98009      1034
cluster_00456    0.98949   0.99647   0.99297       567
cluster_00458    0.97679   0.97591   0.97635      1121
cluster_00460    0.98286   0.98649   0.98467       814
cluster_00463    0.98637   0.98805   0.98721       586
cluster_00467    0.99332   0.98837   0.99084       602
cluster_00483    0.98269   0.98269   0.98269       520
cluster_00484    0.98730   0.98373   0.98551       553
cluster_00007    0.99544   0.98943   0.99242       662
cluster_00036    0.97222   0.96552   0.96886      1015
cluster_00054    0.99211   0.99211   0.99211       507
cluster_00062    0.96004   0.96399   0.96201       972
cluster_00064    0.97377   0.96825   0.97101       882
cluster_00065    0.98834   0.98834   0.98834       772
cluster_00067    0.95833   0.96921   0.96374       617
cluster_00071    0.96533   0.96709   0.96621       547
cluster_00075    0.96048   0.97114   0.96578       901
cluster_00084    0.98847   0.98187   0.98516      1048
cluster_00093    0.98055   0.97166   0.97608       882
cluster_00001    0.98822   0.97767   0.98292      1030
cluster_00002    0.98346   0.98198   0.98272       666
cluster_00003    0.97707   0.98140   0.97923      1129
cluster_00006    0.99875   0.99749   0.99812       798
cluster_00008    0.99284   0.98930   0.99106      1121
cluster_00010    0.98825   0.98593   0.98709       853
cluster_00012    0.96844   0.97826   0.97332       690
cluster_00019    0.99064   0.97782   0.98419       541
cluster_00022    0.97493   0.97881   0.97687       755
cluster_00026    0.98638   0.99042   0.98840       731
cluster_00029    0.98297   0.97194   0.97743       891
cluster_00031    0.97656   0.98098   0.97876      1104
cluster_00043    0.99542   0.99908   0.99725      1088
cluster_00051    0.99257   0.99503   0.99380       805
cluster_00052    0.98053   0.98408   0.98230      1382
cluster_00073    0.98392   0.98182   0.98287       935
cluster_00076    0.98534   0.98981   0.98757       883
cluster_00082    0.99277   0.98742   0.99009      1113
cluster_00107    0.99888   0.99219   0.99552       896
cluster_00432    0.99801   0.99603   0.99702      1008
cluster_00440    0.99284   0.99284   0.99284       977
cluster_00455    0.99000   0.99142   0.99071       699
cluster_00714    0.99776   0.99776   0.99776       891
cluster_00791    0.99441   0.99720   0.99580       714
cluster_00119    0.99769   0.99424   0.99596       868
cluster_00121    1.00000   1.00000   1.00000       729
cluster_00155    0.99631   1.00000   0.99815      1080
cluster_00556    0.99889   0.99669   0.99779       905
cluster_00557    1.00000   0.99912   0.99956      1134
cluster_00689    0.99894   0.99894   0.99894       942
cluster_00692    0.99896   0.99896   0.99896       961
cluster_00718    0.99766   0.99532   0.99649       855
cluster_00725    0.99713   0.99286   0.99499       700
cluster_00727    0.98469   0.99828   0.99144       580
cluster_00729    0.99372   0.99372   0.99372      1115
cluster_00733    1.00000   0.99659   0.99829       586
cluster_00738    0.99545   0.99697   0.99621       659
cluster_00740    0.99839   0.99361   0.99600       626
cluster_00744    0.99353   0.99353   0.99353       927
cluster_00753    0.99658   0.98981   0.99318       883
cluster_00777    0.99528   0.99882   0.99704       844
cluster_00795    0.99601   1.00000   0.99800       749

     accuracy                        0.98354    160000
    macro avg    0.98341   0.98327   0.98333    160000
 weighted avg    0.98356   0.98354   0.98354    160000

2023-07-14 05:10:40,425 =======================================================
2023-07-14 05:10:40,425 

2023-07-14 05:10:41,782 =======================================================
2023-07-14 05:10:41,782 Best f1 classification report:
               precision    recall  f1-score   support

cluster_00205    0.98770   0.98549   0.98659       896
cluster_00222    0.98815   0.99404   0.99108       671
cluster_00232    0.98403   0.97263   0.97830       950
cluster_00246    0.97440   0.96615   0.97025       709
cluster_00259    0.96982   0.97787   0.97383       723
cluster_00261    0.99303   0.99303   0.99303       574
cluster_00262    0.97805   0.98236   0.98020       907
cluster_00267    0.98701   0.98915   0.98808      1383
cluster_00275    0.97135   0.96967   0.97051      1154
cluster_00276    0.96651   0.98217   0.97428       617
cluster_00278    0.97661   0.97518   0.97589       685
cluster_00287    0.98385   0.98820   0.98602       678
cluster_00291    0.98722   0.98582   0.98652       705
cluster_00293    0.98605   0.98605   0.98605      1075
cluster_00294    0.98624   0.99078   0.98851       434
cluster_00296    0.99584   0.98900   0.99241       727
cluster_00298    0.97523   0.98207   0.97864      1283
cluster_00299    0.97028   0.96414   0.96720       474
cluster_00300    0.96905   0.97252   0.97078       837
cluster_00303    0.99011   0.98179   0.98594       714
cluster_00304    0.99309   0.99172   0.99241       725
cluster_00319    0.99060   0.98137   0.98596       859
cluster_00322    0.98377   0.98546   0.98462      1169
cluster_00333    0.96844   0.94971   0.95898       517
cluster_00338    0.96933   0.97231   0.97081       650
cluster_00340    0.98205   0.98458   0.98331       778
cluster_00344    0.96752   0.96422   0.96587       587
cluster_00346    0.97847   0.98483   0.98164       923
cluster_00350    0.98470   0.98205   0.98337      1114
cluster_00352    0.98609   0.97089   0.97843       584
cluster_00359    0.97096   0.96487   0.96790       797
cluster_00360    0.97646   0.97646   0.97646       807
cluster_00361    0.97448   0.95618   0.96524       639
cluster_00365    0.98761   0.98517   0.98639       809
cluster_00368    0.97937   0.98295   0.98116       821
cluster_00373    0.96529   0.97703   0.97112       740
cluster_00374    0.98346   0.98022   0.98184       910
cluster_00375    0.97059   0.97923   0.97489      1011
cluster_00377    0.96657   0.97327   0.96991      1010
cluster_00380    0.99175   0.99175   0.99175       727
cluster_00385    0.98544   0.99315   0.98928      1022
cluster_00388    0.97373   0.97871   0.97621      1174
cluster_00389    0.95268   0.95387   0.95327       802
cluster_00390    0.99201   0.98975   0.99088       878
cluster_00394    0.98440   0.98594   0.98517       640
cluster_00400    0.99080   0.98853   0.98967       436
cluster_00401    0.97598   0.97598   0.97598       666
cluster_00405    0.97424   0.98018   0.97720       656
cluster_00407    0.99042   0.99042   0.99042      1044
cluster_00408    0.97544   0.97316   0.97430       857
cluster_00409    0.97188   0.97086   0.97137       961
cluster_00412    0.97822   0.98640   0.98229       956
cluster_00445    0.96762   0.96947   0.96854       524
cluster_00473    0.98734   0.97704   0.98216       479
cluster_00585    0.97246   0.96552   0.96897       841
cluster_00589    0.99130   0.97938   0.98531       582
cluster_00591    0.98235   0.98983   0.98608       787
cluster_00593    0.97355   0.97035   0.97195       607
cluster_00596    0.97774   0.97955   0.97864       538
cluster_00603    0.98617   0.98481   0.98549       724
cluster_00604    0.99507   0.99018   0.99262       611
cluster_00607    0.98263   0.98507   0.98385       804
cluster_00612    0.99276   0.99396   0.99336       828
cluster_00616    0.97746   0.97546   0.97646       978
cluster_00619    0.95989   0.96792   0.96389       717
cluster_00629    0.98627   0.98740   0.98683       873
cluster_00630    0.98764   0.98886   0.98825       808
cluster_00635    0.98363   0.98116   0.98239       796
cluster_00637    0.96021   0.95044   0.95530       787
cluster_00639    0.98214   0.98629   0.98421       948
cluster_00642    0.98912   0.99020   0.98966       918
cluster_00645    0.97875   0.97461   0.97668       709
cluster_00647    0.97315   0.96696   0.97004       787
cluster_00652    0.98409   0.98409   0.98409       880
cluster_00653    0.99350   0.99188   0.99269       616
cluster_00656    0.98340   0.99025   0.98681       718
cluster_00657    0.95975   0.96692   0.96332       937
cluster_00661    0.98729   0.98451   0.98590       710
cluster_00662    0.98898   0.98799   0.98848       999
cluster_00667    0.98798   0.99156   0.98977       829
cluster_00762    0.99598   0.98935   0.99265       751
cluster_00201    1.00000   1.00000   1.00000       827
cluster_00217    0.98347   0.98483   0.98415       725
cluster_00239    0.98794   0.98362   0.98578       916
cluster_00320    0.99013   0.98182   0.98596       715
cluster_00391    0.98206   0.98738   0.98471      1109
cluster_00398    0.98667   0.98667   0.98667       975
cluster_00415    0.98098   0.98634   0.98365       732
cluster_00477    0.97790   0.98745   0.98265       717
cluster_00478    0.98408   0.98539   0.98474       753
cluster_00479    0.99681   0.98268   0.98969       635
cluster_00078    0.96715   0.97563   0.97137      1026
cluster_00079    0.95283   0.97115   0.96190       728
cluster_00083    0.95848   0.95933   0.95890      1131
cluster_00090    0.96145   0.95928   0.96036       442
cluster_00094    0.97516   0.93452   0.95441       504
cluster_00096    0.97751   0.98557   0.98152       485
cluster_00101    0.98138   0.98689   0.98413       534
cluster_00086    0.99476   0.99737   0.99606      1141
cluster_00095    0.99033   0.99273   0.99153       825
cluster_00097    0.98367   0.98973   0.98669       487
cluster_00106    0.99168   0.99499   0.99333      1198
cluster_00553    0.99048   0.99403   0.99225       837
cluster_00554    0.99661   0.99492   0.99576      1181
cluster_00569    0.99265   0.97473   0.98361       831
cluster_00015    0.99229   0.98219   0.98721       393
cluster_00017    0.98311   0.97579   0.97944      1074
cluster_00018    0.97484   0.98101   0.97792       632
cluster_00023    0.97582   0.96838   0.97209       917
cluster_00025    0.98462   0.98160   0.98310       652
cluster_00030    0.97092   0.98210   0.97648       782
cluster_00035    0.98438   0.97927   0.98182       579
cluster_00039    0.97878   0.97878   0.97878       754
cluster_00042    0.97981   0.98113   0.98047       742
cluster_00046    0.97953   0.98912   0.98430       919
cluster_00055    0.98016   0.97886   0.97951       757
cluster_00059    0.98409   0.97929   0.98168       821
cluster_00061    0.98837   0.98456   0.98646       777
cluster_00274    0.99610   0.99352   0.99481       772
cluster_00308    0.98192   0.97649   0.97920       723
cluster_00337    0.99734   0.99339   0.99536       756
cluster_00362    0.98205   0.99223   0.98711       772
cluster_00369    0.99422   0.99614   0.99518       518
cluster_00392    0.98678   0.98916   0.98797       830
cluster_00414    0.99189   0.99390   0.99289       492
cluster_00419    0.98888   0.99108   0.98998       897
cluster_00420    0.98808   0.98677   0.98743       756
cluster_00421    0.99793   0.98768   0.99278       487
cluster_00422    0.97451   0.96881   0.97165      1026
cluster_00427    0.97050   0.99206   0.98116       630
cluster_00430    0.97222   0.97765   0.97493       895
cluster_00431    0.97463   0.97845   0.97654      1021
cluster_00436    0.99240   0.99240   0.99240       789
cluster_00439    0.98260   0.98998   0.98628      1198
cluster_00444    0.99748   0.99874   0.99811       793
cluster_00447    0.97208   0.97891   0.97548       569
cluster_00448    0.98554   0.98912   0.98733       827
cluster_00450    0.98146   0.97292   0.97717      1034
cluster_00456    0.99465   0.98413   0.98936       567
cluster_00458    0.98122   0.97859   0.97990      1121
cluster_00460    0.98762   0.98034   0.98397       814
cluster_00463    0.98462   0.98294   0.98377       586
cluster_00467    0.98671   0.98671   0.98671       602
cluster_00483    0.98651   0.98462   0.98556       520
cluster_00484    0.98564   0.99277   0.98919       553
cluster_00007    0.99239   0.98489   0.98863       662
cluster_00036    0.97436   0.97340   0.97388      1015
cluster_00054    0.99406   0.99014   0.99209       507
cluster_00062    0.95950   0.95062   0.95504       972
cluster_00064    0.97062   0.97392   0.97227       882
cluster_00065    0.98203   0.99093   0.98646       772
cluster_00067    0.96452   0.96921   0.96686       617
cluster_00071    0.96501   0.95795   0.96147       547
cluster_00075    0.95710   0.96559   0.96133       901
cluster_00084    0.98845   0.97996   0.98419      1048
cluster_00093    0.97704   0.96485   0.97091       882
cluster_00001    0.98641   0.98641   0.98641      1030
cluster_00002    0.98806   0.99399   0.99102       666
cluster_00003    0.97452   0.98229   0.97839      1129
cluster_00006    0.99875   0.99875   0.99875       798
cluster_00008    0.98931   0.99108   0.99020      1121
cluster_00010    0.97887   0.97773   0.97830       853
cluster_00012    0.97971   0.97971   0.97971       690
cluster_00019    0.98708   0.98891   0.98800       541
cluster_00022    0.97878   0.97748   0.97813       755
cluster_00026    0.98080   0.97811   0.97945       731
cluster_00029    0.97753   0.97643   0.97698       891
cluster_00031    0.98182   0.97826   0.98004      1104
cluster_00043    1.00000   0.99908   0.99954      1088
cluster_00051    0.99382   0.99876   0.99628       805
cluster_00052    0.98342   0.98698   0.98519      1382
cluster_00073    0.98825   0.98930   0.98878       935
cluster_00076    0.98643   0.98754   0.98698       883
cluster_00082    0.99187   0.98652   0.98919      1113
cluster_00107    0.99443   0.99665   0.99554       896
cluster_00432    0.99801   0.99504   0.99652      1008
cluster_00440    0.99590   0.99386   0.99488       977
cluster_00455    0.99571   0.99714   0.99643       699
cluster_00714    0.99553   1.00000   0.99776       891
cluster_00791    0.99299   0.99160   0.99229       714
cluster_00119    0.99308   0.99194   0.99251       868
cluster_00121    1.00000   0.99726   0.99863       729
cluster_00155    0.99722   0.99722   0.99722      1080
cluster_00556    0.99778   0.99448   0.99613       905
cluster_00557    0.99561   0.99912   0.99736      1134
cluster_00689    0.99894   0.99575   0.99734       942
cluster_00692    0.99792   0.99792   0.99792       961
cluster_00718    0.99533   0.99766   0.99650       855
cluster_00725    0.99714   0.99714   0.99714       700
cluster_00727    0.98973   0.99655   0.99313       580
cluster_00729    0.99820   0.99372   0.99596      1115
cluster_00733    1.00000   0.99829   0.99915       586
cluster_00738    0.99697   0.99848   0.99773       659
cluster_00740    0.99200   0.99042   0.99121       626
cluster_00744    0.99247   0.99569   0.99408       927
cluster_00753    0.99320   0.99320   0.99320       883
cluster_00777    0.99290   0.99408   0.99349       844
cluster_00795    0.99733   0.99733   0.99733       749

     accuracy                        0.98352    160000
    macro avg    0.98348   0.98322   0.98334    160000
 weighted avg    0.98354   0.98352   0.98352    160000

2023-07-14 05:10:41,782 =======================================================
2023-07-14 05:10:41,782 

2023-07-14 05:10:42,537 Total processing time is 4581.1s
